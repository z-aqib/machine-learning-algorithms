{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform necessary imports\n",
    "import pandas as pd\n",
    "from numpy import mean\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler, Normalizer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, SelectKBest, f_classif, VarianceThreshold, f_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, cross_val_score, GridSearchCV, ParameterGrid\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, make_scorer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get current date and time as a string\n",
    "def get_current_datetime():\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute this predictions metrics\n",
    "def metrics(y_pred, testY):\n",
    "    print(\"starting to compute metrics\")\n",
    "\n",
    "    # display the mean squared error of this prediction\n",
    "    mse = mean_squared_error(testY, y_pred)\n",
    "    print(\"Mean squared error: %.2f\" % mse, \"   \")\n",
    "\n",
    "    # display the root mean squared error\n",
    "    rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "    print(\"Root Mean squared error: %.2f\" % rmse, \"   \")\n",
    "\n",
    "    # display the mean absolute error of this prediction\n",
    "    mae = mean_absolute_error(testY, y_pred)\n",
    "    print(\"Mean absolute error: %.2f\" % mae, \"   \")\n",
    "\n",
    "    # display the coeffeicient of determination of this preduction\n",
    "    r2_Score = r2_score(testY, y_pred)\n",
    "    print(\"Coefficient of determination: %.2f\" % r2_Score, \"    \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward backward selection\n",
    "def fbselection(direction, sample_model, features, X, trainX, trainY, testX, test_data_processed, preprocessor):\n",
    "    print(\"starting\")\n",
    "    selection = SequentialFeatureSelector(sample_model, direction=direction, n_features_to_select=features, scoring='roc_auc')\n",
    "    return modelSelector(sample_model, selection, X, trainX, trainY, testX, test_data_processed, preprocessor)\n",
    "\n",
    "def modelSelector(sample_model, selection, X, trainX, trainY, testX, test_data_processed, preprocessor):\n",
    "    print(\"start extracting\")\n",
    "    trainX = selection.fit_transform(trainX, trainY)\n",
    "    print(\"extracted, transforming\")\n",
    "    testX = selection.transform(testX)                                  # Ensure the test set is transformed similarly\n",
    "    test_data_processed = selection.transform(test_data_processed)      # test data is also transformed\n",
    "    X = selection.transform(X)                                          # full data transforming\n",
    "    print(\"transformed\")\n",
    "\n",
    "    # Get selected feature names\n",
    "    feature_names = preprocessor.get_feature_names_out()  # Get all feature names from preprocessor\n",
    "    selected_features = [feature_names[i] for i in range(len(feature_names)) if selection.get_support()[i]]\n",
    "    print(\"Selected Features:\")\n",
    "    print(selected_features)\n",
    "\n",
    "    return sample_model, X, trainX, trainY, testX, test_data_processed\n",
    "\n",
    "# kbest selection\n",
    "def kbest(sample_model, features, X, trainX, trainY, testX, test_data_processed, preprocessor):\n",
    "    print(\"starting\")\n",
    "    selection = SelectKBest(score_func=f_regression, k=features)\n",
    "    # Fit the selector to training data\n",
    "    selection.fit(trainX, trainY)\n",
    "    # Get selected feature names\n",
    "    feature_names = preprocessor.get_feature_names_out()  # Get all feature names from preprocessor\n",
    "    selected_features = [feature_names[i] for i in range(len(feature_names)) if selection.get_support()[i]]\n",
    "    print(\"Selected Features:\")\n",
    "    print(selected_features)\n",
    "    return modelSelector(sample_model, selection, X, trainX, trainY, testX, test_data_processed, preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance function\n",
    "def featureImportance(sample_model, features, X, trainX, trainY, testX, test_data_processed):\n",
    "    print(\"fitting\")\n",
    "    \n",
    "    # fit the model\n",
    "    sample_model.fit(trainX, trainY)\n",
    "\n",
    "    print(\"extracting features\")\n",
    "\n",
    "    # extract all the feature names from data\n",
    "    importances = sample_model.feature_importances_\n",
    "    feature_names = test_data_processed.columns\n",
    "    print(feature_names)\n",
    "\n",
    "    # sort with respect to importance\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # extract the top ones\n",
    "    top_features = feature_importance_df['Feature'].head(features).values\n",
    "    print(top_features)\n",
    "\n",
    "    # change all data according to the top ones we have selected\n",
    "    trainX = pd.DataFrame(trainX, columns=feature_names)[top_features]\n",
    "    testX = pd.DataFrame(testX, columns=feature_names)[top_features]\n",
    "    X = pd.DataFrame(X, columns=feature_names)[top_features]\n",
    "    test_data_processed = pd.DataFrame(test_data_processed, columns=feature_names)[top_features]\n",
    "\n",
    "    print(\"features extracted\")\n",
    "    \n",
    "    # retrain the model\n",
    "    sample_model.fit(trainX, trainY)\n",
    "\n",
    "    print(\"features trained\")\n",
    "    \n",
    "    return sample_model, X, trainX, trainY, testX, test_data_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch(param_grid, model, trainX, trainY):\n",
    "    print(\"starting grid search\")\n",
    "\n",
    "    # intialize a scorer metric\n",
    "    scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "    # intialize grid search\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring=scorer, verbose=3)\n",
    "    print(\"grid search is intialized\")\n",
    "\n",
    "    # fit the model\n",
    "    grid_search.fit(trainX, trainY)\n",
    "    print(\"grid search fitting completed\")\n",
    "\n",
    "    # display the best model grid search found\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(best_model)\n",
    "\n",
    "    # display the best parameters of the best model\n",
    "    best_parameters = grid_search.best_params_\n",
    "    print(best_parameters)\n",
    "\n",
    "    # display the best score of the best model\n",
    "    print(\"Best cross-validated score:\", grid_search.best_score_)\n",
    "\n",
    "    # assign the best model our model\n",
    "    model = best_model\n",
    "    print(\"model assigned, grid search completed\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFile(model, X, Y, test_data):\n",
    "    print(\"fitting on X Y \", get_current_datetime())\n",
    "    model.fit(X, Y)\n",
    "\n",
    "    print(\"scoring on X Y \", get_current_datetime())\n",
    "    score = model.score(X, Y)\n",
    "    print(\"model test score: \", score, \"    \")\n",
    "\n",
    "    print(\"predicting on test \", get_current_datetime())\n",
    "    test_prediction = model.predict(test_data)\n",
    "    print(test_prediction)\n",
    "\n",
    "    print(\"getting sample submission \", get_current_datetime())\n",
    "    sample_data = pd.read_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger2\\iml-fall-2024-challenge-2\\sample_submission.csv\")\n",
    "    sample_data['price_doc'] = test_prediction\n",
    "\n",
    "    print(\"saving submission \", get_current_datetime())\n",
    "    sample_data.to_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger2\\iml-fall-2024-challenge-2\\knn1.csv\", index=False)\n",
    "    print(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Started Importing Data  2024-11-27 01:25:45\n",
      "train_data shape  (181507, 272)\n",
      "test_data shape  (77789, 272)\n",
      "-> Started splitting columns  2024-11-27 01:26:04\n",
      "Index(['product_type', 'sub_area', 'culture_objects_top_25',\n",
      "       'thermal_power_plant_raion', 'incineration_raion',\n",
      "       'oil_chemistry_raion', 'radiation_raion', 'railroad_terminal_raion',\n",
      "       'big_market_raion', 'nuclear_reactor_raion', 'detention_facility_raion',\n",
      "       'water_1line', 'big_road1_1line', 'railroad_1line', 'ecology'],\n",
      "      dtype='object')\n",
      "Index(['full_sq', 'life_sq', 'floor', 'area_m', 'raion_popul',\n",
      "       'green_zone_part', 'indust_part', 'children_preschool',\n",
      "       'preschool_education_centers_raion', 'children_school',\n",
      "       ...\n",
      "       'cafe_count_5000_price_1500', 'cafe_count_5000_price_2500',\n",
      "       'cafe_count_5000_price_4000', 'cafe_count_5000_price_high',\n",
      "       'big_church_count_5000', 'church_count_5000', 'mosque_count_5000',\n",
      "       'leisure_count_5000', 'sport_count_5000', 'market_count_5000'],\n",
      "      dtype='object', length=256)\n",
      "-> Defining scalers and imputers  2024-11-27 01:26:04\n",
      "-> Data Fitting  2024-11-27 01:26:04\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (256,) (1958,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[127], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m train_transformed \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mfit_transform(train_data)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Convert the transformed data back to a DataFrame\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m train_data_processed \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(train_transformed, columns\u001b[38;5;241m=\u001b[39m\u001b[43mnumerical_cols\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformers_\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamed_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43monehot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcategorical_cols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Apply preprocessing to test data (without fitting)\u001b[39;00m\n\u001b[0;32m     43\u001b[0m test_transformed \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mtransform(test_data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\arraylike.py:186\u001b[0m, in \u001b[0;36mOpsMixin.__add__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__add__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m    100\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m    Get Addition of DataFrame and other, column-wise.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    moose     3.0     NaN\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:7238\u001b[0m, in \u001b[0;36mIndex._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   7228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   7229\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(other, Index)\n\u001b[0;32m   7230\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_object_dtype(other\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   7234\u001b[0m     \u001b[38;5;66;03m# a chance to implement ops before we unwrap them.\u001b[39;00m\n\u001b[0;32m   7235\u001b[0m     \u001b[38;5;66;03m# See https://github.com/pandas-dev/pandas/issues/31109\u001b[39;00m\n\u001b[0;32m   7236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m-> 7238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\base.py:1382\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1379\u001b[0m     rvalues \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(rvalues\u001b[38;5;241m.\u001b[39mstart, rvalues\u001b[38;5;241m.\u001b[39mstop, rvalues\u001b[38;5;241m.\u001b[39mstep)\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1382\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\ops\\array_ops.py:283\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    279\u001b[0m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m--> 283\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\ops\\array_ops.py:218\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    215\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 218\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    221\u001b[0m         left\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[0;32m    222\u001b[0m     ):\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\computation\\expressions.py:242\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 242\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\computation\\expressions.py:73\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TEST_MODE:\n\u001b[0;32m     72\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (256,) (1958,) "
     ]
    }
   ],
   "source": [
    "# Importing data\n",
    "print(\"-> Started Importing Data \", get_current_datetime())\n",
    "train_data = pd.read_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger2\\iml-fall-2024-challenge-2\\train\\train.csv\")\n",
    "test_data = pd.read_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger2\\iml-fall-2024-challenge-2\\test\\test.csv\")\n",
    "\n",
    "print(\"train_data shape \", train_data.shape)\n",
    "print(\"test_data shape \", test_data.shape)\n",
    "\n",
    "# Split data into categorical and numerical\n",
    "print(\"-> Started splitting columns \", get_current_datetime())\n",
    "categorical_cols = train_data.select_dtypes(include=[\"object\"]).columns\n",
    "numerical_cols = train_data.select_dtypes(exclude=[\"object\"]).drop(columns=['price_doc']).columns\n",
    "\n",
    "print(categorical_cols)\n",
    "print(numerical_cols)\n",
    "\n",
    "# Data preprocessing: scalers and imputers on columns\n",
    "print(\"-> Defining scalers and imputers \", get_current_datetime())\n",
    "num_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", MinMaxScaler())\n",
    "])\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "# Column transformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_transformer, numerical_cols),\n",
    "        (\"cat\", cat_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Data fitting: fit the preprocessing on the data\n",
    "print(\"-> Data Fitting \", get_current_datetime())\n",
    "train_transformed = preprocessor.fit_transform(train_data)\n",
    "\n",
    "# Convert the transformed data back to a DataFrame\n",
    "train_data_processed = pd.DataFrame(train_transformed, columns=numerical_cols + list(preprocessor.transformers_[1][1].named_steps['onehot'].get_feature_names_out(categorical_cols)))\n",
    "\n",
    "# Apply preprocessing to test data (without fitting)\n",
    "test_transformed = preprocessor.transform(test_data)\n",
    "\n",
    "# Convert the transformed test data back to a DataFrame\n",
    "test_data_processed = pd.DataFrame(test_transformed, columns=numerical_cols + list(preprocessor.transformers_[1][1].named_steps['onehot'].get_feature_names_out(categorical_cols)))\n",
    "\n",
    "# Now you have the processed DataFrames for both train and test data\n",
    "train_data=train_data_processed\n",
    "test_data=test_data_processed\n",
    "\n",
    "# Data splitting: features and targets\n",
    "print(\"-> Data splitting X Y \", get_current_datetime())\n",
    "X = train_data.drop(columns=['price_doc'])\n",
    "Y = train_data['price_doc']\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "# Data splitting: train, validate, test\n",
    "print(\"-> Data splitting tvt \", get_current_datetime())\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.3, random_state=2)\n",
    "\n",
    "# Model declaration\n",
    "print(\"-> model declaration \", get_current_datetime())\n",
    "model = KNeighborsRegressor(n_neighbors=5)\n",
    "print(model)\n",
    "\n",
    "# Feature Selection\n",
    "print(\"-> feature selection \", get_current_datetime())\n",
    "model, X, trainX, trainY, testX, test_data= kbest(model, 20, X, trainX, trainY, testX, test_data, preprocessor)\n",
    "\n",
    "# Grid Search\n",
    "print(\"-> Grid Search \", get_current_datetime())\n",
    "# param_grid = {\n",
    "#     'model__tol': [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "# }\n",
    "# model = gridsearch(param_grid, model, trainX, trainY)\n",
    "\n",
    "# Model train: full dataset\n",
    "print(\"-> Model train \", get_current_datetime())\n",
    "# model.fit(trainX, trainY)\n",
    "\n",
    "# Model train: sample dataset\n",
    "sample_train = train_data.sample(frac=0.1)\n",
    "sample_X = sample_train.drop(columns=['price_doc'])\n",
    "sample_Y = sample_train['price_doc']\n",
    "\n",
    "print(\"sample taken\")\n",
    "\n",
    "model.fit(sample_X, sample_Y)\n",
    "print(\"model trained\")\n",
    "\n",
    "# Model Score: compute score of model\n",
    "print(\"-> Model Score \", get_current_datetime())\n",
    "# score = model.score(trainX, trainY)\n",
    "score = model.score(sample_X, sample_Y)\n",
    "print(\"model score: \", score)\n",
    "\n",
    "# Prediction: predict and display its metrics\n",
    "print(\"-> Prediction \", get_current_datetime)\n",
    "y_pred = model.predict(testX)\n",
    "print(\"successfully predicted\")\n",
    "metrics(y_pred, testY)\n",
    "    \n",
    "print(\"-> File Creation \", get_current_datetime())\n",
    "createFile(model, X, Y, test_data)\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
