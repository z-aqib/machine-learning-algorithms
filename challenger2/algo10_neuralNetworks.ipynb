{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9837068,"sourceType":"datasetVersion","datasetId":6034234},{"sourceId":9837128,"sourceType":"datasetVersion","datasetId":6034286},{"sourceId":10013045,"sourceType":"datasetVersion","datasetId":6164648}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":5193.546342,"end_time":"2024-11-07T21:46:17.332142","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-11-07T20:19:43.785800","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"8a654c39-212d-4c33-86f9-2884b1bc22c6","cell_type":"markdown","source":"# Importing Libraries\n\nin this part we will install all the necessary libraries on command prompt and then import the necessary functions from those libraries. ","metadata":{"papermill":{"duration":0.013014,"end_time":"2024-11-07T20:19:46.538794","exception":false,"start_time":"2024-11-07T20:19:46.525780","status":"completed"},"tags":[]}},{"id":"bd54b756","cell_type":"code","source":"# importing all the necessary libraries\n\nimport pandas as pd\n\n\n\nfrom numpy import mean\n\nimport numpy as np\n\nimport time\n\n\n\n# step 1: preprocessing\n\nfrom sklearn.impute import SimpleImputer # import some strategic imputer to fill in any missing values using mean\n\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler, Normalizer # scale all the values to one range to avoid any biasness (this bias is seen in mostly naive bayes and knn etc)\n\n\n\nfrom sklearn.impute import KNNImputer # import some strategic imputer to fill missing values using KNN (finds the nearest neighbour and fills it with that value)\n\n\n\nfrom sklearn.feature_selection import SequentialFeatureSelector, SelectKBest, f_classif, VarianceThreshold\n\n\n\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.compose import ColumnTransformer\n\nfrom sklearn.preprocessing import PolynomialFeatures, OneHotEncoder\n\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.linear_model import Ridge, Lasso\n\n\n\n# step 2: data division\n\nfrom sklearn.model_selection import train_test_split, RepeatedKFold, cross_val_score, GridSearchCV, ParameterGrid # to divide the code into train/test using a specific percentage or with/without replacement\n\n\n\n# step 3: model\n\nfrom tensorflow.keras.models import Sequential\n\nfrom tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n\nfrom tensorflow.keras.optimizers import Adam\n\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.regularizers import l2\n\n\n\n# step 4: displaying accuracy\n\nfrom sklearn.metrics import roc_auc_score, accuracy_score # to display the accuracy of our tree\n\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, make_scorer\n\n\n\n# step 5: warning filter\n\nimport warnings\n\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-11-29T16:25:38.478232Z","iopub.execute_input":"2024-11-29T16:25:38.478690Z","iopub.status.idle":"2024-11-29T16:25:56.839237Z","shell.execute_reply.started":"2024-11-29T16:25:38.478652Z","shell.execute_reply":"2024-11-29T16:25:56.838113Z"},"papermill":{"duration":5.853121,"end_time":"2024-11-07T20:19:52.405091","exception":false,"start_time":"2024-11-07T20:19:46.551970","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":1},{"id":"3912ca3f","cell_type":"markdown","source":"# Data Loading\n\ndata shall be loaded into variables as data sets using pandas and csv readers. they will be checked to see if they are loaded properly and will be loaded as 2 sets: train and test as per given in the kaggle data","metadata":{"papermill":{"duration":0.011237,"end_time":"2024-11-07T20:19:52.458899","exception":false,"start_time":"2024-11-07T20:19:52.447662","status":"completed"},"tags":[]}},{"id":"d9125e82","cell_type":"code","source":"# lets load the training data set\n\n# train_data = pd.read_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger2\\iml-fall-2024-challenge-2\\train\\train.csv\")\ntrain_data = pd.read_csv(r\"/kaggle/input/challenge2/train.csv\")\n\n\n# lets also check it by getting the first few rows of the data, there should be x1 - x78 and one target variable Y\n\ntrain_data.head() ","metadata":{"execution":{"iopub.status.busy":"2024-11-29T16:25:56.842215Z","iopub.execute_input":"2024-11-29T16:25:56.843181Z","iopub.status.idle":"2024-11-29T16:26:12.738048Z","shell.execute_reply.started":"2024-11-29T16:25:56.843126Z","shell.execute_reply":"2024-11-29T16:26:12.736281Z"},"papermill":{"duration":4.591761,"end_time":"2024-11-07T20:19:57.062353","exception":false,"start_time":"2024-11-07T20:19:52.470592","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   full_sq  life_sq  floor product_type           sub_area       area_m  \\\n0     43.0     27.0    4.0   Investment           Bibirevo  6407578.100   \n1     34.0     19.0    3.0   Investment  Nagatinskij Zaton  9589336.912   \n2     43.0     29.0    2.0   Investment     Tekstil'shhiki  4808269.831   \n3     77.0     77.0    4.0   Investment          Basmannoe  8398460.622   \n4     67.0     46.0   14.0   Investment     Nizhegorodskoe  7506452.020   \n\n   raion_popul  green_zone_part  indust_part  children_preschool  ...  \\\n0     155572.0         0.189727     0.000070              9576.0  ...   \n1     115352.0         0.372602     0.049637              6880.0  ...   \n2     101708.0         0.112560     0.118537              5879.0  ...   \n3     108171.0         0.015234     0.037316              5706.0  ...   \n4      43795.0         0.007670     0.486246              2418.0  ...   \n\n   cafe_count_5000_price_2500  cafe_count_5000_price_4000  \\\n0                         9.0                         4.0   \n1                        15.0                         3.0   \n2                        10.0                         3.0   \n3                       319.0                       108.0   \n4                        62.0                        14.0   \n\n   cafe_count_5000_price_high  big_church_count_5000  church_count_5000  \\\n0                         0.0                   13.0               22.0   \n1                         0.0                   15.0               29.0   \n2                         0.0                   11.0               27.0   \n3                        17.0                  135.0              236.0   \n4                         1.0                   53.0               78.0   \n\n   mosque_count_5000  leisure_count_5000  sport_count_5000 market_count_5000  \\\n0                1.0                 0.0              52.0               4.0   \n1                1.0                10.0              66.0              14.0   \n2                0.0                 4.0              67.0              10.0   \n3                2.0                91.0             195.0              14.0   \n4                1.0                20.0             113.0              17.0   \n\n    price_doc  \n0   5850000.0  \n1   6000000.0  \n2   5700000.0  \n3  16331452.0  \n4   9100000.0  \n\n[5 rows x 272 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_sq</th>\n      <th>life_sq</th>\n      <th>floor</th>\n      <th>product_type</th>\n      <th>sub_area</th>\n      <th>area_m</th>\n      <th>raion_popul</th>\n      <th>green_zone_part</th>\n      <th>indust_part</th>\n      <th>children_preschool</th>\n      <th>...</th>\n      <th>cafe_count_5000_price_2500</th>\n      <th>cafe_count_5000_price_4000</th>\n      <th>cafe_count_5000_price_high</th>\n      <th>big_church_count_5000</th>\n      <th>church_count_5000</th>\n      <th>mosque_count_5000</th>\n      <th>leisure_count_5000</th>\n      <th>sport_count_5000</th>\n      <th>market_count_5000</th>\n      <th>price_doc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>43.0</td>\n      <td>27.0</td>\n      <td>4.0</td>\n      <td>Investment</td>\n      <td>Bibirevo</td>\n      <td>6407578.100</td>\n      <td>155572.0</td>\n      <td>0.189727</td>\n      <td>0.000070</td>\n      <td>9576.0</td>\n      <td>...</td>\n      <td>9.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>22.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>52.0</td>\n      <td>4.0</td>\n      <td>5850000.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>34.0</td>\n      <td>19.0</td>\n      <td>3.0</td>\n      <td>Investment</td>\n      <td>Nagatinskij Zaton</td>\n      <td>9589336.912</td>\n      <td>115352.0</td>\n      <td>0.372602</td>\n      <td>0.049637</td>\n      <td>6880.0</td>\n      <td>...</td>\n      <td>15.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>15.0</td>\n      <td>29.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>66.0</td>\n      <td>14.0</td>\n      <td>6000000.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>43.0</td>\n      <td>29.0</td>\n      <td>2.0</td>\n      <td>Investment</td>\n      <td>Tekstil'shhiki</td>\n      <td>4808269.831</td>\n      <td>101708.0</td>\n      <td>0.112560</td>\n      <td>0.118537</td>\n      <td>5879.0</td>\n      <td>...</td>\n      <td>10.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>27.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>67.0</td>\n      <td>10.0</td>\n      <td>5700000.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>77.0</td>\n      <td>77.0</td>\n      <td>4.0</td>\n      <td>Investment</td>\n      <td>Basmannoe</td>\n      <td>8398460.622</td>\n      <td>108171.0</td>\n      <td>0.015234</td>\n      <td>0.037316</td>\n      <td>5706.0</td>\n      <td>...</td>\n      <td>319.0</td>\n      <td>108.0</td>\n      <td>17.0</td>\n      <td>135.0</td>\n      <td>236.0</td>\n      <td>2.0</td>\n      <td>91.0</td>\n      <td>195.0</td>\n      <td>14.0</td>\n      <td>16331452.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>67.0</td>\n      <td>46.0</td>\n      <td>14.0</td>\n      <td>Investment</td>\n      <td>Nizhegorodskoe</td>\n      <td>7506452.020</td>\n      <td>43795.0</td>\n      <td>0.007670</td>\n      <td>0.486246</td>\n      <td>2418.0</td>\n      <td>...</td>\n      <td>62.0</td>\n      <td>14.0</td>\n      <td>1.0</td>\n      <td>53.0</td>\n      <td>78.0</td>\n      <td>1.0</td>\n      <td>20.0</td>\n      <td>113.0</td>\n      <td>17.0</td>\n      <td>9100000.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 272 columns</p>\n</div>"},"metadata":{}}],"execution_count":2},{"id":"01f55297","cell_type":"code","source":"# lets load the test data\n\n# test_data = pd.read_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger2\\iml-fall-2024-challenge-2\\test\\test.csv\")\ntest_data = pd.read_csv(r\"/kaggle/input/challenge2/test.csv\")\n\n\n# check if the data has been loaded by getting the first 5 rows - there should be x1 - x78 and no target variable Y as this is test data\n\ntest_data.head() ","metadata":{"execution":{"iopub.status.busy":"2024-11-29T16:26:12.740745Z","iopub.execute_input":"2024-11-29T16:26:12.741253Z","iopub.status.idle":"2024-11-29T16:26:19.399746Z","shell.execute_reply.started":"2024-11-29T16:26:12.741188Z","shell.execute_reply":"2024-11-29T16:26:19.398280Z"},"papermill":{"duration":1.948205,"end_time":"2024-11-07T20:19:59.023969","exception":false,"start_time":"2024-11-07T20:19:57.075764","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"  row ID  full_sq  life_sq  floor product_type           sub_area  \\\n0   Row3     89.0     50.0    9.0   Investment             Mitino   \n1   Row6     25.0     14.0   10.0   Investment         Sokol'niki   \n2  Row11     38.0     19.0   11.0   Investment  Zapadnoe Degunino   \n3  Row12     43.0     28.0    4.0   Investment            Kuncevo   \n4  Row14     31.0     21.0    3.0   Investment          Lefortovo   \n\n         area_m  raion_popul  green_zone_part  indust_part  ...  \\\n0  1.258354e+07     178473.0         0.194703     0.069753  ...   \n1  1.032047e+07      57405.0         0.523439     0.042307  ...   \n2  7.632940e+06      78810.0         0.051844     0.437885  ...   \n3  5.235177e+07     142462.0         0.070662     0.035145  ...   \n4  8.993640e+06      89971.0         0.066941     0.306977  ...   \n\n   cafe_count_5000_price_1500  cafe_count_5000_price_2500  \\\n0                        15.0                        11.0   \n1                       144.0                        81.0   \n2                        39.0                         8.0   \n3                        21.0                        13.0   \n4                       205.0                        88.0   \n\n   cafe_count_5000_price_4000  cafe_count_5000_price_high  \\\n0                         2.0                         1.0   \n1                        16.0                         3.0   \n2                         3.0                         0.0   \n3                         9.0                         1.0   \n4                        19.0                         2.0   \n\n   big_church_count_5000  church_count_5000  mosque_count_5000  \\\n0                    4.0                4.0                0.0   \n1                   38.0               80.0                1.0   \n2                   10.0                9.0                0.0   \n3                    7.0               15.0                0.0   \n4                   63.0              100.0                0.0   \n\n   leisure_count_5000  sport_count_5000 market_count_5000  \n0                 0.0              26.0               3.0  \n1                27.0             127.0               8.0  \n2                 0.0              35.0               4.0  \n3                 2.0              47.0               0.0  \n4                28.0             132.0              14.0  \n\n[5 rows x 272 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row ID</th>\n      <th>full_sq</th>\n      <th>life_sq</th>\n      <th>floor</th>\n      <th>product_type</th>\n      <th>sub_area</th>\n      <th>area_m</th>\n      <th>raion_popul</th>\n      <th>green_zone_part</th>\n      <th>indust_part</th>\n      <th>...</th>\n      <th>cafe_count_5000_price_1500</th>\n      <th>cafe_count_5000_price_2500</th>\n      <th>cafe_count_5000_price_4000</th>\n      <th>cafe_count_5000_price_high</th>\n      <th>big_church_count_5000</th>\n      <th>church_count_5000</th>\n      <th>mosque_count_5000</th>\n      <th>leisure_count_5000</th>\n      <th>sport_count_5000</th>\n      <th>market_count_5000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Row3</td>\n      <td>89.0</td>\n      <td>50.0</td>\n      <td>9.0</td>\n      <td>Investment</td>\n      <td>Mitino</td>\n      <td>1.258354e+07</td>\n      <td>178473.0</td>\n      <td>0.194703</td>\n      <td>0.069753</td>\n      <td>...</td>\n      <td>15.0</td>\n      <td>11.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>26.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Row6</td>\n      <td>25.0</td>\n      <td>14.0</td>\n      <td>10.0</td>\n      <td>Investment</td>\n      <td>Sokol'niki</td>\n      <td>1.032047e+07</td>\n      <td>57405.0</td>\n      <td>0.523439</td>\n      <td>0.042307</td>\n      <td>...</td>\n      <td>144.0</td>\n      <td>81.0</td>\n      <td>16.0</td>\n      <td>3.0</td>\n      <td>38.0</td>\n      <td>80.0</td>\n      <td>1.0</td>\n      <td>27.0</td>\n      <td>127.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Row11</td>\n      <td>38.0</td>\n      <td>19.0</td>\n      <td>11.0</td>\n      <td>Investment</td>\n      <td>Zapadnoe Degunino</td>\n      <td>7.632940e+06</td>\n      <td>78810.0</td>\n      <td>0.051844</td>\n      <td>0.437885</td>\n      <td>...</td>\n      <td>39.0</td>\n      <td>8.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>10.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Row12</td>\n      <td>43.0</td>\n      <td>28.0</td>\n      <td>4.0</td>\n      <td>Investment</td>\n      <td>Kuncevo</td>\n      <td>5.235177e+07</td>\n      <td>142462.0</td>\n      <td>0.070662</td>\n      <td>0.035145</td>\n      <td>...</td>\n      <td>21.0</td>\n      <td>13.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>47.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Row14</td>\n      <td>31.0</td>\n      <td>21.0</td>\n      <td>3.0</td>\n      <td>Investment</td>\n      <td>Lefortovo</td>\n      <td>8.993640e+06</td>\n      <td>89971.0</td>\n      <td>0.066941</td>\n      <td>0.306977</td>\n      <td>...</td>\n      <td>205.0</td>\n      <td>88.0</td>\n      <td>19.0</td>\n      <td>2.0</td>\n      <td>63.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>28.0</td>\n      <td>132.0</td>\n      <td>14.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 272 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"id":"9db89cc8","cell_type":"markdown","source":"# Data Preprocessing\n\nbefore we start processing this data and using algorithms, we will fix this data first, this is called data preprocessing","metadata":{"papermill":{"duration":0.012664,"end_time":"2024-11-07T20:19:59.050712","exception":false,"start_time":"2024-11-07T20:19:59.038048","status":"completed"},"tags":[]}},{"id":"46a83e6e","cell_type":"markdown","source":"## split data into categorical and numerical\n\ncategorical will have one-hot and simple imputer of most frequent while numerical will have simple mean imputer and minmax scaler","metadata":{}},{"id":"306cc606","cell_type":"code","source":"categorical_cols = train_data.select_dtypes(include=[\"object\"]).columns\n\nnumerical_cols = train_data.select_dtypes(exclude=[\"object\"]).drop(columns=['price_doc']).columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T16:26:19.402771Z","iopub.execute_input":"2024-11-29T16:26:19.403307Z","iopub.status.idle":"2024-11-29T16:26:19.710801Z","shell.execute_reply.started":"2024-11-29T16:26:19.403258Z","shell.execute_reply":"2024-11-29T16:26:19.709533Z"}},"outputs":[],"execution_count":4},{"id":"1e90a6a2","cell_type":"code","source":"num_transformer = Pipeline(steps=[\n\n    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n\n    (\"scaler\", StandardScaler())\n\n])\n\ncat_transformer = Pipeline(steps=[\n\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n\n    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T16:26:19.711897Z","iopub.execute_input":"2024-11-29T16:26:19.712186Z","iopub.status.idle":"2024-11-29T16:26:19.719080Z","shell.execute_reply.started":"2024-11-29T16:26:19.712159Z","shell.execute_reply":"2024-11-29T16:26:19.717643Z"}},"outputs":[],"execution_count":5},{"id":"d0e20cc8","cell_type":"code","source":"# Column transformer for preprocessing\n\npreprocessor = ColumnTransformer(\n\n    transformers=[\n\n        (\"num\", num_transformer, numerical_cols),\n\n        (\"cat\", cat_transformer, categorical_cols)\n\n    ]\n\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T16:26:19.720839Z","iopub.execute_input":"2024-11-29T16:26:19.721173Z","iopub.status.idle":"2024-11-29T16:26:19.734290Z","shell.execute_reply.started":"2024-11-29T16:26:19.721141Z","shell.execute_reply":"2024-11-29T16:26:19.732736Z"}},"outputs":[],"execution_count":6},{"id":"2a5e67cf","cell_type":"markdown","source":"## correlation matrix\n\ni tried getting the correlation matrix but apparently a 2000 columns matrix is very computationally expensive as it performs pairs for all. so dont run it. it takes too long and then fails. i ran for 5 minutes. ","metadata":{}},{"id":"aae908d1","cell_type":"code","source":"# # DONT RUN\n\n# corr_matrix = train_data.corr()\n\n# print(corr_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T16:26:19.736275Z","iopub.execute_input":"2024-11-29T16:26:19.736795Z","iopub.status.idle":"2024-11-29T16:26:19.747820Z","shell.execute_reply.started":"2024-11-29T16:26:19.736761Z","shell.execute_reply":"2024-11-29T16:26:19.746497Z"}},"outputs":[],"execution_count":7},{"id":"463d5ca5","cell_type":"markdown","source":"# PCA\n\nprincipal component analysis is applied","metadata":{}},{"id":"68ef094f","cell_type":"code","source":"# # -------------------------- case  --------------------------\n\n# pca = PCA(n_components=33)                                 \n\n# X = pca.fit_transform(X)\n\n# test_data_processed = pca.transform(test_data_processed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T16:26:19.749322Z","iopub.execute_input":"2024-11-29T16:26:19.749727Z","iopub.status.idle":"2024-11-29T16:26:19.766484Z","shell.execute_reply.started":"2024-11-29T16:26:19.749694Z","shell.execute_reply":"2024-11-29T16:26:19.765176Z"}},"outputs":[],"execution_count":8},{"id":"2bd65ed6","cell_type":"markdown","source":"## Data Splitting - festures and targets\n\nthe data in train_data set is of x1 - x78 columns (79 variables) and one target variable (Y). we must split that data so that we can perform data preprocessing on the features variables (will be referred to as X).","metadata":{"papermill":{"duration":0.012565,"end_time":"2024-11-07T20:19:59.480848","exception":false,"start_time":"2024-11-07T20:19:59.468283","status":"completed"},"tags":[]}},{"id":"565fb08f","cell_type":"code","source":"# so in X, it is ALL the columns EXCEPT the last column known as 'Y' (we can confirm this using the train_data.head() we did earlier) so we must get all columns and DROP only the 'y' column\n\nX = train_data.drop(columns=['price_doc'])\n\nX # lets display X and see what it is now","metadata":{"execution":{"iopub.status.busy":"2024-11-29T16:26:19.768291Z","iopub.execute_input":"2024-11-29T16:26:19.768835Z","iopub.status.idle":"2024-11-29T16:26:19.974819Z","shell.execute_reply.started":"2024-11-29T16:26:19.768787Z","shell.execute_reply":"2024-11-29T16:26:19.973522Z"},"papermill":{"duration":0.123675,"end_time":"2024-11-07T20:19:59.617410","exception":false,"start_time":"2024-11-07T20:19:59.493735","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"        full_sq  life_sq  floor product_type                        sub_area  \\\n0          43.0     27.0    4.0   Investment                        Bibirevo   \n1          34.0     19.0    3.0   Investment               Nagatinskij Zaton   \n2          43.0     29.0    2.0   Investment                  Tekstil'shhiki   \n3          77.0     77.0    4.0   Investment                       Basmannoe   \n4          67.0     46.0   14.0   Investment                  Nizhegorodskoe   \n...         ...      ...    ...          ...                             ...   \n181502     48.0     33.0    3.0   Investment  Poselenie Mihajlovo-Jarcevskoe   \n181503     48.0     33.0    3.0   Investment  Poselenie Mihajlovo-Jarcevskoe   \n181504     48.0     33.0    3.0   Investment  Poselenie Mihajlovo-Jarcevskoe   \n181505     48.0     33.0    3.0   Investment  Poselenie Mihajlovo-Jarcevskoe   \n181506     48.0     33.0    3.0   Investment  Poselenie Mihajlovo-Jarcevskoe   \n\n              area_m  raion_popul  green_zone_part  indust_part  \\\n0       6.407578e+06     155572.0         0.189727     0.000070   \n1       9.589337e+06     115352.0         0.372602     0.049637   \n2       4.808270e+06     101708.0         0.112560     0.118537   \n3       8.398461e+06     108171.0         0.015234     0.037316   \n4       7.506452e+06      43795.0         0.007670     0.486246   \n...              ...          ...              ...          ...   \n181502  6.455617e+07       4949.0         0.586175     0.005819   \n181503  6.455617e+07       4949.0         0.586175     0.005819   \n181504  6.455617e+07       4949.0         0.586175     0.005819   \n181505  6.455617e+07       4949.0         0.586175     0.005819   \n181506  6.455617e+07       4949.0         0.586175     0.005819   \n\n        children_preschool  ...  cafe_count_5000_price_1500  \\\n0                   9576.0  ...                        40.0   \n1                   6880.0  ...                        36.0   \n2                   5879.0  ...                        25.0   \n3                   5706.0  ...                       552.0   \n4                   2418.0  ...                       155.0   \n...                    ...  ...                         ...   \n181502               346.0  ...                         0.0   \n181503               346.0  ...                         0.0   \n181504               346.0  ...                         0.0   \n181505               346.0  ...                         0.0   \n181506               346.0  ...                         0.0   \n\n        cafe_count_5000_price_2500  cafe_count_5000_price_4000  \\\n0                              9.0                         4.0   \n1                             15.0                         3.0   \n2                             10.0                         3.0   \n3                            319.0                       108.0   \n4                             62.0                        14.0   \n...                            ...                         ...   \n181502                         0.0                         0.0   \n181503                         0.0                         0.0   \n181504                         0.0                         0.0   \n181505                         0.0                         0.0   \n181506                         0.0                         0.0   \n\n        cafe_count_5000_price_high  big_church_count_5000  church_count_5000  \\\n0                              0.0                   13.0               22.0   \n1                              0.0                   15.0               29.0   \n2                              0.0                   11.0               27.0   \n3                             17.0                  135.0              236.0   \n4                              1.0                   53.0               78.0   \n...                            ...                    ...                ...   \n181502                         0.0                    0.0                2.0   \n181503                         0.0                    0.0                2.0   \n181504                         0.0                    0.0                2.0   \n181505                         0.0                    0.0                2.0   \n181506                         0.0                    0.0                2.0   \n\n        mosque_count_5000  leisure_count_5000 sport_count_5000  \\\n0                     1.0                 0.0             52.0   \n1                     1.0                10.0             66.0   \n2                     0.0                 4.0             67.0   \n3                     2.0                91.0            195.0   \n4                     1.0                20.0            113.0   \n...                   ...                 ...              ...   \n181502                0.0                 0.0              0.0   \n181503                0.0                 0.0              0.0   \n181504                0.0                 0.0              0.0   \n181505                0.0                 0.0              0.0   \n181506                0.0                 0.0              0.0   \n\n        market_count_5000  \n0                     4.0  \n1                    14.0  \n2                    10.0  \n3                    14.0  \n4                    17.0  \n...                   ...  \n181502                0.0  \n181503                0.0  \n181504                0.0  \n181505                0.0  \n181506                0.0  \n\n[181507 rows x 271 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_sq</th>\n      <th>life_sq</th>\n      <th>floor</th>\n      <th>product_type</th>\n      <th>sub_area</th>\n      <th>area_m</th>\n      <th>raion_popul</th>\n      <th>green_zone_part</th>\n      <th>indust_part</th>\n      <th>children_preschool</th>\n      <th>...</th>\n      <th>cafe_count_5000_price_1500</th>\n      <th>cafe_count_5000_price_2500</th>\n      <th>cafe_count_5000_price_4000</th>\n      <th>cafe_count_5000_price_high</th>\n      <th>big_church_count_5000</th>\n      <th>church_count_5000</th>\n      <th>mosque_count_5000</th>\n      <th>leisure_count_5000</th>\n      <th>sport_count_5000</th>\n      <th>market_count_5000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>43.0</td>\n      <td>27.0</td>\n      <td>4.0</td>\n      <td>Investment</td>\n      <td>Bibirevo</td>\n      <td>6.407578e+06</td>\n      <td>155572.0</td>\n      <td>0.189727</td>\n      <td>0.000070</td>\n      <td>9576.0</td>\n      <td>...</td>\n      <td>40.0</td>\n      <td>9.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>22.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>52.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>34.0</td>\n      <td>19.0</td>\n      <td>3.0</td>\n      <td>Investment</td>\n      <td>Nagatinskij Zaton</td>\n      <td>9.589337e+06</td>\n      <td>115352.0</td>\n      <td>0.372602</td>\n      <td>0.049637</td>\n      <td>6880.0</td>\n      <td>...</td>\n      <td>36.0</td>\n      <td>15.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>15.0</td>\n      <td>29.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>66.0</td>\n      <td>14.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>43.0</td>\n      <td>29.0</td>\n      <td>2.0</td>\n      <td>Investment</td>\n      <td>Tekstil'shhiki</td>\n      <td>4.808270e+06</td>\n      <td>101708.0</td>\n      <td>0.112560</td>\n      <td>0.118537</td>\n      <td>5879.0</td>\n      <td>...</td>\n      <td>25.0</td>\n      <td>10.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>27.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>67.0</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>77.0</td>\n      <td>77.0</td>\n      <td>4.0</td>\n      <td>Investment</td>\n      <td>Basmannoe</td>\n      <td>8.398461e+06</td>\n      <td>108171.0</td>\n      <td>0.015234</td>\n      <td>0.037316</td>\n      <td>5706.0</td>\n      <td>...</td>\n      <td>552.0</td>\n      <td>319.0</td>\n      <td>108.0</td>\n      <td>17.0</td>\n      <td>135.0</td>\n      <td>236.0</td>\n      <td>2.0</td>\n      <td>91.0</td>\n      <td>195.0</td>\n      <td>14.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>67.0</td>\n      <td>46.0</td>\n      <td>14.0</td>\n      <td>Investment</td>\n      <td>Nizhegorodskoe</td>\n      <td>7.506452e+06</td>\n      <td>43795.0</td>\n      <td>0.007670</td>\n      <td>0.486246</td>\n      <td>2418.0</td>\n      <td>...</td>\n      <td>155.0</td>\n      <td>62.0</td>\n      <td>14.0</td>\n      <td>1.0</td>\n      <td>53.0</td>\n      <td>78.0</td>\n      <td>1.0</td>\n      <td>20.0</td>\n      <td>113.0</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>181502</th>\n      <td>48.0</td>\n      <td>33.0</td>\n      <td>3.0</td>\n      <td>Investment</td>\n      <td>Poselenie Mihajlovo-Jarcevskoe</td>\n      <td>6.455617e+07</td>\n      <td>4949.0</td>\n      <td>0.586175</td>\n      <td>0.005819</td>\n      <td>346.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>181503</th>\n      <td>48.0</td>\n      <td>33.0</td>\n      <td>3.0</td>\n      <td>Investment</td>\n      <td>Poselenie Mihajlovo-Jarcevskoe</td>\n      <td>6.455617e+07</td>\n      <td>4949.0</td>\n      <td>0.586175</td>\n      <td>0.005819</td>\n      <td>346.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>181504</th>\n      <td>48.0</td>\n      <td>33.0</td>\n      <td>3.0</td>\n      <td>Investment</td>\n      <td>Poselenie Mihajlovo-Jarcevskoe</td>\n      <td>6.455617e+07</td>\n      <td>4949.0</td>\n      <td>0.586175</td>\n      <td>0.005819</td>\n      <td>346.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>181505</th>\n      <td>48.0</td>\n      <td>33.0</td>\n      <td>3.0</td>\n      <td>Investment</td>\n      <td>Poselenie Mihajlovo-Jarcevskoe</td>\n      <td>6.455617e+07</td>\n      <td>4949.0</td>\n      <td>0.586175</td>\n      <td>0.005819</td>\n      <td>346.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>181506</th>\n      <td>48.0</td>\n      <td>33.0</td>\n      <td>3.0</td>\n      <td>Investment</td>\n      <td>Poselenie Mihajlovo-Jarcevskoe</td>\n      <td>6.455617e+07</td>\n      <td>4949.0</td>\n      <td>0.586175</td>\n      <td>0.005819</td>\n      <td>346.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>181507 rows × 271 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"id":"c5fd0e61","cell_type":"code","source":"# so as per our X output, we can see that number of columns in train_data is 79 and number of columns in X is 78 meaning we have successfully performed our removal of target variable\n\n# now to get the target variable alone, we can just get it alone,\n\nY = train_data['price_doc']\n\nY # lets see what it is\n\n# as per our Y output, we can see it is of one column and 246k rows which means we have successfully extracted the target variable column","metadata":{"execution":{"iopub.status.busy":"2024-11-29T16:26:19.979599Z","iopub.execute_input":"2024-11-29T16:26:19.979941Z","iopub.status.idle":"2024-11-29T16:26:19.989333Z","shell.execute_reply.started":"2024-11-29T16:26:19.979912Z","shell.execute_reply":"2024-11-29T16:26:19.987939Z"},"papermill":{"duration":0.023643,"end_time":"2024-11-07T20:19:59.654979","exception":false,"start_time":"2024-11-07T20:19:59.631336","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"0          5850000.0\n1          6000000.0\n2          5700000.0\n3         16331452.0\n4          9100000.0\n             ...    \n181502     3480000.0\n181503     3480000.0\n181504     3480000.0\n181505     3480000.0\n181506     3480000.0\nName: price_doc, Length: 181507, dtype: float64"},"metadata":{}}],"execution_count":10},{"id":"b6e9cfd9","cell_type":"markdown","source":"# Filters\n\nthere are two types of filters to filter out columns/features:\n\n- variance filter (a column which has same values throughout the column like all are sunny)\n\n- correlation filter (two columns which are same like weight in kg and weight in pounds)","metadata":{"papermill":{"duration":0.013362,"end_time":"2024-11-07T20:20:00.756855","exception":false,"start_time":"2024-11-07T20:20:00.743493","status":"completed"},"tags":[]}},{"id":"5934b338","cell_type":"code","source":"# print(\"X : \", X.shape)\n\n# print(\"test data : \", test_data_processed.shape)","metadata":{"execution":{"iopub.status.busy":"2024-11-29T16:26:19.990873Z","iopub.execute_input":"2024-11-29T16:26:19.991272Z","iopub.status.idle":"2024-11-29T16:26:20.000439Z","shell.execute_reply.started":"2024-11-29T16:26:19.991223Z","shell.execute_reply":"2024-11-29T16:26:19.999136Z"},"papermill":{"duration":0.02154,"end_time":"2024-11-07T20:20:00.791959","exception":false,"start_time":"2024-11-07T20:20:00.770419","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":11},{"id":"f9c6b8a2","cell_type":"code","source":"# variance filter\n\n# ----------------------------- case  -----------------------------\n\n# variance_filter = VarianceThreshold(threshold=0.001)  # Adjust the threshold if needed\n\n# X = variance_filter.fit_transform(X)\n\n# test_data_processed = variance_filter.fit_transform(test_data_processed)\n\nX.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-29T16:26:20.002259Z","iopub.execute_input":"2024-11-29T16:26:20.002845Z","iopub.status.idle":"2024-11-29T16:26:20.017060Z","shell.execute_reply.started":"2024-11-29T16:26:20.002735Z","shell.execute_reply":"2024-11-29T16:26:20.015785Z"},"papermill":{"duration":0.021917,"end_time":"2024-11-07T20:20:00.827296","exception":false,"start_time":"2024-11-07T20:20:00.805379","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(181507, 271)"},"metadata":{}}],"execution_count":12},{"id":"f1604caf","cell_type":"code","source":"# test_data_processed.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-29T16:26:20.018357Z","iopub.execute_input":"2024-11-29T16:26:20.018723Z","iopub.status.idle":"2024-11-29T16:26:20.036229Z","shell.execute_reply.started":"2024-11-29T16:26:20.018692Z","shell.execute_reply":"2024-11-29T16:26:20.034842Z"},"papermill":{"duration":0.026133,"end_time":"2024-11-07T20:20:00.868012","exception":false,"start_time":"2024-11-07T20:20:00.841879","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":13},{"id":"dd97f036","cell_type":"code","source":"# # correlation filter\n\n# # ----------------------------- case  -----------------------------\n\n# corr_matrix = pd.DataFrame(X).corr().abs()\n\n# upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n\n# to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n\n# X = pd.DataFrame(X).drop(columns=to_drop)\n\n# test_data_processed = pd.DataFrame(test_data_processed).drop(columns=to_drop)\n\nX.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-29T16:26:20.037860Z","iopub.execute_input":"2024-11-29T16:26:20.038189Z","iopub.status.idle":"2024-11-29T16:26:20.054681Z","shell.execute_reply.started":"2024-11-29T16:26:20.038160Z","shell.execute_reply":"2024-11-29T16:26:20.053261Z"},"papermill":{"duration":0.023607,"end_time":"2024-11-07T20:20:00.905745","exception":false,"start_time":"2024-11-07T20:20:00.882138","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(181507, 271)"},"metadata":{}}],"execution_count":14},{"id":"d523de93","cell_type":"code","source":"# test_data_processed.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-29T16:26:20.056342Z","iopub.execute_input":"2024-11-29T16:26:20.056826Z","iopub.status.idle":"2024-11-29T16:26:20.072103Z","shell.execute_reply.started":"2024-11-29T16:26:20.056783Z","shell.execute_reply":"2024-11-29T16:26:20.070492Z"},"papermill":{"duration":0.023492,"end_time":"2024-11-07T20:20:00.943356","exception":false,"start_time":"2024-11-07T20:20:00.919864","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":15},{"id":"5edcb49b","cell_type":"markdown","source":"## Data Splitting - train and validate\n\nnow our test_data set is of rows with NO target variable whereas the train_data set is WITH target variable.\n\nour rules in machine learning is that we must train half or 70% of the data and then we must check its accuracy using the remaining half or 30% of the data - we can only check accuracy IF we have the answers i.e. the target variable. \n\nSo, what we need to do is, is split the train_data set into 2, by a 70% and 30% ratio. we train the model using the 70% and then test the model using the 30% and then use that model to predict the test_data set.","metadata":{"papermill":{"duration":0.016785,"end_time":"2024-11-07T20:20:00.974594","exception":false,"start_time":"2024-11-07T20:20:00.957809","status":"completed"},"tags":[]}},{"id":"237c64fd","cell_type":"code","source":"# holdout method\n\ntrainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.3, random_state=2)","metadata":{"execution":{"iopub.status.busy":"2024-11-29T16:26:20.074486Z","iopub.execute_input":"2024-11-29T16:26:20.075281Z","iopub.status.idle":"2024-11-29T16:26:20.697112Z","shell.execute_reply.started":"2024-11-29T16:26:20.075226Z","shell.execute_reply":"2024-11-29T16:26:20.695853Z"},"papermill":{"duration":0.273955,"end_time":"2024-11-07T20:20:01.264394","exception":false,"start_time":"2024-11-07T20:20:00.990439","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":16},{"id":"b1485955","cell_type":"markdown","source":"# functions\n\nhere we have defined functions like forward-backward selection, kbest selection & algorithm feature importance","metadata":{"papermill":{"duration":0.013949,"end_time":"2024-11-07T20:20:01.292747","exception":false,"start_time":"2024-11-07T20:20:01.278798","status":"completed"},"tags":[]}},{"id":"836da9a8","cell_type":"code","source":"# forward backward selection\n\ndef fbselection(direction, sample_model, features, X, trainX, trainY, testX, test_data_processed):\n\n    print(\"starting\")\n\n    selection = SequentialFeatureSelector(sample_model, direction=direction, n_features_to_select=features, scoring='roc_auc')\n\n    return modelSelector(sample_model, selection, X, trainX, trainY, testX, test_data_processed)\n\n\n\ndef modelSelector(sample_model, selection, X, trainX, trainY, testX, test_data_processed):\n\n    print(\"start extracting\")\n\n    trainX = selection.fit_transform(trainX, trainY)\n\n    print(\"extracted, transforming\")\n\n    testX = selection.transform(testX)                                  # Ensure the test set is transformed similarly\n\n    test_data_processed = selection.transform(test_data_processed)      # test data is also transformed\n\n    X = selection.transform(X)                                          # full data transforming\n\n    print(\"transformed\")\n\n    return sample_model, X, trainX, trainY, testX, test_data_processed\n\n\n\n# kbest selection\n\ndef kbest(sample_model, features, X, trainX, trainY, testX, test_data_processed):\n\n    print(\"starting\")\n\n    selection = SelectKBest(score_func=f_classif, k=features)\n\n    return modelSelector(sample_model, selection, X, trainX, trainY, testX, test_data_processed)","metadata":{"execution":{"iopub.status.busy":"2024-11-29T16:26:20.699036Z","iopub.execute_input":"2024-11-29T16:26:20.699537Z","iopub.status.idle":"2024-11-29T16:26:20.711891Z","shell.execute_reply.started":"2024-11-29T16:26:20.699486Z","shell.execute_reply":"2024-11-29T16:26:20.710260Z"},"papermill":{"duration":0.023729,"end_time":"2024-11-07T20:20:01.330428","exception":false,"start_time":"2024-11-07T20:20:01.306699","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":17},{"id":"0a0bc955","cell_type":"code","source":"# feature importance function\n\ndef featureImportance(sample_model, features, X, trainX, trainY, testX, test_data_processed):\n\n    print(\"fitting\")\n\n    \n\n    # fit the model\n\n    sample_model.fit(trainX, trainY)\n\n\n\n    print(\"extracting features\")\n\n\n\n    # extract all the feature names from data\n\n    importances = sample_model.feature_importances_\n\n    feature_names = train_data_processed.drop(columns=['Y']).columns\n\n    print(feature_names)\n\n\n\n    # sort with respect to importance\n\n    feature_importance_df = pd.DataFrame({\n\n        'Feature': feature_names,\n\n        'Importance': importances\n\n    }).sort_values(by='Importance', ascending=False)\n\n\n\n    # extract the top ones\n\n    top_features = feature_importance_df['Feature'].head(features).values\n\n    print(top_features)\n\n\n\n    # change all data according to the top ones we have selected\n\n    trainX = pd.DataFrame(trainX, columns=feature_names)[top_features]\n\n    testX = pd.DataFrame(testX, columns=feature_names)[top_features]\n\n    X = pd.DataFrame(X, columns=feature_names)[top_features]\n\n    test_data_processed = pd.DataFrame(test_data_processed, columns=feature_names)[top_features]\n\n\n\n    print(\"features extracted\")\n\n    \n\n    # retrain the model\n\n    sample_model.fit(trainX, trainY)\n\n\n\n    print(\"features trained\")\n\n    \n\n    return sample_model, X, trainX, trainY, testX, test_data_processed","metadata":{"execution":{"iopub.status.busy":"2024-11-29T16:26:20.713406Z","iopub.execute_input":"2024-11-29T16:26:20.713920Z","iopub.status.idle":"2024-11-29T16:26:20.736091Z","shell.execute_reply.started":"2024-11-29T16:26:20.713882Z","shell.execute_reply":"2024-11-29T16:26:20.734693Z"},"papermill":{"duration":0.025235,"end_time":"2024-11-07T20:20:01.370030","exception":false,"start_time":"2024-11-07T20:20:01.344795","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":18},{"id":"fc6047d2","cell_type":"markdown","source":"## model intialization\n\nhere model is intialized","metadata":{"papermill":{"duration":0.013797,"end_time":"2024-11-07T20:20:01.398362","exception":false,"start_time":"2024-11-07T20:20:01.384565","status":"completed"},"tags":[]}},{"id":"4e14b109","cell_type":"code","source":"trainX = preprocessor.fit_transform(trainX)\n\nprint(\"trainX completed\")\n\ntestX = preprocessor.transform(testX)\n\nprint(\"testX completed\")\n\ntest_data = preprocessor.transform(test_data)\n\nprint(\"test data completed\")\n\nX = preprocessor.transform(X)\n\nprint(X.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T16:26:20.738366Z","iopub.execute_input":"2024-11-29T16:26:20.738895Z","iopub.status.idle":"2024-11-29T16:26:34.397405Z","shell.execute_reply.started":"2024-11-29T16:26:20.738831Z","shell.execute_reply":"2024-11-29T16:26:34.396025Z"}},"outputs":[{"name":"stdout","text":"trainX completed\ntestX completed\ntest data completed\n(181507, 2214)\n","output_type":"stream"}],"execution_count":19},{"id":"dc13e847","cell_type":"code","source":"def build_nn(input_dim):\n\n    model = Sequential()\n\n    model.add(Dense(128, activation=\"relu\", kernel_regularizer=l2(0.001)))\n\n    model.add(BatchNormalization())\n\n    model.add(Dropout(0.2))\n\n    model.add(Dense(64, activation=\"relu\"))\n\n    model.add(BatchNormalization())\n\n    model.add(Dropout(0.3))\n\n    model.add(Dense(32, activation=\"relu\"))\n\n    model.add(Dense(16, activation=\"relu\"))\n    model.add(Dropout(0.2))\n    \n    model.add(Dense(1))  # Output layer\n\n    model.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\")\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T16:26:34.399235Z","iopub.execute_input":"2024-11-29T16:26:34.399795Z","iopub.status.idle":"2024-11-29T16:26:34.408814Z","shell.execute_reply.started":"2024-11-29T16:26:34.399737Z","shell.execute_reply":"2024-11-29T16:26:34.407446Z"}},"outputs":[],"execution_count":20},{"id":"ee3a4469","cell_type":"code","source":"# Initialize the model\n\nnn_model = build_nn(trainX.shape[1])\n\n\n\n# Define callbacks\n\nlr_scheduler = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5, verbose=1)\n\nearly_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=1)\n\n\n\n# Train the model\n\nnn_model.fit(\n\n    trainX, trainY,\n\n    validation_data=(testX, testY),\n\n    epochs=150,\n\n    batch_size=16,\n\n    verbose=2,\n\n    callbacks=[lr_scheduler, early_stopping]\n\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T16:26:34.410331Z","iopub.execute_input":"2024-11-29T16:26:34.410726Z","iopub.status.idle":"2024-11-29T16:49:29.008096Z","shell.execute_reply.started":"2024-11-29T16:26:34.410694Z","shell.execute_reply":"2024-11-29T16:49:29.005735Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/150\n7941/7941 - 84s - 11ms/step - loss: 364201113550848.0000 - val_loss: 176922789150720.0000 - learning_rate: 0.0010\nEpoch 2/150\n7941/7941 - 79s - 10ms/step - loss: 211550476435456.0000 - val_loss: 177432111874048.0000 - learning_rate: 0.0010\nEpoch 3/150\n7941/7941 - 80s - 10ms/step - loss: 207044971855872.0000 - val_loss: 177484641337344.0000 - learning_rate: 0.0010\nEpoch 4/150\n7941/7941 - 80s - 10ms/step - loss: 205500494905344.0000 - val_loss: 178169990610944.0000 - learning_rate: 0.0010\nEpoch 5/150\n7941/7941 - 79s - 10ms/step - loss: 200956453060608.0000 - val_loss: 178355731169280.0000 - learning_rate: 0.0010\nEpoch 6/150\n7941/7941 - 78s - 10ms/step - loss: 196739835363328.0000 - val_loss: 174606979694592.0000 - learning_rate: 0.0010\nEpoch 7/150\n7941/7941 - 79s - 10ms/step - loss: 193421973127168.0000 - val_loss: 171961950928896.0000 - learning_rate: 0.0010\nEpoch 8/150\n7941/7941 - 84s - 11ms/step - loss: 188660397899776.0000 - val_loss: 174622481842176.0000 - learning_rate: 0.0010\nEpoch 9/150\n7941/7941 - 84s - 11ms/step - loss: 188402683084800.0000 - val_loss: 175281641881600.0000 - learning_rate: 0.0010\nEpoch 10/150\n7941/7941 - 83s - 10ms/step - loss: 186725297029120.0000 - val_loss: 182677323907072.0000 - learning_rate: 0.0010\nEpoch 11/150\n7941/7941 - 83s - 10ms/step - loss: 185176625774592.0000 - val_loss: 177003152015360.0000 - learning_rate: 0.0010\nEpoch 12/150\n\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n7941/7941 - 81s - 10ms/step - loss: 185461167357952.0000 - val_loss: 173346406793216.0000 - learning_rate: 0.0010\nEpoch 13/150\n7941/7941 - 79s - 10ms/step - loss: 181730635939840.0000 - val_loss: 172339689947136.0000 - learning_rate: 5.0000e-04\nEpoch 14/150\n7941/7941 - 81s - 10ms/step - loss: 181080351047680.0000 - val_loss: 176568420794368.0000 - learning_rate: 5.0000e-04\nEpoch 15/150\n7941/7941 - 79s - 10ms/step - loss: 180365977190400.0000 - val_loss: 174411357356032.0000 - learning_rate: 5.0000e-04\nEpoch 16/150\n7941/7941 - 79s - 10ms/step - loss: 179145434726400.0000 - val_loss: 179656686829568.0000 - learning_rate: 5.0000e-04\nEpoch 17/150\n\nEpoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n7941/7941 - 79s - 10ms/step - loss: 178622052696064.0000 - val_loss: 174381376471040.0000 - learning_rate: 5.0000e-04\nEpoch 17: early stopping\nRestoring model weights from the end of the best epoch: 7.\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7f9ea5e784f0>"},"metadata":{}}],"execution_count":21},{"id":"585f7723","cell_type":"code","source":"print(\"X shape -> \", X.shape)\n\nprint(\"trainX shape -> \", trainX.shape)\n\nprint(\"testX shape -> \", testX.shape)\n\nprint(\"test_data_processed shape -> \", test_data.shape)","metadata":{"execution":{"iopub.status.busy":"2024-11-29T16:49:29.009908Z","iopub.execute_input":"2024-11-29T16:49:29.010317Z","iopub.status.idle":"2024-11-29T16:49:29.017975Z","shell.execute_reply.started":"2024-11-29T16:49:29.010269Z","shell.execute_reply":"2024-11-29T16:49:29.016378Z"},"papermill":{"duration":0.02329,"end_time":"2024-11-07T20:20:14.141486","exception":false,"start_time":"2024-11-07T20:20:14.118196","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"X shape ->  (181507, 2214)\ntrainX shape ->  (127054, 2214)\ntestX shape ->  (54453, 2214)\ntest_data_processed shape ->  (77789, 2214)\n","output_type":"stream"}],"execution_count":22},{"id":"34c9426d","cell_type":"markdown","source":"# feature selection\n\nhere we will apply feature selection and feature importance","metadata":{}},{"id":"b543f060","cell_type":"code","source":"# apply feature selection here\n\n# features_selected = SelectFromModel(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T16:49:29.019564Z","iopub.execute_input":"2024-11-29T16:49:29.019915Z","iopub.status.idle":"2024-11-29T16:49:29.033807Z","shell.execute_reply.started":"2024-11-29T16:49:29.019883Z","shell.execute_reply":"2024-11-29T16:49:29.032525Z"}},"outputs":[],"execution_count":23},{"id":"df4c4143","cell_type":"markdown","source":"## model running\n\nhere we run the model","metadata":{"papermill":{"duration":0.014144,"end_time":"2024-11-07T20:20:14.233534","exception":false,"start_time":"2024-11-07T20:20:14.219390","status":"completed"},"tags":[]}},{"id":"62d5bab5","cell_type":"code","source":"y_pred_scaled = nn_model.predict(testX).flatten()\n\ny_pred = y_pred_scaled","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T16:49:29.035602Z","iopub.execute_input":"2024-11-29T16:49:29.036180Z","iopub.status.idle":"2024-11-29T16:49:39.889742Z","shell.execute_reply.started":"2024-11-29T16:49:29.036133Z","shell.execute_reply":"2024-11-29T16:49:39.888232Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1702/1702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step\n","output_type":"stream"}],"execution_count":24},{"id":"cad49c9d","cell_type":"code","source":"# fit the model\n\nnn_model.fit(trainX, trainY)","metadata":{"execution":{"iopub.status.busy":"2024-11-29T16:49:39.891701Z","iopub.execute_input":"2024-11-29T16:49:39.892210Z","iopub.status.idle":"2024-11-29T16:50:32.972879Z","shell.execute_reply.started":"2024-11-29T16:49:39.892155Z","shell.execute_reply":"2024-11-29T16:50:32.970928Z"},"papermill":{"duration":1652.161599,"end_time":"2024-11-07T20:47:46.409387","exception":false,"start_time":"2024-11-07T20:20:14.247788","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[1m3971/3971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 12ms/step - loss: 184711024476160.0000\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7f9ea5e78a00>"},"metadata":{}}],"execution_count":25},{"id":"329dff96","cell_type":"code","source":"# display information regarding the regression\n\n# print(\"model score: \", nn_model.score(trainX, trainY))\n\n# print(\"model coefficient: \", model.coef_)\n\n# print(\"model intercept: \", model.intercept_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T16:50:32.974800Z","iopub.execute_input":"2024-11-29T16:50:32.975190Z","iopub.status.idle":"2024-11-29T16:50:32.982201Z","shell.execute_reply.started":"2024-11-29T16:50:32.975157Z","shell.execute_reply":"2024-11-29T16:50:32.980907Z"}},"outputs":[],"execution_count":26},{"id":"01ee7e3b","cell_type":"code","source":"# compute this predictions metrics\n\ndef metrics(y_pred, testY):\n\n    print(\"starting to compute metrics\")\n\n    \n\n    # # display the accuracy of this prediction\n\n    # accuracy = accuracy_score(testY, y_pred)\n\n    # print(\"model accuracy = \", accuracy, \"   \")\n\n\n\n    # # now lets calculate the ROC AUC score according to this prediction\n\n    # roc_score = roc_auc_score(testY, y_pred)\n\n    # print(\"roc score = \", roc_score, \"   \")\n\n\n\n    # display the mean squared error of this prediction\n\n    mse = mean_squared_error(testY, y_pred)\n\n    print(\"Mean squared error: %.2f\" % mse, \"   \")\n\n\n\n    # display the root mean squared error\n\n    rmse = np.sqrt(mse)  # Root Mean Squared Error\n\n    print(\"Root Mean squared error: %.2f\" % rmse, \"   \")\n\n\n\n    # display the mean absolute error of this prediction\n\n    mae = mean_absolute_error(testY, y_pred)\n\n    print(\"Mean absolute error: %.2f\" % mae, \"   \")\n\n\n\n    # display the coeffeicient of determination of this preduction\n\n    r2_Score = r2_score(testY, y_pred)\n\n    print(\"Coefficient of determination: %.2f\" % r2_Score, \"    \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T16:50:32.984021Z","iopub.execute_input":"2024-11-29T16:50:32.984607Z","iopub.status.idle":"2024-11-29T16:50:33.002348Z","shell.execute_reply.started":"2024-11-29T16:50:32.984546Z","shell.execute_reply":"2024-11-29T16:50:33.001200Z"}},"outputs":[],"execution_count":27},{"id":"8275492e","cell_type":"code","source":"# predict using this model USING PREDICT\n\ny_pred = nn_model.predict(testX)\n\nprint(\"successfully predicted\")\n\nmetrics(y_pred, testY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T16:50:33.007881Z","iopub.execute_input":"2024-11-29T16:50:33.008207Z","iopub.status.idle":"2024-11-29T16:50:44.316759Z","shell.execute_reply.started":"2024-11-29T16:50:33.008177Z","shell.execute_reply":"2024-11-29T16:50:44.315224Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1702/1702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step\nsuccessfully predicted\nstarting to compute metrics\nMean squared error: 171660426605292.75    \nRoot Mean squared error: 13101924.54    \nMean absolute error: 6327963.11    \nCoefficient of determination: 0.64     \n","output_type":"stream"}],"execution_count":28},{"id":"f8ee212f","cell_type":"code","source":"# # predict using thus model USING PREDICTPROBA\n\n# y_pred_proba = model.predict_proba(testX)[:, 1]\n\n# print(\"successfully predicted\")\n\n# metrics(y_pred_proba, testY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T16:50:44.318793Z","iopub.execute_input":"2024-11-29T16:50:44.319265Z","iopub.status.idle":"2024-11-29T16:50:44.325735Z","shell.execute_reply.started":"2024-11-29T16:50:44.319217Z","shell.execute_reply":"2024-11-29T16:50:44.323534Z"}},"outputs":[],"execution_count":29},{"id":"937ae370","cell_type":"markdown","source":"## predict for test dataset\n\nfit the model and predict for test dataset","metadata":{"papermill":{"duration":0.019827,"end_time":"2024-11-07T20:55:49.286324","exception":false,"start_time":"2024-11-07T20:55:49.266497","status":"completed"},"tags":[]}},{"id":"8f6eb5c2","cell_type":"code","source":"nn_model.fit(X, Y)","metadata":{"execution":{"iopub.status.busy":"2024-11-29T16:50:44.327237Z","iopub.execute_input":"2024-11-29T16:50:44.327613Z","iopub.status.idle":"2024-11-29T16:51:50.480559Z","shell.execute_reply.started":"2024-11-29T16:50:44.327580Z","shell.execute_reply":"2024-11-29T16:51:50.479053Z"},"papermill":{"duration":2249.874308,"end_time":"2024-11-07T21:33:19.180774","exception":false,"start_time":"2024-11-07T20:55:49.306466","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[1m5673/5673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 11ms/step - loss: 185375519670272.0000\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7f9e8c6f7640>"},"metadata":{}}],"execution_count":30},{"id":"f18c11b3","cell_type":"code","source":"# display information regarding the regression\n\n# print(\"model score: \", nn_model.score(X, Y), \"    \")\n\n# print(\"model coefficient: \", model.coef_)\n\n# print(\"model intercept: \", model.intercept_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T16:51:50.481970Z","iopub.execute_input":"2024-11-29T16:51:50.482310Z","iopub.status.idle":"2024-11-29T16:51:50.487230Z","shell.execute_reply.started":"2024-11-29T16:51:50.482277Z","shell.execute_reply":"2024-11-29T16:51:50.486163Z"}},"outputs":[],"execution_count":31},{"id":"e9c93967","cell_type":"code","source":"y_test_pred_scaled = nn_model.predict(test_data).flatten()\n\ny_test_pred = y_test_pred_scaled","metadata":{"execution":{"iopub.status.busy":"2024-11-29T16:51:50.488831Z","iopub.execute_input":"2024-11-29T16:51:50.489273Z","iopub.status.idle":"2024-11-29T16:52:05.617885Z","shell.execute_reply.started":"2024-11-29T16:51:50.489234Z","shell.execute_reply":"2024-11-29T16:52:05.616768Z"},"papermill":{"duration":774.78282,"end_time":"2024-11-07T21:46:13.986713","exception":false,"start_time":"2024-11-07T21:33:19.203893","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[1m2431/2431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step\n","output_type":"stream"}],"execution_count":32},{"id":"98c8bfcf","cell_type":"markdown","source":"## write into csv\n\nnow we write the predictions into the csv file","metadata":{"papermill":{"duration":0.02242,"end_time":"2024-11-07T21:46:14.032429","exception":false,"start_time":"2024-11-07T21:46:14.010009","status":"completed"},"tags":[]}},{"id":"e0573bfc","cell_type":"code","source":"# sample_data = pd.read_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger2\\iml-fall-2024-challenge-2\\sample_submission.csv\")\nsample_data = pd.read_csv(r\"/kaggle/input/challenge2/sample_submission.csv\")\n\n\nsample_data['price_doc'] = y_test_pred\n\n# sample_data = sample_data[]\n\n\n\n# sample_data.to_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger2\\iml-fall-2024-challenge-2\\lasso1.csv\", index=False)\nsample_data.to_csv(r\"/kaggle/working/neuralnetwork1.csv\")\nsample_data","metadata":{"execution":{"iopub.status.busy":"2024-11-29T16:52:05.619487Z","iopub.execute_input":"2024-11-29T16:52:05.620553Z","iopub.status.idle":"2024-11-29T16:52:05.899906Z","shell.execute_reply.started":"2024-11-29T16:52:05.620495Z","shell.execute_reply":"2024-11-29T16:52:05.898585Z"},"papermill":{"duration":0.455346,"end_time":"2024-11-07T21:46:14.510398","exception":false,"start_time":"2024-11-07T21:46:14.055052","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"                    row ID   price_doc\n0                     Row3  11328301.0\n1                     Row6   9420224.0\n2                    Row11   5738602.0\n3                    Row12   7552711.0\n4                    Row14   8317889.0\n...                    ...         ...\n77784  Row18591dupl_228801  57917260.0\n77785  Row18591dupl_228803  52167600.0\n77786  Row18591dupl_228814   2712281.5\n77787  Row18591dupl_228817   2712281.5\n77788  Row18591dupl_228821   2712281.5\n\n[77789 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row ID</th>\n      <th>price_doc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Row3</td>\n      <td>11328301.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Row6</td>\n      <td>9420224.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Row11</td>\n      <td>5738602.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Row12</td>\n      <td>7552711.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Row14</td>\n      <td>8317889.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>77784</th>\n      <td>Row18591dupl_228801</td>\n      <td>57917260.0</td>\n    </tr>\n    <tr>\n      <th>77785</th>\n      <td>Row18591dupl_228803</td>\n      <td>52167600.0</td>\n    </tr>\n    <tr>\n      <th>77786</th>\n      <td>Row18591dupl_228814</td>\n      <td>2712281.5</td>\n    </tr>\n    <tr>\n      <th>77787</th>\n      <td>Row18591dupl_228817</td>\n      <td>2712281.5</td>\n    </tr>\n    <tr>\n      <th>77788</th>\n      <td>Row18591dupl_228821</td>\n      <td>2712281.5</td>\n    </tr>\n  </tbody>\n</table>\n<p>77789 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":33},{"id":"b809270f-fe48-4fe3-9067-c4c8e946ee1c","cell_type":"code","source":"nn_model","metadata":{"execution":{"iopub.status.busy":"2024-11-29T16:52:05.901710Z","iopub.execute_input":"2024-11-29T16:52:05.902101Z","iopub.status.idle":"2024-11-29T16:52:05.910619Z","shell.execute_reply.started":"2024-11-29T16:52:05.902065Z","shell.execute_reply":"2024-11-29T16:52:05.909082Z"},"papermill":{"duration":0.053693,"end_time":"2024-11-07T21:46:14.588137","exception":false,"start_time":"2024-11-07T21:46:14.534444","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"<Sequential name=sequential, built=True>"},"metadata":{}}],"execution_count":34}]}