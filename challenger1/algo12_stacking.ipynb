{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9837068,"sourceType":"datasetVersion","datasetId":6034234},{"sourceId":9837128,"sourceType":"datasetVersion","datasetId":6034286}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":5193.546342,"end_time":"2024-11-07T21:46:17.332142","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-11-07T20:19:43.785800","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries\nin this part we will install all the necessary libraries on command prompt and then import the necessary functions from those libraries. ","metadata":{"papermill":{"duration":0.013014,"end_time":"2024-11-07T20:19:46.538794","exception":false,"start_time":"2024-11-07T20:19:46.525780","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# importing all the necessary libraries\nimport pandas as pd\n\nfrom numpy import mean\nimport numpy as np\nimport time\n\n# step 1: preprocessing\nfrom sklearn.impute import SimpleImputer # import some strategic imputer to fill in any missing values using mean\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler, Normalizer # scale all the values to one range to avoid any biasness (this bias is seen in mostly naive bayes and knn etc)\n\nfrom sklearn.impute import KNNImputer # import some strategic imputer to fill missing values using KNN (finds the nearest neighbour and fills it with that value)\n\nfrom sklearn.feature_selection import SequentialFeatureSelector, SelectKBest, f_classif, VarianceThreshold\n\n# step 2: data division\nfrom sklearn.model_selection import train_test_split, RepeatedKFold, cross_val_score, GridSearchCV, ParameterGrid # to divide the code into train/test using a specific percentage or with/without replacement\n\n# step 3: model\nfrom sklearn.tree import DecisionTreeClassifier                                                        \nfrom sklearn.naive_bayes import GaussianNB                                                              \nfrom sklearn.neighbors import KNeighborsClassifier                                                       \nfrom sklearn.ensemble import BaggingClassifier, VotingClassifier, ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, StackingClassifier\nimport lightgbm as lgb \nimport xgboost as xgb\nfrom catboost import CatBoostClassifier \n\n# step 4: displaying accuracy\nfrom sklearn.metrics import roc_auc_score, accuracy_score # to display the accuracy of our tree\n\n# step 5: warning filter\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"papermill":{"duration":5.853121,"end_time":"2024-11-07T20:19:52.405091","exception":false,"start_time":"2024-11-07T20:19:46.551970","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:34:42.226112Z","iopub.execute_input":"2024-11-09T20:34:42.226484Z","iopub.status.idle":"2024-11-09T20:34:46.885029Z","shell.execute_reply.started":"2024-11-09T20:34:42.226445Z","shell.execute_reply":"2024-11-09T20:34:46.884194Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# use this block to install any libraries not on the system\n# !pip install pandas\n# !pip install sklearn\n# python -m pip install scikit-learn lightgbm xgboost catboost","metadata":{"papermill":{"duration":0.018925,"end_time":"2024-11-07T20:19:52.436076","exception":false,"start_time":"2024-11-07T20:19:52.417151","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:34:46.886648Z","iopub.execute_input":"2024-11-09T20:34:46.887392Z","iopub.status.idle":"2024-11-09T20:34:46.891493Z","shell.execute_reply.started":"2024-11-09T20:34:46.887356Z","shell.execute_reply":"2024-11-09T20:34:46.890419Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Data Loading\ndata shall be loaded into variables as data sets using pandas and csv readers. they will be checked to see if they are loaded properly and will be loaded as 2 sets: train and test as per given in the kaggle data","metadata":{"papermill":{"duration":0.011237,"end_time":"2024-11-07T20:19:52.458899","exception":false,"start_time":"2024-11-07T20:19:52.447662","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# lets load the training data set\ntrain_data = pd.read_csv(r\"/kaggle/input/imlchallenger1/train_set.csv\")\n\n# lets also check it by getting the first few rows of the data, there should be x1 - x78 and one target variable Y\ntrain_data.head() ","metadata":{"papermill":{"duration":4.591761,"end_time":"2024-11-07T20:19:57.062353","exception":false,"start_time":"2024-11-07T20:19:52.470592","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:34:46.892527Z","iopub.execute_input":"2024-11-09T20:34:46.893155Z","iopub.status.idle":"2024-11-09T20:34:51.243865Z","shell.execute_reply.started":"2024-11-09T20:34:46.893109Z","shell.execute_reply":"2024-11-09T20:34:51.242855Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  ...  \\\n0         1  87.000000  34.118411   0   2   0  165.100000   1  829    2  ...   \n1         2  82.372284  31.573280   0   0   1  162.983897   1  724    0  ...   \n2         3  50.000000  27.771653   0   0   1  165.100000   1  895    2  ...   \n3         4  66.236109  26.515922   0   0   1  167.009549   1  637    0  ...   \n4         5  81.303299  20.843691   0   0   1  158.165419   0  564    0  ...   \n\n        X70  X71  X72  X73  X74  X75  X76  X77  X78  Y  \n0  0.040000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n1  0.033431  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n2  0.010000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n3  0.039363  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n4  0.069242  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n\n[5 rows x 79 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RecordId</th>\n      <th>X2</th>\n      <th>X3</th>\n      <th>X4</th>\n      <th>X5</th>\n      <th>X6</th>\n      <th>X7</th>\n      <th>X8</th>\n      <th>X9</th>\n      <th>X10</th>\n      <th>...</th>\n      <th>X70</th>\n      <th>X71</th>\n      <th>X72</th>\n      <th>X73</th>\n      <th>X74</th>\n      <th>X75</th>\n      <th>X76</th>\n      <th>X77</th>\n      <th>X78</th>\n      <th>Y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>87.000000</td>\n      <td>34.118411</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>165.100000</td>\n      <td>1</td>\n      <td>829</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.040000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>82.372284</td>\n      <td>31.573280</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>162.983897</td>\n      <td>1</td>\n      <td>724</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.033431</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>50.000000</td>\n      <td>27.771653</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>165.100000</td>\n      <td>1</td>\n      <td>895</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.010000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>66.236109</td>\n      <td>26.515922</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>167.009549</td>\n      <td>1</td>\n      <td>637</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.039363</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>81.303299</td>\n      <td>20.843691</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>158.165419</td>\n      <td>0</td>\n      <td>564</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.069242</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 79 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# lets load the test data\ntest_data = pd.read_csv(r\"/kaggle/input/imlchallenger1/test_set.csv\")\n\n# check if the data has been loaded by getting the first 5 rows - there should be x1 - x78 and no target variable Y as this is test data\ntest_data.head() ","metadata":{"papermill":{"duration":1.948205,"end_time":"2024-11-07T20:19:59.023969","exception":false,"start_time":"2024-11-07T20:19:57.075764","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:34:51.246159Z","iopub.execute_input":"2024-11-09T20:34:51.246483Z","iopub.status.idle":"2024-11-09T20:34:53.028096Z","shell.execute_reply.started":"2024-11-09T20:34:51.246449Z","shell.execute_reply":"2024-11-09T20:34:53.027152Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  ...  \\\n0    300001  79.000000  17.122318   0   0   1  170.200000   1  700    0  ...   \n1    300002  38.000000  43.693579   0   0   1  165.100000   1  814    0  ...   \n2    300003  36.064225  23.998944   0   0   1  167.086735   1  662    0  ...   \n3    300004  61.846764  31.693449   0   3   1  182.355708   2  862    0  ...   \n4    300005  71.591991  20.086147   1   0   1  166.704917   2  335    0  ...   \n\n        X69       X70  X71  X72  X73  X74  X75  X76  X77  X78  \n0  0.070000  0.030000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n1  0.050000  0.040000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n2  0.006948  0.006948  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n3  0.062613  0.033153  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n4  0.014854  0.004854  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n\n[5 rows x 78 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RecordId</th>\n      <th>X2</th>\n      <th>X3</th>\n      <th>X4</th>\n      <th>X5</th>\n      <th>X6</th>\n      <th>X7</th>\n      <th>X8</th>\n      <th>X9</th>\n      <th>X10</th>\n      <th>...</th>\n      <th>X69</th>\n      <th>X70</th>\n      <th>X71</th>\n      <th>X72</th>\n      <th>X73</th>\n      <th>X74</th>\n      <th>X75</th>\n      <th>X76</th>\n      <th>X77</th>\n      <th>X78</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>300001</td>\n      <td>79.000000</td>\n      <td>17.122318</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>170.200000</td>\n      <td>1</td>\n      <td>700</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.070000</td>\n      <td>0.030000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>300002</td>\n      <td>38.000000</td>\n      <td>43.693579</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>165.100000</td>\n      <td>1</td>\n      <td>814</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.050000</td>\n      <td>0.040000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>300003</td>\n      <td>36.064225</td>\n      <td>23.998944</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>167.086735</td>\n      <td>1</td>\n      <td>662</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.006948</td>\n      <td>0.006948</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>300004</td>\n      <td>61.846764</td>\n      <td>31.693449</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>182.355708</td>\n      <td>2</td>\n      <td>862</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.062613</td>\n      <td>0.033153</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>300005</td>\n      <td>71.591991</td>\n      <td>20.086147</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>166.704917</td>\n      <td>2</td>\n      <td>335</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.014854</td>\n      <td>0.004854</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 78 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Data Preprocessing\nbefore we start processing this data and using algorithms, we will fix this data first, this is called data preprocessing","metadata":{"papermill":{"duration":0.012664,"end_time":"2024-11-07T20:19:59.050712","exception":false,"start_time":"2024-11-07T20:19:59.038048","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Conversion of Categorical to Numerical\nFirst we will convert categorical data to numerical data by doing one hot encoding, which turns it into binary variables","metadata":{"papermill":{"duration":0.013829,"end_time":"2024-11-07T20:19:59.076934","exception":false,"start_time":"2024-11-07T20:19:59.063105","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# one hot encoding - display it\npd.get_dummies(train_data) # this line will convert the train_data to one hot encoding but it will only display the result and not save it","metadata":{"papermill":{"duration":0.178612,"end_time":"2024-11-07T20:19:59.270335","exception":false,"start_time":"2024-11-07T20:19:59.091723","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:34:53.029572Z","iopub.execute_input":"2024-11-09T20:34:53.029979Z","iopub.status.idle":"2024-11-09T20:34:53.188134Z","shell.execute_reply.started":"2024-11-09T20:34:53.029936Z","shell.execute_reply":"2024-11-09T20:34:53.187172Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"        RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  \\\n0              1  87.000000  34.118411   0   2   0  165.100000   1  829    2   \n1              2  82.372284  31.573280   0   0   1  162.983897   1  724    0   \n2              3  50.000000  27.771653   0   0   1  165.100000   1  895    2   \n3              4  66.236109  26.515922   0   0   1  167.009549   1  637    0   \n4              5  81.303299  20.843691   0   0   1  158.165419   0  564    0   \n...          ...        ...        ...  ..  ..  ..         ...  ..  ...  ...   \n246117    246118  65.149110  33.357948   0   0   1  156.317941   1  711    0   \n246118    246119  48.000000  46.736176   0   0   1  157.000000   1  594    2   \n246119    246120  57.472080  41.854115   1   0   0  189.868698   2  455    0   \n246120    246121  66.000000  23.738662   1   0   1  168.000000   2  609    0   \n246121    246122  50.257640  32.753911   0   2   0  173.665068   1  637    0   \n\n        ...       X70  X71  X72       X73  X74       X75  X76  X77       X78  \\\n0       ...  0.040000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n1       ...  0.033431  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n2       ...  0.010000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n3       ...  0.039363  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n4       ...  0.069242  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n...     ...       ...  ...  ...       ...  ...       ...  ...  ...       ...   \n246117  ...  0.027152  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n246118  ...  0.560000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n246119  ...  0.020601  0.0  0.0  0.587987  0.0  0.412013  0.0  0.0  0.412013   \n246120  ... -1.000000  0.0  0.0  1.000000  0.0  0.000000  0.0  0.0  0.000000   \n246121  ...  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n\n        Y  \n0       0  \n1       0  \n2       0  \n3       0  \n4       0  \n...    ..  \n246117  0  \n246118  1  \n246119  0  \n246120  0  \n246121  0  \n\n[246122 rows x 79 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RecordId</th>\n      <th>X2</th>\n      <th>X3</th>\n      <th>X4</th>\n      <th>X5</th>\n      <th>X6</th>\n      <th>X7</th>\n      <th>X8</th>\n      <th>X9</th>\n      <th>X10</th>\n      <th>...</th>\n      <th>X70</th>\n      <th>X71</th>\n      <th>X72</th>\n      <th>X73</th>\n      <th>X74</th>\n      <th>X75</th>\n      <th>X76</th>\n      <th>X77</th>\n      <th>X78</th>\n      <th>Y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>87.000000</td>\n      <td>34.118411</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>165.100000</td>\n      <td>1</td>\n      <td>829</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.040000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>82.372284</td>\n      <td>31.573280</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>162.983897</td>\n      <td>1</td>\n      <td>724</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.033431</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>50.000000</td>\n      <td>27.771653</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>165.100000</td>\n      <td>1</td>\n      <td>895</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.010000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>66.236109</td>\n      <td>26.515922</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>167.009549</td>\n      <td>1</td>\n      <td>637</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.039363</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>81.303299</td>\n      <td>20.843691</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>158.165419</td>\n      <td>0</td>\n      <td>564</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.069242</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>246117</th>\n      <td>246118</td>\n      <td>65.149110</td>\n      <td>33.357948</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>156.317941</td>\n      <td>1</td>\n      <td>711</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.027152</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>246118</th>\n      <td>246119</td>\n      <td>48.000000</td>\n      <td>46.736176</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>157.000000</td>\n      <td>1</td>\n      <td>594</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.560000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>246119</th>\n      <td>246120</td>\n      <td>57.472080</td>\n      <td>41.854115</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>189.868698</td>\n      <td>2</td>\n      <td>455</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.020601</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.587987</td>\n      <td>0.0</td>\n      <td>0.412013</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.412013</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>246120</th>\n      <td>246121</td>\n      <td>66.000000</td>\n      <td>23.738662</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>168.000000</td>\n      <td>2</td>\n      <td>609</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-1.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>246121</th>\n      <td>246122</td>\n      <td>50.257640</td>\n      <td>32.753911</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>173.665068</td>\n      <td>1</td>\n      <td>637</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>246122 rows Ã— 79 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# we can see that there is no change in the number of columns meaning there is no categorical data. but for the sake of running the program. we must perform the preprocessing therefore we shall re-run the one hot encoding and save it somewhere\ntrain_data_processed = pd.get_dummies(train_data)\n\n# now we shall do the same on the test data so that we maintain the rules over all data\ntest_data_processed = pd.get_dummies(test_data)","metadata":{"papermill":{"duration":0.171007,"end_time":"2024-11-07T20:19:59.454757","exception":false,"start_time":"2024-11-07T20:19:59.283750","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:34:53.189407Z","iopub.execute_input":"2024-11-09T20:34:53.189789Z","iopub.status.idle":"2024-11-09T20:34:53.344684Z","shell.execute_reply.started":"2024-11-09T20:34:53.189746Z","shell.execute_reply":"2024-11-09T20:34:53.343679Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Data Splitting - festures and targets\nthe data in train_data set is of x1 - x78 columns (79 variables) and one target variable (Y). we must split that data so that we can perform data preprocessing on the features variables (will be referred to as X).","metadata":{"papermill":{"duration":0.012565,"end_time":"2024-11-07T20:19:59.480848","exception":false,"start_time":"2024-11-07T20:19:59.468283","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# so in X, it is ALL the columns EXCEPT the last column known as 'Y' (we can confirm this using the train_data.head() we did earlier) so we must get all columns and DROP only the 'y' column\nX = train_data_processed.drop(columns=['Y'])\nX # lets display X and see what it is now","metadata":{"papermill":{"duration":0.123675,"end_time":"2024-11-07T20:19:59.617410","exception":false,"start_time":"2024-11-07T20:19:59.493735","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:34:53.346374Z","iopub.execute_input":"2024-11-09T20:34:53.346782Z","iopub.status.idle":"2024-11-09T20:34:53.470850Z","shell.execute_reply.started":"2024-11-09T20:34:53.346734Z","shell.execute_reply":"2024-11-09T20:34:53.469954Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"        RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  \\\n0              1  87.000000  34.118411   0   2   0  165.100000   1  829    2   \n1              2  82.372284  31.573280   0   0   1  162.983897   1  724    0   \n2              3  50.000000  27.771653   0   0   1  165.100000   1  895    2   \n3              4  66.236109  26.515922   0   0   1  167.009549   1  637    0   \n4              5  81.303299  20.843691   0   0   1  158.165419   0  564    0   \n...          ...        ...        ...  ..  ..  ..         ...  ..  ...  ...   \n246117    246118  65.149110  33.357948   0   0   1  156.317941   1  711    0   \n246118    246119  48.000000  46.736176   0   0   1  157.000000   1  594    2   \n246119    246120  57.472080  41.854115   1   0   0  189.868698   2  455    0   \n246120    246121  66.000000  23.738662   1   0   1  168.000000   2  609    0   \n246121    246122  50.257640  32.753911   0   2   0  173.665068   1  637    0   \n\n        ...       X69       X70  X71  X72       X73  X74       X75  X76  X77  \\\n0       ...  0.110000  0.040000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n1       ...  0.100292  0.033431  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n2       ...  0.020000  0.010000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n3       ...  0.108249  0.039363  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n4       ...  0.164645  0.069242  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n...     ...       ...       ...  ...  ...       ...  ...       ...  ...  ...   \n246117  ...  0.088610  0.027152  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n246118  ... -1.000000  0.560000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n246119  ...  0.032961  0.020601  0.0  0.0  0.587987  0.0  0.412013  0.0  0.0   \n246120  ...  0.020000 -1.000000  0.0  0.0  1.000000  0.0  0.000000  0.0  0.0   \n246121  ...  0.013712  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n\n             X78  \n0       0.000000  \n1       0.000000  \n2       0.000000  \n3       0.000000  \n4       0.000000  \n...          ...  \n246117  0.000000  \n246118  0.000000  \n246119  0.412013  \n246120  0.000000  \n246121  0.000000  \n\n[246122 rows x 78 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RecordId</th>\n      <th>X2</th>\n      <th>X3</th>\n      <th>X4</th>\n      <th>X5</th>\n      <th>X6</th>\n      <th>X7</th>\n      <th>X8</th>\n      <th>X9</th>\n      <th>X10</th>\n      <th>...</th>\n      <th>X69</th>\n      <th>X70</th>\n      <th>X71</th>\n      <th>X72</th>\n      <th>X73</th>\n      <th>X74</th>\n      <th>X75</th>\n      <th>X76</th>\n      <th>X77</th>\n      <th>X78</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>87.000000</td>\n      <td>34.118411</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>165.100000</td>\n      <td>1</td>\n      <td>829</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.110000</td>\n      <td>0.040000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>82.372284</td>\n      <td>31.573280</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>162.983897</td>\n      <td>1</td>\n      <td>724</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.100292</td>\n      <td>0.033431</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>50.000000</td>\n      <td>27.771653</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>165.100000</td>\n      <td>1</td>\n      <td>895</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.020000</td>\n      <td>0.010000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>66.236109</td>\n      <td>26.515922</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>167.009549</td>\n      <td>1</td>\n      <td>637</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.108249</td>\n      <td>0.039363</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>81.303299</td>\n      <td>20.843691</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>158.165419</td>\n      <td>0</td>\n      <td>564</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.164645</td>\n      <td>0.069242</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>246117</th>\n      <td>246118</td>\n      <td>65.149110</td>\n      <td>33.357948</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>156.317941</td>\n      <td>1</td>\n      <td>711</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.088610</td>\n      <td>0.027152</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>246118</th>\n      <td>246119</td>\n      <td>48.000000</td>\n      <td>46.736176</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>157.000000</td>\n      <td>1</td>\n      <td>594</td>\n      <td>2</td>\n      <td>...</td>\n      <td>-1.000000</td>\n      <td>0.560000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>246119</th>\n      <td>246120</td>\n      <td>57.472080</td>\n      <td>41.854115</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>189.868698</td>\n      <td>2</td>\n      <td>455</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.032961</td>\n      <td>0.020601</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.587987</td>\n      <td>0.0</td>\n      <td>0.412013</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.412013</td>\n    </tr>\n    <tr>\n      <th>246120</th>\n      <td>246121</td>\n      <td>66.000000</td>\n      <td>23.738662</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>168.000000</td>\n      <td>2</td>\n      <td>609</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.020000</td>\n      <td>-1.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>246121</th>\n      <td>246122</td>\n      <td>50.257640</td>\n      <td>32.753911</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>173.665068</td>\n      <td>1</td>\n      <td>637</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.013712</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>246122 rows Ã— 78 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# so as per our X output, we can see that number of columns in train_data is 79 and number of columns in X is 78 meaning we have successfully performed our removal of target variable\n# now to get the target variable alone, we can just get it alone,\nY = train_data_processed['Y']\nY # lets see what it is\n# as per our Y output, we can see it is of one column and 246k rows which means we have successfully extracted the target variable column","metadata":{"papermill":{"duration":0.023643,"end_time":"2024-11-07T20:19:59.654979","exception":false,"start_time":"2024-11-07T20:19:59.631336","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:34:53.472034Z","iopub.execute_input":"2024-11-09T20:34:53.472322Z","iopub.status.idle":"2024-11-09T20:34:53.479744Z","shell.execute_reply.started":"2024-11-09T20:34:53.472292Z","shell.execute_reply":"2024-11-09T20:34:53.478930Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"0         0\n1         0\n2         0\n3         0\n4         0\n         ..\n246117    0\n246118    1\n246119    0\n246120    0\n246121    0\nName: Y, Length: 246122, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data Imputation \nmany cells in our data may be empty - we must fill these cells with data. we have multiple options to deal with them:\n- we remove the entire rows (Case 1)\n- we fill the cells with the average of the column (Case 2)\n- we fill the cells based on KNN imputation (nearest neighbour) (Case 3)","metadata":{"papermill":{"duration":0.013172,"end_time":"2024-11-07T20:19:59.681675","exception":false,"start_time":"2024-11-07T20:19:59.668503","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Average Mean Imputation\n# ----------------------------- case -----------------------------\n# this will fill all the empty spaces using the average of all the spaces\nimputer = SimpleImputer(strategy='mean')","metadata":{"papermill":{"duration":0.020662,"end_time":"2024-11-07T20:19:59.715854","exception":false,"start_time":"2024-11-07T20:19:59.695192","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:34:53.480806Z","iopub.execute_input":"2024-11-09T20:34:53.481129Z","iopub.status.idle":"2024-11-09T20:34:53.489039Z","shell.execute_reply.started":"2024-11-09T20:34:53.481092Z","shell.execute_reply":"2024-11-09T20:34:53.488148Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# KNN Imputation\n# ----------------------------- case -----------------------------\n# this fills them in using k-nearest neighbours of all the spaces\n# imputer = KNNImputer(n_neighbors=7)","metadata":{"papermill":{"duration":0.019622,"end_time":"2024-11-07T20:19:59.748923","exception":false,"start_time":"2024-11-07T20:19:59.729301","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:34:53.493385Z","iopub.execute_input":"2024-11-09T20:34:53.494436Z","iopub.status.idle":"2024-11-09T20:34:53.502664Z","shell.execute_reply.started":"2024-11-09T20:34:53.494393Z","shell.execute_reply":"2024-11-09T20:34:53.501798Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"X = imputer.fit_transform(X)                                        # fill them in X\ntest_data_processed = imputer.transform(test_data_processed)    # fill them in test data","metadata":{"papermill":{"duration":0.52768,"end_time":"2024-11-07T20:20:00.289899","exception":false,"start_time":"2024-11-07T20:19:59.762219","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:34:53.503799Z","iopub.execute_input":"2024-11-09T20:34:53.504539Z","iopub.status.idle":"2024-11-09T20:34:53.998716Z","shell.execute_reply.started":"2024-11-09T20:34:53.504496Z","shell.execute_reply":"2024-11-09T20:34:53.997941Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Data Scaling\nsome columns may be very large then other columns when compared. it would not affect at the moment as we are using decision trees, but to maintain a fair enviroment, we shall perform scaling on every run.\nthere are two types of scaling: \n- min max scaling (also known as normalization)\n- standardisation (z-score normalization)\n- max abs scaler\n- robust scaler\n- normalizer","metadata":{"papermill":{"duration":0.013394,"end_time":"2024-11-07T20:20:00.317159","exception":false,"start_time":"2024-11-07T20:20:00.303765","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ----------------------------- case  -----------------------------\n# in this case we shall perform min max scaling. to do that, we must use our MinMaxScaler that we have imported above\nscaler = MinMaxScaler()\n# now we must use this scaler to scale X\nscaler.fit_transform(X)","metadata":{"papermill":{"duration":0.157444,"end_time":"2024-11-07T20:20:00.488147","exception":false,"start_time":"2024-11-07T20:20:00.330703","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:34:53.999792Z","iopub.execute_input":"2024-11-09T20:34:54.000107Z","iopub.status.idle":"2024-11-09T20:34:54.135256Z","shell.execute_reply.started":"2024-11-09T20:34:54.000074Z","shell.execute_reply":"2024-11-09T20:34:54.134264Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array([[0.00000000e+00, 9.72602740e-01, 3.63856188e-01, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [4.06304216e-06, 9.09209364e-01, 3.15807703e-01, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [8.12608432e-06, 4.65753425e-01, 2.44038356e-01, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       ...,\n       [9.99991874e-01, 5.68110690e-01, 5.09895343e-01, ...,\n        0.00000000e+00, 0.00000000e+00, 4.12013395e-01],\n       [9.99995937e-01, 6.84931507e-01, 1.67901180e-01, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [1.00000000e+00, 4.69282739e-01, 3.38096342e-01, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"},"metadata":{}}]},{"cell_type":"code","source":"# ----------------------------- case -----------------------------\n# scaler = MaxAbsScaler()\n# # now we must use this scaler to scale X\n# scaler.fit_transform(X)","metadata":{"papermill":{"duration":0.020851,"end_time":"2024-11-07T20:20:00.522797","exception":false,"start_time":"2024-11-07T20:20:00.501946","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:34:54.136332Z","iopub.execute_input":"2024-11-09T20:34:54.136625Z","iopub.status.idle":"2024-11-09T20:34:54.142352Z","shell.execute_reply.started":"2024-11-09T20:34:54.136595Z","shell.execute_reply":"2024-11-09T20:34:54.141292Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# our output shows us that every value in the array is between 0 and 1. thus lets save this value on X\nX = scaler.fit_transform(X)\n\n# now we must do the same on our test_data set\ntest_data_processed = scaler.transform(test_data_processed)","metadata":{"papermill":{"duration":0.193573,"end_time":"2024-11-07T20:20:00.729710","exception":false,"start_time":"2024-11-07T20:20:00.536137","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:34:54.143502Z","iopub.execute_input":"2024-11-09T20:34:54.144338Z","iopub.status.idle":"2024-11-09T20:34:54.322420Z","shell.execute_reply.started":"2024-11-09T20:34:54.144303Z","shell.execute_reply":"2024-11-09T20:34:54.321404Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Filters\nthere are two types of filters to filter out columns/features:\n- variance filter (a column which has same values throughout the column like all are sunny)\n- correlation filter (two columns which are same like weight in kg and weight in pounds)","metadata":{"papermill":{"duration":0.013362,"end_time":"2024-11-07T20:20:00.756855","exception":false,"start_time":"2024-11-07T20:20:00.743493","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(\"X : \", X.shape)\nprint(\"test data : \", test_data_processed.shape)","metadata":{"papermill":{"duration":0.02154,"end_time":"2024-11-07T20:20:00.791959","exception":false,"start_time":"2024-11-07T20:20:00.770419","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:34:54.323554Z","iopub.execute_input":"2024-11-09T20:34:54.323862Z","iopub.status.idle":"2024-11-09T20:34:54.329537Z","shell.execute_reply.started":"2024-11-09T20:34:54.323829Z","shell.execute_reply":"2024-11-09T20:34:54.328588Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"X :  (246122, 78)\ntest data :  (105482, 78)\n","output_type":"stream"}]},{"cell_type":"code","source":"# variance filter\n# ----------------------------- case  -----------------------------\n# variance_filter = VarianceThreshold(threshold=0.001)  # Adjust the threshold if needed\n# X = variance_filter.fit_transform(X)\n# test_data_processed = variance_filter.fit_transform(test_data_processed)\nX.shape","metadata":{"papermill":{"duration":0.021917,"end_time":"2024-11-07T20:20:00.827296","exception":false,"start_time":"2024-11-07T20:20:00.805379","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:34:54.331052Z","iopub.execute_input":"2024-11-09T20:34:54.331337Z","iopub.status.idle":"2024-11-09T20:34:54.339745Z","shell.execute_reply.started":"2024-11-09T20:34:54.331307Z","shell.execute_reply":"2024-11-09T20:34:54.338759Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(246122, 78)"},"metadata":{}}]},{"cell_type":"code","source":"test_data_processed.shape","metadata":{"papermill":{"duration":0.026133,"end_time":"2024-11-07T20:20:00.868012","exception":false,"start_time":"2024-11-07T20:20:00.841879","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:34:54.341526Z","iopub.execute_input":"2024-11-09T20:34:54.341918Z","iopub.status.idle":"2024-11-09T20:34:54.352761Z","shell.execute_reply.started":"2024-11-09T20:34:54.341864Z","shell.execute_reply":"2024-11-09T20:34:54.351903Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(105482, 78)"},"metadata":{}}]},{"cell_type":"code","source":"# # correlation filter\n# # ----------------------------- case  -----------------------------\n# corr_matrix = pd.DataFrame(X).corr().abs()\n# upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n# to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n# X = pd.DataFrame(X).drop(columns=to_drop)\n# test_data_processed = pd.DataFrame(test_data_processed).drop(columns=to_drop)\nX.shape","metadata":{"papermill":{"duration":0.023607,"end_time":"2024-11-07T20:20:00.905745","exception":false,"start_time":"2024-11-07T20:20:00.882138","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:34:54.354212Z","iopub.execute_input":"2024-11-09T20:34:54.354559Z","iopub.status.idle":"2024-11-09T20:34:54.364098Z","shell.execute_reply.started":"2024-11-09T20:34:54.354519Z","shell.execute_reply":"2024-11-09T20:34:54.362857Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(246122, 78)"},"metadata":{}}]},{"cell_type":"code","source":"test_data_processed.shape","metadata":{"papermill":{"duration":0.023492,"end_time":"2024-11-07T20:20:00.943356","exception":false,"start_time":"2024-11-07T20:20:00.919864","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:34:54.365330Z","iopub.execute_input":"2024-11-09T20:34:54.365730Z","iopub.status.idle":"2024-11-09T20:34:54.378456Z","shell.execute_reply.started":"2024-11-09T20:34:54.365688Z","shell.execute_reply":"2024-11-09T20:34:54.377574Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(105482, 78)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data Splitting - train and validate\nnow our test_data set is of rows with NO target variable whereas the train_data set is WITH target variable.\nour rules in machine learning is that we must train half or 70% of the data and then we must check its accuracy using the remaining half or 30% of the data - we can only check accuracy IF we have the answers i.e. the target variable. \nSo, what we need to do is, is split the train_data set into 2, by a 70% and 30% ratio. we train the model using the 70% and then test the model using the 30% and then use that model to predict the test_data set.","metadata":{"papermill":{"duration":0.016785,"end_time":"2024-11-07T20:20:00.974594","exception":false,"start_time":"2024-11-07T20:20:00.957809","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# holdout method\ntrainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.3, random_state=2)","metadata":{"papermill":{"duration":0.273955,"end_time":"2024-11-07T20:20:01.264394","exception":false,"start_time":"2024-11-07T20:20:00.990439","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:34:54.379772Z","iopub.execute_input":"2024-11-09T20:34:54.380121Z","iopub.status.idle":"2024-11-09T20:34:54.615792Z","shell.execute_reply.started":"2024-11-09T20:34:54.380082Z","shell.execute_reply":"2024-11-09T20:34:54.614961Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# functions","metadata":{"papermill":{"duration":0.013949,"end_time":"2024-11-07T20:20:01.292747","exception":false,"start_time":"2024-11-07T20:20:01.278798","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def fbselection(direction, sample_model, features, X, trainX, trainY, testX, test_data_processed):\n    print(\"starting\")\n    selection = SequentialFeatureSelector(sample_model, direction=direction, n_features_to_select=features, scoring='roc_auc')\n    return modelSelector(sample_model, selection, X, trainX, trainY, testX, test_data_processed)\n\ndef modelSelector(sample_model, selection, X, trainX, trainY, testX, test_data_processed):\n    print(\"start extracting\")\n    trainX = selection.fit_transform(trainX, trainY)\n    print(\"extracted, transforming\")\n    testX = selection.transform(testX)                                  # Ensure the test set is transformed similarly\n    test_data_processed = selection.transform(test_data_processed)      # test data is also transformed\n    X = selection.transform(X)                                          # full data transforming\n    print(\"transformed\")\n    return sample_model, X, trainX, trainY, testX, test_data_processed\n\ndef kbest(sample_model, features, X, trainX, trainY, testX, test_data_processed):\n    print(\"starting\")\n    selection = SelectKBest(score_func=f_classif, k=features)\n    return modelSelector(sample_model, selection, X, trainX, trainY, testX, test_data_processed)","metadata":{"papermill":{"duration":0.023729,"end_time":"2024-11-07T20:20:01.330428","exception":false,"start_time":"2024-11-07T20:20:01.306699","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:34:54.616979Z","iopub.execute_input":"2024-11-09T20:34:54.617302Z","iopub.status.idle":"2024-11-09T20:34:54.625434Z","shell.execute_reply.started":"2024-11-09T20:34:54.617269Z","shell.execute_reply":"2024-11-09T20:34:54.624603Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def featureImportance(sample_model, features, X, trainX, trainY, testX, test_data_processed):\n    print(\"fitting\")\n    \n    # fit the model\n    sample_model.fit(trainX, trainY)\n\n    print(\"extracting features\")\n\n    # extract all the feature names from data\n    importances = sample_model.feature_importances_\n    feature_names = train_data_processed.drop(columns=['Y']).columns\n    print(feature_names)\n\n    # sort with respect to importance\n    feature_importance_df = pd.DataFrame({\n        'Feature': feature_names,\n        'Importance': importances\n    }).sort_values(by='Importance', ascending=False)\n\n    # extract the top ones\n    top_features = feature_importance_df['Feature'].head(features).values\n    print(top_features)\n\n    # change all data according to the top ones we have selected\n    trainX = pd.DataFrame(trainX, columns=feature_names)[top_features]\n    testX = pd.DataFrame(testX, columns=feature_names)[top_features]\n    X = pd.DataFrame(X, columns=feature_names)[top_features]\n    test_data_processed = pd.DataFrame(test_data_processed, columns=feature_names)[top_features]\n\n    print(\"features extracted\")\n    \n    # retrain the model\n    sample_model.fit(trainX, trainY)\n\n    print(\"features trained\")\n    \n    return sample_model, X, trainX, trainY, testX, test_data_processed","metadata":{"papermill":{"duration":0.025235,"end_time":"2024-11-07T20:20:01.370030","exception":false,"start_time":"2024-11-07T20:20:01.344795","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:34:54.626670Z","iopub.execute_input":"2024-11-09T20:34:54.626998Z","iopub.status.idle":"2024-11-09T20:34:54.637011Z","shell.execute_reply.started":"2024-11-09T20:34:54.626952Z","shell.execute_reply":"2024-11-09T20:34:54.636252Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## model intialization\nhere model is intialized","metadata":{"papermill":{"duration":0.013797,"end_time":"2024-11-07T20:20:01.398362","exception":false,"start_time":"2024-11-07T20:20:01.384565","status":"completed"},"tags":[]}},{"cell_type":"code","source":"### SAMPLE ###\n# -------------------- case X (add the case number here) --------------------\n# # intialize models here as model_1, model_2, perform feature selection and feature importance BEFORE they are inserted in stacking\n# model_1 = \n# model_2 = \n# # intialize estimators here\n# estimators = [('model_1', model_1), ('model_2', model_2)]\n# # intialize stacking\n# model = StackingClassifier(estimators=estimators, final_estimator=model_name, verbose=2)","metadata":{"papermill":{"duration":0.021268,"end_time":"2024-11-07T20:20:01.433590","exception":false,"start_time":"2024-11-07T20:20:01.412322","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:34:54.638241Z","iopub.execute_input":"2024-11-09T20:34:54.638616Z","iopub.status.idle":"2024-11-09T20:34:54.651652Z","shell.execute_reply.started":"2024-11-09T20:34:54.638557Z","shell.execute_reply":"2024-11-09T20:34:54.650861Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# # -------------------- case 191d --------------------\n# # intialize models here as model_1, model_2, perform feature selection and feature importance BEFORE they are inserted in stacking\n# model_3 = xgb.XGBClassifier(n_estimators=2000 ,learning_rate= 0.03, max_depth = 4, random_state  = 42, device = \"cuda\")\n# model_3, X, trainX, trainY, testX, test_data_processed = featureImportance(model_3, 40, X, trainX, trainY, testX, test_data_processed)\n# model_2 = lgb.LGBMClassifier(learning_rate=0.02, max_depth=2, n_estimators=4000 , device='gpu')\n# model_1 = BaggingClassifier(estimator= model_2, n_estimators=100, verbose=2, n_jobs=-1)\n# # intialize estimators here\n# estimators = [('model_1', model_1), ('model_2', model_2), ('model_3', model_3)]\n# # intialize stacking\n# model = StackingClassifier(estimators=estimators, final_estimator=model_2)","metadata":{"execution":{"iopub.status.busy":"2024-11-09T20:34:54.652956Z","iopub.execute_input":"2024-11-09T20:34:54.653255Z","iopub.status.idle":"2024-11-09T20:34:54.661861Z","shell.execute_reply.started":"2024-11-09T20:34:54.653226Z","shell.execute_reply":"2024-11-09T20:34:54.661171Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# # -------------------- case 191e --------------------\n# # intialize models here as model_1, model_2, perform feature selection and feature importance BEFORE they are inserted in stacking\n# model_1 = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=15, max_features=60, min_samples_leaf=80)\n# model_2 = BaggingClassifier(estimator=model_1, n_estimators=50, verbose=2)\n# # intialize estimators here\n# estimators = [('model_1', model_1), ('model_2', model_2)]\n# # intialize stacking\n# model = StackingClassifier(estimators=estimators, final_estimator=DecisionTreeClassifier(), verbose=2)","metadata":{"execution":{"iopub.status.busy":"2024-11-09T20:34:54.663148Z","iopub.execute_input":"2024-11-09T20:34:54.663812Z","iopub.status.idle":"2024-11-09T20:34:54.675473Z","shell.execute_reply.started":"2024-11-09T20:34:54.663770Z","shell.execute_reply":"2024-11-09T20:34:54.674671Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# # -------------------- case 194a, 194b --------------------\n# # intialize models here as model_1, model_2, ..., perform feature selection and feature importance BEFORE they are inserted in stacking\n# model_1 = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=15, random_state=42)\n# model_2 = DecisionTreeClassifier(criterion='gini', max_depth=7, min_samples_split=10, random_state=42)\n# model_3 = DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_split=5, random_state=42)\n# # Initialize estimators for stacking\n# estimators = [('model_1', model_1), ('model_2', model_2), ('model_3', model_3)]\n# # Set up the StackingClassifier using another Decision Tree as the final estimator\n# model = StackingClassifier(estimators=estimators, final_estimator=DecisionTreeClassifier(max_depth=8, random_state=42))","metadata":{"execution":{"iopub.status.busy":"2024-11-09T20:34:54.676410Z","iopub.execute_input":"2024-11-09T20:34:54.676676Z","iopub.status.idle":"2024-11-09T20:34:54.685912Z","shell.execute_reply.started":"2024-11-09T20:34:54.676646Z","shell.execute_reply":"2024-11-09T20:34:54.685069Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# # -------------------- case 197 (add the case number here) --------------------\n# # intialize models here as model_1, model_2, perform feature selection and feature importance BEFORE they are inserted in stacking\n# model_1 = GaussianNB(var_smoothing=1e-9)\n# model_2 = GaussianNB(var_smoothing=1e-8)\n# model_3 = GaussianNB(var_smoothing=1e-7)\n# # Initialize estimators for stacking\n# estimators = [('nb1', model_1), ('nb2', model_2), ('nb3', model_3)]\n# # Set up the StackingClassifier using another Naive Bayes as the final estimator\n# model = StackingClassifier(estimators=estimators, final_estimator=GaussianNB(), verbose=2)","metadata":{"execution":{"iopub.status.busy":"2024-11-09T20:34:54.687011Z","iopub.execute_input":"2024-11-09T20:34:54.687294Z","iopub.status.idle":"2024-11-09T20:34:54.698419Z","shell.execute_reply.started":"2024-11-09T20:34:54.687264Z","shell.execute_reply":"2024-11-09T20:34:54.697691Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# -------------------- case X (add the case number here) --------------------\n# intialize models here as model_1, model_2, perform feature selection and feature importance BEFORE they are inserted in stacking\nmodel_1 = KNeighborsClassifier(n_neighbors=1500, weights=\"distance\")\nmodel_2 = KNeighborsClassifier(n_neighbors=1000, weights=\"distance\")\nmodel_3 = KNeighborsClassifier(n_neighbors=1200, weights=\"uniform\")\n# Define estimators for stacking\nestimators = [('knn1', model_1), ('knn2', model_2), ('knn3', model_3)]\n# Initialize StackingClassifier with KNN as the final estimator\nmodel = StackingClassifier(estimators=estimators, final_estimator=KNeighborsClassifier(n_neighbors=500, weights=\"distance\"), verbose=2)","metadata":{"execution":{"iopub.status.busy":"2024-11-09T20:34:54.703949Z","iopub.execute_input":"2024-11-09T20:34:54.704235Z","iopub.status.idle":"2024-11-09T20:34:54.710777Z","shell.execute_reply.started":"2024-11-09T20:34:54.704205Z","shell.execute_reply":"2024-11-09T20:34:54.709945Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# # forward selection\n# model_1, X, trainX, trainY, testX, test_data_processed = fbselection('forward', model_1, 15, X, trainX, trainY, testX, test_data_processed)","metadata":{"execution":{"iopub.status.busy":"2024-11-09T20:34:54.711848Z","iopub.execute_input":"2024-11-09T20:34:54.712162Z","iopub.status.idle":"2024-11-09T20:34:54.724508Z","shell.execute_reply.started":"2024-11-09T20:34:54.712132Z","shell.execute_reply":"2024-11-09T20:34:54.723639Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# kbest selection\nmodel_1, X, trainX, trainY, testX, test_data_processed = kbest(model_1, 5, X, trainX, trainY, testX, test_data_processed)","metadata":{"execution":{"iopub.status.busy":"2024-11-09T20:34:54.725468Z","iopub.execute_input":"2024-11-09T20:34:54.725759Z","iopub.status.idle":"2024-11-09T20:34:54.941630Z","shell.execute_reply.started":"2024-11-09T20:34:54.725728Z","shell.execute_reply":"2024-11-09T20:34:54.940702Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"starting\nstart extracting\nextracted, transforming\ntransformed\n","output_type":"stream"}]},{"cell_type":"code","source":"# feature importance\n# model_4, X, trainX, trainY, testX, test_data_processed = featureImportance( xgb.XGBClassifier(), 45, X, trainX, trainY, testX, test_data_processed )","metadata":{"execution":{"iopub.status.busy":"2024-11-09T20:34:54.942772Z","iopub.execute_input":"2024-11-09T20:34:54.943166Z","iopub.status.idle":"2024-11-09T20:34:54.947820Z","shell.execute_reply.started":"2024-11-09T20:34:54.943133Z","shell.execute_reply":"2024-11-09T20:34:54.946875Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"print(\"X shape -> \", X.shape)\nprint(\"trainX shape -> \", trainX.shape)\nprint(\"testX shape -> \", testX.shape)\nprint(\"test_data_processed shape -> \", test_data_processed.shape)","metadata":{"papermill":{"duration":0.02329,"end_time":"2024-11-07T20:20:14.141486","exception":false,"start_time":"2024-11-07T20:20:14.118196","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:59:17.664418Z","iopub.execute_input":"2024-11-09T20:59:17.665239Z","iopub.status.idle":"2024-11-09T20:59:17.670557Z","shell.execute_reply.started":"2024-11-09T20:59:17.665194Z","shell.execute_reply":"2024-11-09T20:59:17.669286Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"X shape ->  (246122, 5)\ntrainX shape ->  (172285, 5)\ntestX shape ->  (73837, 5)\ntest_data_processed shape ->  (105482, 5)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Bagging intialization\nhere we will introduce and intialize bagging","metadata":{"papermill":{"duration":0.014003,"end_time":"2024-11-07T20:20:14.169733","exception":false,"start_time":"2024-11-07T20:20:14.155730","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# model = BaggingClassifier(estimator=model, n_estimators=10, verbose=2)\n# -- ","metadata":{"papermill":{"duration":0.020997,"end_time":"2024-11-07T20:20:14.205105","exception":false,"start_time":"2024-11-07T20:20:14.184108","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:59:17.678802Z","iopub.execute_input":"2024-11-09T20:59:17.679260Z","iopub.status.idle":"2024-11-09T20:59:17.683699Z","shell.execute_reply.started":"2024-11-09T20:59:17.679226Z","shell.execute_reply":"2024-11-09T20:59:17.682787Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"## model running\nhere we run the model","metadata":{"papermill":{"duration":0.014144,"end_time":"2024-11-07T20:20:14.233534","exception":false,"start_time":"2024-11-07T20:20:14.219390","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# fit the model\nmodel.fit(trainX, trainY)","metadata":{"papermill":{"duration":1652.161599,"end_time":"2024-11-07T20:47:46.409387","exception":false,"start_time":"2024-11-07T20:20:14.247788","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:59:17.685105Z","iopub.execute_input":"2024-11-09T20:59:17.685373Z","iopub.status.idle":"2024-11-09T20:59:18.863822Z","shell.execute_reply.started":"2024-11-09T20:59:17.685344Z","shell.execute_reply":"2024-11-09T20:59:18.861622Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Building estimator 1 of 10 for this parallel run (total 10)...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_base.py:35\u001b[0m, in \u001b[0;36m_fit_single_estimator\u001b[0;34m(estimator, X, y, sample_weight, message_clsname, message)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m---> 35\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n","\u001b[0;31mTypeError\u001b[0m: KNeighborsClassifier.fit() got an unexpected keyword argument 'sample_weight'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# fit the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainY\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_bagging.py:337\u001b[0m, in \u001b[0;36mBaseBagging.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# Convert data (X is required to be 2d and indexable)\u001b[39;00m\n\u001b[1;32m    329\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    330\u001b[0m     X,\n\u001b[1;32m    331\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    335\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    336\u001b[0m )\n\u001b[0;32m--> 337\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_bagging.py:472\u001b[0m, in \u001b[0;36mBaseBagging._fit\u001b[0;34m(self, X, y, max_samples, max_depth, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    469\u001b[0m seeds \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mrandint(MAX_INT, size\u001b[38;5;241m=\u001b[39mn_more_estimators)\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds \u001b[38;5;241m=\u001b[39m seeds\n\u001b[0;32m--> 472\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_estimators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_n_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;66;03m# Reduce\u001b[39;00m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    491\u001b[0m     itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(t[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m all_results)\n\u001b[1;32m    492\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_bagging.py:141\u001b[0m, in \u001b[0;36m_parallel_build_estimators\u001b[0;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose, check_input)\u001b[0m\n\u001b[1;32m    138\u001b[0m         curr_sample_weight[not_indices_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    140\u001b[0m     X_ \u001b[38;5;241m=\u001b[39m X[:, features] \u001b[38;5;28;01mif\u001b[39;00m requires_feature_indexing \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[0;32m--> 141\u001b[0m     \u001b[43mestimator_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     X_ \u001b[38;5;241m=\u001b[39m X[indices][:, features] \u001b[38;5;28;01mif\u001b[39;00m requires_feature_indexing \u001b[38;5;28;01melse\u001b[39;00m X[indices]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_stacking.py:660\u001b[0m, in \u001b[0;36mStackingClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m    659\u001b[0m     y_encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder\u001b[38;5;241m.\u001b[39mtransform(y)\n\u001b[0;32m--> 660\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_stacking.py:209\u001b[0m, in \u001b[0;36m_BaseStacking.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mappend(estimator)\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;66;03m# Fit the base estimators on the whole training data. Those\u001b[39;00m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;66;03m# base estimators will be used in transform, predict, and\u001b[39;00m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;66;03m# predict_proba. They are exposed publicly.\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_single_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mall_estimators\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdrop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_estimators_ \u001b[38;5;241m=\u001b[39m Bunch()\n\u001b[1;32m    216\u001b[0m est_fitted_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_base.py:38\u001b[0m, in \u001b[0;36m_fit_single_estimator\u001b[0;34m(estimator, X, y, sample_weight, message_clsname, message)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munexpected keyword argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(exc):\n\u001b[0;32m---> 38\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     39\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     40\u001b[0m                     estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m     41\u001b[0m                 )\n\u001b[1;32m     42\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","\u001b[0;31mTypeError\u001b[0m: Underlying estimator KNeighborsClassifier does not support sample weights."],"ename":"TypeError","evalue":"Underlying estimator KNeighborsClassifier does not support sample weights.","output_type":"error"}]},{"cell_type":"code","source":"# predict using this model\ny_pred = model.predict(testX)","metadata":{"papermill":{"duration":482.700644,"end_time":"2024-11-07T20:55:49.135292","exception":false,"start_time":"2024-11-07T20:47:46.434648","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:59:18.864972Z","iopub.status.idle":"2024-11-09T20:59:18.865462Z","shell.execute_reply.started":"2024-11-09T20:59:18.865204Z","shell.execute_reply":"2024-11-09T20:59:18.865230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display the accuracy of this prediction\naccuracy = accuracy_score(testY, y_pred)\nprint(\"model accuracy = \", accuracy, \"   \")\n\n# now lets calculate the ROC AUC score according to this prediction\nroc_score = roc_auc_score(testY, y_pred)\nprint(\"roc score = \", roc_score, \"   \")","metadata":{"papermill":{"duration":0.075397,"end_time":"2024-11-07T20:55:49.239118","exception":false,"start_time":"2024-11-07T20:55:49.163721","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:59:18.866777Z","iopub.status.idle":"2024-11-09T20:59:18.867251Z","shell.execute_reply.started":"2024-11-09T20:59:18.867021Z","shell.execute_reply":"2024-11-09T20:59:18.867046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## predict for test dataset\nfit the model and predict for test dataset","metadata":{"papermill":{"duration":0.019827,"end_time":"2024-11-07T20:55:49.286324","exception":false,"start_time":"2024-11-07T20:55:49.266497","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model.fit(X, Y)","metadata":{"papermill":{"duration":2249.874308,"end_time":"2024-11-07T21:33:19.180774","exception":false,"start_time":"2024-11-07T20:55:49.306466","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:59:18.868432Z","iopub.status.idle":"2024-11-09T20:59:18.868760Z","shell.execute_reply.started":"2024-11-09T20:59:18.868594Z","shell.execute_reply":"2024-11-09T20:59:18.868611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_prediction = model.predict_proba(test_data_processed)\n\ntest_prediction=test_prediction[:, 1]\n\nprint(test_prediction)","metadata":{"papermill":{"duration":774.78282,"end_time":"2024-11-07T21:46:13.986713","exception":false,"start_time":"2024-11-07T21:33:19.203893","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:59:18.869578Z","iopub.status.idle":"2024-11-09T20:59:18.869930Z","shell.execute_reply.started":"2024-11-09T20:59:18.869734Z","shell.execute_reply":"2024-11-09T20:59:18.869752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## write into csv\nnow we write the predictions into the csv file","metadata":{"papermill":{"duration":0.02242,"end_time":"2024-11-07T21:46:14.032429","exception":false,"start_time":"2024-11-07T21:46:14.010009","status":"completed"},"tags":[]}},{"cell_type":"code","source":"sample_data = pd.read_csv(r\"/kaggle/input/sample-sub/sample_submission.csv\")\n\nsample_data['Y'] = test_prediction\nsample_data\n\nsample_data.to_csv(r\"/kaggle/working/stacking2.csv\", index=False)\nsample_data","metadata":{"papermill":{"duration":0.455346,"end_time":"2024-11-07T21:46:14.510398","exception":false,"start_time":"2024-11-07T21:46:14.055052","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:59:18.872014Z","iopub.status.idle":"2024-11-09T20:59:18.872349Z","shell.execute_reply.started":"2024-11-09T20:59:18.872183Z","shell.execute_reply":"2024-11-09T20:59:18.872200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"papermill":{"duration":0.053693,"end_time":"2024-11-07T21:46:14.588137","exception":false,"start_time":"2024-11-07T21:46:14.534444","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T20:59:18.873390Z","iopub.status.idle":"2024-11-09T20:59:18.873713Z","shell.execute_reply.started":"2024-11-09T20:59:18.873549Z","shell.execute_reply":"2024-11-09T20:59:18.873565Z"},"trusted":true},"execution_count":null,"outputs":[]}]}