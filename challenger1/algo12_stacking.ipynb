{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "126be725",
   "metadata": {
    "papermill": {
     "duration": 0.013014,
     "end_time": "2024-11-07T20:19:46.538794",
     "exception": false,
     "start_time": "2024-11-07T20:19:46.525780",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing Libraries\n",
    "in this part we will install all the necessary libraries on command prompt and then import the necessary functions from those libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb0caee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:19:46.565504Z",
     "iopub.status.busy": "2024-11-07T20:19:46.565120Z",
     "iopub.status.idle": "2024-11-07T20:19:52.402667Z",
     "shell.execute_reply": "2024-11-07T20:19:52.401802Z"
    },
    "papermill": {
     "duration": 5.853121,
     "end_time": "2024-11-07T20:19:52.405091",
     "exception": false,
     "start_time": "2024-11-07T20:19:46.551970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing all the necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import mean\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# step 1: preprocessing\n",
    "from sklearn.impute import SimpleImputer # import some strategic imputer to fill in any missing values using mean\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler, Normalizer # scale all the values to one range to avoid any biasness (this bias is seen in mostly naive bayes and knn etc)\n",
    "\n",
    "from sklearn.impute import KNNImputer # import some strategic imputer to fill missing values using KNN (finds the nearest neighbour and fills it with that value)\n",
    "\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, SelectKBest, f_classif, VarianceThreshold\n",
    "\n",
    "# step 2: data division\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, cross_val_score, GridSearchCV, ParameterGrid # to divide the code into train/test using a specific percentage or with/without replacement\n",
    "\n",
    "# step 3: model\n",
    "from sklearn.tree import DecisionTreeClassifier                                                        \n",
    "from sklearn.naive_bayes import GaussianNB                                                              \n",
    "from sklearn.neighbors import KNeighborsClassifier                                                       \n",
    "from sklearn.ensemble import BaggingClassifier, VotingClassifier, ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, StackingClassifier\n",
    "import lightgbm as lgb \n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier \n",
    "\n",
    "# step 4: displaying accuracy\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score # to display the accuracy of our tree\n",
    "\n",
    "# step 5: warning filter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec0c9bc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:19:52.430651Z",
     "iopub.status.busy": "2024-11-07T20:19:52.429823Z",
     "iopub.status.idle": "2024-11-07T20:19:52.434215Z",
     "shell.execute_reply": "2024-11-07T20:19:52.433355Z"
    },
    "papermill": {
     "duration": 0.018925,
     "end_time": "2024-11-07T20:19:52.436076",
     "exception": false,
     "start_time": "2024-11-07T20:19:52.417151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use this block to install any libraries not on the system\n",
    "# !pip install pandas\n",
    "# !pip install sklearn\n",
    "# python -m pip install scikit-learn lightgbm xgboost catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f62347",
   "metadata": {
    "papermill": {
     "duration": 0.011237,
     "end_time": "2024-11-07T20:19:52.458899",
     "exception": false,
     "start_time": "2024-11-07T20:19:52.447662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Loading\n",
    "data shall be loaded into variables as data sets using pandas and csv readers. they will be checked to see if they are loaded properly and will be loaded as 2 sets: train and test as per given in the kaggle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c686f422",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:19:52.483708Z",
     "iopub.status.busy": "2024-11-07T20:19:52.483353Z",
     "iopub.status.idle": "2024-11-07T20:19:57.060124Z",
     "shell.execute_reply": "2024-11-07T20:19:57.059215Z"
    },
    "papermill": {
     "duration": 4.591761,
     "end_time": "2024-11-07T20:19:57.062353",
     "exception": false,
     "start_time": "2024-11-07T20:19:52.470592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.118411</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>829</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>82.372284</td>\n",
       "      <td>31.573280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162.983897</td>\n",
       "      <td>1</td>\n",
       "      <td>724</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>27.771653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>895</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>66.236109</td>\n",
       "      <td>26.515922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.009549</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>81.303299</td>\n",
       "      <td>20.843691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158.165419</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  ...  \\\n",
       "0         1  87.000000  34.118411   0   2   0  165.100000   1  829    2  ...   \n",
       "1         2  82.372284  31.573280   0   0   1  162.983897   1  724    0  ...   \n",
       "2         3  50.000000  27.771653   0   0   1  165.100000   1  895    2  ...   \n",
       "3         4  66.236109  26.515922   0   0   1  167.009549   1  637    0  ...   \n",
       "4         5  81.303299  20.843691   0   0   1  158.165419   0  564    0  ...   \n",
       "\n",
       "        X70  X71  X72  X73  X74  X75  X76  X77  X78  Y  \n",
       "0  0.040000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "1  0.033431  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "2  0.010000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "3  0.039363  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "4  0.069242  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets load the training data set\n",
    "train_data = pd.read_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger1\\iml-fall-2024-challenge-1\\train_set.csv\")\n",
    "\n",
    "# lets also check it by getting the first few rows of the data, there should be x1 - x78 and one target variable Y\n",
    "train_data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "585db5cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:19:57.089386Z",
     "iopub.status.busy": "2024-11-07T20:19:57.089050Z",
     "iopub.status.idle": "2024-11-07T20:19:59.021719Z",
     "shell.execute_reply": "2024-11-07T20:19:59.020726Z"
    },
    "papermill": {
     "duration": 1.948205,
     "end_time": "2024-11-07T20:19:59.023969",
     "exception": false,
     "start_time": "2024-11-07T20:19:57.075764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X69</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300001</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>17.122318</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>170.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300002</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>43.693579</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>814</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300003</td>\n",
       "      <td>36.064225</td>\n",
       "      <td>23.998944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.086735</td>\n",
       "      <td>1</td>\n",
       "      <td>662</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300004</td>\n",
       "      <td>61.846764</td>\n",
       "      <td>31.693449</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>182.355708</td>\n",
       "      <td>2</td>\n",
       "      <td>862</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062613</td>\n",
       "      <td>0.033153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300005</td>\n",
       "      <td>71.591991</td>\n",
       "      <td>20.086147</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>166.704917</td>\n",
       "      <td>2</td>\n",
       "      <td>335</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014854</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  ...  \\\n",
       "0    300001  79.000000  17.122318   0   0   1  170.200000   1  700    0  ...   \n",
       "1    300002  38.000000  43.693579   0   0   1  165.100000   1  814    0  ...   \n",
       "2    300003  36.064225  23.998944   0   0   1  167.086735   1  662    0  ...   \n",
       "3    300004  61.846764  31.693449   0   3   1  182.355708   2  862    0  ...   \n",
       "4    300005  71.591991  20.086147   1   0   1  166.704917   2  335    0  ...   \n",
       "\n",
       "        X69       X70  X71  X72  X73  X74  X75  X76  X77  X78  \n",
       "0  0.070000  0.030000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.050000  0.040000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.006948  0.006948  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.062613  0.033153  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.014854  0.004854  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets load the test data\n",
    "test_data = pd.read_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger1\\iml-fall-2024-challenge-1\\test_set.csv\")\n",
    "\n",
    "# check if the data has been loaded by getting the first 5 rows - there should be x1 - x78 and no target variable Y as this is test data\n",
    "test_data.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ebc4d3",
   "metadata": {
    "papermill": {
     "duration": 0.012664,
     "end_time": "2024-11-07T20:19:59.050712",
     "exception": false,
     "start_time": "2024-11-07T20:19:59.038048",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preprocessing\n",
    "before we start processing this data and using algorithms, we will fix this data first, this is called data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7f9416",
   "metadata": {
    "papermill": {
     "duration": 0.013829,
     "end_time": "2024-11-07T20:19:59.076934",
     "exception": false,
     "start_time": "2024-11-07T20:19:59.063105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Conversion of Categorical to Numerical\n",
    "First we will convert categorical data to numerical data by doing one hot encoding, which turns it into binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdb6fc9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:19:59.106812Z",
     "iopub.status.busy": "2024-11-07T20:19:59.106425Z",
     "iopub.status.idle": "2024-11-07T20:19:59.268056Z",
     "shell.execute_reply": "2024-11-07T20:19:59.267018Z"
    },
    "papermill": {
     "duration": 0.178612,
     "end_time": "2024-11-07T20:19:59.270335",
     "exception": false,
     "start_time": "2024-11-07T20:19:59.091723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.118411</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>829</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>82.372284</td>\n",
       "      <td>31.573280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162.983897</td>\n",
       "      <td>1</td>\n",
       "      <td>724</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>27.771653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>895</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>66.236109</td>\n",
       "      <td>26.515922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.009549</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>81.303299</td>\n",
       "      <td>20.843691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158.165419</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246117</th>\n",
       "      <td>246118</td>\n",
       "      <td>65.149110</td>\n",
       "      <td>33.357948</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156.317941</td>\n",
       "      <td>1</td>\n",
       "      <td>711</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246118</th>\n",
       "      <td>246119</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>46.736176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246119</th>\n",
       "      <td>246120</td>\n",
       "      <td>57.472080</td>\n",
       "      <td>41.854115</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189.868698</td>\n",
       "      <td>2</td>\n",
       "      <td>455</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246120</th>\n",
       "      <td>246121</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>23.738662</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246121</th>\n",
       "      <td>246122</td>\n",
       "      <td>50.257640</td>\n",
       "      <td>32.753911</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>173.665068</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246122 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  \\\n",
       "0              1  87.000000  34.118411   0   2   0  165.100000   1  829    2   \n",
       "1              2  82.372284  31.573280   0   0   1  162.983897   1  724    0   \n",
       "2              3  50.000000  27.771653   0   0   1  165.100000   1  895    2   \n",
       "3              4  66.236109  26.515922   0   0   1  167.009549   1  637    0   \n",
       "4              5  81.303299  20.843691   0   0   1  158.165419   0  564    0   \n",
       "...          ...        ...        ...  ..  ..  ..         ...  ..  ...  ...   \n",
       "246117    246118  65.149110  33.357948   0   0   1  156.317941   1  711    0   \n",
       "246118    246119  48.000000  46.736176   0   0   1  157.000000   1  594    2   \n",
       "246119    246120  57.472080  41.854115   1   0   0  189.868698   2  455    0   \n",
       "246120    246121  66.000000  23.738662   1   0   1  168.000000   2  609    0   \n",
       "246121    246122  50.257640  32.753911   0   2   0  173.665068   1  637    0   \n",
       "\n",
       "        ...       X70  X71  X72       X73  X74       X75  X76  X77       X78  \\\n",
       "0       ...  0.040000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "1       ...  0.033431  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "2       ...  0.010000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "3       ...  0.039363  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "4       ...  0.069242  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "...     ...       ...  ...  ...       ...  ...       ...  ...  ...       ...   \n",
       "246117  ...  0.027152  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "246118  ...  0.560000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "246119  ...  0.020601  0.0  0.0  0.587987  0.0  0.412013  0.0  0.0  0.412013   \n",
       "246120  ... -1.000000  0.0  0.0  1.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "246121  ...  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "\n",
       "        Y  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "...    ..  \n",
       "246117  0  \n",
       "246118  1  \n",
       "246119  0  \n",
       "246120  0  \n",
       "246121  0  \n",
       "\n",
       "[246122 rows x 79 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding - display it\n",
    "pd.get_dummies(train_data) # this line will convert the train_data to one hot encoding but it will only display the result and not save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "167c78ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:19:59.297801Z",
     "iopub.status.busy": "2024-11-07T20:19:59.297458Z",
     "iopub.status.idle": "2024-11-07T20:19:59.452254Z",
     "shell.execute_reply": "2024-11-07T20:19:59.451460Z"
    },
    "papermill": {
     "duration": 0.171007,
     "end_time": "2024-11-07T20:19:59.454757",
     "exception": false,
     "start_time": "2024-11-07T20:19:59.283750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we can see that there is no change in the number of columns meaning there is no categorical data. but for the sake of running the program. we must perform the preprocessing therefore we shall re-run the one hot encoding and save it somewhere\n",
    "train_data_processed = pd.get_dummies(train_data)\n",
    "\n",
    "# now we shall do the same on the test data so that we maintain the rules over all data\n",
    "test_data_processed = pd.get_dummies(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a502b343",
   "metadata": {
    "papermill": {
     "duration": 0.012565,
     "end_time": "2024-11-07T20:19:59.480848",
     "exception": false,
     "start_time": "2024-11-07T20:19:59.468283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Splitting - festures and targets\n",
    "the data in train_data set is of x1 - x78 columns (79 variables) and one target variable (Y). we must split that data so that we can perform data preprocessing on the features variables (will be referred to as X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7042a9be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:19:59.508822Z",
     "iopub.status.busy": "2024-11-07T20:19:59.508413Z",
     "iopub.status.idle": "2024-11-07T20:19:59.615233Z",
     "shell.execute_reply": "2024-11-07T20:19:59.614345Z"
    },
    "papermill": {
     "duration": 0.123675,
     "end_time": "2024-11-07T20:19:59.617410",
     "exception": false,
     "start_time": "2024-11-07T20:19:59.493735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X69</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.118411</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>829</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>82.372284</td>\n",
       "      <td>31.573280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162.983897</td>\n",
       "      <td>1</td>\n",
       "      <td>724</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100292</td>\n",
       "      <td>0.033431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>27.771653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>895</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>66.236109</td>\n",
       "      <td>26.515922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.009549</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108249</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>81.303299</td>\n",
       "      <td>20.843691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158.165419</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164645</td>\n",
       "      <td>0.069242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246117</th>\n",
       "      <td>246118</td>\n",
       "      <td>65.149110</td>\n",
       "      <td>33.357948</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156.317941</td>\n",
       "      <td>1</td>\n",
       "      <td>711</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088610</td>\n",
       "      <td>0.027152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246118</th>\n",
       "      <td>246119</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>46.736176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246119</th>\n",
       "      <td>246120</td>\n",
       "      <td>57.472080</td>\n",
       "      <td>41.854115</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189.868698</td>\n",
       "      <td>2</td>\n",
       "      <td>455</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032961</td>\n",
       "      <td>0.020601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246120</th>\n",
       "      <td>246121</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>23.738662</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246121</th>\n",
       "      <td>246122</td>\n",
       "      <td>50.257640</td>\n",
       "      <td>32.753911</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>173.665068</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246122 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  \\\n",
       "0              1  87.000000  34.118411   0   2   0  165.100000   1  829    2   \n",
       "1              2  82.372284  31.573280   0   0   1  162.983897   1  724    0   \n",
       "2              3  50.000000  27.771653   0   0   1  165.100000   1  895    2   \n",
       "3              4  66.236109  26.515922   0   0   1  167.009549   1  637    0   \n",
       "4              5  81.303299  20.843691   0   0   1  158.165419   0  564    0   \n",
       "...          ...        ...        ...  ..  ..  ..         ...  ..  ...  ...   \n",
       "246117    246118  65.149110  33.357948   0   0   1  156.317941   1  711    0   \n",
       "246118    246119  48.000000  46.736176   0   0   1  157.000000   1  594    2   \n",
       "246119    246120  57.472080  41.854115   1   0   0  189.868698   2  455    0   \n",
       "246120    246121  66.000000  23.738662   1   0   1  168.000000   2  609    0   \n",
       "246121    246122  50.257640  32.753911   0   2   0  173.665068   1  637    0   \n",
       "\n",
       "        ...       X69       X70  X71  X72       X73  X74       X75  X76  X77  \\\n",
       "0       ...  0.110000  0.040000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "1       ...  0.100292  0.033431  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "2       ...  0.020000  0.010000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "3       ...  0.108249  0.039363  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "4       ...  0.164645  0.069242  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "...     ...       ...       ...  ...  ...       ...  ...       ...  ...  ...   \n",
       "246117  ...  0.088610  0.027152  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "246118  ... -1.000000  0.560000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "246119  ...  0.032961  0.020601  0.0  0.0  0.587987  0.0  0.412013  0.0  0.0   \n",
       "246120  ...  0.020000 -1.000000  0.0  0.0  1.000000  0.0  0.000000  0.0  0.0   \n",
       "246121  ...  0.013712  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "\n",
       "             X78  \n",
       "0       0.000000  \n",
       "1       0.000000  \n",
       "2       0.000000  \n",
       "3       0.000000  \n",
       "4       0.000000  \n",
       "...          ...  \n",
       "246117  0.000000  \n",
       "246118  0.000000  \n",
       "246119  0.412013  \n",
       "246120  0.000000  \n",
       "246121  0.000000  \n",
       "\n",
       "[246122 rows x 78 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so in X, it is ALL the columns EXCEPT the last column known as 'Y' (we can confirm this using the train_data.head() we did earlier) so we must get all columns and DROP only the 'y' column\n",
    "X = train_data_processed.drop(columns=['Y'])\n",
    "X # lets display X and see what it is now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c88e149",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:19:59.646139Z",
     "iopub.status.busy": "2024-11-07T20:19:59.645488Z",
     "iopub.status.idle": "2024-11-07T20:19:59.653098Z",
     "shell.execute_reply": "2024-11-07T20:19:59.652210Z"
    },
    "papermill": {
     "duration": 0.023643,
     "end_time": "2024-11-07T20:19:59.654979",
     "exception": false,
     "start_time": "2024-11-07T20:19:59.631336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "246117    0\n",
       "246118    1\n",
       "246119    0\n",
       "246120    0\n",
       "246121    0\n",
       "Name: Y, Length: 246122, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so as per our X output, we can see that number of columns in train_data is 79 and number of columns in X is 78 meaning we have successfully performed our removal of target variable\n",
    "# now to get the target variable alone, we can just get it alone,\n",
    "Y = train_data_processed['Y']\n",
    "Y # lets see what it is\n",
    "# as per our Y output, we can see it is of one column and 246k rows which means we have successfully extracted the target variable column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3b00d8",
   "metadata": {
    "papermill": {
     "duration": 0.013172,
     "end_time": "2024-11-07T20:19:59.681675",
     "exception": false,
     "start_time": "2024-11-07T20:19:59.668503",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Imputation \n",
    "many cells in our data may be empty - we must fill these cells with data. we have multiple options to deal with them:\n",
    "- we remove the entire rows (Case 1)\n",
    "- we fill the cells with the average of the column (Case 2)\n",
    "- we fill the cells based on KNN imputation (nearest neighbour) (Case 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "870cf6c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:19:59.709964Z",
     "iopub.status.busy": "2024-11-07T20:19:59.709584Z",
     "iopub.status.idle": "2024-11-07T20:19:59.713906Z",
     "shell.execute_reply": "2024-11-07T20:19:59.713074Z"
    },
    "papermill": {
     "duration": 0.020662,
     "end_time": "2024-11-07T20:19:59.715854",
     "exception": false,
     "start_time": "2024-11-07T20:19:59.695192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Average Mean Imputation\n",
    "# ----------------------------- case -----------------------------\n",
    "# this will fill all the empty spaces using the average of all the spaces\n",
    "imputer = SimpleImputer(strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fc88898",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:19:59.743901Z",
     "iopub.status.busy": "2024-11-07T20:19:59.743274Z",
     "iopub.status.idle": "2024-11-07T20:19:59.747042Z",
     "shell.execute_reply": "2024-11-07T20:19:59.746212Z"
    },
    "papermill": {
     "duration": 0.019622,
     "end_time": "2024-11-07T20:19:59.748923",
     "exception": false,
     "start_time": "2024-11-07T20:19:59.729301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# KNN Imputation\n",
    "# ----------------------------- case -----------------------------\n",
    "# this fills them in using k-nearest neighbours of all the spaces\n",
    "# imputer = KNNImputer(n_neighbors=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf0e6f36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:19:59.776713Z",
     "iopub.status.busy": "2024-11-07T20:19:59.776389Z",
     "iopub.status.idle": "2024-11-07T20:20:00.287054Z",
     "shell.execute_reply": "2024-11-07T20:20:00.286257Z"
    },
    "papermill": {
     "duration": 0.52768,
     "end_time": "2024-11-07T20:20:00.289899",
     "exception": false,
     "start_time": "2024-11-07T20:19:59.762219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = imputer.fit_transform(X)                                        # fill them in X\n",
    "test_data_processed = imputer.transform(test_data_processed)    # fill them in test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc30a1f",
   "metadata": {
    "papermill": {
     "duration": 0.013394,
     "end_time": "2024-11-07T20:20:00.317159",
     "exception": false,
     "start_time": "2024-11-07T20:20:00.303765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Scaling\n",
    "some columns may be very large then other columns when compared. it would not affect at the moment as we are using decision trees, but to maintain a fair enviroment, we shall perform scaling on every run.\n",
    "there are two types of scaling: \n",
    "- min max scaling (also known as normalization)\n",
    "- standardisation (z-score normalization)\n",
    "- max abs scaler\n",
    "- robust scaler\n",
    "- normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e639b5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:20:00.345451Z",
     "iopub.status.busy": "2024-11-07T20:20:00.345083Z",
     "iopub.status.idle": "2024-11-07T20:20:00.486159Z",
     "shell.execute_reply": "2024-11-07T20:20:00.485235Z"
    },
    "papermill": {
     "duration": 0.157444,
     "end_time": "2024-11-07T20:20:00.488147",
     "exception": false,
     "start_time": "2024-11-07T20:20:00.330703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 9.72602740e-01, 3.63856188e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [4.06304216e-06, 9.09209364e-01, 3.15807703e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [8.12608432e-06, 4.65753425e-01, 2.44038356e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [9.99991874e-01, 5.68110690e-01, 5.09895343e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.12013395e-01],\n",
       "       [9.99995937e-01, 6.84931507e-01, 1.67901180e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 4.69282739e-01, 3.38096342e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------- case  -----------------------------\n",
    "# in this case we shall perform min max scaling. to do that, we must use our MinMaxScaler that we have imported above\n",
    "scaler = MinMaxScaler()\n",
    "# now we must use this scaler to scale X\n",
    "scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7a046f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:20:00.517343Z",
     "iopub.status.busy": "2024-11-07T20:20:00.516776Z",
     "iopub.status.idle": "2024-11-07T20:20:00.520873Z",
     "shell.execute_reply": "2024-11-07T20:20:00.519990Z"
    },
    "papermill": {
     "duration": 0.020851,
     "end_time": "2024-11-07T20:20:00.522797",
     "exception": false,
     "start_time": "2024-11-07T20:20:00.501946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------------------------- case -----------------------------\n",
    "# scaler = MaxAbsScaler()\n",
    "# # now we must use this scaler to scale X\n",
    "# scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac03aa2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:20:00.551017Z",
     "iopub.status.busy": "2024-11-07T20:20:00.550693Z",
     "iopub.status.idle": "2024-11-07T20:20:00.727421Z",
     "shell.execute_reply": "2024-11-07T20:20:00.726637Z"
    },
    "papermill": {
     "duration": 0.193573,
     "end_time": "2024-11-07T20:20:00.729710",
     "exception": false,
     "start_time": "2024-11-07T20:20:00.536137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# our output shows us that every value in the array is between 0 and 1. thus lets save this value on X\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# now we must do the same on our test_data set\n",
    "test_data_processed = scaler.transform(test_data_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad32516",
   "metadata": {
    "papermill": {
     "duration": 0.013362,
     "end_time": "2024-11-07T20:20:00.756855",
     "exception": false,
     "start_time": "2024-11-07T20:20:00.743493",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Filters\n",
    "there are two types of filters to filter out columns/features:\n",
    "- variance filter (a column which has same values throughout the column like all are sunny)\n",
    "- correlation filter (two columns which are same like weight in kg and weight in pounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd140eab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:20:00.785302Z",
     "iopub.status.busy": "2024-11-07T20:20:00.784945Z",
     "iopub.status.idle": "2024-11-07T20:20:00.790032Z",
     "shell.execute_reply": "2024-11-07T20:20:00.789109Z"
    },
    "papermill": {
     "duration": 0.02154,
     "end_time": "2024-11-07T20:20:00.791959",
     "exception": false,
     "start_time": "2024-11-07T20:20:00.770419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :  (246122, 78)\n",
      "test data :  (105482, 78)\n"
     ]
    }
   ],
   "source": [
    "print(\"X : \", X.shape)\n",
    "print(\"test data : \", test_data_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77621ca6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:20:00.820052Z",
     "iopub.status.busy": "2024-11-07T20:20:00.819720Z",
     "iopub.status.idle": "2024-11-07T20:20:00.825423Z",
     "shell.execute_reply": "2024-11-07T20:20:00.824628Z"
    },
    "papermill": {
     "duration": 0.021917,
     "end_time": "2024-11-07T20:20:00.827296",
     "exception": false,
     "start_time": "2024-11-07T20:20:00.805379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246122, 78)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variance filter\n",
    "# ----------------------------- case  -----------------------------\n",
    "# variance_filter = VarianceThreshold(threshold=0.001)  # Adjust the threshold if needed\n",
    "# X = variance_filter.fit_transform(X)\n",
    "# test_data_processed = variance_filter.fit_transform(test_data_processed)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "972f4dfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:20:00.860354Z",
     "iopub.status.busy": "2024-11-07T20:20:00.860018Z",
     "iopub.status.idle": "2024-11-07T20:20:00.866097Z",
     "shell.execute_reply": "2024-11-07T20:20:00.865158Z"
    },
    "papermill": {
     "duration": 0.026133,
     "end_time": "2024-11-07T20:20:00.868012",
     "exception": false,
     "start_time": "2024-11-07T20:20:00.841879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105482, 78)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3736d880",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:20:00.897232Z",
     "iopub.status.busy": "2024-11-07T20:20:00.896901Z",
     "iopub.status.idle": "2024-11-07T20:20:00.903888Z",
     "shell.execute_reply": "2024-11-07T20:20:00.903028Z"
    },
    "papermill": {
     "duration": 0.023607,
     "end_time": "2024-11-07T20:20:00.905745",
     "exception": false,
     "start_time": "2024-11-07T20:20:00.882138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246122, 78)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # correlation filter\n",
    "# # ----------------------------- case  -----------------------------\n",
    "# corr_matrix = pd.DataFrame(X).corr().abs()\n",
    "# upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "# to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "# X = pd.DataFrame(X).drop(columns=to_drop)\n",
    "# test_data_processed = pd.DataFrame(test_data_processed).drop(columns=to_drop)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89ed6910",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:20:00.936021Z",
     "iopub.status.busy": "2024-11-07T20:20:00.935703Z",
     "iopub.status.idle": "2024-11-07T20:20:00.941302Z",
     "shell.execute_reply": "2024-11-07T20:20:00.940439Z"
    },
    "papermill": {
     "duration": 0.023492,
     "end_time": "2024-11-07T20:20:00.943356",
     "exception": false,
     "start_time": "2024-11-07T20:20:00.919864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105482, 78)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_processed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05397f44",
   "metadata": {
    "papermill": {
     "duration": 0.016785,
     "end_time": "2024-11-07T20:20:00.974594",
     "exception": false,
     "start_time": "2024-11-07T20:20:00.957809",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Splitting - train and validate\n",
    "now our test_data set is of rows with NO target variable whereas the train_data set is WITH target variable.\n",
    "our rules in machine learning is that we must train half or 70% of the data and then we must check its accuracy using the remaining half or 30% of the data - we can only check accuracy IF we have the answers i.e. the target variable. \n",
    "So, what we need to do is, is split the train_data set into 2, by a 70% and 30% ratio. we train the model using the 70% and then test the model using the 30% and then use that model to predict the test_data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eea1ffaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:20:01.011712Z",
     "iopub.status.busy": "2024-11-07T20:20:01.011071Z",
     "iopub.status.idle": "2024-11-07T20:20:01.262010Z",
     "shell.execute_reply": "2024-11-07T20:20:01.260955Z"
    },
    "papermill": {
     "duration": 0.273955,
     "end_time": "2024-11-07T20:20:01.264394",
     "exception": false,
     "start_time": "2024-11-07T20:20:00.990439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# holdout method\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f84541",
   "metadata": {
    "papermill": {
     "duration": 0.013949,
     "end_time": "2024-11-07T20:20:01.292747",
     "exception": false,
     "start_time": "2024-11-07T20:20:01.278798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cc5a369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:20:01.322131Z",
     "iopub.status.busy": "2024-11-07T20:20:01.321773Z",
     "iopub.status.idle": "2024-11-07T20:20:01.328390Z",
     "shell.execute_reply": "2024-11-07T20:20:01.327465Z"
    },
    "papermill": {
     "duration": 0.023729,
     "end_time": "2024-11-07T20:20:01.330428",
     "exception": false,
     "start_time": "2024-11-07T20:20:01.306699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fbselection(direction, sample_model, features):\n",
    "    selection = SequentialFeatureSelector(sample_model, direction=direction, n_features_to_select=features, scoring='roc_auc')\n",
    "    return modelSelector(sample_model, selection)\n",
    "\n",
    "def modelSelector(sample_model, selection):\n",
    "    trainX = selection.fit_transform(trainX, trainY)\n",
    "    testX = selection.transform(testX)                                  # Ensure the test set is transformed similarly\n",
    "    test_data_processed = selection.transform(test_data_processed)      # test data is also transformed\n",
    "    X = selection.transform(X)                                          # full data transforming\n",
    "    return sample_model\n",
    "\n",
    "def kbest(sample_model, features):\n",
    "    selection = SelectKBest(score_func=f_classif, k=features)\n",
    "    return modelSelector(sample_model, selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eea2e257",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:20:01.360042Z",
     "iopub.status.busy": "2024-11-07T20:20:01.359730Z",
     "iopub.status.idle": "2024-11-07T20:20:01.368183Z",
     "shell.execute_reply": "2024-11-07T20:20:01.367346Z"
    },
    "papermill": {
     "duration": 0.025235,
     "end_time": "2024-11-07T20:20:01.370030",
     "exception": false,
     "start_time": "2024-11-07T20:20:01.344795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def featureImportance(sample_model, features, X, trainX, trainY, testX, test_data_processed):\n",
    "    print(\"fitting\")\n",
    "    \n",
    "    # fit the model\n",
    "    sample_model.fit(trainX, trainY)\n",
    "\n",
    "    print(\"extracting features\")\n",
    "\n",
    "    # extract all the feature names from data\n",
    "    importances = sample_model.feature_importances_\n",
    "    feature_names = train_data_processed.drop(columns=['Y']).columns\n",
    "    print(feature_names)\n",
    "\n",
    "    # sort with respect to importance\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # extract the top ones\n",
    "    top_features = feature_importance_df['Feature'].head(features).values\n",
    "    print(top_features)\n",
    "\n",
    "    # change all data according to the top ones we have selected\n",
    "    trainX = pd.DataFrame(trainX, columns=feature_names)[top_features]\n",
    "    testX = pd.DataFrame(testX, columns=feature_names)[top_features]\n",
    "    X = pd.DataFrame(X, columns=feature_names)[top_features]\n",
    "    test_data_processed = pd.DataFrame(test_data_processed, columns=feature_names)[top_features]\n",
    "\n",
    "    print(\"features extracted\")\n",
    "    \n",
    "    # retrain the model\n",
    "    sample_model.fit(trainX, trainY)\n",
    "\n",
    "    print(\"features trained\")\n",
    "    \n",
    "    return sample_model, X, trainX, trainY, testX, test_data_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1931f52c",
   "metadata": {
    "papermill": {
     "duration": 0.013797,
     "end_time": "2024-11-07T20:20:01.398362",
     "exception": false,
     "start_time": "2024-11-07T20:20:01.384565",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## model intialization\n",
    "here model is intialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea9d74c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:20:01.428186Z",
     "iopub.status.busy": "2024-11-07T20:20:01.427365Z",
     "iopub.status.idle": "2024-11-07T20:20:01.431622Z",
     "shell.execute_reply": "2024-11-07T20:20:01.430753Z"
    },
    "papermill": {
     "duration": 0.021268,
     "end_time": "2024-11-07T20:20:01.433590",
     "exception": false,
     "start_time": "2024-11-07T20:20:01.412322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### SAMPLE ###\n",
    "# -------------------- case X (add the case number here) --------------------\n",
    "# # intialize models here as model_1, model_2, perform feature selection and feature importance BEFORE they are inserted in stacking\n",
    "# model_1 = \n",
    "# model_2 = \n",
    "# # intialize estimators here\n",
    "# estimators = [('model_1', model_1), ('model_2', model_2)]\n",
    "# # intialize stacking\n",
    "# model = StackingClassifier(estimators=estimators, final_estimator=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67b3e6f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:20:14.134493Z",
     "iopub.status.busy": "2024-11-07T20:20:14.133868Z",
     "iopub.status.idle": "2024-11-07T20:20:14.138899Z",
     "shell.execute_reply": "2024-11-07T20:20:14.138075Z"
    },
    "papermill": {
     "duration": 0.02329,
     "end_time": "2024-11-07T20:20:14.141486",
     "exception": false,
     "start_time": "2024-11-07T20:20:14.118196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape ->  (246122, 45)\n",
      "trainX shape ->  (172285, 45)\n",
      "testX shape ->  (73837, 45)\n",
      "test_data_processed shape ->  (105482, 45)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape -> \", X.shape)\n",
    "print(\"trainX shape -> \", trainX.shape)\n",
    "print(\"testX shape -> \", testX.shape)\n",
    "print(\"test_data_processed shape -> \", test_data_processed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1b67bf",
   "metadata": {
    "papermill": {
     "duration": 0.014003,
     "end_time": "2024-11-07T20:20:14.169733",
     "exception": false,
     "start_time": "2024-11-07T20:20:14.155730",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Bagging intialization\n",
    "here we will introduce and intialize bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b185dd58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:20:14.199757Z",
     "iopub.status.busy": "2024-11-07T20:20:14.199358Z",
     "iopub.status.idle": "2024-11-07T20:20:14.203243Z",
     "shell.execute_reply": "2024-11-07T20:20:14.202488Z"
    },
    "papermill": {
     "duration": 0.020997,
     "end_time": "2024-11-07T20:20:14.205105",
     "exception": false,
     "start_time": "2024-11-07T20:20:14.184108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = BaggingClassifier(estimator=model, n_estimators=50, verbose=2)\n",
    "# -- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212db568",
   "metadata": {
    "papermill": {
     "duration": 0.014144,
     "end_time": "2024-11-07T20:20:14.233534",
     "exception": false,
     "start_time": "2024-11-07T20:20:14.219390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## model running\n",
    "here we run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d6d755",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:20:14.264026Z",
     "iopub.status.busy": "2024-11-07T20:20:14.263296Z",
     "iopub.status.idle": "2024-11-07T20:47:46.404160Z",
     "shell.execute_reply": "2024-11-07T20:47:46.402744Z"
    },
    "papermill": {
     "duration": 1652.161599,
     "end_time": "2024-11-07T20:47:46.409387",
     "exception": false,
     "start_time": "2024-11-07T20:20:14.247788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7c397b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:47:46.456383Z",
     "iopub.status.busy": "2024-11-07T20:47:46.455989Z",
     "iopub.status.idle": "2024-11-07T20:55:49.131374Z",
     "shell.execute_reply": "2024-11-07T20:55:49.130272Z"
    },
    "papermill": {
     "duration": 482.700644,
     "end_time": "2024-11-07T20:55:49.135292",
     "exception": false,
     "start_time": "2024-11-07T20:47:46.434648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:  7.9min finished\n"
     ]
    }
   ],
   "source": [
    "# predict using this model\n",
    "y_pred = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b9643b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:55:49.186552Z",
     "iopub.status.busy": "2024-11-07T20:55:49.185610Z",
     "iopub.status.idle": "2024-11-07T20:55:49.235375Z",
     "shell.execute_reply": "2024-11-07T20:55:49.234403Z"
    },
    "papermill": {
     "duration": 0.075397,
     "end_time": "2024-11-07T20:55:49.239118",
     "exception": false,
     "start_time": "2024-11-07T20:55:49.163721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy =  0.9972642442136056    \n",
      "roc score =  0.5320899445821543    \n"
     ]
    }
   ],
   "source": [
    "# display the accuracy of this prediction\n",
    "accuracy = accuracy_score(testY, y_pred)\n",
    "print(\"model accuracy = \", accuracy, \"   \")\n",
    "\n",
    "# now lets calculate the ROC AUC score according to this prediction\n",
    "roc_score = roc_auc_score(testY, y_pred)\n",
    "print(\"roc score = \", roc_score, \"   \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bac5912",
   "metadata": {
    "papermill": {
     "duration": 0.019827,
     "end_time": "2024-11-07T20:55:49.286324",
     "exception": false,
     "start_time": "2024-11-07T20:55:49.266497",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## predict for test dataset\n",
    "fit the model and predict for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bd912c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:55:49.328298Z",
     "iopub.status.busy": "2024-11-07T20:55:49.327483Z",
     "iopub.status.idle": "2024-11-07T21:33:19.178486Z",
     "shell.execute_reply": "2024-11-07T21:33:19.177259Z"
    },
    "papermill": {
     "duration": 2249.874308,
     "end_time": "2024-11-07T21:33:19.180774",
     "exception": false,
     "start_time": "2024-11-07T20:55:49.306466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (5.26 MB) transferred to GPU in 0.017213 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002670 -> initscore=-5.923005\n",
      "[LightGBM] [Info] Start training from score -5.923005\n",
      "Building estimator 22 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 447, number of negative: 171838\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (5.26 MB) transferred to GPU in 0.013293 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002629 -> initscore=-5.938380\n",
      "[LightGBM] [Info] Start training from score -5.938380\n",
      "Building estimator 23 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 447, number of negative: 171838\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (5.26 MB) transferred to GPU in 0.019506 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002699 -> initscore=-5.912165\n",
      "[LightGBM] [Info] Start training from score -5.912165\n",
      "Building estimator 24 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 447, number of negative: 171838\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (5.26 MB) transferred to GPU in 0.013414 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002560 -> initscore=-5.965297\n",
      "[LightGBM] [Info] Start training from score -5.965297\n",
      "Building estimator 25 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 447, number of negative: 171838\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (5.26 MB) transferred to GPU in 0.018711 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002507 -> initscore=-5.985969\n",
      "[LightGBM] [Info] Start training from score -5.985969\n",
      "Building estimator 1 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.017293 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002527 -> initscore=-5.978112\n",
      "[LightGBM] [Info] Start training from score -5.978112\n",
      "Building estimator 2 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.033585 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002629 -> initscore=-5.938604\n",
      "[LightGBM] [Info] Start training from score -5.938604\n",
      "Building estimator 3 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.018349 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002629 -> initscore=-5.938604\n",
      "[LightGBM] [Info] Start training from score -5.938604\n",
      "Building estimator 4 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9191\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.036537 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002629 -> initscore=-5.938604\n",
      "[LightGBM] [Info] Start training from score -5.938604\n",
      "Building estimator 5 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.021464 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002608 -> initscore=-5.946382\n",
      "[LightGBM] [Info] Start training from score -5.946382\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Building estimator 6 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9191\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (5.26 MB) transferred to GPU in 0.016661 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002461 -> initscore=-6.004708\n",
      "[LightGBM] [Info] Start training from score -6.004708\n",
      "Building estimator 22 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 447, number of negative: 171838\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (5.26 MB) transferred to GPU in 0.022791 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002449 -> initscore=-6.009448\n",
      "[LightGBM] [Info] Start training from score -6.009448\n",
      "Building estimator 23 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 447, number of negative: 171838\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (5.26 MB) transferred to GPU in 0.012879 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002606 -> initscore=-5.947273\n",
      "[LightGBM] [Info] Start training from score -5.947273\n",
      "Building estimator 24 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 447, number of negative: 171838\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (5.26 MB) transferred to GPU in 0.023096 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002682 -> initscore=-5.918655\n",
      "[LightGBM] [Info] Start training from score -5.918655\n",
      "Building estimator 25 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 447, number of negative: 171838\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (5.26 MB) transferred to GPU in 0.013585 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002316 -> initscore=-6.065625\n",
      "[LightGBM] [Info] Start training from score -6.065625\n",
      "Building estimator 1 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.025650 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002316 -> initscore=-6.065628\n",
      "[LightGBM] [Info] Start training from score -6.065628\n",
      "Building estimator 2 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.039259 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002657 -> initscore=-5.927815\n",
      "[LightGBM] [Info] Start training from score -5.927815\n",
      "Building estimator 3 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.018054 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002523 -> initscore=-5.979725\n",
      "[LightGBM] [Info] Start training from score -5.979725\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Building estimator 4 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.022574 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002604 -> initscore=-5.947945\n",
      "[LightGBM] [Info] Start training from score -5.947945\n",
      "Building estimator 5 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.021925 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002682 -> initscore=-5.918658\n",
      "[LightGBM] [Info] Start training from score -5.918658\n",
      "Building estimator 6 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (5.26 MB) transferred to GPU in 0.022398 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002606 -> initscore=-5.947273\n",
      "[LightGBM] [Info] Start training from score -5.947273\n",
      "Building estimator 22 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 447, number of negative: 171838\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (5.26 MB) transferred to GPU in 0.013576 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002635 -> initscore=-5.936170\n",
      "[LightGBM] [Info] Start training from score -5.936170\n",
      "Building estimator 23 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 447, number of negative: 171838\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (5.26 MB) transferred to GPU in 0.016147 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002426 -> initscore=-6.018995\n",
      "[LightGBM] [Info] Start training from score -6.018995\n",
      "Building estimator 24 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 447, number of negative: 171838\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (5.26 MB) transferred to GPU in 0.018391 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002467 -> initscore=-6.002346\n",
      "[LightGBM] [Info] Start training from score -6.002346\n",
      "Building estimator 25 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 447, number of negative: 171838\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (5.26 MB) transferred to GPU in 0.017401 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002357 -> initscore=-6.048193\n",
      "[LightGBM] [Info] Start training from score -6.048193\n",
      "Building estimator 1 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.021964 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002779 -> initscore=-5.882842\n",
      "[LightGBM] [Info] Start training from score -5.882842\n",
      "Building estimator 2 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.019914 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002690 -> initscore=-5.915624\n",
      "[LightGBM] [Info] Start training from score -5.915624\n",
      "Building estimator 3 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9191\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.021329 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002682 -> initscore=-5.918658\n",
      "[LightGBM] [Info] Start training from score -5.918658\n",
      "Building estimator 4 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.033314 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002698 -> initscore=-5.912599\n",
      "[LightGBM] [Info] Start training from score -5.912599\n",
      "Building estimator 5 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.022683 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002726 -> initscore=-5.902083\n",
      "[LightGBM] [Info] Start training from score -5.902083\n",
      "Building estimator 6 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.021135 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (5.26 MB) transferred to GPU in 0.015269 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002728 -> initscore=-5.901441\n",
      "[LightGBM] [Info] Start training from score -5.901441\n",
      "Building estimator 22 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 447, number of negative: 171838\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (5.26 MB) transferred to GPU in 0.021173 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002641 -> initscore=-5.933963\n",
      "[LightGBM] [Info] Start training from score -5.933963\n",
      "Building estimator 23 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 447, number of negative: 171838\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (5.26 MB) transferred to GPU in 0.021199 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002577 -> initscore=-5.958500\n",
      "[LightGBM] [Info] Start training from score -5.958500\n",
      "Building estimator 24 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 447, number of negative: 171838\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (5.26 MB) transferred to GPU in 0.016651 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002705 -> initscore=-5.910011\n",
      "[LightGBM] [Info] Start training from score -5.910011\n",
      "Building estimator 25 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 447, number of negative: 171838\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (5.26 MB) transferred to GPU in 0.034505 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002380 -> initscore=-6.038366\n",
      "[LightGBM] [Info] Start training from score -6.038366\n",
      "Building estimator 1 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.026243 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002706 -> initscore=-5.909583\n",
      "[LightGBM] [Info] Start training from score -5.909583\n",
      "Building estimator 2 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.024643 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002694 -> initscore=-5.914110\n",
      "[LightGBM] [Info] Start training from score -5.914110\n",
      "Building estimator 3 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.019372 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002877 -> initscore=-5.848258\n",
      "[LightGBM] [Info] Start training from score -5.848258\n",
      "Building estimator 4 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.025141 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002592 -> initscore=-5.952649\n",
      "[LightGBM] [Info] Start training from score -5.952649\n",
      "Building estimator 5 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.022799 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002686 -> initscore=-5.917140\n",
      "[LightGBM] [Info] Start training from score -5.917140\n",
      "Building estimator 6 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.020299 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002641 -> initscore=-5.933966\n",
      "[LightGBM] [Info] Start training from score -5.933966\n",
      "Building estimator 7 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.027383 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002503 -> initscore=-5.987830\n",
      "[LightGBM] [Info] Start training from score -5.987830\n",
      "Building estimator 8 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.029343 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002556 -> initscore=-5.966892\n",
      "[LightGBM] [Info] Start training from score -5.966892\n",
      "Building estimator 9 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.022006 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002665 -> initscore=-5.924753\n",
      "[LightGBM] [Info] Start training from score -5.924753\n",
      "Building estimator 10 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.020379 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002767 -> initscore=-5.887250\n",
      "[LightGBM] [Info] Start training from score -5.887250\n",
      "Building estimator 11 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.025882 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002621 -> initscore=-5.941708\n",
      "[LightGBM] [Info] Start training from score -5.941708\n",
      "Building estimator 12 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.020766 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002446 -> initscore=-6.010876\n",
      "[LightGBM] [Info] Start training from score -6.010876\n",
      "Building estimator 13 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.022081 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002844 -> initscore=-5.859654\n",
      "[LightGBM] [Info] Start training from score -5.859654\n",
      "Building estimator 14 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.021415 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002552 -> initscore=-5.968488\n",
      "[LightGBM] [Info] Start training from score -5.968488\n",
      "Building estimator 15 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.023199 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002816 -> initscore=-5.869733\n",
      "[LightGBM] [Info] Start training from score -5.869733\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Building estimator 16 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.021976 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002503 -> initscore=-5.987830\n",
      "[LightGBM] [Info] Start training from score -5.987830\n",
      "Building estimator 7 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.025946 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002653 -> initscore=-5.929349\n",
      "[LightGBM] [Info] Start training from score -5.929349\n",
      "Building estimator 8 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.023079 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002604 -> initscore=-5.947945\n",
      "[LightGBM] [Info] Start training from score -5.947945\n",
      "Building estimator 9 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.023863 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002621 -> initscore=-5.941708\n",
      "[LightGBM] [Info] Start training from score -5.941708\n",
      "Building estimator 10 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.023120 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002706 -> initscore=-5.909583\n",
      "[LightGBM] [Info] Start training from score -5.909583\n",
      "Building estimator 11 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.020345 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002625 -> initscore=-5.940155\n",
      "[LightGBM] [Info] Start training from score -5.940155\n",
      "Building estimator 12 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.024704 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002706 -> initscore=-5.909583\n",
      "[LightGBM] [Info] Start training from score -5.909583\n",
      "Building estimator 13 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.024857 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002543 -> initscore=-5.971686\n",
      "[LightGBM] [Info] Start training from score -5.971686\n",
      "Building estimator 14 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.031387 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002604 -> initscore=-5.947945\n",
      "[LightGBM] [Info] Start training from score -5.947945\n",
      "Building estimator 15 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.017718 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002576 -> initscore=-5.958954\n",
      "[LightGBM] [Info] Start training from score -5.958954\n",
      "Building estimator 16 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.028917 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002621 -> initscore=-5.941708\n",
      "[LightGBM] [Info] Start training from score -5.941708\n",
      "Building estimator 7 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.021415 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002588 -> initscore=-5.954221\n",
      "[LightGBM] [Info] Start training from score -5.954221\n",
      "Building estimator 8 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.021258 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002706 -> initscore=-5.909583\n",
      "[LightGBM] [Info] Start training from score -5.909583\n",
      "Building estimator 9 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.017707 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002682 -> initscore=-5.918658\n",
      "[LightGBM] [Info] Start training from score -5.918658\n",
      "Building estimator 10 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.024858 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002572 -> initscore=-5.960537\n",
      "[LightGBM] [Info] Start training from score -5.960537\n",
      "Building estimator 11 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9191\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.031967 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002751 -> initscore=-5.893157\n",
      "[LightGBM] [Info] Start training from score -5.893157\n",
      "Building estimator 12 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.019009 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002641 -> initscore=-5.933966\n",
      "[LightGBM] [Info] Start training from score -5.933966\n",
      "Building estimator 13 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.022173 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002572 -> initscore=-5.960537\n",
      "[LightGBM] [Info] Start training from score -5.960537\n",
      "Building estimator 14 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.022599 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002556 -> initscore=-5.966892\n",
      "[LightGBM] [Info] Start training from score -5.966892\n",
      "Building estimator 15 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.025657 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002775 -> initscore=-5.884309\n",
      "[LightGBM] [Info] Start training from score -5.884309\n",
      "Building estimator 16 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.019822 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002523 -> initscore=-5.979725\n",
      "[LightGBM] [Info] Start training from score -5.979725\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002580 -> initscore=-5.957374\n",
      "[LightGBM] [Info] Start training from score -5.957374\n",
      "Building estimator 7 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.022722 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002548 -> initscore=-5.970085\n",
      "[LightGBM] [Info] Start training from score -5.970085\n",
      "Building estimator 8 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.020103 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002682 -> initscore=-5.918658\n",
      "[LightGBM] [Info] Start training from score -5.918658\n",
      "Building estimator 9 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.020145 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002665 -> initscore=-5.924753\n",
      "[LightGBM] [Info] Start training from score -5.924753\n",
      "Building estimator 10 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.028630 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002556 -> initscore=-5.966892\n",
      "[LightGBM] [Info] Start training from score -5.966892\n",
      "Building estimator 11 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.023421 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002568 -> initscore=-5.962122\n",
      "[LightGBM] [Info] Start training from score -5.962122\n",
      "Building estimator 12 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.025759 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002751 -> initscore=-5.893157\n",
      "[LightGBM] [Info] Start training from score -5.893157\n",
      "Building estimator 13 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.026083 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002572 -> initscore=-5.960537\n",
      "[LightGBM] [Info] Start training from score -5.960537\n",
      "Building estimator 14 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.023651 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002706 -> initscore=-5.909583\n",
      "[LightGBM] [Info] Start training from score -5.909583\n",
      "Building estimator 15 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.018016 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002340 -> initscore=-6.055132\n",
      "[LightGBM] [Info] Start training from score -6.055132\n",
      "Building estimator 16 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.023028 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002556 -> initscore=-5.966892\n",
      "[LightGBM] [Info] Start training from score -5.966892\n",
      "Building estimator 17 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.022499 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002653 -> initscore=-5.929349\n",
      "[LightGBM] [Info] Start training from score -5.929349\n",
      "Building estimator 17 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.019330 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002617 -> initscore=-5.943264\n",
      "[LightGBM] [Info] Start training from score -5.943264\n",
      "Building estimator 18 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.016996 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002645 -> initscore=-5.932424\n",
      "[LightGBM] [Info] Start training from score -5.932424\n",
      "Building estimator 19 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.022899 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002608 -> initscore=-5.946382\n",
      "[LightGBM] [Info] Start training from score -5.946382\n",
      "Building estimator 20 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.020693 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002600 -> initscore=-5.949511\n",
      "[LightGBM] [Info] Start training from score -5.949511\n",
      "Building estimator 21 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.020509 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002434 -> initscore=-6.015884\n",
      "[LightGBM] [Info] Start training from score -6.015884\n",
      "Building estimator 22 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.021564 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002706 -> initscore=-5.909583\n",
      "[LightGBM] [Info] Start training from score -5.909583\n",
      "Building estimator 23 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.029545 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002722 -> initscore=-5.903579\n",
      "[LightGBM] [Info] Start training from score -5.903579\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Building estimator 17 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.025267 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002791 -> initscore=-5.878453\n",
      "[LightGBM] [Info] Start training from score -5.878453\n",
      "Building estimator 18 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.022716 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002576 -> initscore=-5.958954\n",
      "[LightGBM] [Info] Start training from score -5.958954\n",
      "Building estimator 19 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.019611 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002507 -> initscore=-5.986204\n",
      "[LightGBM] [Info] Start training from score -5.986204\n",
      "Building estimator 20 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.032611 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002771 -> initscore=-5.885778\n",
      "[LightGBM] [Info] Start training from score -5.885778\n",
      "Building estimator 21 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.027669 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002418 -> initscore=-6.022601\n",
      "[LightGBM] [Info] Start training from score -6.022601\n",
      "Building estimator 22 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.027224 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002877 -> initscore=-5.848258\n",
      "[LightGBM] [Info] Start training from score -5.848258\n",
      "Building estimator 23 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.028631 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002625 -> initscore=-5.940155\n",
      "[LightGBM] [Info] Start training from score -5.940155\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Building estimator 24 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.027948 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002539 -> initscore=-5.973288\n",
      "[LightGBM] [Info] Start training from score -5.973288\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Building estimator 25 of 25 for this parallel run (total 100)...\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.024875 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002556 -> initscore=-5.966892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed: 37.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ..................... (1 of 2) Processing bg_c, total=37.0min\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 9190\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 40\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 30 dense feature groups (7.51 MB) transferred to GPU in 0.007384 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002637 -> initscore=-5.935510\n",
      "[LightGBM] [Info] Start training from score -5.935510\n",
      "[Voting] ..................... (2 of 2) Processing lgb2, total=  29.3s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;bg_c&#x27;,\n",
       "                              BaggingClassifier(estimator=LGBMClassifier(device=&#x27;gpu&#x27;,\n",
       "                                                                         learning_rate=0.02,\n",
       "                                                                         max_depth=2,\n",
       "                                                                         n_estimators=4000),\n",
       "                                                n_estimators=100, n_jobs=-1,\n",
       "                                                verbose=2)),\n",
       "                             (&#x27;lgb2&#x27;,\n",
       "                              LGBMClassifier(device=&#x27;gpu&#x27;, learning_rate=0.02,\n",
       "                                             max_depth=2, n_estimators=4000))],\n",
       "                 verbose=True, voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;bg_c&#x27;,\n",
       "                              BaggingClassifier(estimator=LGBMClassifier(device=&#x27;gpu&#x27;,\n",
       "                                                                         learning_rate=0.02,\n",
       "                                                                         max_depth=2,\n",
       "                                                                         n_estimators=4000),\n",
       "                                                n_estimators=100, n_jobs=-1,\n",
       "                                                verbose=2)),\n",
       "                             (&#x27;lgb2&#x27;,\n",
       "                              LGBMClassifier(device=&#x27;gpu&#x27;, learning_rate=0.02,\n",
       "                                             max_depth=2, n_estimators=4000))],\n",
       "                 verbose=True, voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>bg_c</label></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(device=&#x27;gpu&#x27;, learning_rate=0.02, max_depth=2, n_estimators=4000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(device=&#x27;gpu&#x27;, learning_rate=0.02, max_depth=2, n_estimators=4000)</pre></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgb2</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(device=&#x27;gpu&#x27;, learning_rate=0.02, max_depth=2, n_estimators=4000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('bg_c',\n",
       "                              BaggingClassifier(estimator=LGBMClassifier(device='gpu',\n",
       "                                                                         learning_rate=0.02,\n",
       "                                                                         max_depth=2,\n",
       "                                                                         n_estimators=4000),\n",
       "                                                n_estimators=100, n_jobs=-1,\n",
       "                                                verbose=2)),\n",
       "                             ('lgb2',\n",
       "                              LGBMClassifier(device='gpu', learning_rate=0.02,\n",
       "                                             max_depth=2, n_estimators=4000))],\n",
       "                 verbose=True, voting='soft')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d7a96d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T21:33:19.228471Z",
     "iopub.status.busy": "2024-11-07T21:33:19.228088Z",
     "iopub.status.idle": "2024-11-07T21:46:13.984584Z",
     "shell.execute_reply": "2024-11-07T21:46:13.983555Z"
    },
    "papermill": {
     "duration": 774.78282,
     "end_time": "2024-11-07T21:46:13.986713",
     "exception": false,
     "start_time": "2024-11-07T21:33:19.203893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed: 12.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.43835307e-04 1.05531859e-03 8.13667994e-06 ... 1.58473616e-04\n",
      " 2.37375568e-05 7.92331301e-05]\n"
     ]
    }
   ],
   "source": [
    "test_prediction = model.predict_proba(test_data_processed)\n",
    "\n",
    "test_prediction=test_prediction[:, 1]\n",
    "\n",
    "print(test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5c0d31",
   "metadata": {
    "papermill": {
     "duration": 0.02242,
     "end_time": "2024-11-07T21:46:14.032429",
     "exception": false,
     "start_time": "2024-11-07T21:46:14.010009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## write into csv\n",
    "now we write the predictions into the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a24da1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T21:46:14.079625Z",
     "iopub.status.busy": "2024-11-07T21:46:14.078766Z",
     "iopub.status.idle": "2024-11-07T21:46:14.508006Z",
     "shell.execute_reply": "2024-11-07T21:46:14.507046Z"
    },
    "papermill": {
     "duration": 0.455346,
     "end_time": "2024-11-07T21:46:14.510398",
     "exception": false,
     "start_time": "2024-11-07T21:46:14.055052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300001</td>\n",
       "      <td>0.000544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300002</td>\n",
       "      <td>0.001055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300003</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300004</td>\n",
       "      <td>0.000747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300005</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105477</th>\n",
       "      <td>405478</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105478</th>\n",
       "      <td>405479</td>\n",
       "      <td>0.366285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105479</th>\n",
       "      <td>405480</td>\n",
       "      <td>0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105480</th>\n",
       "      <td>405481</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105481</th>\n",
       "      <td>405482</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105482 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RecordId         Y\n",
       "0         300001  0.000544\n",
       "1         300002  0.001055\n",
       "2         300003  0.000008\n",
       "3         300004  0.000747\n",
       "4         300005  0.000060\n",
       "...          ...       ...\n",
       "105477    405478  0.000011\n",
       "105478    405479  0.366285\n",
       "105479    405480  0.000158\n",
       "105480    405481  0.000024\n",
       "105481    405482  0.000079\n",
       "\n",
       "[105482 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = pd.read_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger1\\iml-fall-2024-challenge-1\\sample_submission.csv\")\n",
    "\n",
    "sample_data['Y'] = test_prediction\n",
    "sample_data\n",
    "\n",
    "sample_data.to_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger1\\iml-fall-2024-challenge-1\\rf1.csv\", index=False)\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42866b84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T21:46:14.559730Z",
     "iopub.status.busy": "2024-11-07T21:46:14.559178Z",
     "iopub.status.idle": "2024-11-07T21:46:14.586202Z",
     "shell.execute_reply": "2024-11-07T21:46:14.585331Z"
    },
    "papermill": {
     "duration": 0.053693,
     "end_time": "2024-11-07T21:46:14.588137",
     "exception": false,
     "start_time": "2024-11-07T21:46:14.534444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;bg_c&#x27;,\n",
       "                              BaggingClassifier(estimator=LGBMClassifier(device=&#x27;gpu&#x27;,\n",
       "                                                                         learning_rate=0.02,\n",
       "                                                                         max_depth=2,\n",
       "                                                                         n_estimators=4000),\n",
       "                                                n_estimators=100, n_jobs=-1,\n",
       "                                                verbose=2)),\n",
       "                             (&#x27;lgb2&#x27;,\n",
       "                              LGBMClassifier(device=&#x27;gpu&#x27;, learning_rate=0.02,\n",
       "                                             max_depth=2, n_estimators=4000))],\n",
       "                 verbose=True, voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;bg_c&#x27;,\n",
       "                              BaggingClassifier(estimator=LGBMClassifier(device=&#x27;gpu&#x27;,\n",
       "                                                                         learning_rate=0.02,\n",
       "                                                                         max_depth=2,\n",
       "                                                                         n_estimators=4000),\n",
       "                                                n_estimators=100, n_jobs=-1,\n",
       "                                                verbose=2)),\n",
       "                             (&#x27;lgb2&#x27;,\n",
       "                              LGBMClassifier(device=&#x27;gpu&#x27;, learning_rate=0.02,\n",
       "                                             max_depth=2, n_estimators=4000))],\n",
       "                 verbose=True, voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>bg_c</label></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(device=&#x27;gpu&#x27;, learning_rate=0.02, max_depth=2, n_estimators=4000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(device=&#x27;gpu&#x27;, learning_rate=0.02, max_depth=2, n_estimators=4000)</pre></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgb2</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(device=&#x27;gpu&#x27;, learning_rate=0.02, max_depth=2, n_estimators=4000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('bg_c',\n",
       "                              BaggingClassifier(estimator=LGBMClassifier(device='gpu',\n",
       "                                                                         learning_rate=0.02,\n",
       "                                                                         max_depth=2,\n",
       "                                                                         n_estimators=4000),\n",
       "                                                n_estimators=100, n_jobs=-1,\n",
       "                                                verbose=2)),\n",
       "                             ('lgb2',\n",
       "                              LGBMClassifier(device='gpu', learning_rate=0.02,\n",
       "                                             max_depth=2, n_estimators=4000))],\n",
       "                 verbose=True, voting='soft')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6034234,
     "sourceId": 9837068,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6034286,
     "sourceId": 9837128,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5193.546342,
   "end_time": "2024-11-07T21:46:17.332142",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-07T20:19:43.785800",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
