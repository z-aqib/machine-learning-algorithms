{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries\n",
    "in this part we will install all the necessary libraries on command prompt and then import the necessary functions from those libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# step 1: preprocessing\n",
    "from sklearn.impute import SimpleImputer # import some strategic imputer to fill in any missing values using mean\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler, Normalizer # scale all the values to one range to avoid any biasness (this bias is seen in mostly naive bayes and knn etc)\n",
    "\n",
    "from sklearn.impute import KNNImputer # import some strategic imputer to fill missing values using KNN (finds the nearest neighbour and fills it with that value)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# step 2: data division\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, cross_val_score # to divide the code into train/test using a specific percentage or with/without replacement\n",
    "\n",
    "# step 3: decision trees creation and tuning\n",
    "from sklearn.tree import DecisionTreeClassifier # to intialize a decision tree maker, its hyper parameters can be defined or set by a grid\n",
    "from sklearn.model_selection import GridSearchCV # to set different hyper parameters for creating a decision tree\n",
    "\n",
    "# step 4: displaying accuracy\n",
    "from sklearn.metrics import roc_auc_score # to display the accuracy of our tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this block to install any libraries not on the system\n",
    "# !pip install pandas\n",
    "# !pip install sklearn\n",
    "# python -m pip install scikit-learn lightgbm xgboost catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "data shall be loaded into variables as data sets using pandas and csv readers. they will be checked to see if they are loaded properly and will be loaded as 2 sets: train and test as per given in the kaggle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.118411</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>829</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>82.372284</td>\n",
       "      <td>31.573280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162.983897</td>\n",
       "      <td>1</td>\n",
       "      <td>724</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>27.771653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>895</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>66.236109</td>\n",
       "      <td>26.515922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.009549</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>81.303299</td>\n",
       "      <td>20.843691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158.165419</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  ...  \\\n",
       "0         1  87.000000  34.118411   0   2   0  165.100000   1  829    2  ...   \n",
       "1         2  82.372284  31.573280   0   0   1  162.983897   1  724    0  ...   \n",
       "2         3  50.000000  27.771653   0   0   1  165.100000   1  895    2  ...   \n",
       "3         4  66.236109  26.515922   0   0   1  167.009549   1  637    0  ...   \n",
       "4         5  81.303299  20.843691   0   0   1  158.165419   0  564    0  ...   \n",
       "\n",
       "        X70  X71  X72  X73  X74  X75  X76  X77  X78  Y  \n",
       "0  0.040000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "1  0.033431  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "2  0.010000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "3  0.039363  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "4  0.069242  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets load the training data set\n",
    "train_data = pd.read_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger1\\iml-fall-2024-challenge-1\\train_set.csv\")\n",
    "\n",
    "# lets also check it by getting the first few rows of the data, there should be x1 - x78 and one target variable Y\n",
    "train_data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X69</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300001</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>17.122318</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>170.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300002</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>43.693579</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>814</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300003</td>\n",
       "      <td>36.064225</td>\n",
       "      <td>23.998944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.086735</td>\n",
       "      <td>1</td>\n",
       "      <td>662</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300004</td>\n",
       "      <td>61.846764</td>\n",
       "      <td>31.693449</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>182.355708</td>\n",
       "      <td>2</td>\n",
       "      <td>862</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062613</td>\n",
       "      <td>0.033153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300005</td>\n",
       "      <td>71.591991</td>\n",
       "      <td>20.086147</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>166.704917</td>\n",
       "      <td>2</td>\n",
       "      <td>335</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014854</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  ...  \\\n",
       "0    300001  79.000000  17.122318   0   0   1  170.200000   1  700    0  ...   \n",
       "1    300002  38.000000  43.693579   0   0   1  165.100000   1  814    0  ...   \n",
       "2    300003  36.064225  23.998944   0   0   1  167.086735   1  662    0  ...   \n",
       "3    300004  61.846764  31.693449   0   3   1  182.355708   2  862    0  ...   \n",
       "4    300005  71.591991  20.086147   1   0   1  166.704917   2  335    0  ...   \n",
       "\n",
       "        X69       X70  X71  X72  X73  X74  X75  X76  X77  X78  \n",
       "0  0.070000  0.030000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.050000  0.040000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.006948  0.006948  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.062613  0.033153  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.014854  0.004854  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets load the test data\n",
    "test_data = pd.read_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger1\\iml-fall-2024-challenge-1\\test_set.csv\")\n",
    "\n",
    "# check if the data has been loaded by getting the first 5 rows - there should be x1 - x78 and no target variable Y as this is test data\n",
    "test_data.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "before we start processing this data and using algorithms, we will fix this data first, this is called data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion of Categorical to Numerical\n",
    "First we will convert categorical data to numerical data by doing one hot encoding, which turns it into binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.118411</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>829</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>82.372284</td>\n",
       "      <td>31.573280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162.983897</td>\n",
       "      <td>1</td>\n",
       "      <td>724</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>27.771653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>895</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>66.236109</td>\n",
       "      <td>26.515922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.009549</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>81.303299</td>\n",
       "      <td>20.843691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158.165419</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246117</th>\n",
       "      <td>246118</td>\n",
       "      <td>65.149110</td>\n",
       "      <td>33.357948</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156.317941</td>\n",
       "      <td>1</td>\n",
       "      <td>711</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246118</th>\n",
       "      <td>246119</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>46.736176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246119</th>\n",
       "      <td>246120</td>\n",
       "      <td>57.472080</td>\n",
       "      <td>41.854115</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189.868698</td>\n",
       "      <td>2</td>\n",
       "      <td>455</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246120</th>\n",
       "      <td>246121</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>23.738662</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246121</th>\n",
       "      <td>246122</td>\n",
       "      <td>50.257640</td>\n",
       "      <td>32.753911</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>173.665068</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246122 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  \\\n",
       "0              1  87.000000  34.118411   0   2   0  165.100000   1  829    2   \n",
       "1              2  82.372284  31.573280   0   0   1  162.983897   1  724    0   \n",
       "2              3  50.000000  27.771653   0   0   1  165.100000   1  895    2   \n",
       "3              4  66.236109  26.515922   0   0   1  167.009549   1  637    0   \n",
       "4              5  81.303299  20.843691   0   0   1  158.165419   0  564    0   \n",
       "...          ...        ...        ...  ..  ..  ..         ...  ..  ...  ...   \n",
       "246117    246118  65.149110  33.357948   0   0   1  156.317941   1  711    0   \n",
       "246118    246119  48.000000  46.736176   0   0   1  157.000000   1  594    2   \n",
       "246119    246120  57.472080  41.854115   1   0   0  189.868698   2  455    0   \n",
       "246120    246121  66.000000  23.738662   1   0   1  168.000000   2  609    0   \n",
       "246121    246122  50.257640  32.753911   0   2   0  173.665068   1  637    0   \n",
       "\n",
       "        ...       X70  X71  X72       X73  X74       X75  X76  X77       X78  \\\n",
       "0       ...  0.040000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "1       ...  0.033431  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "2       ...  0.010000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "3       ...  0.039363  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "4       ...  0.069242  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "...     ...       ...  ...  ...       ...  ...       ...  ...  ...       ...   \n",
       "246117  ...  0.027152  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "246118  ...  0.560000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "246119  ...  0.020601  0.0  0.0  0.587987  0.0  0.412013  0.0  0.0  0.412013   \n",
       "246120  ... -1.000000  0.0  0.0  1.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "246121  ...  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "\n",
       "        Y  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "...    ..  \n",
       "246117  0  \n",
       "246118  1  \n",
       "246119  0  \n",
       "246120  0  \n",
       "246121  0  \n",
       "\n",
       "[246122 rows x 79 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding - display it\n",
    "pd.get_dummies(train_data) # this line will convert the train_data to one hot encoding but it will only display the result and not save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that there is no change in the number of columns meaning there is no categorical data. but for the sake of running the program. we must perform the preprocessing therefore we shall re-run the one hot encoding and save it somewhere\n",
    "train_data_processed = pd.get_dummies(train_data)\n",
    "\n",
    "# now we shall do the same on the test data so that we maintain the rules over all data\n",
    "test_data_processed = pd.get_dummies(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting - festures and targets\n",
    "the data in train_data set is of x1 - x78 columns (79 variables) and one target variable (Y). we must split that data so that we can perform data preprocessing on the features variables (will be referred to as X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X69</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.118411</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>829</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>82.372284</td>\n",
       "      <td>31.573280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162.983897</td>\n",
       "      <td>1</td>\n",
       "      <td>724</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100292</td>\n",
       "      <td>0.033431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>27.771653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>895</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>66.236109</td>\n",
       "      <td>26.515922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.009549</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108249</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>81.303299</td>\n",
       "      <td>20.843691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158.165419</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164645</td>\n",
       "      <td>0.069242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246117</th>\n",
       "      <td>246118</td>\n",
       "      <td>65.149110</td>\n",
       "      <td>33.357948</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156.317941</td>\n",
       "      <td>1</td>\n",
       "      <td>711</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088610</td>\n",
       "      <td>0.027152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246118</th>\n",
       "      <td>246119</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>46.736176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246119</th>\n",
       "      <td>246120</td>\n",
       "      <td>57.472080</td>\n",
       "      <td>41.854115</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189.868698</td>\n",
       "      <td>2</td>\n",
       "      <td>455</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032961</td>\n",
       "      <td>0.020601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246120</th>\n",
       "      <td>246121</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>23.738662</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246121</th>\n",
       "      <td>246122</td>\n",
       "      <td>50.257640</td>\n",
       "      <td>32.753911</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>173.665068</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246122 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  \\\n",
       "0              1  87.000000  34.118411   0   2   0  165.100000   1  829    2   \n",
       "1              2  82.372284  31.573280   0   0   1  162.983897   1  724    0   \n",
       "2              3  50.000000  27.771653   0   0   1  165.100000   1  895    2   \n",
       "3              4  66.236109  26.515922   0   0   1  167.009549   1  637    0   \n",
       "4              5  81.303299  20.843691   0   0   1  158.165419   0  564    0   \n",
       "...          ...        ...        ...  ..  ..  ..         ...  ..  ...  ...   \n",
       "246117    246118  65.149110  33.357948   0   0   1  156.317941   1  711    0   \n",
       "246118    246119  48.000000  46.736176   0   0   1  157.000000   1  594    2   \n",
       "246119    246120  57.472080  41.854115   1   0   0  189.868698   2  455    0   \n",
       "246120    246121  66.000000  23.738662   1   0   1  168.000000   2  609    0   \n",
       "246121    246122  50.257640  32.753911   0   2   0  173.665068   1  637    0   \n",
       "\n",
       "        ...       X69       X70  X71  X72       X73  X74       X75  X76  X77  \\\n",
       "0       ...  0.110000  0.040000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "1       ...  0.100292  0.033431  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "2       ...  0.020000  0.010000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "3       ...  0.108249  0.039363  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "4       ...  0.164645  0.069242  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "...     ...       ...       ...  ...  ...       ...  ...       ...  ...  ...   \n",
       "246117  ...  0.088610  0.027152  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "246118  ... -1.000000  0.560000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "246119  ...  0.032961  0.020601  0.0  0.0  0.587987  0.0  0.412013  0.0  0.0   \n",
       "246120  ...  0.020000 -1.000000  0.0  0.0  1.000000  0.0  0.000000  0.0  0.0   \n",
       "246121  ...  0.013712  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "\n",
       "             X78  \n",
       "0       0.000000  \n",
       "1       0.000000  \n",
       "2       0.000000  \n",
       "3       0.000000  \n",
       "4       0.000000  \n",
       "...          ...  \n",
       "246117  0.000000  \n",
       "246118  0.000000  \n",
       "246119  0.412013  \n",
       "246120  0.000000  \n",
       "246121  0.000000  \n",
       "\n",
       "[246122 rows x 78 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so in X, it is ALL the columns EXCEPT the last column known as 'Y' (we can confirm this using the train_data.head() we did earlier) so we must get all columns and DROP only the 'y' column\n",
    "X = train_data_processed.drop(columns=['Y'])\n",
    "X # lets display X and see what it is now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "246117    0\n",
       "246118    1\n",
       "246119    0\n",
       "246120    0\n",
       "246121    0\n",
       "Name: Y, Length: 246122, dtype: int64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so as per our X output, we can see that number of columns in train_data is 79 and number of columns in X is 78 meaning we have successfully performed our removal of target variable\n",
    "# now to get the target variable alone, we can just get it alone,\n",
    "Y = train_data_processed['Y']\n",
    "Y # lets see what it is\n",
    "# as per our Y output, we can see it is of one column and 246k rows which means we have successfully extracted the target variable column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imputation \n",
    "many cells in our data may be empty - we must fill these cells with data. we have multiple options to deal with them:\n",
    "- we remove the entire rows (Case 1)\n",
    "- we fill the cells with the average of the column (Case 2)\n",
    "- we fill the cells based on KNN imputation (nearest neighbour) (Case 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows method\n",
    "# ----------------------------- case 1 to case 10 -----------------------------\n",
    "# in this case, lets remove the entire rows that have NaN values. before saving the removed rows data set, lets first run it and display it to see the outcome, then we shall save in X\n",
    "# X.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove rows method\n",
    "# ----------------------------- case 1 to case 10 -----------------------------\n",
    "# # so we originally had 246122 rows and now after removing empty cell rows we have 239650 rows which is a 6472 rows difference. as our first try, lets work with it. lets assign this data set in place of X\n",
    "# X = X.dropna(axis=0)\n",
    "# X\n",
    "# these above 2 lines were commented out as there was an error handling, rows were being removed from X and not from Y so we fixed it by removing from train_data and then splitting into X and Y\n",
    "# train_data_processed = train_data_processed.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Mean Imputation\n",
    "# ----------------------------- case 11, 13, 15, 17, 19 -----------------------------\n",
    "# this will fill all the empty spaces using the average of all the spaces\n",
    "# imputer = SimpleImputer(strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Imputation\n",
    "# ----------------------------- case 12, 14, 16, 18, 20 to 30, 156, 158 -----------------------------\n",
    "# this fills them in using k-nearest neighbours of all the spaces\n",
    "imputer = KNNImputer(n_neighbors=7)\n",
    "# --\n",
    "# imputer = KNNImputer(n_neighbors=5)   # case 12, 18, 24\n",
    "# imputer = KNNImputer(n_neighbors=3)   # case 14, 21, 23\n",
    "# imputer = KNNImputer(n_neighbors=7)   # case 16, 20, 22, 25 to 30, 156, 158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputer.fit_transform(X)                                        # fill them in X\n",
    "test_data_processed = imputer.fit_transform(test_data_processed)    # fill them in test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scaling\n",
    "some columns may be very large then other columns when compared. it would not affect at the moment as we are using decision trees, but to maintain a fair enviroment, we shall perform scaling on every run.\n",
    "there are two types of scaling: \n",
    "- min max scaling (also known as normalization)\n",
    "- standardisation (z-score normalization)\n",
    "- max abs scaler\n",
    "- robust scaler\n",
    "- normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min Max Scaler\n",
    "# ----------------------------- case 1 to case 12, 21, 22 -----------------------------\n",
    "# in this case we shall perform min max scaling. to do that, we must use our MinMaxScaler that we have imported above\n",
    "# scaler = MinMaxScaler()\n",
    "# # now we must use this scaler to scale X\n",
    "# scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaler\n",
    "# ----------------------------- case 13 to case 14 -----------------------------\n",
    "# scaler = StandardScaler()\n",
    "# # now we must use this scaler to scale X\n",
    "# scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.06302565e-06, 9.77528090e-01, 5.03110176e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [8.12605131e-06, 9.25531276e-01, 4.65579663e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.21890770e-05, 5.61797753e-01, 4.09520864e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [9.99991874e-01, 6.45753712e-01, 6.17180876e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.12013395e-01],\n",
       "       [9.99995937e-01, 7.41573034e-01, 3.50050368e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 5.64692584e-01, 4.82989245e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max Absolute Scaler\n",
    "# ----------------------------- case 15 to case 16, 23 to 30, 156, 158 -----------------------------\n",
    "scaler = MaxAbsScaler()\n",
    "# now we must use this scaler to scale X\n",
    "scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust Scaler\n",
    "# ----------------------------- case 17 to case 18 -----------------------------\n",
    "# scaler = RobustScaler()\n",
    "# # now we must use this scaler to scale X\n",
    "# scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizer Scaler\n",
    "# ----------------------------- case 19 to case 20 -----------------------------\n",
    "# scaler = Normalizer()\n",
    "# # now we must use this scaler to scale X\n",
    "# scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the scaler - runs for all\n",
    "# our output shows us that every value in the array is between 0 and 1. thus lets save this value on X\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# now we must do the same on our test_data set\n",
    "test_data_processed = scaler.fit_transform(test_data_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "principal component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- CASE 156, 158 ----------------------\n",
    "pca = PCA(n_components=24)                                  # case 158\n",
    "X = pca.fit_transform(X)\n",
    "test_data_processed = pca.transform(test_data_processed)\n",
    "# --\n",
    "# pca = PCA(n_components=15)                                # case 156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative explained variance: [0.1495171  0.26263393 0.36785899 0.44556092 0.51063964 0.55650573\n",
      " 0.59655267 0.62830431 0.65988035 0.6895308  0.71492548 0.73865492\n",
      " 0.7620061  0.78429172 0.80461263 0.82288486 0.83584002 0.8481433\n",
      " 0.85906995 0.86933164 0.87869748 0.88773651 0.89600653 0.90321484]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot an elbow graph to find the optimal number of components\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "pca.explained_variance_ratio_.round(3)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "print(\"Cumulative explained variance:\", cumulative_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting - train and validate\n",
    "now our test_data set is of rows with NO target variable whereas the train_data set is WITH target variable. there are two ways:\n",
    "\n",
    "- our rules in machine learning is that we must train half or 70% of the data and then we must check its accuracy using the remaining half or 30% of the data - we can only check accuracy IF we have the answers i.e. the target variable. \n",
    "So, what we need to do is, is split the train_data set into 2, by a 70% and 30% ratio. we train the model using the 70% and then test the model using the 30% and then use that model to predict the test_data set.\n",
    "- k cross fold: we part the data into k groups and keep k-1 as train and 1 as test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- case 1 to case 27, 156, 158 -----------------------------\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- case 28 to case 30 -----------------------------\n",
    "# crossfold = RepeatedKFold(n_splits=15, n_repeats=1)#, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Algorithm Running\n",
    "now we shall begin running our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets intialize our decision tree with some parameters\n",
    "decisiontree = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=15, max_features=60, min_samples_leaf=80)\n",
    "# --\n",
    "# decisiontree = DecisionTreeClassifier(criterion='gini', max_depth=7, min_samples_split=20)                                            # case 1\n",
    "# decisiontree = DecisionTreeClassifier(criterion='entropy', max_depth=7, min_samples_split=20)                                         # case 2 \n",
    "# decisiontree = DecisionTreeClassifier(criterion='entropy', max_depth=7, min_samples_split=15)                                         # case 3\n",
    "# decisiontree = DecisionTreeClassifier(criterion='entropy', max_depth=8, min_samples_split=15)                                         # case 4\n",
    "# decisiontree = DecisionTreeClassifier(criterion='entropy', max_depth=6, min_samples_split=15)                                         # case 5\n",
    "# decisiontree = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=15)                                         # case 6\n",
    "# decisiontree = DecisionTreeClassifier(criterion='entropy', max_depth=4, min_samples_split=15)                                         # case 7\n",
    "# decisiontree = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=15, max_features=10)                        # case 8\n",
    "# decisiontree = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=15, max_features=50)                        # case 9\n",
    "# decisiontree = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=15, max_features=60)                        # case 10 to 24\n",
    "# decisiontree = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=15, max_features=60, min_samples_leaf=50)   # case 25\n",
    "# decisiontree = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=15, max_features=60, min_samples_leaf=80)   # case 26\n",
    "# decisiontree = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=15, max_features=60, min_samples_leaf=100)  # case 27 to 30, 156, 158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc score =  0.5\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------- case 1 to case 27, 156, 158 -----------------------------\n",
    "# now lets fit this model onto our data\n",
    "decisiontree.fit(trainX, trainY)\n",
    "\n",
    "# after fitting, lets predict our testX and analyse the accuracy\n",
    "prediction = decisiontree.predict(testX)\n",
    "\n",
    "# now lets calculate the ROC AUC score according to this prediction\n",
    "roc_score = roc_auc_score(testY, prediction)\n",
    "\n",
    "print(\"roc score = \", roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- case 28 to case 30 -----------------------------\n",
    "# scores = cross_val_score(decisiontree, X, Y, scoring=\"roc_auc\", cv = crossfold)     \n",
    "# score = format(mean(scores), '.4f')\n",
    "# score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict for test dataset\n",
    "fit the model and predict for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00039679 0.01362436 0.00171322 ... 0.00039679 0.00039679 0.00171322]\n"
     ]
    }
   ],
   "source": [
    "decisiontree.fit(X, Y)\n",
    "\n",
    "test_prediction = decisiontree.predict_proba(test_data_processed)\n",
    "\n",
    "test_prediction=test_prediction[:, 1]\n",
    "\n",
    "print(test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write into csv\n",
    "now we write the predictions into the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300001</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300002</td>\n",
       "      <td>0.013624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300003</td>\n",
       "      <td>0.001713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300004</td>\n",
       "      <td>0.002072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300005</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105477</th>\n",
       "      <td>405478</td>\n",
       "      <td>0.001798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105478</th>\n",
       "      <td>405479</td>\n",
       "      <td>0.094340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105479</th>\n",
       "      <td>405480</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105480</th>\n",
       "      <td>405481</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105481</th>\n",
       "      <td>405482</td>\n",
       "      <td>0.001713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105482 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RecordId         Y\n",
       "0         300001  0.000397\n",
       "1         300002  0.013624\n",
       "2         300003  0.001713\n",
       "3         300004  0.002072\n",
       "4         300005  0.000397\n",
       "...          ...       ...\n",
       "105477    405478  0.001798\n",
       "105478    405479  0.094340\n",
       "105479    405480  0.000397\n",
       "105480    405481  0.000397\n",
       "105481    405482  0.001713\n",
       "\n",
       "[105482 rows x 2 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = pd.read_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger1\\iml-fall-2024-challenge-1\\sample_submission.csv\")\n",
    "\n",
    "sample_data['Y'] = test_prediction\n",
    "sample_data\n",
    "\n",
    "sample_data.to_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger1\\iml-fall-2024-challenge-1\\dt1.csv\", index=False)\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=5, max_features=60,\n",
       "                       min_samples_leaf=80, min_samples_split=15)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=5, max_features=60,\n",
       "                       min_samples_leaf=80, min_samples_split=15)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=60,\n",
       "                       min_samples_leaf=80, min_samples_split=15)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decisiontree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
