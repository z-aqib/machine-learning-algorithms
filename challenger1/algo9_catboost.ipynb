{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries\n",
    "in this part we will install all the necessary libraries on command prompt and then import the necessary functions from those libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import mean\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# step 1: preprocessing\n",
    "from sklearn.impute import SimpleImputer # import some strategic imputer to fill in any missing values using mean\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler, Normalizer # scale all the values to one range to avoid any biasness (this bias is seen in mostly naive bayes and knn etc)\n",
    "\n",
    "from sklearn.impute import KNNImputer # import some strategic imputer to fill missing values using KNN (finds the nearest neighbour and fills it with that value)\n",
    "\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, SelectKBest, f_classif, VarianceThreshold\n",
    "\n",
    "# step 2: data division\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, cross_val_score, GridSearchCV, ParameterGrid # to divide the code into train/test using a specific percentage or with/without replacement\n",
    "\n",
    "# step 3: model\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# step 4: displaying accuracy\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score # to display the accuracy of our tree\n",
    "\n",
    "# step 5: warning filter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this block to install any libraries not on the system\n",
    "# !pip install pandas\n",
    "# !pip install sklearn\n",
    "# python -m pip install scikit-learn lightgbm xgboost catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "data shall be loaded into variables as data sets using pandas and csv readers. they will be checked to see if they are loaded properly and will be loaded as 2 sets: train and test as per given in the kaggle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.118411</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>829</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>82.372284</td>\n",
       "      <td>31.573280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162.983897</td>\n",
       "      <td>1</td>\n",
       "      <td>724</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>27.771653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>895</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>66.236109</td>\n",
       "      <td>26.515922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.009549</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>81.303299</td>\n",
       "      <td>20.843691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158.165419</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  ...  \\\n",
       "0         1  87.000000  34.118411   0   2   0  165.100000   1  829    2  ...   \n",
       "1         2  82.372284  31.573280   0   0   1  162.983897   1  724    0  ...   \n",
       "2         3  50.000000  27.771653   0   0   1  165.100000   1  895    2  ...   \n",
       "3         4  66.236109  26.515922   0   0   1  167.009549   1  637    0  ...   \n",
       "4         5  81.303299  20.843691   0   0   1  158.165419   0  564    0  ...   \n",
       "\n",
       "        X70  X71  X72  X73  X74  X75  X76  X77  X78  Y  \n",
       "0  0.040000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "1  0.033431  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "2  0.010000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "3  0.039363  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "4  0.069242  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets load the training data set\n",
    "train_data = pd.read_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger1\\iml-fall-2024-challenge-1\\train_set.csv\")\n",
    "\n",
    "# lets also check it by getting the first few rows of the data, there should be x1 - x78 and one target variable Y\n",
    "train_data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X69</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300001</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>17.122318</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>170.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300002</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>43.693579</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>814</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300003</td>\n",
       "      <td>36.064225</td>\n",
       "      <td>23.998944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.086735</td>\n",
       "      <td>1</td>\n",
       "      <td>662</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300004</td>\n",
       "      <td>61.846764</td>\n",
       "      <td>31.693449</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>182.355708</td>\n",
       "      <td>2</td>\n",
       "      <td>862</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062613</td>\n",
       "      <td>0.033153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300005</td>\n",
       "      <td>71.591991</td>\n",
       "      <td>20.086147</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>166.704917</td>\n",
       "      <td>2</td>\n",
       "      <td>335</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014854</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  ...  \\\n",
       "0    300001  79.000000  17.122318   0   0   1  170.200000   1  700    0  ...   \n",
       "1    300002  38.000000  43.693579   0   0   1  165.100000   1  814    0  ...   \n",
       "2    300003  36.064225  23.998944   0   0   1  167.086735   1  662    0  ...   \n",
       "3    300004  61.846764  31.693449   0   3   1  182.355708   2  862    0  ...   \n",
       "4    300005  71.591991  20.086147   1   0   1  166.704917   2  335    0  ...   \n",
       "\n",
       "        X69       X70  X71  X72  X73  X74  X75  X76  X77  X78  \n",
       "0  0.070000  0.030000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.050000  0.040000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.006948  0.006948  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.062613  0.033153  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.014854  0.004854  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets load the test data\n",
    "test_data = pd.read_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger1\\iml-fall-2024-challenge-1\\test_set.csv\")\n",
    "\n",
    "# check if the data has been loaded by getting the first 5 rows - there should be x1 - x78 and no target variable Y as this is test data\n",
    "test_data.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "before we start processing this data and using algorithms, we will fix this data first, this is called data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion of Categorical to Numerical\n",
    "First we will convert categorical data to numerical data by doing one hot encoding, which turns it into binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.118411</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>829</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>82.372284</td>\n",
       "      <td>31.573280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162.983897</td>\n",
       "      <td>1</td>\n",
       "      <td>724</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>27.771653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>895</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>66.236109</td>\n",
       "      <td>26.515922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.009549</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>81.303299</td>\n",
       "      <td>20.843691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158.165419</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246117</th>\n",
       "      <td>246118</td>\n",
       "      <td>65.149110</td>\n",
       "      <td>33.357948</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156.317941</td>\n",
       "      <td>1</td>\n",
       "      <td>711</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246118</th>\n",
       "      <td>246119</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>46.736176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246119</th>\n",
       "      <td>246120</td>\n",
       "      <td>57.472080</td>\n",
       "      <td>41.854115</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189.868698</td>\n",
       "      <td>2</td>\n",
       "      <td>455</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246120</th>\n",
       "      <td>246121</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>23.738662</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246121</th>\n",
       "      <td>246122</td>\n",
       "      <td>50.257640</td>\n",
       "      <td>32.753911</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>173.665068</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246122 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  \\\n",
       "0              1  87.000000  34.118411   0   2   0  165.100000   1  829    2   \n",
       "1              2  82.372284  31.573280   0   0   1  162.983897   1  724    0   \n",
       "2              3  50.000000  27.771653   0   0   1  165.100000   1  895    2   \n",
       "3              4  66.236109  26.515922   0   0   1  167.009549   1  637    0   \n",
       "4              5  81.303299  20.843691   0   0   1  158.165419   0  564    0   \n",
       "...          ...        ...        ...  ..  ..  ..         ...  ..  ...  ...   \n",
       "246117    246118  65.149110  33.357948   0   0   1  156.317941   1  711    0   \n",
       "246118    246119  48.000000  46.736176   0   0   1  157.000000   1  594    2   \n",
       "246119    246120  57.472080  41.854115   1   0   0  189.868698   2  455    0   \n",
       "246120    246121  66.000000  23.738662   1   0   1  168.000000   2  609    0   \n",
       "246121    246122  50.257640  32.753911   0   2   0  173.665068   1  637    0   \n",
       "\n",
       "        ...       X70  X71  X72       X73  X74       X75  X76  X77       X78  \\\n",
       "0       ...  0.040000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "1       ...  0.033431  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "2       ...  0.010000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "3       ...  0.039363  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "4       ...  0.069242  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "...     ...       ...  ...  ...       ...  ...       ...  ...  ...       ...   \n",
       "246117  ...  0.027152  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "246118  ...  0.560000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "246119  ...  0.020601  0.0  0.0  0.587987  0.0  0.412013  0.0  0.0  0.412013   \n",
       "246120  ... -1.000000  0.0  0.0  1.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "246121  ...  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "\n",
       "        Y  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "...    ..  \n",
       "246117  0  \n",
       "246118  1  \n",
       "246119  0  \n",
       "246120  0  \n",
       "246121  0  \n",
       "\n",
       "[246122 rows x 79 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding - display it\n",
    "pd.get_dummies(train_data) # this line will convert the train_data to one hot encoding but it will only display the result and not save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that there is no change in the number of columns meaning there is no categorical data. but for the sake of running the program. we must perform the preprocessing therefore we shall re-run the one hot encoding and save it somewhere\n",
    "train_data_processed = pd.get_dummies(train_data)\n",
    "\n",
    "# now we shall do the same on the test data so that we maintain the rules over all data\n",
    "test_data_processed = pd.get_dummies(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting - festures and targets\n",
    "the data in train_data set is of x1 - x78 columns (79 variables) and one target variable (Y). we must split that data so that we can perform data preprocessing on the features variables (will be referred to as X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X69</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.118411</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>829</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>82.372284</td>\n",
       "      <td>31.573280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162.983897</td>\n",
       "      <td>1</td>\n",
       "      <td>724</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100292</td>\n",
       "      <td>0.033431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>27.771653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>895</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>66.236109</td>\n",
       "      <td>26.515922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.009549</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108249</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>81.303299</td>\n",
       "      <td>20.843691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158.165419</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164645</td>\n",
       "      <td>0.069242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246117</th>\n",
       "      <td>246118</td>\n",
       "      <td>65.149110</td>\n",
       "      <td>33.357948</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156.317941</td>\n",
       "      <td>1</td>\n",
       "      <td>711</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088610</td>\n",
       "      <td>0.027152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246118</th>\n",
       "      <td>246119</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>46.736176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246119</th>\n",
       "      <td>246120</td>\n",
       "      <td>57.472080</td>\n",
       "      <td>41.854115</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189.868698</td>\n",
       "      <td>2</td>\n",
       "      <td>455</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032961</td>\n",
       "      <td>0.020601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246120</th>\n",
       "      <td>246121</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>23.738662</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246121</th>\n",
       "      <td>246122</td>\n",
       "      <td>50.257640</td>\n",
       "      <td>32.753911</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>173.665068</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246122 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  \\\n",
       "0              1  87.000000  34.118411   0   2   0  165.100000   1  829    2   \n",
       "1              2  82.372284  31.573280   0   0   1  162.983897   1  724    0   \n",
       "2              3  50.000000  27.771653   0   0   1  165.100000   1  895    2   \n",
       "3              4  66.236109  26.515922   0   0   1  167.009549   1  637    0   \n",
       "4              5  81.303299  20.843691   0   0   1  158.165419   0  564    0   \n",
       "...          ...        ...        ...  ..  ..  ..         ...  ..  ...  ...   \n",
       "246117    246118  65.149110  33.357948   0   0   1  156.317941   1  711    0   \n",
       "246118    246119  48.000000  46.736176   0   0   1  157.000000   1  594    2   \n",
       "246119    246120  57.472080  41.854115   1   0   0  189.868698   2  455    0   \n",
       "246120    246121  66.000000  23.738662   1   0   1  168.000000   2  609    0   \n",
       "246121    246122  50.257640  32.753911   0   2   0  173.665068   1  637    0   \n",
       "\n",
       "        ...       X69       X70  X71  X72       X73  X74       X75  X76  X77  \\\n",
       "0       ...  0.110000  0.040000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "1       ...  0.100292  0.033431  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "2       ...  0.020000  0.010000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "3       ...  0.108249  0.039363  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "4       ...  0.164645  0.069242  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "...     ...       ...       ...  ...  ...       ...  ...       ...  ...  ...   \n",
       "246117  ...  0.088610  0.027152  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "246118  ... -1.000000  0.560000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "246119  ...  0.032961  0.020601  0.0  0.0  0.587987  0.0  0.412013  0.0  0.0   \n",
       "246120  ...  0.020000 -1.000000  0.0  0.0  1.000000  0.0  0.000000  0.0  0.0   \n",
       "246121  ...  0.013712  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "\n",
       "             X78  \n",
       "0       0.000000  \n",
       "1       0.000000  \n",
       "2       0.000000  \n",
       "3       0.000000  \n",
       "4       0.000000  \n",
       "...          ...  \n",
       "246117  0.000000  \n",
       "246118  0.000000  \n",
       "246119  0.412013  \n",
       "246120  0.000000  \n",
       "246121  0.000000  \n",
       "\n",
       "[246122 rows x 78 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so in X, it is ALL the columns EXCEPT the last column known as 'Y' (we can confirm this using the train_data.head() we did earlier) so we must get all columns and DROP only the 'y' column\n",
    "X = train_data_processed.drop(columns=['Y'])\n",
    "X # lets display X and see what it is now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "246117    0\n",
       "246118    1\n",
       "246119    0\n",
       "246120    0\n",
       "246121    0\n",
       "Name: Y, Length: 246122, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so as per our X output, we can see that number of columns in train_data is 79 and number of columns in X is 78 meaning we have successfully performed our removal of target variable\n",
    "# now to get the target variable alone, we can just get it alone,\n",
    "Y = train_data_processed['Y']\n",
    "Y # lets see what it is\n",
    "# as per our Y output, we can see it is of one column and 246k rows which means we have successfully extracted the target variable column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imputation \n",
    "many cells in our data may be empty - we must fill these cells with data. we have multiple options to deal with them:\n",
    "- we remove the entire rows (Case 1)\n",
    "- we fill the cells with the average of the column (Case 2)\n",
    "- we fill the cells based on KNN imputation (nearest neighbour) (Case 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE ROWS \n",
    "# ----------------------------- case  -----------------------------\n",
    "# in this case, lets remove the entire rows that have NaN values. before saving the removed rows data set, lets first run it and display it to see the outcome, then we shall save in X\n",
    "# X.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE ROWS\n",
    "# # so we originally had 246122 rows and now after removing empty cell rows we have 239650 rows which is a 6472 rows difference. as our first try, lets work with it. lets assign this data set in place of X\n",
    "# X = X.dropna(axis=0)\n",
    "# X\n",
    "# these above 2 lines were commented out as there was an error handling, rows were being removed from X and not from Y so we fixed it by removing from train_data and then splitting into X and Y\n",
    "# train_data_processed = train_data_processed.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Mean Imputation\n",
    "# ----------------------------- case  -----------------------------\n",
    "# this will fill all the empty spaces using the average of all the spaces\n",
    "imputer = SimpleImputer(strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Imputation\n",
    "# ----------------------------- case -----------------------------\n",
    "# this fills them in using k-nearest neighbours of all the spaces\n",
    "# imputer = KNNImputer(n_neighbors=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputer.fit_transform(X)                                        # fill them in X\n",
    "test_data_processed = imputer.fit_transform(test_data_processed)    # fill them in test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scaling\n",
    "some columns may be very large then other columns when compared. it would not affect at the moment as we are using decision trees, but to maintain a fair enviroment, we shall perform scaling on every run.\n",
    "there are two types of scaling: \n",
    "- min max scaling (also known as normalization)\n",
    "- standardisation (z-score normalization)\n",
    "- max abs scaler\n",
    "- robust scaler\n",
    "- normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- case  -----------------------------\n",
    "# in this case we shall perform min max scaling. to do that, we must use our MinMaxScaler that we have imported above\n",
    "# scaler = MinMaxScaler()\n",
    "# # now we must use this scaler to scale X\n",
    "# scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.06302565e-06, 9.77528090e-01, 5.03110176e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [8.12605131e-06, 9.25531276e-01, 4.65579663e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.21890770e-05, 5.61797753e-01, 4.09520864e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [9.99991874e-01, 6.45753712e-01, 6.17180876e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.12013395e-01],\n",
       "       [9.99995937e-01, 7.41573034e-01, 3.50050368e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 5.64692584e-01, 4.82989245e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------- case  -----------------------------\n",
    "scaler = MaxAbsScaler()\n",
    "# now we must use this scaler to scale X\n",
    "scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our output shows us that every value in the array is between 0 and 1. thus lets save this value on X\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# now we must do the same on our test_data set\n",
    "test_data_processed = scaler.fit_transform(test_data_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filters\n",
    "there are two types of filters to filter out columns/features:\n",
    "- variance filter (a column which has same values throughout the column like all are sunny)\n",
    "- correlation filter (two columns which are same like weight in kg and weight in pounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :  (246122, 78)\n",
      "test data :  (105482, 78)\n"
     ]
    }
   ],
   "source": [
    "print(\"X : \", X.shape)\n",
    "print(\"test data : \", test_data_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246122, 78)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variance filter\n",
    "# ----------------------------- case  -----------------------------\n",
    "# variance_filter = VarianceThreshold(threshold=0.001)  # Adjust the threshold if needed\n",
    "# X = variance_filter.fit_transform(X)\n",
    "# test_data_processed = variance_filter.fit_transform(test_data_processed)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105482, 78)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246122, 78)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # correlation filter\n",
    "# # ----------------------------- case  -----------------------------\n",
    "# corr_matrix = pd.DataFrame(X).corr().abs()\n",
    "# upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "# to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "# X = pd.DataFrame(X).drop(columns=to_drop)\n",
    "# test_data_processed = pd.DataFrame(test_data_processed).drop(columns=to_drop)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105482, 78)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_processed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting - train and validate\n",
    "now our test_data set is of rows with NO target variable whereas the train_data set is WITH target variable.\n",
    "our rules in machine learning is that we must train half or 70% of the data and then we must check its accuracy using the remaining half or 30% of the data - we can only check accuracy IF we have the answers i.e. the target variable. \n",
    "So, what we need to do is, is split the train_data set into 2, by a 70% and 30% ratio. we train the model using the 70% and then test the model using the 30% and then use that model to predict the test_data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holdout method\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model intialization\n",
    "here model is intialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier()\n",
    "# --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "in this we select columns and features we want to keep. there are several algos to do so:\n",
    "- forward selection\n",
    "- backward selection\n",
    "- Kbest (best out of all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward selection\n",
    "# ----------------------------- case -----------------------------\n",
    "# selection = SequentialFeatureSelector(model, direction='forward',n_features_to_select=10, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # backward selection\n",
    "# selection = SequentialFeatureSelector(model, direction='backward',n_features_to_select=5, scoring='roc_auc', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k best\n",
    "# ----------------------------- case -----------------------------\n",
    "# selection = SelectKBest(score_func=f_classif, k=5)             # Use f_classif for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection fitting\n",
    "# trainX = selection.fit_transform(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection applying\n",
    "# testX = selection.transform(testX)                                  # Ensure the test set is transformed similarly\n",
    "# test_data_processed = selection.transform(test_data_processed)      # test data is also transformed\n",
    "# X = selection.transform(X)                                          # full data transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172285, 78)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyper parameters of grid\n",
    "# param_grid = {\n",
    "#     'max_depth': [2, 3, 6, 7, 8, 9, 10],\n",
    "#     'learning_rate': [0.001, 0.005, 0.01, 0.05],\n",
    "#     'n_estimators': [400, 500, 1000, 2000, 3000]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize grid search\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "# grid_search.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the best model grid search found\n",
    "# best_model = grid_search.best_estimator_\n",
    "# best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the best parameters of the best model\n",
    "# best_parameters = grid_search.best_params_\n",
    "# best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the best model our model\n",
    "# model = best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging intialization\n",
    "here we will introduce and intialize bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = BaggingClassifier(estimator=model, n_estimators=50, verbose=2)\n",
    "# -- \n",
    "# model = BaggingClassifier(estimator=model, n_estimators=50)                   # case\n",
    "# model = BaggingClassifier(estimator=model, n_estimators=100)                  # case "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model running\n",
    "here we run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.092856\n",
      "0:\tlearn: 0.4470045\ttotal: 269ms\tremaining: 4m 28s\n",
      "1:\tlearn: 0.2909611\ttotal: 397ms\tremaining: 3m 17s\n",
      "2:\tlearn: 0.1893640\ttotal: 530ms\tremaining: 2m 56s\n",
      "3:\tlearn: 0.1284326\ttotal: 650ms\tremaining: 2m 41s\n",
      "4:\tlearn: 0.0891739\ttotal: 779ms\tremaining: 2m 35s\n",
      "5:\tlearn: 0.0649353\ttotal: 911ms\tremaining: 2m 30s\n",
      "6:\tlearn: 0.0493412\ttotal: 1.06s\tremaining: 2m 29s\n",
      "7:\tlearn: 0.0388342\ttotal: 1.19s\tremaining: 2m 28s\n",
      "8:\tlearn: 0.0320255\ttotal: 1.32s\tremaining: 2m 25s\n",
      "9:\tlearn: 0.0268845\ttotal: 1.42s\tremaining: 2m 20s\n",
      "10:\tlearn: 0.0235381\ttotal: 1.53s\tremaining: 2m 17s\n",
      "11:\tlearn: 0.0210651\ttotal: 1.64s\tremaining: 2m 15s\n",
      "12:\tlearn: 0.0191424\ttotal: 1.77s\tremaining: 2m 14s\n",
      "13:\tlearn: 0.0178500\ttotal: 1.9s\tremaining: 2m 13s\n",
      "14:\tlearn: 0.0168758\ttotal: 2s\tremaining: 2m 11s\n",
      "15:\tlearn: 0.0160902\ttotal: 2.1s\tremaining: 2m 8s\n",
      "16:\tlearn: 0.0155701\ttotal: 2.21s\tremaining: 2m 8s\n",
      "17:\tlearn: 0.0149558\ttotal: 2.32s\tremaining: 2m 6s\n",
      "18:\tlearn: 0.0145421\ttotal: 2.41s\tremaining: 2m 4s\n",
      "19:\tlearn: 0.0142399\ttotal: 2.51s\tremaining: 2m 2s\n",
      "20:\tlearn: 0.0139144\ttotal: 2.62s\tremaining: 2m 2s\n",
      "21:\tlearn: 0.0136769\ttotal: 2.75s\tremaining: 2m 2s\n",
      "22:\tlearn: 0.0135008\ttotal: 2.87s\tremaining: 2m 1s\n",
      "23:\tlearn: 0.0133915\ttotal: 2.98s\tremaining: 2m 1s\n",
      "24:\tlearn: 0.0132908\ttotal: 3.09s\tremaining: 2m\n",
      "25:\tlearn: 0.0131541\ttotal: 3.2s\tremaining: 1m 59s\n",
      "26:\tlearn: 0.0130117\ttotal: 3.3s\tremaining: 1m 58s\n",
      "27:\tlearn: 0.0128801\ttotal: 3.4s\tremaining: 1m 58s\n",
      "28:\tlearn: 0.0127845\ttotal: 3.5s\tremaining: 1m 57s\n",
      "29:\tlearn: 0.0126931\ttotal: 3.6s\tremaining: 1m 56s\n",
      "30:\tlearn: 0.0126242\ttotal: 3.72s\tremaining: 1m 56s\n",
      "31:\tlearn: 0.0125485\ttotal: 3.85s\tremaining: 1m 56s\n",
      "32:\tlearn: 0.0124238\ttotal: 3.96s\tremaining: 1m 56s\n",
      "33:\tlearn: 0.0123193\ttotal: 4.05s\tremaining: 1m 55s\n",
      "34:\tlearn: 0.0122209\ttotal: 4.16s\tremaining: 1m 54s\n",
      "35:\tlearn: 0.0121751\ttotal: 4.29s\tremaining: 1m 54s\n",
      "36:\tlearn: 0.0121223\ttotal: 4.41s\tremaining: 1m 54s\n",
      "37:\tlearn: 0.0120738\ttotal: 4.52s\tremaining: 1m 54s\n",
      "38:\tlearn: 0.0120405\ttotal: 4.64s\tremaining: 1m 54s\n",
      "39:\tlearn: 0.0119671\ttotal: 4.75s\tremaining: 1m 53s\n",
      "40:\tlearn: 0.0118946\ttotal: 4.85s\tremaining: 1m 53s\n",
      "41:\tlearn: 0.0118389\ttotal: 4.95s\tremaining: 1m 52s\n",
      "42:\tlearn: 0.0117946\ttotal: 5.07s\tremaining: 1m 52s\n",
      "43:\tlearn: 0.0117162\ttotal: 5.18s\tremaining: 1m 52s\n",
      "44:\tlearn: 0.0116804\ttotal: 5.29s\tremaining: 1m 52s\n",
      "45:\tlearn: 0.0116304\ttotal: 5.39s\tremaining: 1m 51s\n",
      "46:\tlearn: 0.0115615\ttotal: 5.51s\tremaining: 1m 51s\n",
      "47:\tlearn: 0.0115235\ttotal: 5.63s\tremaining: 1m 51s\n",
      "48:\tlearn: 0.0114977\ttotal: 5.75s\tremaining: 1m 51s\n",
      "49:\tlearn: 0.0114558\ttotal: 5.89s\tremaining: 1m 51s\n",
      "50:\tlearn: 0.0114327\ttotal: 6s\tremaining: 1m 51s\n",
      "51:\tlearn: 0.0114051\ttotal: 6.11s\tremaining: 1m 51s\n",
      "52:\tlearn: 0.0113200\ttotal: 6.2s\tremaining: 1m 50s\n",
      "53:\tlearn: 0.0112896\ttotal: 6.31s\tremaining: 1m 50s\n",
      "54:\tlearn: 0.0112671\ttotal: 6.4s\tremaining: 1m 50s\n",
      "55:\tlearn: 0.0112269\ttotal: 6.5s\tremaining: 1m 49s\n",
      "56:\tlearn: 0.0111918\ttotal: 6.62s\tremaining: 1m 49s\n",
      "57:\tlearn: 0.0111724\ttotal: 6.77s\tremaining: 1m 50s\n",
      "58:\tlearn: 0.0111478\ttotal: 6.88s\tremaining: 1m 49s\n",
      "59:\tlearn: 0.0111091\ttotal: 6.98s\tremaining: 1m 49s\n",
      "60:\tlearn: 0.0110768\ttotal: 7.08s\tremaining: 1m 49s\n",
      "61:\tlearn: 0.0110573\ttotal: 7.2s\tremaining: 1m 48s\n",
      "62:\tlearn: 0.0110343\ttotal: 7.29s\tremaining: 1m 48s\n",
      "63:\tlearn: 0.0109878\ttotal: 7.39s\tremaining: 1m 48s\n",
      "64:\tlearn: 0.0109550\ttotal: 7.51s\tremaining: 1m 47s\n",
      "65:\tlearn: 0.0109194\ttotal: 7.63s\tremaining: 1m 47s\n",
      "66:\tlearn: 0.0108481\ttotal: 7.78s\tremaining: 1m 48s\n",
      "67:\tlearn: 0.0108163\ttotal: 7.89s\tremaining: 1m 48s\n",
      "68:\tlearn: 0.0107678\ttotal: 8.01s\tremaining: 1m 48s\n",
      "69:\tlearn: 0.0107454\ttotal: 8.11s\tremaining: 1m 47s\n",
      "70:\tlearn: 0.0106995\ttotal: 8.21s\tremaining: 1m 47s\n",
      "71:\tlearn: 0.0106778\ttotal: 8.32s\tremaining: 1m 47s\n",
      "72:\tlearn: 0.0106441\ttotal: 8.46s\tremaining: 1m 47s\n",
      "73:\tlearn: 0.0105984\ttotal: 8.57s\tremaining: 1m 47s\n",
      "74:\tlearn: 0.0105690\ttotal: 8.71s\tremaining: 1m 47s\n",
      "75:\tlearn: 0.0105410\ttotal: 8.84s\tremaining: 1m 47s\n",
      "76:\tlearn: 0.0104911\ttotal: 9.11s\tremaining: 1m 49s\n",
      "77:\tlearn: 0.0104624\ttotal: 9.29s\tremaining: 1m 49s\n",
      "78:\tlearn: 0.0104310\ttotal: 9.43s\tremaining: 1m 49s\n",
      "79:\tlearn: 0.0103988\ttotal: 9.57s\tremaining: 1m 50s\n",
      "80:\tlearn: 0.0103858\ttotal: 9.76s\tremaining: 1m 50s\n",
      "81:\tlearn: 0.0103655\ttotal: 9.87s\tremaining: 1m 50s\n",
      "82:\tlearn: 0.0103421\ttotal: 9.97s\tremaining: 1m 50s\n",
      "83:\tlearn: 0.0103061\ttotal: 10.1s\tremaining: 1m 50s\n",
      "84:\tlearn: 0.0102804\ttotal: 10.2s\tremaining: 1m 49s\n",
      "85:\tlearn: 0.0102357\ttotal: 10.3s\tremaining: 1m 49s\n",
      "86:\tlearn: 0.0102014\ttotal: 10.4s\tremaining: 1m 49s\n",
      "87:\tlearn: 0.0101856\ttotal: 10.5s\tremaining: 1m 48s\n",
      "88:\tlearn: 0.0101660\ttotal: 10.6s\tremaining: 1m 48s\n",
      "89:\tlearn: 0.0101444\ttotal: 10.7s\tremaining: 1m 48s\n",
      "90:\tlearn: 0.0101195\ttotal: 10.8s\tremaining: 1m 48s\n",
      "91:\tlearn: 0.0100994\ttotal: 11s\tremaining: 1m 48s\n",
      "92:\tlearn: 0.0100794\ttotal: 11.1s\tremaining: 1m 47s\n",
      "93:\tlearn: 0.0100588\ttotal: 11.1s\tremaining: 1m 47s\n",
      "94:\tlearn: 0.0099747\ttotal: 11.3s\tremaining: 1m 47s\n",
      "95:\tlearn: 0.0099555\ttotal: 11.4s\tremaining: 1m 47s\n",
      "96:\tlearn: 0.0099435\ttotal: 11.5s\tremaining: 1m 47s\n",
      "97:\tlearn: 0.0099244\ttotal: 11.6s\tremaining: 1m 46s\n",
      "98:\tlearn: 0.0099109\ttotal: 11.7s\tremaining: 1m 46s\n",
      "99:\tlearn: 0.0098858\ttotal: 11.9s\tremaining: 1m 46s\n",
      "100:\tlearn: 0.0098637\ttotal: 12s\tremaining: 1m 47s\n",
      "101:\tlearn: 0.0098410\ttotal: 12.2s\tremaining: 1m 47s\n",
      "102:\tlearn: 0.0098157\ttotal: 12.3s\tremaining: 1m 46s\n",
      "103:\tlearn: 0.0098044\ttotal: 12.4s\tremaining: 1m 46s\n",
      "104:\tlearn: 0.0097840\ttotal: 12.5s\tremaining: 1m 46s\n",
      "105:\tlearn: 0.0097626\ttotal: 12.6s\tremaining: 1m 46s\n",
      "106:\tlearn: 0.0097520\ttotal: 12.7s\tremaining: 1m 46s\n",
      "107:\tlearn: 0.0097334\ttotal: 12.9s\tremaining: 1m 46s\n",
      "108:\tlearn: 0.0097222\ttotal: 13s\tremaining: 1m 45s\n",
      "109:\tlearn: 0.0096876\ttotal: 13.1s\tremaining: 1m 45s\n",
      "110:\tlearn: 0.0096700\ttotal: 13.2s\tremaining: 1m 45s\n",
      "111:\tlearn: 0.0096451\ttotal: 13.3s\tremaining: 1m 45s\n",
      "112:\tlearn: 0.0096291\ttotal: 13.4s\tremaining: 1m 45s\n",
      "113:\tlearn: 0.0095968\ttotal: 13.6s\tremaining: 1m 45s\n",
      "114:\tlearn: 0.0095788\ttotal: 13.7s\tremaining: 1m 45s\n",
      "115:\tlearn: 0.0095601\ttotal: 13.8s\tremaining: 1m 45s\n",
      "116:\tlearn: 0.0095207\ttotal: 13.9s\tremaining: 1m 44s\n",
      "117:\tlearn: 0.0094939\ttotal: 14s\tremaining: 1m 44s\n",
      "118:\tlearn: 0.0094712\ttotal: 14.1s\tremaining: 1m 44s\n",
      "119:\tlearn: 0.0094436\ttotal: 14.2s\tremaining: 1m 44s\n",
      "120:\tlearn: 0.0094244\ttotal: 14.3s\tremaining: 1m 44s\n",
      "121:\tlearn: 0.0094098\ttotal: 14.4s\tremaining: 1m 43s\n",
      "122:\tlearn: 0.0093953\ttotal: 14.6s\tremaining: 1m 43s\n",
      "123:\tlearn: 0.0093843\ttotal: 14.7s\tremaining: 1m 43s\n",
      "124:\tlearn: 0.0093717\ttotal: 14.8s\tremaining: 1m 43s\n",
      "125:\tlearn: 0.0093566\ttotal: 14.9s\tremaining: 1m 43s\n",
      "126:\tlearn: 0.0093383\ttotal: 15s\tremaining: 1m 43s\n",
      "127:\tlearn: 0.0093291\ttotal: 15.1s\tremaining: 1m 42s\n",
      "128:\tlearn: 0.0093107\ttotal: 15.2s\tremaining: 1m 42s\n",
      "129:\tlearn: 0.0092963\ttotal: 15.3s\tremaining: 1m 42s\n",
      "130:\tlearn: 0.0092715\ttotal: 15.4s\tremaining: 1m 42s\n",
      "131:\tlearn: 0.0092485\ttotal: 15.5s\tremaining: 1m 42s\n",
      "132:\tlearn: 0.0092327\ttotal: 15.6s\tremaining: 1m 41s\n",
      "133:\tlearn: 0.0092265\ttotal: 15.8s\tremaining: 1m 42s\n",
      "134:\tlearn: 0.0092160\ttotal: 15.9s\tremaining: 1m 41s\n",
      "135:\tlearn: 0.0091871\ttotal: 16s\tremaining: 1m 41s\n",
      "136:\tlearn: 0.0091769\ttotal: 16.1s\tremaining: 1m 41s\n",
      "137:\tlearn: 0.0091658\ttotal: 16.2s\tremaining: 1m 41s\n",
      "138:\tlearn: 0.0091531\ttotal: 16.3s\tremaining: 1m 41s\n",
      "139:\tlearn: 0.0091338\ttotal: 16.4s\tremaining: 1m 40s\n",
      "140:\tlearn: 0.0091163\ttotal: 16.5s\tremaining: 1m 40s\n",
      "141:\tlearn: 0.0090830\ttotal: 16.6s\tremaining: 1m 40s\n",
      "142:\tlearn: 0.0090623\ttotal: 16.8s\tremaining: 1m 40s\n",
      "143:\tlearn: 0.0090415\ttotal: 16.9s\tremaining: 1m 40s\n",
      "144:\tlearn: 0.0090236\ttotal: 17s\tremaining: 1m 40s\n",
      "145:\tlearn: 0.0090137\ttotal: 17.1s\tremaining: 1m 39s\n",
      "146:\tlearn: 0.0089769\ttotal: 17.2s\tremaining: 1m 39s\n",
      "147:\tlearn: 0.0089615\ttotal: 17.3s\tremaining: 1m 39s\n",
      "148:\tlearn: 0.0089524\ttotal: 17.4s\tremaining: 1m 39s\n",
      "149:\tlearn: 0.0089462\ttotal: 17.5s\tremaining: 1m 39s\n",
      "150:\tlearn: 0.0089230\ttotal: 17.6s\tremaining: 1m 39s\n",
      "151:\tlearn: 0.0089120\ttotal: 17.8s\tremaining: 1m 39s\n",
      "152:\tlearn: 0.0089057\ttotal: 17.8s\tremaining: 1m 38s\n",
      "153:\tlearn: 0.0088645\ttotal: 18.1s\tremaining: 1m 39s\n",
      "154:\tlearn: 0.0088521\ttotal: 18.4s\tremaining: 1m 40s\n",
      "155:\tlearn: 0.0088350\ttotal: 18.7s\tremaining: 1m 41s\n",
      "156:\tlearn: 0.0088248\ttotal: 18.9s\tremaining: 1m 41s\n",
      "157:\tlearn: 0.0087932\ttotal: 19.2s\tremaining: 1m 42s\n",
      "158:\tlearn: 0.0087841\ttotal: 19.5s\tremaining: 1m 43s\n",
      "159:\tlearn: 0.0087674\ttotal: 19.7s\tremaining: 1m 43s\n",
      "160:\tlearn: 0.0087533\ttotal: 19.8s\tremaining: 1m 43s\n",
      "161:\tlearn: 0.0087239\ttotal: 20s\tremaining: 1m 43s\n",
      "162:\tlearn: 0.0087088\ttotal: 20.1s\tremaining: 1m 43s\n",
      "163:\tlearn: 0.0086689\ttotal: 20.3s\tremaining: 1m 43s\n",
      "164:\tlearn: 0.0086610\ttotal: 20.4s\tremaining: 1m 43s\n",
      "165:\tlearn: 0.0086540\ttotal: 20.5s\tremaining: 1m 43s\n",
      "166:\tlearn: 0.0086315\ttotal: 20.7s\tremaining: 1m 43s\n",
      "167:\tlearn: 0.0086174\ttotal: 20.8s\tremaining: 1m 42s\n",
      "168:\tlearn: 0.0085859\ttotal: 20.9s\tremaining: 1m 42s\n",
      "169:\tlearn: 0.0085555\ttotal: 21s\tremaining: 1m 42s\n",
      "170:\tlearn: 0.0085344\ttotal: 21.2s\tremaining: 1m 42s\n",
      "171:\tlearn: 0.0085223\ttotal: 21.3s\tremaining: 1m 42s\n",
      "172:\tlearn: 0.0084887\ttotal: 21.5s\tremaining: 1m 42s\n",
      "173:\tlearn: 0.0084698\ttotal: 21.6s\tremaining: 1m 42s\n",
      "174:\tlearn: 0.0084470\ttotal: 21.8s\tremaining: 1m 42s\n",
      "175:\tlearn: 0.0084364\ttotal: 22.2s\tremaining: 1m 43s\n",
      "176:\tlearn: 0.0084254\ttotal: 22.3s\tremaining: 1m 43s\n",
      "177:\tlearn: 0.0083882\ttotal: 22.4s\tremaining: 1m 43s\n",
      "178:\tlearn: 0.0083659\ttotal: 22.6s\tremaining: 1m 43s\n",
      "179:\tlearn: 0.0083506\ttotal: 22.7s\tremaining: 1m 43s\n",
      "180:\tlearn: 0.0083407\ttotal: 22.9s\tremaining: 1m 43s\n",
      "181:\tlearn: 0.0083269\ttotal: 23s\tremaining: 1m 43s\n",
      "182:\tlearn: 0.0083214\ttotal: 23.1s\tremaining: 1m 43s\n",
      "183:\tlearn: 0.0083094\ttotal: 23.2s\tremaining: 1m 42s\n",
      "184:\tlearn: 0.0082768\ttotal: 23.3s\tremaining: 1m 42s\n",
      "185:\tlearn: 0.0082513\ttotal: 23.5s\tremaining: 1m 42s\n",
      "186:\tlearn: 0.0082454\ttotal: 23.6s\tremaining: 1m 42s\n",
      "187:\tlearn: 0.0082360\ttotal: 23.7s\tremaining: 1m 42s\n",
      "188:\tlearn: 0.0082258\ttotal: 23.9s\tremaining: 1m 42s\n",
      "189:\tlearn: 0.0082106\ttotal: 24s\tremaining: 1m 42s\n",
      "190:\tlearn: 0.0082034\ttotal: 24.2s\tremaining: 1m 42s\n",
      "191:\tlearn: 0.0081931\ttotal: 24.4s\tremaining: 1m 42s\n",
      "192:\tlearn: 0.0081660\ttotal: 24.5s\tremaining: 1m 42s\n",
      "193:\tlearn: 0.0081520\ttotal: 24.8s\tremaining: 1m 43s\n",
      "194:\tlearn: 0.0081352\ttotal: 24.9s\tremaining: 1m 42s\n",
      "195:\tlearn: 0.0081007\ttotal: 25s\tremaining: 1m 42s\n",
      "196:\tlearn: 0.0080924\ttotal: 25.2s\tremaining: 1m 42s\n",
      "197:\tlearn: 0.0080662\ttotal: 25.3s\tremaining: 1m 42s\n",
      "198:\tlearn: 0.0080544\ttotal: 25.5s\tremaining: 1m 42s\n",
      "199:\tlearn: 0.0080465\ttotal: 25.6s\tremaining: 1m 42s\n",
      "200:\tlearn: 0.0080376\ttotal: 25.8s\tremaining: 1m 42s\n",
      "201:\tlearn: 0.0080060\ttotal: 25.9s\tremaining: 1m 42s\n",
      "202:\tlearn: 0.0079890\ttotal: 26s\tremaining: 1m 42s\n",
      "203:\tlearn: 0.0079645\ttotal: 26.1s\tremaining: 1m 41s\n",
      "204:\tlearn: 0.0079619\ttotal: 26.2s\tremaining: 1m 41s\n",
      "205:\tlearn: 0.0079372\ttotal: 26.3s\tremaining: 1m 41s\n",
      "206:\tlearn: 0.0079322\ttotal: 26.4s\tremaining: 1m 41s\n",
      "207:\tlearn: 0.0079252\ttotal: 26.5s\tremaining: 1m 40s\n",
      "208:\tlearn: 0.0079173\ttotal: 26.7s\tremaining: 1m 40s\n",
      "209:\tlearn: 0.0079095\ttotal: 26.8s\tremaining: 1m 40s\n",
      "210:\tlearn: 0.0078991\ttotal: 26.9s\tremaining: 1m 40s\n",
      "211:\tlearn: 0.0078738\ttotal: 27s\tremaining: 1m 40s\n",
      "212:\tlearn: 0.0078623\ttotal: 27.1s\tremaining: 1m 40s\n",
      "213:\tlearn: 0.0078425\ttotal: 27.2s\tremaining: 1m 40s\n",
      "214:\tlearn: 0.0078189\ttotal: 27.3s\tremaining: 1m 39s\n",
      "215:\tlearn: 0.0078076\ttotal: 27.4s\tremaining: 1m 39s\n",
      "216:\tlearn: 0.0077957\ttotal: 27.5s\tremaining: 1m 39s\n",
      "217:\tlearn: 0.0077738\ttotal: 27.7s\tremaining: 1m 39s\n",
      "218:\tlearn: 0.0077602\ttotal: 27.8s\tremaining: 1m 39s\n",
      "219:\tlearn: 0.0077480\ttotal: 27.9s\tremaining: 1m 39s\n",
      "220:\tlearn: 0.0077369\ttotal: 28s\tremaining: 1m 38s\n",
      "221:\tlearn: 0.0077313\ttotal: 28.2s\tremaining: 1m 38s\n",
      "222:\tlearn: 0.0077128\ttotal: 28.3s\tremaining: 1m 38s\n",
      "223:\tlearn: 0.0076953\ttotal: 28.4s\tremaining: 1m 38s\n",
      "224:\tlearn: 0.0076849\ttotal: 28.5s\tremaining: 1m 38s\n",
      "225:\tlearn: 0.0076653\ttotal: 28.7s\tremaining: 1m 38s\n",
      "226:\tlearn: 0.0076535\ttotal: 28.9s\tremaining: 1m 38s\n",
      "227:\tlearn: 0.0076336\ttotal: 29s\tremaining: 1m 38s\n",
      "228:\tlearn: 0.0076211\ttotal: 29.1s\tremaining: 1m 38s\n",
      "229:\tlearn: 0.0076006\ttotal: 29.3s\tremaining: 1m 37s\n",
      "230:\tlearn: 0.0075789\ttotal: 29.4s\tremaining: 1m 37s\n",
      "231:\tlearn: 0.0075651\ttotal: 29.5s\tremaining: 1m 37s\n",
      "232:\tlearn: 0.0075465\ttotal: 29.6s\tremaining: 1m 37s\n",
      "233:\tlearn: 0.0075397\ttotal: 29.8s\tremaining: 1m 37s\n",
      "234:\tlearn: 0.0075358\ttotal: 29.9s\tremaining: 1m 37s\n",
      "235:\tlearn: 0.0075292\ttotal: 30s\tremaining: 1m 37s\n",
      "236:\tlearn: 0.0075171\ttotal: 30.1s\tremaining: 1m 37s\n",
      "237:\tlearn: 0.0075059\ttotal: 30.3s\tremaining: 1m 37s\n",
      "238:\tlearn: 0.0074760\ttotal: 30.5s\tremaining: 1m 37s\n",
      "239:\tlearn: 0.0074624\ttotal: 30.7s\tremaining: 1m 37s\n",
      "240:\tlearn: 0.0074399\ttotal: 30.8s\tremaining: 1m 36s\n",
      "241:\tlearn: 0.0074252\ttotal: 30.9s\tremaining: 1m 36s\n",
      "242:\tlearn: 0.0074178\ttotal: 31.1s\tremaining: 1m 36s\n",
      "243:\tlearn: 0.0074019\ttotal: 31.2s\tremaining: 1m 36s\n",
      "244:\tlearn: 0.0073815\ttotal: 31.3s\tremaining: 1m 36s\n",
      "245:\tlearn: 0.0073775\ttotal: 31.4s\tremaining: 1m 36s\n",
      "246:\tlearn: 0.0073683\ttotal: 31.5s\tremaining: 1m 35s\n",
      "247:\tlearn: 0.0073642\ttotal: 31.6s\tremaining: 1m 35s\n",
      "248:\tlearn: 0.0073481\ttotal: 31.7s\tremaining: 1m 35s\n",
      "249:\tlearn: 0.0073436\ttotal: 31.8s\tremaining: 1m 35s\n",
      "250:\tlearn: 0.0073377\ttotal: 31.9s\tremaining: 1m 35s\n",
      "251:\tlearn: 0.0073154\ttotal: 32s\tremaining: 1m 35s\n",
      "252:\tlearn: 0.0072943\ttotal: 32.1s\tremaining: 1m 34s\n",
      "253:\tlearn: 0.0072876\ttotal: 32.3s\tremaining: 1m 34s\n",
      "254:\tlearn: 0.0072676\ttotal: 32.4s\tremaining: 1m 34s\n",
      "255:\tlearn: 0.0072596\ttotal: 32.5s\tremaining: 1m 34s\n",
      "256:\tlearn: 0.0072500\ttotal: 32.6s\tremaining: 1m 34s\n",
      "257:\tlearn: 0.0072310\ttotal: 32.8s\tremaining: 1m 34s\n",
      "258:\tlearn: 0.0072224\ttotal: 32.9s\tremaining: 1m 34s\n",
      "259:\tlearn: 0.0071989\ttotal: 33s\tremaining: 1m 33s\n",
      "260:\tlearn: 0.0071797\ttotal: 33.1s\tremaining: 1m 33s\n",
      "261:\tlearn: 0.0071661\ttotal: 33.3s\tremaining: 1m 33s\n",
      "262:\tlearn: 0.0071590\ttotal: 33.4s\tremaining: 1m 33s\n",
      "263:\tlearn: 0.0071562\ttotal: 33.5s\tremaining: 1m 33s\n",
      "264:\tlearn: 0.0071338\ttotal: 33.7s\tremaining: 1m 33s\n",
      "265:\tlearn: 0.0071231\ttotal: 33.9s\tremaining: 1m 33s\n",
      "266:\tlearn: 0.0071036\ttotal: 34s\tremaining: 1m 33s\n",
      "267:\tlearn: 0.0070884\ttotal: 34.2s\tremaining: 1m 33s\n",
      "268:\tlearn: 0.0070856\ttotal: 34.3s\tremaining: 1m 33s\n",
      "269:\tlearn: 0.0070808\ttotal: 34.5s\tremaining: 1m 33s\n",
      "270:\tlearn: 0.0070740\ttotal: 34.6s\tremaining: 1m 33s\n",
      "271:\tlearn: 0.0070599\ttotal: 34.8s\tremaining: 1m 33s\n",
      "272:\tlearn: 0.0070471\ttotal: 35s\tremaining: 1m 33s\n",
      "273:\tlearn: 0.0070385\ttotal: 35.1s\tremaining: 1m 33s\n",
      "274:\tlearn: 0.0070283\ttotal: 35.3s\tremaining: 1m 33s\n",
      "275:\tlearn: 0.0070099\ttotal: 35.4s\tremaining: 1m 32s\n",
      "276:\tlearn: 0.0069981\ttotal: 35.6s\tremaining: 1m 33s\n",
      "277:\tlearn: 0.0069919\ttotal: 35.8s\tremaining: 1m 32s\n",
      "278:\tlearn: 0.0069788\ttotal: 36s\tremaining: 1m 32s\n",
      "279:\tlearn: 0.0069598\ttotal: 36.2s\tremaining: 1m 33s\n",
      "280:\tlearn: 0.0069445\ttotal: 36.4s\tremaining: 1m 33s\n",
      "281:\tlearn: 0.0069182\ttotal: 36.6s\tremaining: 1m 33s\n",
      "282:\tlearn: 0.0069041\ttotal: 36.8s\tremaining: 1m 33s\n",
      "283:\tlearn: 0.0068902\ttotal: 36.9s\tremaining: 1m 32s\n",
      "284:\tlearn: 0.0068825\ttotal: 37s\tremaining: 1m 32s\n",
      "285:\tlearn: 0.0068607\ttotal: 37.1s\tremaining: 1m 32s\n",
      "286:\tlearn: 0.0068447\ttotal: 37.2s\tremaining: 1m 32s\n",
      "287:\tlearn: 0.0068252\ttotal: 37.3s\tremaining: 1m 32s\n",
      "288:\tlearn: 0.0068228\ttotal: 37.4s\tremaining: 1m 32s\n",
      "289:\tlearn: 0.0068206\ttotal: 37.5s\tremaining: 1m 31s\n",
      "290:\tlearn: 0.0067936\ttotal: 37.7s\tremaining: 1m 31s\n",
      "291:\tlearn: 0.0067854\ttotal: 37.8s\tremaining: 1m 31s\n",
      "292:\tlearn: 0.0067704\ttotal: 37.9s\tremaining: 1m 31s\n",
      "293:\tlearn: 0.0067593\ttotal: 38.1s\tremaining: 1m 31s\n",
      "294:\tlearn: 0.0067530\ttotal: 38.2s\tremaining: 1m 31s\n",
      "295:\tlearn: 0.0067277\ttotal: 38.3s\tremaining: 1m 31s\n",
      "296:\tlearn: 0.0067183\ttotal: 38.4s\tremaining: 1m 31s\n",
      "297:\tlearn: 0.0067121\ttotal: 38.6s\tremaining: 1m 30s\n",
      "298:\tlearn: 0.0067037\ttotal: 38.7s\tremaining: 1m 30s\n",
      "299:\tlearn: 0.0066970\ttotal: 38.9s\tremaining: 1m 30s\n",
      "300:\tlearn: 0.0066833\ttotal: 39s\tremaining: 1m 30s\n",
      "301:\tlearn: 0.0066747\ttotal: 39.1s\tremaining: 1m 30s\n",
      "302:\tlearn: 0.0066489\ttotal: 39.2s\tremaining: 1m 30s\n",
      "303:\tlearn: 0.0066328\ttotal: 39.4s\tremaining: 1m 30s\n",
      "304:\tlearn: 0.0066308\ttotal: 39.5s\tremaining: 1m 29s\n",
      "305:\tlearn: 0.0066264\ttotal: 39.6s\tremaining: 1m 29s\n",
      "306:\tlearn: 0.0066103\ttotal: 39.9s\tremaining: 1m 30s\n",
      "307:\tlearn: 0.0065934\ttotal: 40.1s\tremaining: 1m 30s\n",
      "308:\tlearn: 0.0065870\ttotal: 40.2s\tremaining: 1m 29s\n",
      "309:\tlearn: 0.0065752\ttotal: 40.3s\tremaining: 1m 29s\n",
      "310:\tlearn: 0.0065564\ttotal: 40.4s\tremaining: 1m 29s\n",
      "311:\tlearn: 0.0065356\ttotal: 40.6s\tremaining: 1m 29s\n",
      "312:\tlearn: 0.0065084\ttotal: 40.7s\tremaining: 1m 29s\n",
      "313:\tlearn: 0.0065018\ttotal: 40.8s\tremaining: 1m 29s\n",
      "314:\tlearn: 0.0064849\ttotal: 41s\tremaining: 1m 29s\n",
      "315:\tlearn: 0.0064746\ttotal: 41.1s\tremaining: 1m 28s\n",
      "316:\tlearn: 0.0064693\ttotal: 41.2s\tremaining: 1m 28s\n",
      "317:\tlearn: 0.0064674\ttotal: 41.3s\tremaining: 1m 28s\n",
      "318:\tlearn: 0.0064525\ttotal: 41.4s\tremaining: 1m 28s\n",
      "319:\tlearn: 0.0064402\ttotal: 41.5s\tremaining: 1m 28s\n",
      "320:\tlearn: 0.0064350\ttotal: 41.7s\tremaining: 1m 28s\n",
      "321:\tlearn: 0.0064270\ttotal: 41.8s\tremaining: 1m 27s\n",
      "322:\tlearn: 0.0064220\ttotal: 41.9s\tremaining: 1m 27s\n",
      "323:\tlearn: 0.0064097\ttotal: 42s\tremaining: 1m 27s\n",
      "324:\tlearn: 0.0063870\ttotal: 42.1s\tremaining: 1m 27s\n",
      "325:\tlearn: 0.0063764\ttotal: 42.2s\tremaining: 1m 27s\n",
      "326:\tlearn: 0.0063590\ttotal: 42.4s\tremaining: 1m 27s\n",
      "327:\tlearn: 0.0063469\ttotal: 42.5s\tremaining: 1m 27s\n",
      "328:\tlearn: 0.0063349\ttotal: 42.6s\tremaining: 1m 26s\n",
      "329:\tlearn: 0.0063163\ttotal: 42.8s\tremaining: 1m 26s\n",
      "330:\tlearn: 0.0063097\ttotal: 42.9s\tremaining: 1m 26s\n",
      "331:\tlearn: 0.0063040\ttotal: 43s\tremaining: 1m 26s\n",
      "332:\tlearn: 0.0062994\ttotal: 43.2s\tremaining: 1m 26s\n",
      "333:\tlearn: 0.0062909\ttotal: 43.3s\tremaining: 1m 26s\n",
      "334:\tlearn: 0.0062807\ttotal: 43.4s\tremaining: 1m 26s\n",
      "335:\tlearn: 0.0062696\ttotal: 43.5s\tremaining: 1m 25s\n",
      "336:\tlearn: 0.0062401\ttotal: 43.7s\tremaining: 1m 25s\n",
      "337:\tlearn: 0.0062321\ttotal: 43.8s\tremaining: 1m 25s\n",
      "338:\tlearn: 0.0062210\ttotal: 43.9s\tremaining: 1m 25s\n",
      "339:\tlearn: 0.0062162\ttotal: 44s\tremaining: 1m 25s\n",
      "340:\tlearn: 0.0061850\ttotal: 44.2s\tremaining: 1m 25s\n",
      "341:\tlearn: 0.0061732\ttotal: 44.3s\tremaining: 1m 25s\n",
      "342:\tlearn: 0.0061585\ttotal: 44.5s\tremaining: 1m 25s\n",
      "343:\tlearn: 0.0061529\ttotal: 44.6s\tremaining: 1m 25s\n",
      "344:\tlearn: 0.0061388\ttotal: 44.7s\tremaining: 1m 24s\n",
      "345:\tlearn: 0.0061249\ttotal: 44.9s\tremaining: 1m 24s\n",
      "346:\tlearn: 0.0061125\ttotal: 45s\tremaining: 1m 24s\n",
      "347:\tlearn: 0.0061065\ttotal: 45.1s\tremaining: 1m 24s\n",
      "348:\tlearn: 0.0060798\ttotal: 45.3s\tremaining: 1m 24s\n",
      "349:\tlearn: 0.0060734\ttotal: 45.4s\tremaining: 1m 24s\n",
      "350:\tlearn: 0.0060692\ttotal: 45.6s\tremaining: 1m 24s\n",
      "351:\tlearn: 0.0060622\ttotal: 45.8s\tremaining: 1m 24s\n",
      "352:\tlearn: 0.0060517\ttotal: 46s\tremaining: 1m 24s\n",
      "353:\tlearn: 0.0060401\ttotal: 46.2s\tremaining: 1m 24s\n",
      "354:\tlearn: 0.0060162\ttotal: 46.4s\tremaining: 1m 24s\n",
      "355:\tlearn: 0.0060104\ttotal: 46.5s\tremaining: 1m 24s\n",
      "356:\tlearn: 0.0060027\ttotal: 46.7s\tremaining: 1m 24s\n",
      "357:\tlearn: 0.0059964\ttotal: 46.9s\tremaining: 1m 24s\n",
      "358:\tlearn: 0.0059666\ttotal: 47s\tremaining: 1m 23s\n",
      "359:\tlearn: 0.0059619\ttotal: 47.1s\tremaining: 1m 23s\n",
      "360:\tlearn: 0.0059466\ttotal: 47.3s\tremaining: 1m 23s\n",
      "361:\tlearn: 0.0059386\ttotal: 47.5s\tremaining: 1m 23s\n",
      "362:\tlearn: 0.0059272\ttotal: 47.6s\tremaining: 1m 23s\n",
      "363:\tlearn: 0.0059125\ttotal: 47.8s\tremaining: 1m 23s\n",
      "364:\tlearn: 0.0059036\ttotal: 48s\tremaining: 1m 23s\n",
      "365:\tlearn: 0.0058941\ttotal: 48.2s\tremaining: 1m 23s\n",
      "366:\tlearn: 0.0058887\ttotal: 48.3s\tremaining: 1m 23s\n",
      "367:\tlearn: 0.0058845\ttotal: 48.5s\tremaining: 1m 23s\n",
      "368:\tlearn: 0.0058732\ttotal: 48.7s\tremaining: 1m 23s\n",
      "369:\tlearn: 0.0058648\ttotal: 48.9s\tremaining: 1m 23s\n",
      "370:\tlearn: 0.0058589\ttotal: 49s\tremaining: 1m 23s\n",
      "371:\tlearn: 0.0058517\ttotal: 49.1s\tremaining: 1m 22s\n",
      "372:\tlearn: 0.0058432\ttotal: 49.3s\tremaining: 1m 22s\n",
      "373:\tlearn: 0.0058304\ttotal: 49.4s\tremaining: 1m 22s\n",
      "374:\tlearn: 0.0058270\ttotal: 49.5s\tremaining: 1m 22s\n",
      "375:\tlearn: 0.0058123\ttotal: 49.7s\tremaining: 1m 22s\n",
      "376:\tlearn: 0.0057962\ttotal: 49.8s\tremaining: 1m 22s\n",
      "377:\tlearn: 0.0057942\ttotal: 50s\tremaining: 1m 22s\n",
      "378:\tlearn: 0.0057883\ttotal: 50.1s\tremaining: 1m 22s\n",
      "379:\tlearn: 0.0057824\ttotal: 50.3s\tremaining: 1m 21s\n",
      "380:\tlearn: 0.0057737\ttotal: 50.4s\tremaining: 1m 21s\n",
      "381:\tlearn: 0.0057692\ttotal: 50.5s\tremaining: 1m 21s\n",
      "382:\tlearn: 0.0057608\ttotal: 50.6s\tremaining: 1m 21s\n",
      "383:\tlearn: 0.0057460\ttotal: 50.8s\tremaining: 1m 21s\n",
      "384:\tlearn: 0.0057264\ttotal: 50.9s\tremaining: 1m 21s\n",
      "385:\tlearn: 0.0057217\ttotal: 51.1s\tremaining: 1m 21s\n",
      "386:\tlearn: 0.0057064\ttotal: 51.3s\tremaining: 1m 21s\n",
      "387:\tlearn: 0.0056953\ttotal: 51.4s\tremaining: 1m 21s\n",
      "388:\tlearn: 0.0056896\ttotal: 51.6s\tremaining: 1m 21s\n",
      "389:\tlearn: 0.0056696\ttotal: 51.7s\tremaining: 1m 20s\n",
      "390:\tlearn: 0.0056628\ttotal: 52s\tremaining: 1m 20s\n",
      "391:\tlearn: 0.0056526\ttotal: 52.1s\tremaining: 1m 20s\n",
      "392:\tlearn: 0.0056477\ttotal: 52.3s\tremaining: 1m 20s\n",
      "393:\tlearn: 0.0056417\ttotal: 52.4s\tremaining: 1m 20s\n",
      "394:\tlearn: 0.0056265\ttotal: 52.5s\tremaining: 1m 20s\n",
      "395:\tlearn: 0.0056175\ttotal: 52.6s\tremaining: 1m 20s\n",
      "396:\tlearn: 0.0056066\ttotal: 52.7s\tremaining: 1m 20s\n",
      "397:\tlearn: 0.0056029\ttotal: 52.9s\tremaining: 1m 19s\n",
      "398:\tlearn: 0.0055882\ttotal: 53s\tremaining: 1m 19s\n",
      "399:\tlearn: 0.0055852\ttotal: 53.1s\tremaining: 1m 19s\n",
      "400:\tlearn: 0.0055808\ttotal: 53.2s\tremaining: 1m 19s\n",
      "401:\tlearn: 0.0055726\ttotal: 53.3s\tremaining: 1m 19s\n",
      "402:\tlearn: 0.0055559\ttotal: 53.4s\tremaining: 1m 19s\n",
      "403:\tlearn: 0.0055509\ttotal: 53.6s\tremaining: 1m 19s\n",
      "404:\tlearn: 0.0055457\ttotal: 53.8s\tremaining: 1m 18s\n",
      "405:\tlearn: 0.0055401\ttotal: 53.9s\tremaining: 1m 18s\n",
      "406:\tlearn: 0.0055287\ttotal: 54s\tremaining: 1m 18s\n",
      "407:\tlearn: 0.0055251\ttotal: 54.1s\tremaining: 1m 18s\n",
      "408:\tlearn: 0.0055224\ttotal: 54.2s\tremaining: 1m 18s\n",
      "409:\tlearn: 0.0055176\ttotal: 54.3s\tremaining: 1m 18s\n",
      "410:\tlearn: 0.0055006\ttotal: 54.5s\tremaining: 1m 18s\n",
      "411:\tlearn: 0.0054771\ttotal: 54.6s\tremaining: 1m 17s\n",
      "412:\tlearn: 0.0054584\ttotal: 54.7s\tremaining: 1m 17s\n",
      "413:\tlearn: 0.0054478\ttotal: 54.9s\tremaining: 1m 17s\n",
      "414:\tlearn: 0.0054429\ttotal: 55s\tremaining: 1m 17s\n",
      "415:\tlearn: 0.0054305\ttotal: 55.1s\tremaining: 1m 17s\n",
      "416:\tlearn: 0.0054197\ttotal: 55.2s\tremaining: 1m 17s\n",
      "417:\tlearn: 0.0054117\ttotal: 55.4s\tremaining: 1m 17s\n",
      "418:\tlearn: 0.0054069\ttotal: 55.5s\tremaining: 1m 16s\n",
      "419:\tlearn: 0.0053998\ttotal: 55.6s\tremaining: 1m 16s\n",
      "420:\tlearn: 0.0053954\ttotal: 55.8s\tremaining: 1m 16s\n",
      "421:\tlearn: 0.0053751\ttotal: 55.9s\tremaining: 1m 16s\n",
      "422:\tlearn: 0.0053709\ttotal: 56s\tremaining: 1m 16s\n",
      "423:\tlearn: 0.0053603\ttotal: 56.2s\tremaining: 1m 16s\n",
      "424:\tlearn: 0.0053549\ttotal: 56.3s\tremaining: 1m 16s\n",
      "425:\tlearn: 0.0053502\ttotal: 56.5s\tremaining: 1m 16s\n",
      "426:\tlearn: 0.0053416\ttotal: 56.7s\tremaining: 1m 16s\n",
      "427:\tlearn: 0.0053257\ttotal: 56.8s\tremaining: 1m 15s\n",
      "428:\tlearn: 0.0053104\ttotal: 57s\tremaining: 1m 15s\n",
      "429:\tlearn: 0.0053040\ttotal: 57.1s\tremaining: 1m 15s\n",
      "430:\tlearn: 0.0052942\ttotal: 57.3s\tremaining: 1m 15s\n",
      "431:\tlearn: 0.0052897\ttotal: 57.4s\tremaining: 1m 15s\n",
      "432:\tlearn: 0.0052722\ttotal: 57.7s\tremaining: 1m 15s\n",
      "433:\tlearn: 0.0052629\ttotal: 57.8s\tremaining: 1m 15s\n",
      "434:\tlearn: 0.0052594\ttotal: 58s\tremaining: 1m 15s\n",
      "435:\tlearn: 0.0052398\ttotal: 58.2s\tremaining: 1m 15s\n",
      "436:\tlearn: 0.0052351\ttotal: 58.3s\tremaining: 1m 15s\n",
      "437:\tlearn: 0.0052307\ttotal: 58.5s\tremaining: 1m 15s\n",
      "438:\tlearn: 0.0052118\ttotal: 58.7s\tremaining: 1m 15s\n",
      "439:\tlearn: 0.0052045\ttotal: 58.9s\tremaining: 1m 14s\n",
      "440:\tlearn: 0.0051992\ttotal: 59s\tremaining: 1m 14s\n",
      "441:\tlearn: 0.0051900\ttotal: 59.1s\tremaining: 1m 14s\n",
      "442:\tlearn: 0.0051796\ttotal: 59.2s\tremaining: 1m 14s\n",
      "443:\tlearn: 0.0051772\ttotal: 59.4s\tremaining: 1m 14s\n",
      "444:\tlearn: 0.0051715\ttotal: 59.6s\tremaining: 1m 14s\n",
      "445:\tlearn: 0.0051655\ttotal: 59.8s\tremaining: 1m 14s\n",
      "446:\tlearn: 0.0051547\ttotal: 59.9s\tremaining: 1m 14s\n",
      "447:\tlearn: 0.0051511\ttotal: 1m\tremaining: 1m 13s\n",
      "448:\tlearn: 0.0051502\ttotal: 1m\tremaining: 1m 13s\n",
      "449:\tlearn: 0.0051467\ttotal: 1m\tremaining: 1m 13s\n",
      "450:\tlearn: 0.0051344\ttotal: 1m\tremaining: 1m 13s\n",
      "451:\tlearn: 0.0051201\ttotal: 1m\tremaining: 1m 13s\n",
      "452:\tlearn: 0.0051096\ttotal: 1m 1s\tremaining: 1m 13s\n",
      "453:\tlearn: 0.0051035\ttotal: 1m 1s\tremaining: 1m 13s\n",
      "454:\tlearn: 0.0050970\ttotal: 1m 1s\tremaining: 1m 13s\n",
      "455:\tlearn: 0.0050916\ttotal: 1m 1s\tremaining: 1m 13s\n",
      "456:\tlearn: 0.0050863\ttotal: 1m 1s\tremaining: 1m 13s\n",
      "457:\tlearn: 0.0050782\ttotal: 1m 1s\tremaining: 1m 13s\n",
      "458:\tlearn: 0.0050735\ttotal: 1m 2s\tremaining: 1m 13s\n",
      "459:\tlearn: 0.0050658\ttotal: 1m 2s\tremaining: 1m 13s\n",
      "460:\tlearn: 0.0050482\ttotal: 1m 2s\tremaining: 1m 12s\n",
      "461:\tlearn: 0.0050375\ttotal: 1m 2s\tremaining: 1m 12s\n",
      "462:\tlearn: 0.0050173\ttotal: 1m 2s\tremaining: 1m 12s\n",
      "463:\tlearn: 0.0050116\ttotal: 1m 3s\tremaining: 1m 12s\n",
      "464:\tlearn: 0.0050092\ttotal: 1m 3s\tremaining: 1m 12s\n",
      "465:\tlearn: 0.0050016\ttotal: 1m 3s\tremaining: 1m 12s\n",
      "466:\tlearn: 0.0049806\ttotal: 1m 3s\tremaining: 1m 12s\n",
      "467:\tlearn: 0.0049742\ttotal: 1m 3s\tremaining: 1m 12s\n",
      "468:\tlearn: 0.0049637\ttotal: 1m 3s\tremaining: 1m 12s\n",
      "469:\tlearn: 0.0049607\ttotal: 1m 3s\tremaining: 1m 12s\n",
      "470:\tlearn: 0.0049494\ttotal: 1m 4s\tremaining: 1m 12s\n",
      "471:\tlearn: 0.0049456\ttotal: 1m 4s\tremaining: 1m 11s\n",
      "472:\tlearn: 0.0049337\ttotal: 1m 4s\tremaining: 1m 11s\n",
      "473:\tlearn: 0.0049277\ttotal: 1m 4s\tremaining: 1m 11s\n",
      "474:\tlearn: 0.0049225\ttotal: 1m 4s\tremaining: 1m 11s\n",
      "475:\tlearn: 0.0049109\ttotal: 1m 4s\tremaining: 1m 11s\n",
      "476:\tlearn: 0.0049061\ttotal: 1m 5s\tremaining: 1m 11s\n",
      "477:\tlearn: 0.0049035\ttotal: 1m 5s\tremaining: 1m 11s\n",
      "478:\tlearn: 0.0048975\ttotal: 1m 5s\tremaining: 1m 11s\n",
      "479:\tlearn: 0.0048919\ttotal: 1m 5s\tremaining: 1m 11s\n",
      "480:\tlearn: 0.0048885\ttotal: 1m 5s\tremaining: 1m 11s\n",
      "481:\tlearn: 0.0048862\ttotal: 1m 6s\tremaining: 1m 10s\n",
      "482:\tlearn: 0.0048757\ttotal: 1m 6s\tremaining: 1m 10s\n",
      "483:\tlearn: 0.0048682\ttotal: 1m 6s\tremaining: 1m 10s\n",
      "484:\tlearn: 0.0048593\ttotal: 1m 6s\tremaining: 1m 10s\n",
      "485:\tlearn: 0.0048429\ttotal: 1m 6s\tremaining: 1m 10s\n",
      "486:\tlearn: 0.0048401\ttotal: 1m 6s\tremaining: 1m 10s\n",
      "487:\tlearn: 0.0048366\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "488:\tlearn: 0.0048225\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "489:\tlearn: 0.0048195\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "490:\tlearn: 0.0048158\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "491:\tlearn: 0.0048074\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "492:\tlearn: 0.0047988\ttotal: 1m 8s\tremaining: 1m 10s\n",
      "493:\tlearn: 0.0047922\ttotal: 1m 8s\tremaining: 1m 10s\n",
      "494:\tlearn: 0.0047897\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "495:\tlearn: 0.0047724\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "496:\tlearn: 0.0047683\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "497:\tlearn: 0.0047588\ttotal: 1m 9s\tremaining: 1m 9s\n",
      "498:\tlearn: 0.0047524\ttotal: 1m 9s\tremaining: 1m 9s\n",
      "499:\tlearn: 0.0047319\ttotal: 1m 9s\tremaining: 1m 9s\n",
      "500:\tlearn: 0.0047219\ttotal: 1m 9s\tremaining: 1m 9s\n",
      "501:\tlearn: 0.0047155\ttotal: 1m 9s\tremaining: 1m 9s\n",
      "502:\tlearn: 0.0047123\ttotal: 1m 10s\tremaining: 1m 9s\n",
      "503:\tlearn: 0.0047034\ttotal: 1m 10s\tremaining: 1m 9s\n",
      "504:\tlearn: 0.0046899\ttotal: 1m 10s\tremaining: 1m 8s\n",
      "505:\tlearn: 0.0046855\ttotal: 1m 10s\tremaining: 1m 8s\n",
      "506:\tlearn: 0.0046800\ttotal: 1m 10s\tremaining: 1m 8s\n",
      "507:\tlearn: 0.0046733\ttotal: 1m 10s\tremaining: 1m 8s\n",
      "508:\tlearn: 0.0046627\ttotal: 1m 10s\tremaining: 1m 8s\n",
      "509:\tlearn: 0.0046570\ttotal: 1m 11s\tremaining: 1m 8s\n",
      "510:\tlearn: 0.0046498\ttotal: 1m 11s\tremaining: 1m 8s\n",
      "511:\tlearn: 0.0046463\ttotal: 1m 11s\tremaining: 1m 8s\n",
      "512:\tlearn: 0.0046432\ttotal: 1m 11s\tremaining: 1m 7s\n",
      "513:\tlearn: 0.0046382\ttotal: 1m 11s\tremaining: 1m 7s\n",
      "514:\tlearn: 0.0046337\ttotal: 1m 11s\tremaining: 1m 7s\n",
      "515:\tlearn: 0.0046283\ttotal: 1m 12s\tremaining: 1m 7s\n",
      "516:\tlearn: 0.0046242\ttotal: 1m 12s\tremaining: 1m 7s\n",
      "517:\tlearn: 0.0046198\ttotal: 1m 12s\tremaining: 1m 7s\n",
      "518:\tlearn: 0.0046004\ttotal: 1m 12s\tremaining: 1m 7s\n",
      "519:\tlearn: 0.0045973\ttotal: 1m 12s\tremaining: 1m 7s\n",
      "520:\tlearn: 0.0045938\ttotal: 1m 13s\tremaining: 1m 7s\n",
      "521:\tlearn: 0.0045878\ttotal: 1m 13s\tremaining: 1m 7s\n",
      "522:\tlearn: 0.0045821\ttotal: 1m 13s\tremaining: 1m 6s\n",
      "523:\tlearn: 0.0045777\ttotal: 1m 13s\tremaining: 1m 6s\n",
      "524:\tlearn: 0.0045766\ttotal: 1m 13s\tremaining: 1m 6s\n",
      "525:\tlearn: 0.0045704\ttotal: 1m 14s\tremaining: 1m 6s\n",
      "526:\tlearn: 0.0045580\ttotal: 1m 14s\tremaining: 1m 6s\n",
      "527:\tlearn: 0.0045459\ttotal: 1m 14s\tremaining: 1m 6s\n",
      "528:\tlearn: 0.0045432\ttotal: 1m 14s\tremaining: 1m 6s\n",
      "529:\tlearn: 0.0045395\ttotal: 1m 14s\tremaining: 1m 6s\n",
      "530:\tlearn: 0.0045275\ttotal: 1m 15s\tremaining: 1m 6s\n",
      "531:\tlearn: 0.0045216\ttotal: 1m 15s\tremaining: 1m 6s\n",
      "532:\tlearn: 0.0045189\ttotal: 1m 15s\tremaining: 1m 6s\n",
      "533:\tlearn: 0.0045081\ttotal: 1m 15s\tremaining: 1m 5s\n",
      "534:\tlearn: 0.0045072\ttotal: 1m 15s\tremaining: 1m 5s\n",
      "535:\tlearn: 0.0044983\ttotal: 1m 15s\tremaining: 1m 5s\n",
      "536:\tlearn: 0.0044920\ttotal: 1m 16s\tremaining: 1m 5s\n",
      "537:\tlearn: 0.0044870\ttotal: 1m 16s\tremaining: 1m 5s\n",
      "538:\tlearn: 0.0044859\ttotal: 1m 17s\tremaining: 1m 6s\n",
      "539:\tlearn: 0.0044841\ttotal: 1m 17s\tremaining: 1m 6s\n",
      "540:\tlearn: 0.0044701\ttotal: 1m 17s\tremaining: 1m 5s\n",
      "541:\tlearn: 0.0044657\ttotal: 1m 18s\tremaining: 1m 5s\n",
      "542:\tlearn: 0.0044631\ttotal: 1m 18s\tremaining: 1m 6s\n",
      "543:\tlearn: 0.0044576\ttotal: 1m 18s\tremaining: 1m 5s\n",
      "544:\tlearn: 0.0044475\ttotal: 1m 19s\tremaining: 1m 6s\n",
      "545:\tlearn: 0.0044392\ttotal: 1m 19s\tremaining: 1m 5s\n",
      "546:\tlearn: 0.0044331\ttotal: 1m 19s\tremaining: 1m 5s\n",
      "547:\tlearn: 0.0044281\ttotal: 1m 19s\tremaining: 1m 5s\n",
      "548:\tlearn: 0.0044211\ttotal: 1m 22s\tremaining: 1m 7s\n",
      "549:\tlearn: 0.0044126\ttotal: 1m 22s\tremaining: 1m 7s\n",
      "550:\tlearn: 0.0044092\ttotal: 1m 22s\tremaining: 1m 7s\n",
      "551:\tlearn: 0.0044050\ttotal: 1m 22s\tremaining: 1m 6s\n",
      "552:\tlearn: 0.0044031\ttotal: 1m 22s\tremaining: 1m 6s\n",
      "553:\tlearn: 0.0044006\ttotal: 1m 22s\tremaining: 1m 6s\n",
      "554:\tlearn: 0.0043961\ttotal: 1m 22s\tremaining: 1m 6s\n",
      "555:\tlearn: 0.0043922\ttotal: 1m 22s\tremaining: 1m 6s\n",
      "556:\tlearn: 0.0043911\ttotal: 1m 23s\tremaining: 1m 6s\n",
      "557:\tlearn: 0.0043901\ttotal: 1m 23s\tremaining: 1m 5s\n",
      "558:\tlearn: 0.0043806\ttotal: 1m 23s\tremaining: 1m 5s\n",
      "559:\tlearn: 0.0043774\ttotal: 1m 23s\tremaining: 1m 5s\n",
      "560:\tlearn: 0.0043671\ttotal: 1m 24s\tremaining: 1m 5s\n",
      "561:\tlearn: 0.0043655\ttotal: 1m 24s\tremaining: 1m 5s\n",
      "562:\tlearn: 0.0043617\ttotal: 1m 24s\tremaining: 1m 5s\n",
      "563:\tlearn: 0.0043517\ttotal: 1m 24s\tremaining: 1m 5s\n",
      "564:\tlearn: 0.0043495\ttotal: 1m 25s\tremaining: 1m 5s\n",
      "565:\tlearn: 0.0043391\ttotal: 1m 25s\tremaining: 1m 5s\n",
      "566:\tlearn: 0.0043357\ttotal: 1m 25s\tremaining: 1m 5s\n",
      "567:\tlearn: 0.0043317\ttotal: 1m 26s\tremaining: 1m 5s\n",
      "568:\tlearn: 0.0043186\ttotal: 1m 26s\tremaining: 1m 5s\n",
      "569:\tlearn: 0.0043107\ttotal: 1m 26s\tremaining: 1m 5s\n",
      "570:\tlearn: 0.0043013\ttotal: 1m 26s\tremaining: 1m 5s\n",
      "571:\tlearn: 0.0042979\ttotal: 1m 26s\tremaining: 1m 5s\n",
      "572:\tlearn: 0.0042937\ttotal: 1m 28s\tremaining: 1m 5s\n",
      "573:\tlearn: 0.0042854\ttotal: 1m 29s\tremaining: 1m 6s\n",
      "574:\tlearn: 0.0042831\ttotal: 1m 29s\tremaining: 1m 6s\n",
      "575:\tlearn: 0.0042759\ttotal: 1m 29s\tremaining: 1m 5s\n",
      "576:\tlearn: 0.0042711\ttotal: 1m 29s\tremaining: 1m 5s\n",
      "577:\tlearn: 0.0042633\ttotal: 1m 29s\tremaining: 1m 5s\n",
      "578:\tlearn: 0.0042571\ttotal: 1m 29s\tremaining: 1m 5s\n",
      "579:\tlearn: 0.0042530\ttotal: 1m 30s\tremaining: 1m 5s\n",
      "580:\tlearn: 0.0042377\ttotal: 1m 30s\tremaining: 1m 5s\n",
      "581:\tlearn: 0.0042344\ttotal: 1m 30s\tremaining: 1m 5s\n",
      "582:\tlearn: 0.0042336\ttotal: 1m 31s\tremaining: 1m 5s\n",
      "583:\tlearn: 0.0042304\ttotal: 1m 31s\tremaining: 1m 5s\n",
      "584:\tlearn: 0.0042221\ttotal: 1m 31s\tremaining: 1m 5s\n",
      "585:\tlearn: 0.0042198\ttotal: 1m 33s\tremaining: 1m 6s\n",
      "586:\tlearn: 0.0042164\ttotal: 1m 34s\tremaining: 1m 6s\n",
      "587:\tlearn: 0.0042147\ttotal: 1m 35s\tremaining: 1m 6s\n",
      "588:\tlearn: 0.0042104\ttotal: 1m 35s\tremaining: 1m 6s\n",
      "589:\tlearn: 0.0042085\ttotal: 1m 38s\tremaining: 1m 8s\n",
      "590:\tlearn: 0.0042046\ttotal: 1m 41s\tremaining: 1m 9s\n",
      "591:\tlearn: 0.0042030\ttotal: 1m 41s\tremaining: 1m 9s\n",
      "592:\tlearn: 0.0041990\ttotal: 1m 41s\tremaining: 1m 9s\n",
      "593:\tlearn: 0.0041967\ttotal: 1m 41s\tremaining: 1m 9s\n",
      "594:\tlearn: 0.0041935\ttotal: 1m 41s\tremaining: 1m 9s\n",
      "595:\tlearn: 0.0041818\ttotal: 1m 41s\tremaining: 1m 8s\n",
      "596:\tlearn: 0.0041773\ttotal: 1m 41s\tremaining: 1m 8s\n",
      "597:\tlearn: 0.0041692\ttotal: 1m 41s\tremaining: 1m 8s\n",
      "598:\tlearn: 0.0041644\ttotal: 1m 41s\tremaining: 1m 8s\n",
      "599:\tlearn: 0.0041587\ttotal: 1m 41s\tremaining: 1m 7s\n",
      "600:\tlearn: 0.0041522\ttotal: 1m 41s\tremaining: 1m 7s\n",
      "601:\tlearn: 0.0041489\ttotal: 1m 42s\tremaining: 1m 7s\n",
      "602:\tlearn: 0.0041447\ttotal: 1m 42s\tremaining: 1m 7s\n",
      "603:\tlearn: 0.0041441\ttotal: 1m 42s\tremaining: 1m 6s\n",
      "604:\tlearn: 0.0041387\ttotal: 1m 42s\tremaining: 1m 6s\n",
      "605:\tlearn: 0.0041347\ttotal: 1m 42s\tremaining: 1m 6s\n",
      "606:\tlearn: 0.0041309\ttotal: 1m 42s\tremaining: 1m 6s\n",
      "607:\tlearn: 0.0041279\ttotal: 1m 42s\tremaining: 1m 6s\n",
      "608:\tlearn: 0.0041259\ttotal: 1m 42s\tremaining: 1m 5s\n",
      "609:\tlearn: 0.0041156\ttotal: 1m 42s\tremaining: 1m 5s\n",
      "610:\tlearn: 0.0041126\ttotal: 1m 42s\tremaining: 1m 5s\n",
      "611:\tlearn: 0.0041086\ttotal: 1m 42s\tremaining: 1m 5s\n",
      "612:\tlearn: 0.0041080\ttotal: 1m 42s\tremaining: 1m 4s\n",
      "613:\tlearn: 0.0041012\ttotal: 1m 43s\tremaining: 1m 4s\n",
      "614:\tlearn: 0.0040941\ttotal: 1m 44s\tremaining: 1m 5s\n",
      "615:\tlearn: 0.0040837\ttotal: 1m 44s\tremaining: 1m 5s\n",
      "616:\tlearn: 0.0040647\ttotal: 1m 45s\tremaining: 1m 5s\n",
      "617:\tlearn: 0.0040533\ttotal: 1m 45s\tremaining: 1m 5s\n",
      "618:\tlearn: 0.0040527\ttotal: 1m 45s\tremaining: 1m 4s\n",
      "619:\tlearn: 0.0040470\ttotal: 1m 46s\tremaining: 1m 5s\n",
      "620:\tlearn: 0.0040451\ttotal: 1m 47s\tremaining: 1m 5s\n",
      "621:\tlearn: 0.0040435\ttotal: 1m 47s\tremaining: 1m 5s\n",
      "622:\tlearn: 0.0040395\ttotal: 1m 47s\tremaining: 1m 5s\n",
      "623:\tlearn: 0.0040365\ttotal: 1m 47s\tremaining: 1m 4s\n",
      "624:\tlearn: 0.0040346\ttotal: 1m 48s\tremaining: 1m 4s\n",
      "625:\tlearn: 0.0040282\ttotal: 1m 49s\tremaining: 1m 5s\n",
      "626:\tlearn: 0.0040240\ttotal: 1m 49s\tremaining: 1m 5s\n",
      "627:\tlearn: 0.0040218\ttotal: 1m 52s\tremaining: 1m 6s\n",
      "628:\tlearn: 0.0040078\ttotal: 1m 52s\tremaining: 1m 6s\n",
      "629:\tlearn: 0.0040047\ttotal: 1m 52s\tremaining: 1m 5s\n",
      "630:\tlearn: 0.0039932\ttotal: 1m 52s\tremaining: 1m 5s\n",
      "631:\tlearn: 0.0039888\ttotal: 1m 52s\tremaining: 1m 5s\n",
      "632:\tlearn: 0.0039870\ttotal: 1m 52s\tremaining: 1m 5s\n",
      "633:\tlearn: 0.0039774\ttotal: 1m 52s\tremaining: 1m 4s\n",
      "634:\tlearn: 0.0039746\ttotal: 1m 52s\tremaining: 1m 4s\n",
      "635:\tlearn: 0.0039708\ttotal: 1m 52s\tremaining: 1m 4s\n",
      "636:\tlearn: 0.0039669\ttotal: 1m 52s\tremaining: 1m 4s\n",
      "637:\tlearn: 0.0039618\ttotal: 1m 52s\tremaining: 1m 4s\n",
      "638:\tlearn: 0.0039598\ttotal: 1m 52s\tremaining: 1m 3s\n",
      "639:\tlearn: 0.0039543\ttotal: 1m 52s\tremaining: 1m 3s\n",
      "640:\tlearn: 0.0039529\ttotal: 1m 53s\tremaining: 1m 3s\n",
      "641:\tlearn: 0.0039479\ttotal: 1m 53s\tremaining: 1m 3s\n",
      "642:\tlearn: 0.0039403\ttotal: 1m 53s\tremaining: 1m 2s\n",
      "643:\tlearn: 0.0039351\ttotal: 1m 53s\tremaining: 1m 2s\n",
      "644:\tlearn: 0.0039325\ttotal: 1m 54s\tremaining: 1m 3s\n",
      "645:\tlearn: 0.0039239\ttotal: 1m 56s\tremaining: 1m 3s\n",
      "646:\tlearn: 0.0039167\ttotal: 1m 56s\tremaining: 1m 3s\n",
      "647:\tlearn: 0.0039142\ttotal: 1m 56s\tremaining: 1m 3s\n",
      "648:\tlearn: 0.0039084\ttotal: 1m 56s\tremaining: 1m 2s\n",
      "649:\tlearn: 0.0039028\ttotal: 1m 56s\tremaining: 1m 2s\n",
      "650:\tlearn: 0.0038990\ttotal: 1m 56s\tremaining: 1m 2s\n",
      "651:\tlearn: 0.0038939\ttotal: 1m 56s\tremaining: 1m 2s\n",
      "652:\tlearn: 0.0038849\ttotal: 1m 57s\tremaining: 1m 2s\n",
      "653:\tlearn: 0.0038755\ttotal: 1m 58s\tremaining: 1m 2s\n",
      "654:\tlearn: 0.0038738\ttotal: 1m 58s\tremaining: 1m 2s\n",
      "655:\tlearn: 0.0038637\ttotal: 1m 59s\tremaining: 1m 2s\n",
      "656:\tlearn: 0.0038589\ttotal: 1m 59s\tremaining: 1m 2s\n",
      "657:\tlearn: 0.0038517\ttotal: 1m 59s\tremaining: 1m 2s\n",
      "658:\tlearn: 0.0038501\ttotal: 1m 59s\tremaining: 1m 2s\n",
      "659:\tlearn: 0.0038415\ttotal: 1m 59s\tremaining: 1m 1s\n",
      "660:\tlearn: 0.0038393\ttotal: 2m\tremaining: 1m 1s\n",
      "661:\tlearn: 0.0038286\ttotal: 2m\tremaining: 1m 1s\n",
      "662:\tlearn: 0.0038224\ttotal: 2m\tremaining: 1m 1s\n",
      "663:\tlearn: 0.0038190\ttotal: 2m\tremaining: 1m\n",
      "664:\tlearn: 0.0038143\ttotal: 2m\tremaining: 1m\n",
      "665:\tlearn: 0.0037987\ttotal: 2m\tremaining: 1m\n",
      "666:\tlearn: 0.0037865\ttotal: 2m 1s\tremaining: 1m\n",
      "667:\tlearn: 0.0037830\ttotal: 2m 1s\tremaining: 1m\n",
      "668:\tlearn: 0.0037798\ttotal: 2m 1s\tremaining: 1m\n",
      "669:\tlearn: 0.0037755\ttotal: 2m 1s\tremaining: 59.9s\n",
      "670:\tlearn: 0.0037687\ttotal: 2m 1s\tremaining: 59.7s\n",
      "671:\tlearn: 0.0037672\ttotal: 2m 2s\tremaining: 59.7s\n",
      "672:\tlearn: 0.0037645\ttotal: 2m 2s\tremaining: 59.5s\n",
      "673:\tlearn: 0.0037544\ttotal: 2m 2s\tremaining: 59.3s\n",
      "674:\tlearn: 0.0037491\ttotal: 2m 2s\tremaining: 59.2s\n",
      "675:\tlearn: 0.0037395\ttotal: 2m 3s\tremaining: 59s\n",
      "676:\tlearn: 0.0037381\ttotal: 2m 3s\tremaining: 58.8s\n",
      "677:\tlearn: 0.0037356\ttotal: 2m 3s\tremaining: 58.6s\n",
      "678:\tlearn: 0.0037306\ttotal: 2m 3s\tremaining: 58.4s\n",
      "679:\tlearn: 0.0037237\ttotal: 2m 3s\tremaining: 58.3s\n",
      "680:\tlearn: 0.0037215\ttotal: 2m 4s\tremaining: 58.1s\n",
      "681:\tlearn: 0.0037140\ttotal: 2m 4s\tremaining: 58s\n",
      "682:\tlearn: 0.0037068\ttotal: 2m 4s\tremaining: 57.8s\n",
      "683:\tlearn: 0.0037018\ttotal: 2m 4s\tremaining: 57.6s\n",
      "684:\tlearn: 0.0036860\ttotal: 2m 4s\tremaining: 57.4s\n",
      "685:\tlearn: 0.0036802\ttotal: 2m 5s\tremaining: 57.3s\n",
      "686:\tlearn: 0.0036759\ttotal: 2m 5s\tremaining: 57.1s\n",
      "687:\tlearn: 0.0036705\ttotal: 2m 5s\tremaining: 56.9s\n",
      "688:\tlearn: 0.0036701\ttotal: 2m 5s\tremaining: 56.7s\n",
      "689:\tlearn: 0.0036668\ttotal: 2m 5s\tremaining: 56.6s\n",
      "690:\tlearn: 0.0036643\ttotal: 2m 6s\tremaining: 56.4s\n",
      "691:\tlearn: 0.0036595\ttotal: 2m 6s\tremaining: 56.5s\n",
      "692:\tlearn: 0.0036509\ttotal: 2m 6s\tremaining: 56.2s\n",
      "693:\tlearn: 0.0036496\ttotal: 2m 7s\tremaining: 56s\n",
      "694:\tlearn: 0.0036397\ttotal: 2m 7s\tremaining: 55.8s\n",
      "695:\tlearn: 0.0036340\ttotal: 2m 7s\tremaining: 55.6s\n",
      "696:\tlearn: 0.0036315\ttotal: 2m 7s\tremaining: 55.4s\n",
      "697:\tlearn: 0.0036265\ttotal: 2m 7s\tremaining: 55.2s\n",
      "698:\tlearn: 0.0036204\ttotal: 2m 7s\tremaining: 55.1s\n",
      "699:\tlearn: 0.0036171\ttotal: 2m 8s\tremaining: 54.9s\n",
      "700:\tlearn: 0.0036166\ttotal: 2m 8s\tremaining: 54.7s\n",
      "701:\tlearn: 0.0036127\ttotal: 2m 8s\tremaining: 54.6s\n",
      "702:\tlearn: 0.0035970\ttotal: 2m 8s\tremaining: 54.4s\n",
      "703:\tlearn: 0.0035946\ttotal: 2m 9s\tremaining: 54.3s\n",
      "704:\tlearn: 0.0035890\ttotal: 2m 9s\tremaining: 54.1s\n",
      "705:\tlearn: 0.0035851\ttotal: 2m 9s\tremaining: 53.9s\n",
      "706:\tlearn: 0.0035794\ttotal: 2m 11s\tremaining: 54.4s\n",
      "707:\tlearn: 0.0035774\ttotal: 2m 11s\tremaining: 54.2s\n",
      "708:\tlearn: 0.0035703\ttotal: 2m 12s\tremaining: 54.2s\n",
      "709:\tlearn: 0.0035691\ttotal: 2m 12s\tremaining: 54s\n",
      "710:\tlearn: 0.0035646\ttotal: 2m 15s\tremaining: 55s\n",
      "711:\tlearn: 0.0035629\ttotal: 2m 16s\tremaining: 55.4s\n",
      "712:\tlearn: 0.0035615\ttotal: 2m 17s\tremaining: 55.2s\n",
      "713:\tlearn: 0.0035573\ttotal: 2m 17s\tremaining: 54.9s\n",
      "714:\tlearn: 0.0035542\ttotal: 2m 17s\tremaining: 54.7s\n",
      "715:\tlearn: 0.0035514\ttotal: 2m 17s\tremaining: 54.5s\n",
      "716:\tlearn: 0.0035467\ttotal: 2m 17s\tremaining: 54.2s\n",
      "717:\tlearn: 0.0035409\ttotal: 2m 17s\tremaining: 54s\n",
      "718:\tlearn: 0.0035393\ttotal: 2m 17s\tremaining: 53.7s\n",
      "719:\tlearn: 0.0035341\ttotal: 2m 17s\tremaining: 53.5s\n",
      "720:\tlearn: 0.0035329\ttotal: 2m 17s\tremaining: 53.3s\n",
      "721:\tlearn: 0.0035309\ttotal: 2m 17s\tremaining: 53s\n",
      "722:\tlearn: 0.0035253\ttotal: 2m 17s\tremaining: 52.8s\n",
      "723:\tlearn: 0.0035212\ttotal: 2m 17s\tremaining: 52.6s\n",
      "724:\tlearn: 0.0035183\ttotal: 2m 17s\tremaining: 52.3s\n",
      "725:\tlearn: 0.0035131\ttotal: 2m 18s\tremaining: 52.1s\n",
      "726:\tlearn: 0.0035115\ttotal: 2m 18s\tremaining: 51.9s\n",
      "727:\tlearn: 0.0035088\ttotal: 2m 18s\tremaining: 51.7s\n",
      "728:\tlearn: 0.0035050\ttotal: 2m 18s\tremaining: 51.6s\n",
      "729:\tlearn: 0.0035033\ttotal: 2m 18s\tremaining: 51.4s\n",
      "730:\tlearn: 0.0034991\ttotal: 2m 19s\tremaining: 51.2s\n",
      "731:\tlearn: 0.0034970\ttotal: 2m 19s\tremaining: 51s\n",
      "732:\tlearn: 0.0034912\ttotal: 2m 19s\tremaining: 50.8s\n",
      "733:\tlearn: 0.0034867\ttotal: 2m 19s\tremaining: 50.6s\n",
      "734:\tlearn: 0.0034841\ttotal: 2m 19s\tremaining: 50.4s\n",
      "735:\tlearn: 0.0034705\ttotal: 2m 20s\tremaining: 50.2s\n",
      "736:\tlearn: 0.0034697\ttotal: 2m 20s\tremaining: 50.1s\n",
      "737:\tlearn: 0.0034677\ttotal: 2m 20s\tremaining: 49.9s\n",
      "738:\tlearn: 0.0034597\ttotal: 2m 20s\tremaining: 49.7s\n",
      "739:\tlearn: 0.0034575\ttotal: 2m 21s\tremaining: 49.5s\n",
      "740:\tlearn: 0.0034474\ttotal: 2m 21s\tremaining: 49.4s\n",
      "741:\tlearn: 0.0034450\ttotal: 2m 21s\tremaining: 49.2s\n",
      "742:\tlearn: 0.0034408\ttotal: 2m 21s\tremaining: 49.1s\n",
      "743:\tlearn: 0.0034329\ttotal: 2m 22s\tremaining: 49s\n",
      "744:\tlearn: 0.0034311\ttotal: 2m 22s\tremaining: 48.8s\n",
      "745:\tlearn: 0.0034294\ttotal: 2m 22s\tremaining: 48.6s\n",
      "746:\tlearn: 0.0034290\ttotal: 2m 23s\tremaining: 48.4s\n",
      "747:\tlearn: 0.0034227\ttotal: 2m 23s\tremaining: 48.3s\n",
      "748:\tlearn: 0.0034210\ttotal: 2m 23s\tremaining: 48.1s\n",
      "749:\tlearn: 0.0034196\ttotal: 2m 23s\tremaining: 47.9s\n",
      "750:\tlearn: 0.0034175\ttotal: 2m 24s\tremaining: 47.7s\n",
      "751:\tlearn: 0.0034123\ttotal: 2m 24s\tremaining: 47.6s\n",
      "752:\tlearn: 0.0034085\ttotal: 2m 24s\tremaining: 47.4s\n",
      "753:\tlearn: 0.0034022\ttotal: 2m 24s\tremaining: 47.2s\n",
      "754:\tlearn: 0.0033937\ttotal: 2m 25s\tremaining: 47.2s\n",
      "755:\tlearn: 0.0033914\ttotal: 2m 25s\tremaining: 47s\n",
      "756:\tlearn: 0.0033878\ttotal: 2m 25s\tremaining: 46.7s\n",
      "757:\tlearn: 0.0033841\ttotal: 2m 25s\tremaining: 46.5s\n",
      "758:\tlearn: 0.0033807\ttotal: 2m 25s\tremaining: 46.3s\n",
      "759:\tlearn: 0.0033736\ttotal: 2m 26s\tremaining: 46.1s\n",
      "760:\tlearn: 0.0033718\ttotal: 2m 26s\tremaining: 46s\n",
      "761:\tlearn: 0.0033694\ttotal: 2m 26s\tremaining: 45.8s\n",
      "762:\tlearn: 0.0033620\ttotal: 2m 26s\tremaining: 45.6s\n",
      "763:\tlearn: 0.0033594\ttotal: 2m 27s\tremaining: 45.4s\n",
      "764:\tlearn: 0.0033575\ttotal: 2m 27s\tremaining: 45.2s\n",
      "765:\tlearn: 0.0033532\ttotal: 2m 27s\tremaining: 45s\n",
      "766:\tlearn: 0.0033475\ttotal: 2m 27s\tremaining: 44.9s\n",
      "767:\tlearn: 0.0033446\ttotal: 2m 27s\tremaining: 44.7s\n",
      "768:\tlearn: 0.0033432\ttotal: 2m 28s\tremaining: 44.5s\n",
      "769:\tlearn: 0.0033341\ttotal: 2m 28s\tremaining: 44.3s\n",
      "770:\tlearn: 0.0033285\ttotal: 2m 28s\tremaining: 44.1s\n",
      "771:\tlearn: 0.0033229\ttotal: 2m 29s\tremaining: 44s\n",
      "772:\tlearn: 0.0033212\ttotal: 2m 29s\tremaining: 43.8s\n",
      "773:\tlearn: 0.0033170\ttotal: 2m 29s\tremaining: 43.6s\n",
      "774:\tlearn: 0.0033135\ttotal: 2m 29s\tremaining: 43.5s\n",
      "775:\tlearn: 0.0033099\ttotal: 2m 29s\tremaining: 43.3s\n",
      "776:\tlearn: 0.0033051\ttotal: 2m 30s\tremaining: 43.1s\n",
      "777:\tlearn: 0.0032934\ttotal: 2m 30s\tremaining: 42.9s\n",
      "778:\tlearn: 0.0032885\ttotal: 2m 30s\tremaining: 42.7s\n",
      "779:\tlearn: 0.0032783\ttotal: 2m 30s\tremaining: 42.5s\n",
      "780:\tlearn: 0.0032766\ttotal: 2m 31s\tremaining: 42.4s\n",
      "781:\tlearn: 0.0032714\ttotal: 2m 31s\tremaining: 42.2s\n",
      "782:\tlearn: 0.0032687\ttotal: 2m 31s\tremaining: 42s\n",
      "783:\tlearn: 0.0032663\ttotal: 2m 31s\tremaining: 41.8s\n",
      "784:\tlearn: 0.0032653\ttotal: 2m 31s\tremaining: 41.6s\n",
      "785:\tlearn: 0.0032628\ttotal: 2m 32s\tremaining: 41.4s\n",
      "786:\tlearn: 0.0032550\ttotal: 2m 32s\tremaining: 41.2s\n",
      "787:\tlearn: 0.0032493\ttotal: 2m 32s\tremaining: 41s\n",
      "788:\tlearn: 0.0032468\ttotal: 2m 32s\tremaining: 40.8s\n",
      "789:\tlearn: 0.0032443\ttotal: 2m 32s\tremaining: 40.7s\n",
      "790:\tlearn: 0.0032426\ttotal: 2m 33s\tremaining: 40.5s\n",
      "791:\tlearn: 0.0032388\ttotal: 2m 33s\tremaining: 40.4s\n",
      "792:\tlearn: 0.0032366\ttotal: 2m 33s\tremaining: 40.2s\n",
      "793:\tlearn: 0.0032335\ttotal: 2m 34s\tremaining: 40s\n",
      "794:\tlearn: 0.0032316\ttotal: 2m 34s\tremaining: 39.8s\n",
      "795:\tlearn: 0.0032300\ttotal: 2m 34s\tremaining: 39.6s\n",
      "796:\tlearn: 0.0032272\ttotal: 2m 34s\tremaining: 39.4s\n",
      "797:\tlearn: 0.0032247\ttotal: 2m 34s\tremaining: 39.2s\n",
      "798:\tlearn: 0.0032207\ttotal: 2m 35s\tremaining: 39s\n",
      "799:\tlearn: 0.0032144\ttotal: 2m 35s\tremaining: 38.8s\n",
      "800:\tlearn: 0.0032121\ttotal: 2m 35s\tremaining: 38.7s\n",
      "801:\tlearn: 0.0032057\ttotal: 2m 35s\tremaining: 38.5s\n",
      "802:\tlearn: 0.0032042\ttotal: 2m 36s\tremaining: 38.3s\n",
      "803:\tlearn: 0.0032009\ttotal: 2m 36s\tremaining: 38.1s\n",
      "804:\tlearn: 0.0031983\ttotal: 2m 36s\tremaining: 37.9s\n",
      "805:\tlearn: 0.0031963\ttotal: 2m 36s\tremaining: 37.7s\n",
      "806:\tlearn: 0.0031926\ttotal: 2m 36s\tremaining: 37.5s\n",
      "807:\tlearn: 0.0031904\ttotal: 2m 37s\tremaining: 37.3s\n",
      "808:\tlearn: 0.0031873\ttotal: 2m 37s\tremaining: 37.1s\n",
      "809:\tlearn: 0.0031835\ttotal: 2m 37s\tremaining: 37s\n",
      "810:\tlearn: 0.0031791\ttotal: 2m 37s\tremaining: 36.8s\n",
      "811:\tlearn: 0.0031773\ttotal: 2m 38s\tremaining: 36.6s\n",
      "812:\tlearn: 0.0031747\ttotal: 2m 38s\tremaining: 36.4s\n",
      "813:\tlearn: 0.0031731\ttotal: 2m 38s\tremaining: 36.2s\n",
      "814:\tlearn: 0.0031693\ttotal: 2m 38s\tremaining: 36s\n",
      "815:\tlearn: 0.0031651\ttotal: 2m 39s\tremaining: 35.9s\n",
      "816:\tlearn: 0.0031629\ttotal: 2m 39s\tremaining: 35.7s\n",
      "817:\tlearn: 0.0031503\ttotal: 2m 39s\tremaining: 35.5s\n",
      "818:\tlearn: 0.0031432\ttotal: 2m 39s\tremaining: 35.3s\n",
      "819:\tlearn: 0.0031355\ttotal: 2m 40s\tremaining: 35.1s\n",
      "820:\tlearn: 0.0031320\ttotal: 2m 40s\tremaining: 34.9s\n",
      "821:\tlearn: 0.0031299\ttotal: 2m 40s\tremaining: 34.7s\n",
      "822:\tlearn: 0.0031280\ttotal: 2m 40s\tremaining: 34.5s\n",
      "823:\tlearn: 0.0031239\ttotal: 2m 40s\tremaining: 34.3s\n",
      "824:\tlearn: 0.0031218\ttotal: 2m 40s\tremaining: 34.1s\n",
      "825:\tlearn: 0.0031206\ttotal: 2m 41s\tremaining: 33.9s\n",
      "826:\tlearn: 0.0031190\ttotal: 2m 41s\tremaining: 33.8s\n",
      "827:\tlearn: 0.0031137\ttotal: 2m 41s\tremaining: 33.6s\n",
      "828:\tlearn: 0.0031085\ttotal: 2m 41s\tremaining: 33.4s\n",
      "829:\tlearn: 0.0031018\ttotal: 2m 42s\tremaining: 33.2s\n",
      "830:\tlearn: 0.0030998\ttotal: 2m 42s\tremaining: 33s\n",
      "831:\tlearn: 0.0030987\ttotal: 2m 42s\tremaining: 32.9s\n",
      "832:\tlearn: 0.0030952\ttotal: 2m 45s\tremaining: 33.2s\n",
      "833:\tlearn: 0.0030917\ttotal: 2m 46s\tremaining: 33.2s\n",
      "834:\tlearn: 0.0030900\ttotal: 2m 46s\tremaining: 33s\n",
      "835:\tlearn: 0.0030887\ttotal: 2m 46s\tremaining: 32.7s\n",
      "836:\tlearn: 0.0030833\ttotal: 2m 47s\tremaining: 32.5s\n",
      "837:\tlearn: 0.0030771\ttotal: 2m 47s\tremaining: 32.3s\n",
      "838:\tlearn: 0.0030640\ttotal: 2m 47s\tremaining: 32.1s\n",
      "839:\tlearn: 0.0030594\ttotal: 2m 47s\tremaining: 31.9s\n",
      "840:\tlearn: 0.0030550\ttotal: 2m 47s\tremaining: 31.7s\n",
      "841:\tlearn: 0.0030513\ttotal: 2m 47s\tremaining: 31.5s\n",
      "842:\tlearn: 0.0030484\ttotal: 2m 47s\tremaining: 31.3s\n",
      "843:\tlearn: 0.0030402\ttotal: 2m 48s\tremaining: 31.1s\n",
      "844:\tlearn: 0.0030367\ttotal: 2m 48s\tremaining: 30.9s\n",
      "845:\tlearn: 0.0030359\ttotal: 2m 48s\tremaining: 30.7s\n",
      "846:\tlearn: 0.0030338\ttotal: 2m 48s\tremaining: 30.4s\n",
      "847:\tlearn: 0.0030311\ttotal: 2m 48s\tremaining: 30.2s\n",
      "848:\tlearn: 0.0030295\ttotal: 2m 48s\tremaining: 30s\n",
      "849:\tlearn: 0.0030264\ttotal: 2m 49s\tremaining: 29.8s\n",
      "850:\tlearn: 0.0030204\ttotal: 2m 49s\tremaining: 29.6s\n",
      "851:\tlearn: 0.0030171\ttotal: 2m 49s\tremaining: 29.4s\n",
      "852:\tlearn: 0.0030147\ttotal: 2m 49s\tremaining: 29.2s\n",
      "853:\tlearn: 0.0030138\ttotal: 2m 49s\tremaining: 29s\n",
      "854:\tlearn: 0.0030121\ttotal: 2m 49s\tremaining: 28.8s\n",
      "855:\tlearn: 0.0030053\ttotal: 2m 50s\tremaining: 28.6s\n",
      "856:\tlearn: 0.0030034\ttotal: 2m 50s\tremaining: 28.4s\n",
      "857:\tlearn: 0.0029978\ttotal: 2m 50s\tremaining: 28.2s\n",
      "858:\tlearn: 0.0029942\ttotal: 2m 50s\tremaining: 28s\n",
      "859:\tlearn: 0.0029918\ttotal: 2m 50s\tremaining: 27.8s\n",
      "860:\tlearn: 0.0029899\ttotal: 2m 50s\tremaining: 27.6s\n",
      "861:\tlearn: 0.0029867\ttotal: 2m 51s\tremaining: 27.4s\n",
      "862:\tlearn: 0.0029855\ttotal: 2m 51s\tremaining: 27.2s\n",
      "863:\tlearn: 0.0029825\ttotal: 2m 51s\tremaining: 27s\n",
      "864:\tlearn: 0.0029787\ttotal: 2m 51s\tremaining: 26.8s\n",
      "865:\tlearn: 0.0029771\ttotal: 2m 51s\tremaining: 26.6s\n",
      "866:\tlearn: 0.0029739\ttotal: 2m 52s\tremaining: 26.4s\n",
      "867:\tlearn: 0.0029728\ttotal: 2m 52s\tremaining: 26.2s\n",
      "868:\tlearn: 0.0029601\ttotal: 2m 52s\tremaining: 26s\n",
      "869:\tlearn: 0.0029590\ttotal: 2m 55s\tremaining: 26.2s\n",
      "870:\tlearn: 0.0029532\ttotal: 2m 55s\tremaining: 26s\n",
      "871:\tlearn: 0.0029498\ttotal: 2m 56s\tremaining: 25.9s\n",
      "872:\tlearn: 0.0029459\ttotal: 3m\tremaining: 26.2s\n",
      "873:\tlearn: 0.0029437\ttotal: 3m\tremaining: 26s\n",
      "874:\tlearn: 0.0029352\ttotal: 3m\tremaining: 25.8s\n",
      "875:\tlearn: 0.0029312\ttotal: 3m\tremaining: 25.6s\n",
      "876:\tlearn: 0.0029257\ttotal: 3m\tremaining: 25.3s\n",
      "877:\tlearn: 0.0029228\ttotal: 3m\tremaining: 25.1s\n",
      "878:\tlearn: 0.0029207\ttotal: 3m\tremaining: 24.9s\n",
      "879:\tlearn: 0.0029174\ttotal: 3m 1s\tremaining: 24.7s\n",
      "880:\tlearn: 0.0029121\ttotal: 3m 1s\tremaining: 24.5s\n",
      "881:\tlearn: 0.0029098\ttotal: 3m 1s\tremaining: 24.3s\n",
      "882:\tlearn: 0.0029071\ttotal: 3m 1s\tremaining: 24s\n",
      "883:\tlearn: 0.0029020\ttotal: 3m 1s\tremaining: 23.8s\n",
      "884:\tlearn: 0.0028950\ttotal: 3m 1s\tremaining: 23.6s\n",
      "885:\tlearn: 0.0028932\ttotal: 3m 1s\tremaining: 23.4s\n",
      "886:\tlearn: 0.0028878\ttotal: 3m 1s\tremaining: 23.1s\n",
      "887:\tlearn: 0.0028866\ttotal: 3m 1s\tremaining: 22.9s\n",
      "888:\tlearn: 0.0028834\ttotal: 3m 1s\tremaining: 22.7s\n",
      "889:\tlearn: 0.0028809\ttotal: 3m 1s\tremaining: 22.5s\n",
      "890:\tlearn: 0.0028765\ttotal: 3m 2s\tremaining: 22.3s\n",
      "891:\tlearn: 0.0028732\ttotal: 3m 2s\tremaining: 22.1s\n",
      "892:\tlearn: 0.0028553\ttotal: 3m 2s\tremaining: 21.9s\n",
      "893:\tlearn: 0.0028531\ttotal: 3m 2s\tremaining: 21.7s\n",
      "894:\tlearn: 0.0028498\ttotal: 3m 2s\tremaining: 21.5s\n",
      "895:\tlearn: 0.0028489\ttotal: 3m 3s\tremaining: 21.2s\n",
      "896:\tlearn: 0.0028458\ttotal: 3m 3s\tremaining: 21s\n",
      "897:\tlearn: 0.0028434\ttotal: 3m 3s\tremaining: 20.8s\n",
      "898:\tlearn: 0.0028385\ttotal: 3m 3s\tremaining: 20.6s\n",
      "899:\tlearn: 0.0028341\ttotal: 3m 3s\tremaining: 20.4s\n",
      "900:\tlearn: 0.0028307\ttotal: 3m 3s\tremaining: 20.2s\n",
      "901:\tlearn: 0.0028293\ttotal: 3m 4s\tremaining: 20s\n",
      "902:\tlearn: 0.0028268\ttotal: 3m 4s\tremaining: 19.8s\n",
      "903:\tlearn: 0.0028216\ttotal: 3m 4s\tremaining: 19.6s\n",
      "904:\tlearn: 0.0028205\ttotal: 3m 4s\tremaining: 19.4s\n",
      "905:\tlearn: 0.0028170\ttotal: 3m 5s\tremaining: 19.2s\n",
      "906:\tlearn: 0.0028126\ttotal: 3m 5s\tremaining: 19s\n",
      "907:\tlearn: 0.0028053\ttotal: 3m 5s\tremaining: 18.8s\n",
      "908:\tlearn: 0.0027921\ttotal: 3m 5s\tremaining: 18.6s\n",
      "909:\tlearn: 0.0027875\ttotal: 3m 5s\tremaining: 18.4s\n",
      "910:\tlearn: 0.0027840\ttotal: 3m 5s\tremaining: 18.2s\n",
      "911:\tlearn: 0.0027781\ttotal: 3m 6s\tremaining: 17.9s\n",
      "912:\tlearn: 0.0027737\ttotal: 3m 6s\tremaining: 17.7s\n",
      "913:\tlearn: 0.0027718\ttotal: 3m 7s\tremaining: 17.6s\n",
      "914:\tlearn: 0.0027692\ttotal: 3m 7s\tremaining: 17.4s\n",
      "915:\tlearn: 0.0027670\ttotal: 3m 7s\tremaining: 17.2s\n",
      "916:\tlearn: 0.0027647\ttotal: 3m 7s\tremaining: 17s\n",
      "917:\tlearn: 0.0027617\ttotal: 3m 7s\tremaining: 16.8s\n",
      "918:\tlearn: 0.0027589\ttotal: 3m 8s\tremaining: 16.6s\n",
      "919:\tlearn: 0.0027562\ttotal: 3m 8s\tremaining: 16.4s\n",
      "920:\tlearn: 0.0027535\ttotal: 3m 8s\tremaining: 16.2s\n",
      "921:\tlearn: 0.0027484\ttotal: 3m 8s\tremaining: 16s\n",
      "922:\tlearn: 0.0027462\ttotal: 3m 8s\tremaining: 15.7s\n",
      "923:\tlearn: 0.0027445\ttotal: 3m 8s\tremaining: 15.5s\n",
      "924:\tlearn: 0.0027425\ttotal: 3m 9s\tremaining: 15.3s\n",
      "925:\tlearn: 0.0027394\ttotal: 3m 9s\tremaining: 15.1s\n",
      "926:\tlearn: 0.0027311\ttotal: 3m 9s\tremaining: 14.9s\n",
      "927:\tlearn: 0.0027265\ttotal: 3m 9s\tremaining: 14.7s\n",
      "928:\tlearn: 0.0027183\ttotal: 3m 10s\tremaining: 14.6s\n",
      "929:\tlearn: 0.0027157\ttotal: 3m 10s\tremaining: 14.3s\n",
      "930:\tlearn: 0.0027116\ttotal: 3m 10s\tremaining: 14.1s\n",
      "931:\tlearn: 0.0027086\ttotal: 3m 11s\tremaining: 14s\n",
      "932:\tlearn: 0.0027056\ttotal: 3m 14s\tremaining: 14s\n",
      "933:\tlearn: 0.0027003\ttotal: 3m 14s\tremaining: 13.8s\n",
      "934:\tlearn: 0.0026975\ttotal: 3m 15s\tremaining: 13.6s\n",
      "935:\tlearn: 0.0026899\ttotal: 3m 15s\tremaining: 13.3s\n",
      "936:\tlearn: 0.0026848\ttotal: 3m 15s\tremaining: 13.1s\n",
      "937:\tlearn: 0.0026834\ttotal: 3m 15s\tremaining: 12.9s\n",
      "938:\tlearn: 0.0026828\ttotal: 3m 15s\tremaining: 12.7s\n",
      "939:\tlearn: 0.0026770\ttotal: 3m 15s\tremaining: 12.5s\n",
      "940:\tlearn: 0.0026757\ttotal: 3m 15s\tremaining: 12.3s\n",
      "941:\tlearn: 0.0026735\ttotal: 3m 15s\tremaining: 12.1s\n",
      "942:\tlearn: 0.0026706\ttotal: 3m 15s\tremaining: 11.8s\n",
      "943:\tlearn: 0.0026690\ttotal: 3m 16s\tremaining: 11.6s\n",
      "944:\tlearn: 0.0026612\ttotal: 3m 16s\tremaining: 11.4s\n",
      "945:\tlearn: 0.0026588\ttotal: 3m 16s\tremaining: 11.2s\n",
      "946:\tlearn: 0.0026542\ttotal: 3m 16s\tremaining: 11s\n",
      "947:\tlearn: 0.0026524\ttotal: 3m 16s\tremaining: 10.8s\n",
      "948:\tlearn: 0.0026514\ttotal: 3m 16s\tremaining: 10.6s\n",
      "949:\tlearn: 0.0026483\ttotal: 3m 16s\tremaining: 10.4s\n",
      "950:\tlearn: 0.0026473\ttotal: 3m 17s\tremaining: 10.2s\n",
      "951:\tlearn: 0.0026416\ttotal: 3m 17s\tremaining: 9.95s\n",
      "952:\tlearn: 0.0026408\ttotal: 3m 17s\tremaining: 9.74s\n",
      "953:\tlearn: 0.0026403\ttotal: 3m 17s\tremaining: 9.54s\n",
      "954:\tlearn: 0.0026375\ttotal: 3m 18s\tremaining: 9.33s\n",
      "955:\tlearn: 0.0026356\ttotal: 3m 18s\tremaining: 9.13s\n",
      "956:\tlearn: 0.0026314\ttotal: 3m 18s\tremaining: 8.92s\n",
      "957:\tlearn: 0.0026301\ttotal: 3m 18s\tremaining: 8.72s\n",
      "958:\tlearn: 0.0026298\ttotal: 3m 19s\tremaining: 8.51s\n",
      "959:\tlearn: 0.0026248\ttotal: 3m 19s\tremaining: 8.31s\n",
      "960:\tlearn: 0.0026228\ttotal: 3m 19s\tremaining: 8.11s\n",
      "961:\tlearn: 0.0026201\ttotal: 3m 20s\tremaining: 7.9s\n",
      "962:\tlearn: 0.0026180\ttotal: 3m 20s\tremaining: 7.69s\n",
      "963:\tlearn: 0.0026169\ttotal: 3m 20s\tremaining: 7.48s\n",
      "964:\tlearn: 0.0026145\ttotal: 3m 20s\tremaining: 7.28s\n",
      "965:\tlearn: 0.0026055\ttotal: 3m 20s\tremaining: 7.07s\n",
      "966:\tlearn: 0.0026039\ttotal: 3m 21s\tremaining: 6.86s\n",
      "967:\tlearn: 0.0026037\ttotal: 3m 21s\tremaining: 6.65s\n",
      "968:\tlearn: 0.0026016\ttotal: 3m 21s\tremaining: 6.44s\n",
      "969:\tlearn: 0.0025996\ttotal: 3m 21s\tremaining: 6.24s\n",
      "970:\tlearn: 0.0025970\ttotal: 3m 21s\tremaining: 6.03s\n",
      "971:\tlearn: 0.0025957\ttotal: 3m 22s\tremaining: 5.84s\n",
      "972:\tlearn: 0.0025941\ttotal: 3m 25s\tremaining: 5.69s\n",
      "973:\tlearn: 0.0025919\ttotal: 3m 26s\tremaining: 5.51s\n",
      "974:\tlearn: 0.0025905\ttotal: 3m 28s\tremaining: 5.34s\n",
      "975:\tlearn: 0.0025898\ttotal: 3m 28s\tremaining: 5.13s\n",
      "976:\tlearn: 0.0025876\ttotal: 3m 30s\tremaining: 4.95s\n",
      "977:\tlearn: 0.0025841\ttotal: 3m 31s\tremaining: 4.76s\n",
      "978:\tlearn: 0.0025815\ttotal: 3m 34s\tremaining: 4.59s\n",
      "979:\tlearn: 0.0025806\ttotal: 3m 35s\tremaining: 4.41s\n",
      "980:\tlearn: 0.0025802\ttotal: 3m 36s\tremaining: 4.2s\n",
      "981:\tlearn: 0.0025754\ttotal: 3m 36s\tremaining: 3.97s\n",
      "982:\tlearn: 0.0025714\ttotal: 3m 36s\tremaining: 3.75s\n",
      "983:\tlearn: 0.0025680\ttotal: 3m 36s\tremaining: 3.53s\n",
      "984:\tlearn: 0.0025668\ttotal: 3m 37s\tremaining: 3.31s\n",
      "985:\tlearn: 0.0025659\ttotal: 3m 37s\tremaining: 3.08s\n",
      "986:\tlearn: 0.0025619\ttotal: 3m 37s\tremaining: 2.86s\n",
      "987:\tlearn: 0.0025547\ttotal: 3m 37s\tremaining: 2.64s\n",
      "988:\tlearn: 0.0025482\ttotal: 3m 37s\tremaining: 2.42s\n",
      "989:\tlearn: 0.0025447\ttotal: 3m 37s\tremaining: 2.2s\n",
      "990:\tlearn: 0.0025425\ttotal: 3m 38s\tremaining: 1.98s\n",
      "991:\tlearn: 0.0025406\ttotal: 3m 39s\tremaining: 1.77s\n",
      "992:\tlearn: 0.0025385\ttotal: 3m 41s\tremaining: 1.56s\n",
      "993:\tlearn: 0.0025368\ttotal: 3m 42s\tremaining: 1.34s\n",
      "994:\tlearn: 0.0025360\ttotal: 3m 42s\tremaining: 1.12s\n",
      "995:\tlearn: 0.0025324\ttotal: 3m 42s\tremaining: 894ms\n",
      "996:\tlearn: 0.0025288\ttotal: 3m 42s\tremaining: 670ms\n",
      "997:\tlearn: 0.0025269\ttotal: 3m 42s\tremaining: 447ms\n",
      "998:\tlearn: 0.0025262\ttotal: 3m 42s\tremaining: 223ms\n",
      "999:\tlearn: 0.0025240\ttotal: 3m 42s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x256ea5f8980>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using this model\n",
    "y_pred = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy =  0.99729133090456    \n",
      "roc score =  0.5215311004784688    \n"
     ]
    }
   ],
   "source": [
    "# display the accuracy of this prediction\n",
    "accuracy = accuracy_score(testY, y_pred)\n",
    "print(\"model accuracy = \", accuracy, \"   \")\n",
    "\n",
    "# now lets calculate the ROC AUC score according to this prediction\n",
    "roc_score = roc_auc_score(testY, y_pred)\n",
    "print(\"roc score = \", roc_score, \"   \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict for test dataset\n",
    "fit the model and predict for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.108132\n",
      "0:\tlearn: 0.4139274\ttotal: 397ms\tremaining: 6m 36s\n",
      "1:\tlearn: 0.2425068\ttotal: 706ms\tremaining: 5m 52s\n",
      "2:\tlearn: 0.1516779\ttotal: 998ms\tremaining: 5m 31s\n",
      "3:\tlearn: 0.0985596\ttotal: 1.31s\tremaining: 5m 26s\n",
      "4:\tlearn: 0.0666411\ttotal: 1.65s\tremaining: 5m 29s\n",
      "5:\tlearn: 0.0481520\ttotal: 1.99s\tremaining: 5m 29s\n",
      "6:\tlearn: 0.0369155\ttotal: 3.74s\tremaining: 8m 50s\n",
      "7:\tlearn: 0.0296320\ttotal: 4.41s\tremaining: 9m 7s\n",
      "8:\tlearn: 0.0250362\ttotal: 4.55s\tremaining: 8m 21s\n",
      "9:\tlearn: 0.0219024\ttotal: 4.85s\tremaining: 8m\n",
      "10:\tlearn: 0.0196295\ttotal: 5.41s\tremaining: 8m 6s\n",
      "11:\tlearn: 0.0180892\ttotal: 5.53s\tremaining: 7m 35s\n",
      "12:\tlearn: 0.0167367\ttotal: 5.7s\tremaining: 7m 12s\n",
      "13:\tlearn: 0.0157935\ttotal: 5.86s\tremaining: 6m 52s\n",
      "14:\tlearn: 0.0151893\ttotal: 6.05s\tremaining: 6m 37s\n",
      "15:\tlearn: 0.0146315\ttotal: 6.25s\tremaining: 6m 24s\n",
      "16:\tlearn: 0.0142451\ttotal: 6.41s\tremaining: 6m 10s\n",
      "17:\tlearn: 0.0139593\ttotal: 6.63s\tremaining: 6m 1s\n",
      "18:\tlearn: 0.0136795\ttotal: 6.88s\tremaining: 5m 55s\n",
      "19:\tlearn: 0.0134839\ttotal: 7.18s\tremaining: 5m 51s\n",
      "20:\tlearn: 0.0132933\ttotal: 7.47s\tremaining: 5m 48s\n",
      "21:\tlearn: 0.0131854\ttotal: 7.74s\tremaining: 5m 43s\n",
      "22:\tlearn: 0.0130703\ttotal: 7.98s\tremaining: 5m 39s\n",
      "23:\tlearn: 0.0129961\ttotal: 8.23s\tremaining: 5m 34s\n",
      "24:\tlearn: 0.0129152\ttotal: 8.47s\tremaining: 5m 30s\n",
      "25:\tlearn: 0.0128423\ttotal: 8.8s\tremaining: 5m 29s\n",
      "26:\tlearn: 0.0127778\ttotal: 8.98s\tremaining: 5m 23s\n",
      "27:\tlearn: 0.0127092\ttotal: 9.25s\tremaining: 5m 21s\n",
      "28:\tlearn: 0.0126457\ttotal: 9.55s\tremaining: 5m 19s\n",
      "29:\tlearn: 0.0125582\ttotal: 9.87s\tremaining: 5m 19s\n",
      "30:\tlearn: 0.0124734\ttotal: 10.1s\tremaining: 5m 17s\n",
      "31:\tlearn: 0.0124231\ttotal: 10.4s\tremaining: 5m 14s\n",
      "32:\tlearn: 0.0123696\ttotal: 10.7s\tremaining: 5m 12s\n",
      "33:\tlearn: 0.0123400\ttotal: 11s\tremaining: 5m 11s\n",
      "34:\tlearn: 0.0122682\ttotal: 11.2s\tremaining: 5m 9s\n",
      "35:\tlearn: 0.0122356\ttotal: 11.8s\tremaining: 5m 16s\n",
      "36:\tlearn: 0.0122005\ttotal: 12s\tremaining: 5m 13s\n",
      "37:\tlearn: 0.0121577\ttotal: 12.3s\tremaining: 5m 11s\n",
      "38:\tlearn: 0.0121128\ttotal: 12.6s\tremaining: 5m 10s\n",
      "39:\tlearn: 0.0120807\ttotal: 12.9s\tremaining: 5m 9s\n",
      "40:\tlearn: 0.0120517\ttotal: 13.1s\tremaining: 5m 6s\n",
      "41:\tlearn: 0.0120021\ttotal: 13.4s\tremaining: 5m 5s\n",
      "42:\tlearn: 0.0119721\ttotal: 13.7s\tremaining: 5m 4s\n",
      "43:\tlearn: 0.0119133\ttotal: 14s\tremaining: 5m 3s\n",
      "44:\tlearn: 0.0118494\ttotal: 14.3s\tremaining: 5m 3s\n",
      "45:\tlearn: 0.0117815\ttotal: 14.8s\tremaining: 5m 7s\n",
      "46:\tlearn: 0.0117568\ttotal: 15.3s\tremaining: 5m 10s\n",
      "47:\tlearn: 0.0117351\ttotal: 15.8s\tremaining: 5m 12s\n",
      "48:\tlearn: 0.0116982\ttotal: 16.1s\tremaining: 5m 12s\n",
      "49:\tlearn: 0.0116440\ttotal: 16.5s\tremaining: 5m 12s\n",
      "50:\tlearn: 0.0116126\ttotal: 16.7s\tremaining: 5m 11s\n",
      "51:\tlearn: 0.0115631\ttotal: 17s\tremaining: 5m 10s\n",
      "52:\tlearn: 0.0115252\ttotal: 17.5s\tremaining: 5m 12s\n",
      "53:\tlearn: 0.0114834\ttotal: 17.7s\tremaining: 5m 9s\n",
      "54:\tlearn: 0.0114433\ttotal: 18s\tremaining: 5m 8s\n",
      "55:\tlearn: 0.0114146\ttotal: 18.2s\tremaining: 5m 7s\n",
      "56:\tlearn: 0.0113751\ttotal: 18.4s\tremaining: 5m 4s\n",
      "57:\tlearn: 0.0113421\ttotal: 18.7s\tremaining: 5m 2s\n",
      "58:\tlearn: 0.0113084\ttotal: 19s\tremaining: 5m 2s\n",
      "59:\tlearn: 0.0112857\ttotal: 19.3s\tremaining: 5m 1s\n",
      "60:\tlearn: 0.0112597\ttotal: 19.6s\tremaining: 5m 1s\n",
      "61:\tlearn: 0.0112029\ttotal: 19.8s\tremaining: 4m 59s\n",
      "62:\tlearn: 0.0111689\ttotal: 20.1s\tremaining: 4m 59s\n",
      "63:\tlearn: 0.0111251\ttotal: 20.4s\tremaining: 4m 58s\n",
      "64:\tlearn: 0.0110870\ttotal: 20.6s\tremaining: 4m 57s\n",
      "65:\tlearn: 0.0110582\ttotal: 20.8s\tremaining: 4m 54s\n",
      "66:\tlearn: 0.0110252\ttotal: 21.1s\tremaining: 4m 53s\n",
      "67:\tlearn: 0.0109966\ttotal: 21.4s\tremaining: 4m 53s\n",
      "68:\tlearn: 0.0109657\ttotal: 21.7s\tremaining: 4m 52s\n",
      "69:\tlearn: 0.0109469\ttotal: 21.9s\tremaining: 4m 50s\n",
      "70:\tlearn: 0.0109179\ttotal: 22.1s\tremaining: 4m 49s\n",
      "71:\tlearn: 0.0109031\ttotal: 22.4s\tremaining: 4m 48s\n",
      "72:\tlearn: 0.0108851\ttotal: 22.6s\tremaining: 4m 47s\n",
      "73:\tlearn: 0.0108541\ttotal: 22.9s\tremaining: 4m 46s\n",
      "74:\tlearn: 0.0108121\ttotal: 23.1s\tremaining: 4m 45s\n",
      "75:\tlearn: 0.0107723\ttotal: 23.3s\tremaining: 4m 43s\n",
      "76:\tlearn: 0.0107459\ttotal: 23.6s\tremaining: 4m 43s\n",
      "77:\tlearn: 0.0107146\ttotal: 23.9s\tremaining: 4m 42s\n",
      "78:\tlearn: 0.0107029\ttotal: 24.5s\tremaining: 4m 45s\n",
      "79:\tlearn: 0.0106576\ttotal: 24.7s\tremaining: 4m 43s\n",
      "80:\tlearn: 0.0106476\ttotal: 24.9s\tremaining: 4m 42s\n",
      "81:\tlearn: 0.0106199\ttotal: 25s\tremaining: 4m 40s\n",
      "82:\tlearn: 0.0105944\ttotal: 25.3s\tremaining: 4m 39s\n",
      "83:\tlearn: 0.0105602\ttotal: 25.5s\tremaining: 4m 37s\n",
      "84:\tlearn: 0.0105276\ttotal: 26s\tremaining: 4m 39s\n",
      "85:\tlearn: 0.0104904\ttotal: 26.2s\tremaining: 4m 38s\n",
      "86:\tlearn: 0.0104640\ttotal: 26.5s\tremaining: 4m 37s\n",
      "87:\tlearn: 0.0104519\ttotal: 26.7s\tremaining: 4m 36s\n",
      "88:\tlearn: 0.0104278\ttotal: 26.8s\tremaining: 4m 34s\n",
      "89:\tlearn: 0.0104021\ttotal: 27s\tremaining: 4m 33s\n",
      "90:\tlearn: 0.0103657\ttotal: 27.3s\tremaining: 4m 33s\n",
      "91:\tlearn: 0.0103572\ttotal: 27.5s\tremaining: 4m 31s\n",
      "92:\tlearn: 0.0103200\ttotal: 27.8s\tremaining: 4m 31s\n",
      "93:\tlearn: 0.0102936\ttotal: 28.2s\tremaining: 4m 32s\n",
      "94:\tlearn: 0.0102543\ttotal: 29.7s\tremaining: 4m 42s\n",
      "95:\tlearn: 0.0102410\ttotal: 29.9s\tremaining: 4m 41s\n",
      "96:\tlearn: 0.0102157\ttotal: 32.1s\tremaining: 4m 59s\n",
      "97:\tlearn: 0.0101983\ttotal: 32.3s\tremaining: 4m 57s\n",
      "98:\tlearn: 0.0101605\ttotal: 32.4s\tremaining: 4m 55s\n",
      "99:\tlearn: 0.0101466\ttotal: 32.5s\tremaining: 4m 52s\n",
      "100:\tlearn: 0.0101267\ttotal: 32.7s\tremaining: 4m 51s\n",
      "101:\tlearn: 0.0101044\ttotal: 32.8s\tremaining: 4m 49s\n",
      "102:\tlearn: 0.0100801\ttotal: 33s\tremaining: 4m 47s\n",
      "103:\tlearn: 0.0100707\ttotal: 33.3s\tremaining: 4m 47s\n",
      "104:\tlearn: 0.0100369\ttotal: 35.3s\tremaining: 5m 1s\n",
      "105:\tlearn: 0.0100121\ttotal: 35.5s\tremaining: 4m 59s\n",
      "106:\tlearn: 0.0099966\ttotal: 37.3s\tremaining: 5m 11s\n",
      "107:\tlearn: 0.0099585\ttotal: 38.3s\tremaining: 5m 16s\n",
      "108:\tlearn: 0.0099392\ttotal: 39.4s\tremaining: 5m 21s\n",
      "109:\tlearn: 0.0099079\ttotal: 39.9s\tremaining: 5m 22s\n",
      "110:\tlearn: 0.0098797\ttotal: 40.2s\tremaining: 5m 21s\n",
      "111:\tlearn: 0.0098585\ttotal: 40.3s\tremaining: 5m 19s\n",
      "112:\tlearn: 0.0098352\ttotal: 41.2s\tremaining: 5m 23s\n",
      "113:\tlearn: 0.0098163\ttotal: 42.2s\tremaining: 5m 28s\n",
      "114:\tlearn: 0.0097935\ttotal: 44.6s\tremaining: 5m 42s\n",
      "115:\tlearn: 0.0097572\ttotal: 44.7s\tremaining: 5m 40s\n",
      "116:\tlearn: 0.0097356\ttotal: 44.8s\tremaining: 5m 38s\n",
      "117:\tlearn: 0.0097117\ttotal: 44.9s\tremaining: 5m 35s\n",
      "118:\tlearn: 0.0096912\ttotal: 45s\tremaining: 5m 33s\n",
      "119:\tlearn: 0.0096823\ttotal: 45.1s\tremaining: 5m 30s\n",
      "120:\tlearn: 0.0096663\ttotal: 45.2s\tremaining: 5m 28s\n",
      "121:\tlearn: 0.0096546\ttotal: 45.3s\tremaining: 5m 25s\n",
      "122:\tlearn: 0.0096448\ttotal: 45.3s\tremaining: 5m 23s\n",
      "123:\tlearn: 0.0096230\ttotal: 45.5s\tremaining: 5m 21s\n",
      "124:\tlearn: 0.0096061\ttotal: 45.6s\tremaining: 5m 19s\n",
      "125:\tlearn: 0.0095819\ttotal: 45.7s\tremaining: 5m 17s\n",
      "126:\tlearn: 0.0095606\ttotal: 46s\tremaining: 5m 16s\n",
      "127:\tlearn: 0.0095243\ttotal: 46.2s\tremaining: 5m 15s\n",
      "128:\tlearn: 0.0095092\ttotal: 46.4s\tremaining: 5m 13s\n",
      "129:\tlearn: 0.0094906\ttotal: 46.8s\tremaining: 5m 13s\n",
      "130:\tlearn: 0.0094697\ttotal: 47s\tremaining: 5m 12s\n",
      "131:\tlearn: 0.0094485\ttotal: 47.3s\tremaining: 5m 10s\n",
      "132:\tlearn: 0.0094215\ttotal: 47.5s\tremaining: 5m 9s\n",
      "133:\tlearn: 0.0094079\ttotal: 47.7s\tremaining: 5m 8s\n",
      "134:\tlearn: 0.0093889\ttotal: 48.1s\tremaining: 5m 8s\n",
      "135:\tlearn: 0.0093719\ttotal: 48.4s\tremaining: 5m 7s\n",
      "136:\tlearn: 0.0093454\ttotal: 48.6s\tremaining: 5m 6s\n",
      "137:\tlearn: 0.0093188\ttotal: 48.9s\tremaining: 5m 5s\n",
      "138:\tlearn: 0.0093088\ttotal: 49.2s\tremaining: 5m 4s\n",
      "139:\tlearn: 0.0092915\ttotal: 49.5s\tremaining: 5m 3s\n",
      "140:\tlearn: 0.0092740\ttotal: 49.8s\tremaining: 5m 3s\n",
      "141:\tlearn: 0.0092434\ttotal: 50s\tremaining: 5m 1s\n",
      "142:\tlearn: 0.0092077\ttotal: 50.2s\tremaining: 5m\n",
      "143:\tlearn: 0.0091846\ttotal: 50.5s\tremaining: 5m\n",
      "144:\tlearn: 0.0091577\ttotal: 50.7s\tremaining: 4m 58s\n",
      "145:\tlearn: 0.0091357\ttotal: 51s\tremaining: 4m 58s\n",
      "146:\tlearn: 0.0091123\ttotal: 51.2s\tremaining: 4m 57s\n",
      "147:\tlearn: 0.0090970\ttotal: 51.4s\tremaining: 4m 56s\n",
      "148:\tlearn: 0.0090754\ttotal: 51.7s\tremaining: 4m 55s\n",
      "149:\tlearn: 0.0090670\ttotal: 51.9s\tremaining: 4m 54s\n",
      "150:\tlearn: 0.0090496\ttotal: 52.1s\tremaining: 4m 52s\n",
      "151:\tlearn: 0.0090263\ttotal: 52.3s\tremaining: 4m 51s\n",
      "152:\tlearn: 0.0090150\ttotal: 52.4s\tremaining: 4m 50s\n",
      "153:\tlearn: 0.0089946\ttotal: 52.9s\tremaining: 4m 50s\n",
      "154:\tlearn: 0.0089667\ttotal: 54.6s\tremaining: 4m 57s\n",
      "155:\tlearn: 0.0089562\ttotal: 55.7s\tremaining: 5m 1s\n",
      "156:\tlearn: 0.0089440\ttotal: 57.1s\tremaining: 5m 6s\n",
      "157:\tlearn: 0.0089319\ttotal: 57.3s\tremaining: 5m 5s\n",
      "158:\tlearn: 0.0089210\ttotal: 57.5s\tremaining: 5m 4s\n",
      "159:\tlearn: 0.0089071\ttotal: 57.7s\tremaining: 5m 3s\n",
      "160:\tlearn: 0.0088833\ttotal: 58.2s\tremaining: 5m 3s\n",
      "161:\tlearn: 0.0088527\ttotal: 58.5s\tremaining: 5m 2s\n",
      "162:\tlearn: 0.0088296\ttotal: 58.8s\tremaining: 5m 1s\n",
      "163:\tlearn: 0.0088173\ttotal: 59.2s\tremaining: 5m 1s\n",
      "164:\tlearn: 0.0088094\ttotal: 59.6s\tremaining: 5m 1s\n",
      "165:\tlearn: 0.0087914\ttotal: 60s\tremaining: 5m 1s\n",
      "166:\tlearn: 0.0087863\ttotal: 1m\tremaining: 5m\n",
      "167:\tlearn: 0.0087771\ttotal: 1m\tremaining: 5m\n",
      "168:\tlearn: 0.0087549\ttotal: 1m\tremaining: 4m 59s\n",
      "169:\tlearn: 0.0087382\ttotal: 1m 1s\tremaining: 4m 59s\n",
      "170:\tlearn: 0.0087322\ttotal: 1m 1s\tremaining: 4m 58s\n",
      "171:\tlearn: 0.0087205\ttotal: 1m 1s\tremaining: 4m 57s\n",
      "172:\tlearn: 0.0086940\ttotal: 1m 2s\tremaining: 4m 56s\n",
      "173:\tlearn: 0.0086803\ttotal: 1m 2s\tremaining: 4m 55s\n",
      "174:\tlearn: 0.0086555\ttotal: 1m 2s\tremaining: 4m 54s\n",
      "175:\tlearn: 0.0086295\ttotal: 1m 2s\tremaining: 4m 53s\n",
      "176:\tlearn: 0.0086202\ttotal: 1m 2s\tremaining: 4m 52s\n",
      "177:\tlearn: 0.0086114\ttotal: 1m 3s\tremaining: 4m 51s\n",
      "178:\tlearn: 0.0085895\ttotal: 1m 4s\tremaining: 4m 53s\n",
      "179:\tlearn: 0.0085623\ttotal: 1m 4s\tremaining: 4m 54s\n",
      "180:\tlearn: 0.0085545\ttotal: 1m 4s\tremaining: 4m 53s\n",
      "181:\tlearn: 0.0085177\ttotal: 1m 5s\tremaining: 4m 52s\n",
      "182:\tlearn: 0.0084966\ttotal: 1m 5s\tremaining: 4m 51s\n",
      "183:\tlearn: 0.0084871\ttotal: 1m 7s\tremaining: 4m 57s\n",
      "184:\tlearn: 0.0084702\ttotal: 1m 7s\tremaining: 4m 55s\n",
      "185:\tlearn: 0.0084520\ttotal: 1m 7s\tremaining: 4m 54s\n",
      "186:\tlearn: 0.0084367\ttotal: 1m 7s\tremaining: 4m 53s\n",
      "187:\tlearn: 0.0084282\ttotal: 1m 8s\tremaining: 4m 55s\n",
      "188:\tlearn: 0.0084065\ttotal: 1m 9s\tremaining: 4m 56s\n",
      "189:\tlearn: 0.0083916\ttotal: 1m 9s\tremaining: 4m 54s\n",
      "190:\tlearn: 0.0083759\ttotal: 1m 10s\tremaining: 5m\n",
      "191:\tlearn: 0.0083645\ttotal: 1m 12s\tremaining: 5m 3s\n",
      "192:\tlearn: 0.0083518\ttotal: 1m 12s\tremaining: 5m 1s\n",
      "193:\tlearn: 0.0083378\ttotal: 1m 12s\tremaining: 5m\n",
      "194:\tlearn: 0.0083109\ttotal: 1m 12s\tremaining: 4m 58s\n",
      "195:\tlearn: 0.0082866\ttotal: 1m 12s\tremaining: 4m 57s\n",
      "196:\tlearn: 0.0082666\ttotal: 1m 12s\tremaining: 4m 55s\n",
      "197:\tlearn: 0.0082429\ttotal: 1m 12s\tremaining: 4m 54s\n",
      "198:\tlearn: 0.0082324\ttotal: 1m 12s\tremaining: 4m 53s\n",
      "199:\tlearn: 0.0082177\ttotal: 1m 13s\tremaining: 4m 52s\n",
      "200:\tlearn: 0.0082048\ttotal: 1m 14s\tremaining: 4m 54s\n",
      "201:\tlearn: 0.0081798\ttotal: 1m 14s\tremaining: 4m 53s\n",
      "202:\tlearn: 0.0081731\ttotal: 1m 15s\tremaining: 4m 54s\n",
      "203:\tlearn: 0.0081501\ttotal: 1m 15s\tremaining: 4m 53s\n",
      "204:\tlearn: 0.0081291\ttotal: 1m 15s\tremaining: 4m 52s\n",
      "205:\tlearn: 0.0081125\ttotal: 1m 17s\tremaining: 4m 57s\n",
      "206:\tlearn: 0.0081023\ttotal: 1m 17s\tremaining: 4m 57s\n",
      "207:\tlearn: 0.0080813\ttotal: 1m 17s\tremaining: 4m 55s\n",
      "208:\tlearn: 0.0080757\ttotal: 1m 17s\tremaining: 4m 54s\n",
      "209:\tlearn: 0.0080450\ttotal: 1m 17s\tremaining: 4m 53s\n",
      "210:\tlearn: 0.0080275\ttotal: 1m 18s\tremaining: 4m 51s\n",
      "211:\tlearn: 0.0080149\ttotal: 1m 18s\tremaining: 4m 50s\n",
      "212:\tlearn: 0.0080034\ttotal: 1m 18s\tremaining: 4m 49s\n",
      "213:\tlearn: 0.0079889\ttotal: 1m 18s\tremaining: 4m 48s\n",
      "214:\tlearn: 0.0079737\ttotal: 1m 18s\tremaining: 4m 47s\n",
      "215:\tlearn: 0.0079562\ttotal: 1m 18s\tremaining: 4m 46s\n",
      "216:\tlearn: 0.0079330\ttotal: 1m 19s\tremaining: 4m 45s\n",
      "217:\tlearn: 0.0079170\ttotal: 1m 19s\tremaining: 4m 45s\n",
      "218:\tlearn: 0.0079002\ttotal: 1m 19s\tremaining: 4m 44s\n",
      "219:\tlearn: 0.0078865\ttotal: 1m 19s\tremaining: 4m 43s\n",
      "220:\tlearn: 0.0078694\ttotal: 1m 20s\tremaining: 4m 42s\n",
      "221:\tlearn: 0.0078585\ttotal: 1m 20s\tremaining: 4m 41s\n",
      "222:\tlearn: 0.0078484\ttotal: 1m 20s\tremaining: 4m 41s\n",
      "223:\tlearn: 0.0078408\ttotal: 1m 21s\tremaining: 4m 40s\n",
      "224:\tlearn: 0.0078349\ttotal: 1m 21s\tremaining: 4m 39s\n",
      "225:\tlearn: 0.0078178\ttotal: 1m 21s\tremaining: 4m 40s\n",
      "226:\tlearn: 0.0078021\ttotal: 1m 22s\tremaining: 4m 39s\n",
      "227:\tlearn: 0.0077877\ttotal: 1m 22s\tremaining: 4m 38s\n",
      "228:\tlearn: 0.0077664\ttotal: 1m 22s\tremaining: 4m 37s\n",
      "229:\tlearn: 0.0077623\ttotal: 1m 22s\tremaining: 4m 36s\n",
      "230:\tlearn: 0.0077430\ttotal: 1m 23s\tremaining: 4m 37s\n",
      "231:\tlearn: 0.0077357\ttotal: 1m 26s\tremaining: 4m 44s\n",
      "232:\tlearn: 0.0077287\ttotal: 1m 26s\tremaining: 4m 44s\n",
      "233:\tlearn: 0.0077046\ttotal: 1m 27s\tremaining: 4m 45s\n",
      "234:\tlearn: 0.0076753\ttotal: 1m 27s\tremaining: 4m 44s\n",
      "235:\tlearn: 0.0076595\ttotal: 1m 27s\tremaining: 4m 42s\n",
      "236:\tlearn: 0.0076431\ttotal: 1m 27s\tremaining: 4m 41s\n",
      "237:\tlearn: 0.0076333\ttotal: 1m 27s\tremaining: 4m 40s\n",
      "238:\tlearn: 0.0076160\ttotal: 1m 27s\tremaining: 4m 38s\n",
      "239:\tlearn: 0.0076033\ttotal: 1m 27s\tremaining: 4m 37s\n",
      "240:\tlearn: 0.0075947\ttotal: 1m 27s\tremaining: 4m 36s\n",
      "241:\tlearn: 0.0075826\ttotal: 1m 27s\tremaining: 4m 35s\n",
      "242:\tlearn: 0.0075710\ttotal: 1m 28s\tremaining: 4m 34s\n",
      "243:\tlearn: 0.0075631\ttotal: 1m 28s\tremaining: 4m 33s\n",
      "244:\tlearn: 0.0075491\ttotal: 1m 28s\tremaining: 4m 33s\n",
      "245:\tlearn: 0.0075405\ttotal: 1m 28s\tremaining: 4m 32s\n",
      "246:\tlearn: 0.0075309\ttotal: 1m 29s\tremaining: 4m 32s\n",
      "247:\tlearn: 0.0075215\ttotal: 1m 29s\tremaining: 4m 32s\n",
      "248:\tlearn: 0.0075156\ttotal: 1m 30s\tremaining: 4m 31s\n",
      "249:\tlearn: 0.0074957\ttotal: 1m 30s\tremaining: 4m 31s\n",
      "250:\tlearn: 0.0074911\ttotal: 1m 30s\tremaining: 4m 31s\n",
      "251:\tlearn: 0.0074780\ttotal: 1m 31s\tremaining: 4m 31s\n",
      "252:\tlearn: 0.0074691\ttotal: 1m 31s\tremaining: 4m 30s\n",
      "253:\tlearn: 0.0074548\ttotal: 1m 32s\tremaining: 4m 30s\n",
      "254:\tlearn: 0.0074356\ttotal: 1m 32s\tremaining: 4m 30s\n",
      "255:\tlearn: 0.0074255\ttotal: 1m 32s\tremaining: 4m 29s\n",
      "256:\tlearn: 0.0074115\ttotal: 1m 33s\tremaining: 4m 28s\n",
      "257:\tlearn: 0.0074010\ttotal: 1m 33s\tremaining: 4m 28s\n",
      "258:\tlearn: 0.0073867\ttotal: 1m 33s\tremaining: 4m 27s\n",
      "259:\tlearn: 0.0073741\ttotal: 1m 33s\tremaining: 4m 26s\n",
      "260:\tlearn: 0.0073670\ttotal: 1m 33s\tremaining: 4m 25s\n",
      "261:\tlearn: 0.0073548\ttotal: 1m 34s\tremaining: 4m 25s\n",
      "262:\tlearn: 0.0073422\ttotal: 1m 34s\tremaining: 4m 24s\n",
      "263:\tlearn: 0.0073311\ttotal: 1m 34s\tremaining: 4m 23s\n",
      "264:\tlearn: 0.0073163\ttotal: 1m 34s\tremaining: 4m 22s\n",
      "265:\tlearn: 0.0072983\ttotal: 1m 34s\tremaining: 4m 21s\n",
      "266:\tlearn: 0.0072848\ttotal: 1m 35s\tremaining: 4m 21s\n",
      "267:\tlearn: 0.0072737\ttotal: 1m 35s\tremaining: 4m 20s\n",
      "268:\tlearn: 0.0072501\ttotal: 1m 35s\tremaining: 4m 19s\n",
      "269:\tlearn: 0.0072466\ttotal: 1m 35s\tremaining: 4m 19s\n",
      "270:\tlearn: 0.0072381\ttotal: 1m 36s\tremaining: 4m 19s\n",
      "271:\tlearn: 0.0072122\ttotal: 1m 36s\tremaining: 4m 18s\n",
      "272:\tlearn: 0.0072050\ttotal: 1m 36s\tremaining: 4m 17s\n",
      "273:\tlearn: 0.0071884\ttotal: 1m 37s\tremaining: 4m 17s\n",
      "274:\tlearn: 0.0071780\ttotal: 1m 37s\tremaining: 4m 16s\n",
      "275:\tlearn: 0.0071617\ttotal: 1m 37s\tremaining: 4m 15s\n",
      "276:\tlearn: 0.0071470\ttotal: 1m 37s\tremaining: 4m 15s\n",
      "277:\tlearn: 0.0071376\ttotal: 1m 37s\tremaining: 4m 14s\n",
      "278:\tlearn: 0.0071249\ttotal: 1m 38s\tremaining: 4m 13s\n",
      "279:\tlearn: 0.0071199\ttotal: 1m 38s\tremaining: 4m 12s\n",
      "280:\tlearn: 0.0071175\ttotal: 1m 38s\tremaining: 4m 12s\n",
      "281:\tlearn: 0.0071116\ttotal: 1m 38s\tremaining: 4m 11s\n",
      "282:\tlearn: 0.0071047\ttotal: 1m 38s\tremaining: 4m 10s\n",
      "283:\tlearn: 0.0070931\ttotal: 1m 39s\tremaining: 4m 10s\n",
      "284:\tlearn: 0.0070666\ttotal: 1m 39s\tremaining: 4m 9s\n",
      "285:\tlearn: 0.0070560\ttotal: 1m 39s\tremaining: 4m 8s\n",
      "286:\tlearn: 0.0070467\ttotal: 1m 39s\tremaining: 4m 8s\n",
      "287:\tlearn: 0.0070345\ttotal: 1m 40s\tremaining: 4m 7s\n",
      "288:\tlearn: 0.0070082\ttotal: 1m 40s\tremaining: 4m 6s\n",
      "289:\tlearn: 0.0069837\ttotal: 1m 40s\tremaining: 4m 5s\n",
      "290:\tlearn: 0.0069676\ttotal: 1m 40s\tremaining: 4m 5s\n",
      "291:\tlearn: 0.0069561\ttotal: 1m 40s\tremaining: 4m 4s\n",
      "292:\tlearn: 0.0069472\ttotal: 1m 41s\tremaining: 4m 3s\n",
      "293:\tlearn: 0.0069356\ttotal: 1m 41s\tremaining: 4m 3s\n",
      "294:\tlearn: 0.0069317\ttotal: 1m 41s\tremaining: 4m 2s\n",
      "295:\tlearn: 0.0069206\ttotal: 1m 41s\tremaining: 4m 2s\n",
      "296:\tlearn: 0.0069012\ttotal: 1m 42s\tremaining: 4m 1s\n",
      "297:\tlearn: 0.0068953\ttotal: 1m 42s\tremaining: 4m 1s\n",
      "298:\tlearn: 0.0068814\ttotal: 1m 42s\tremaining: 4m\n",
      "299:\tlearn: 0.0068751\ttotal: 1m 42s\tremaining: 4m\n",
      "300:\tlearn: 0.0068638\ttotal: 1m 43s\tremaining: 3m 59s\n",
      "301:\tlearn: 0.0068515\ttotal: 1m 43s\tremaining: 3m 58s\n",
      "302:\tlearn: 0.0068282\ttotal: 1m 43s\tremaining: 3m 58s\n",
      "303:\tlearn: 0.0068202\ttotal: 1m 43s\tremaining: 3m 57s\n",
      "304:\tlearn: 0.0068150\ttotal: 1m 43s\tremaining: 3m 56s\n",
      "305:\tlearn: 0.0068102\ttotal: 1m 44s\tremaining: 3m 56s\n",
      "306:\tlearn: 0.0068000\ttotal: 1m 44s\tremaining: 3m 55s\n",
      "307:\tlearn: 0.0067934\ttotal: 1m 44s\tremaining: 3m 55s\n",
      "308:\tlearn: 0.0067841\ttotal: 1m 45s\tremaining: 3m 54s\n",
      "309:\tlearn: 0.0067761\ttotal: 1m 45s\tremaining: 3m 54s\n",
      "310:\tlearn: 0.0067560\ttotal: 1m 45s\tremaining: 3m 53s\n",
      "311:\tlearn: 0.0067451\ttotal: 1m 45s\tremaining: 3m 53s\n",
      "312:\tlearn: 0.0067338\ttotal: 1m 45s\tremaining: 3m 52s\n",
      "313:\tlearn: 0.0067152\ttotal: 1m 46s\tremaining: 3m 51s\n",
      "314:\tlearn: 0.0067109\ttotal: 1m 46s\tremaining: 3m 52s\n",
      "315:\tlearn: 0.0067035\ttotal: 1m 47s\tremaining: 3m 53s\n",
      "316:\tlearn: 0.0066874\ttotal: 1m 48s\tremaining: 3m 52s\n",
      "317:\tlearn: 0.0066751\ttotal: 1m 48s\tremaining: 3m 52s\n",
      "318:\tlearn: 0.0066713\ttotal: 1m 48s\tremaining: 3m 51s\n",
      "319:\tlearn: 0.0066567\ttotal: 1m 48s\tremaining: 3m 50s\n",
      "320:\tlearn: 0.0066418\ttotal: 1m 48s\tremaining: 3m 50s\n",
      "321:\tlearn: 0.0066246\ttotal: 1m 49s\tremaining: 3m 51s\n",
      "322:\tlearn: 0.0066166\ttotal: 1m 50s\tremaining: 3m 51s\n",
      "323:\tlearn: 0.0066054\ttotal: 1m 50s\tremaining: 3m 50s\n",
      "324:\tlearn: 0.0066013\ttotal: 1m 50s\tremaining: 3m 49s\n",
      "325:\tlearn: 0.0065828\ttotal: 1m 50s\tremaining: 3m 48s\n",
      "326:\tlearn: 0.0065648\ttotal: 1m 50s\tremaining: 3m 48s\n",
      "327:\tlearn: 0.0065586\ttotal: 1m 51s\tremaining: 3m 47s\n",
      "328:\tlearn: 0.0065486\ttotal: 1m 51s\tremaining: 3m 47s\n",
      "329:\tlearn: 0.0065295\ttotal: 1m 51s\tremaining: 3m 46s\n",
      "330:\tlearn: 0.0065210\ttotal: 1m 51s\tremaining: 3m 45s\n",
      "331:\tlearn: 0.0065159\ttotal: 1m 52s\tremaining: 3m 45s\n",
      "332:\tlearn: 0.0065070\ttotal: 1m 52s\tremaining: 3m 44s\n",
      "333:\tlearn: 0.0064963\ttotal: 1m 52s\tremaining: 3m 44s\n",
      "334:\tlearn: 0.0064893\ttotal: 1m 52s\tremaining: 3m 43s\n",
      "335:\tlearn: 0.0064851\ttotal: 1m 52s\tremaining: 3m 42s\n",
      "336:\tlearn: 0.0064628\ttotal: 1m 53s\tremaining: 3m 42s\n",
      "337:\tlearn: 0.0064576\ttotal: 1m 53s\tremaining: 3m 41s\n",
      "338:\tlearn: 0.0064418\ttotal: 1m 53s\tremaining: 3m 41s\n",
      "339:\tlearn: 0.0064363\ttotal: 1m 53s\tremaining: 3m 40s\n",
      "340:\tlearn: 0.0064301\ttotal: 1m 54s\tremaining: 3m 40s\n",
      "341:\tlearn: 0.0064235\ttotal: 1m 54s\tremaining: 3m 41s\n",
      "342:\tlearn: 0.0064162\ttotal: 1m 55s\tremaining: 3m 40s\n",
      "343:\tlearn: 0.0064011\ttotal: 1m 55s\tremaining: 3m 40s\n",
      "344:\tlearn: 0.0063868\ttotal: 1m 56s\tremaining: 3m 40s\n",
      "345:\tlearn: 0.0063783\ttotal: 1m 56s\tremaining: 3m 39s\n",
      "346:\tlearn: 0.0063708\ttotal: 1m 57s\tremaining: 3m 41s\n",
      "347:\tlearn: 0.0063662\ttotal: 1m 57s\tremaining: 3m 40s\n",
      "348:\tlearn: 0.0063577\ttotal: 1m 58s\tremaining: 3m 40s\n",
      "349:\tlearn: 0.0063531\ttotal: 1m 58s\tremaining: 3m 40s\n",
      "350:\tlearn: 0.0063348\ttotal: 2m\tremaining: 3m 43s\n",
      "351:\tlearn: 0.0063239\ttotal: 2m\tremaining: 3m 42s\n",
      "352:\tlearn: 0.0063199\ttotal: 2m\tremaining: 3m 41s\n",
      "353:\tlearn: 0.0063127\ttotal: 2m 1s\tremaining: 3m 40s\n",
      "354:\tlearn: 0.0063067\ttotal: 2m 1s\tremaining: 3m 40s\n",
      "355:\tlearn: 0.0062985\ttotal: 2m 1s\tremaining: 3m 39s\n",
      "356:\tlearn: 0.0062902\ttotal: 2m 1s\tremaining: 3m 38s\n",
      "357:\tlearn: 0.0062835\ttotal: 2m 1s\tremaining: 3m 37s\n",
      "358:\tlearn: 0.0062769\ttotal: 2m 1s\tremaining: 3m 37s\n",
      "359:\tlearn: 0.0062692\ttotal: 2m 1s\tremaining: 3m 36s\n",
      "360:\tlearn: 0.0062556\ttotal: 2m 2s\tremaining: 3m 36s\n",
      "361:\tlearn: 0.0062442\ttotal: 2m 2s\tremaining: 3m 35s\n",
      "362:\tlearn: 0.0062400\ttotal: 2m 2s\tremaining: 3m 35s\n",
      "363:\tlearn: 0.0062369\ttotal: 2m 3s\tremaining: 3m 35s\n",
      "364:\tlearn: 0.0062326\ttotal: 2m 3s\tremaining: 3m 35s\n",
      "365:\tlearn: 0.0062161\ttotal: 2m 4s\tremaining: 3m 35s\n",
      "366:\tlearn: 0.0062061\ttotal: 2m 4s\tremaining: 3m 34s\n",
      "367:\tlearn: 0.0061964\ttotal: 2m 4s\tremaining: 3m 34s\n",
      "368:\tlearn: 0.0061829\ttotal: 2m 5s\tremaining: 3m 33s\n",
      "369:\tlearn: 0.0061751\ttotal: 2m 5s\tremaining: 3m 33s\n",
      "370:\tlearn: 0.0061621\ttotal: 2m 5s\tremaining: 3m 32s\n",
      "371:\tlearn: 0.0061538\ttotal: 2m 5s\tremaining: 3m 32s\n",
      "372:\tlearn: 0.0061320\ttotal: 2m 6s\tremaining: 3m 32s\n",
      "373:\tlearn: 0.0061270\ttotal: 2m 6s\tremaining: 3m 31s\n",
      "374:\tlearn: 0.0061220\ttotal: 2m 6s\tremaining: 3m 31s\n",
      "375:\tlearn: 0.0061050\ttotal: 2m 6s\tremaining: 3m 30s\n",
      "376:\tlearn: 0.0061020\ttotal: 2m 7s\tremaining: 3m 30s\n",
      "377:\tlearn: 0.0060878\ttotal: 2m 7s\tremaining: 3m 29s\n",
      "378:\tlearn: 0.0060766\ttotal: 2m 7s\tremaining: 3m 29s\n",
      "379:\tlearn: 0.0060725\ttotal: 2m 8s\tremaining: 3m 29s\n",
      "380:\tlearn: 0.0060654\ttotal: 2m 8s\tremaining: 3m 28s\n",
      "381:\tlearn: 0.0060503\ttotal: 2m 8s\tremaining: 3m 28s\n",
      "382:\tlearn: 0.0060407\ttotal: 2m 9s\tremaining: 3m 27s\n",
      "383:\tlearn: 0.0060345\ttotal: 2m 9s\tremaining: 3m 27s\n",
      "384:\tlearn: 0.0060173\ttotal: 2m 9s\tremaining: 3m 26s\n",
      "385:\tlearn: 0.0060142\ttotal: 2m 9s\tremaining: 3m 26s\n",
      "386:\tlearn: 0.0059984\ttotal: 2m 10s\tremaining: 3m 26s\n",
      "387:\tlearn: 0.0059903\ttotal: 2m 10s\tremaining: 3m 25s\n",
      "388:\tlearn: 0.0059852\ttotal: 2m 10s\tremaining: 3m 25s\n",
      "389:\tlearn: 0.0059834\ttotal: 2m 10s\tremaining: 3m 24s\n",
      "390:\tlearn: 0.0059756\ttotal: 2m 11s\tremaining: 3m 24s\n",
      "391:\tlearn: 0.0059692\ttotal: 2m 11s\tremaining: 3m 23s\n",
      "392:\tlearn: 0.0059603\ttotal: 2m 11s\tremaining: 3m 23s\n",
      "393:\tlearn: 0.0059561\ttotal: 2m 12s\tremaining: 3m 23s\n",
      "394:\tlearn: 0.0059513\ttotal: 2m 12s\tremaining: 3m 22s\n",
      "395:\tlearn: 0.0059464\ttotal: 2m 12s\tremaining: 3m 22s\n",
      "396:\tlearn: 0.0059412\ttotal: 2m 12s\tremaining: 3m 21s\n",
      "397:\tlearn: 0.0059364\ttotal: 2m 13s\tremaining: 3m 21s\n",
      "398:\tlearn: 0.0059297\ttotal: 2m 13s\tremaining: 3m 21s\n",
      "399:\tlearn: 0.0059219\ttotal: 2m 13s\tremaining: 3m 20s\n",
      "400:\tlearn: 0.0059168\ttotal: 2m 14s\tremaining: 3m 20s\n",
      "401:\tlearn: 0.0059098\ttotal: 2m 14s\tremaining: 3m 19s\n",
      "402:\tlearn: 0.0059048\ttotal: 2m 14s\tremaining: 3m 19s\n",
      "403:\tlearn: 0.0059021\ttotal: 2m 14s\tremaining: 3m 18s\n",
      "404:\tlearn: 0.0058958\ttotal: 2m 15s\tremaining: 3m 18s\n",
      "405:\tlearn: 0.0058832\ttotal: 2m 15s\tremaining: 3m 17s\n",
      "406:\tlearn: 0.0058772\ttotal: 2m 15s\tremaining: 3m 17s\n",
      "407:\tlearn: 0.0058698\ttotal: 2m 15s\tremaining: 3m 16s\n",
      "408:\tlearn: 0.0058633\ttotal: 2m 15s\tremaining: 3m 16s\n",
      "409:\tlearn: 0.0058551\ttotal: 2m 16s\tremaining: 3m 15s\n",
      "410:\tlearn: 0.0058427\ttotal: 2m 16s\tremaining: 3m 15s\n",
      "411:\tlearn: 0.0058380\ttotal: 2m 17s\tremaining: 3m 15s\n",
      "412:\tlearn: 0.0058347\ttotal: 2m 17s\tremaining: 3m 15s\n",
      "413:\tlearn: 0.0058290\ttotal: 2m 17s\tremaining: 3m 14s\n",
      "414:\tlearn: 0.0058260\ttotal: 2m 17s\tremaining: 3m 13s\n",
      "415:\tlearn: 0.0058124\ttotal: 2m 17s\tremaining: 3m 13s\n",
      "416:\tlearn: 0.0058099\ttotal: 2m 17s\tremaining: 3m 12s\n",
      "417:\tlearn: 0.0057998\ttotal: 2m 18s\tremaining: 3m 12s\n",
      "418:\tlearn: 0.0057960\ttotal: 2m 18s\tremaining: 3m 11s\n",
      "419:\tlearn: 0.0057924\ttotal: 2m 18s\tremaining: 3m 11s\n",
      "420:\tlearn: 0.0057819\ttotal: 2m 18s\tremaining: 3m 11s\n",
      "421:\tlearn: 0.0057771\ttotal: 2m 19s\tremaining: 3m 10s\n",
      "422:\tlearn: 0.0057706\ttotal: 2m 19s\tremaining: 3m 10s\n",
      "423:\tlearn: 0.0057623\ttotal: 2m 19s\tremaining: 3m 9s\n",
      "424:\tlearn: 0.0057586\ttotal: 2m 19s\tremaining: 3m 9s\n",
      "425:\tlearn: 0.0057471\ttotal: 2m 19s\tremaining: 3m 8s\n",
      "426:\tlearn: 0.0057437\ttotal: 2m 21s\tremaining: 3m 9s\n",
      "427:\tlearn: 0.0057370\ttotal: 2m 21s\tremaining: 3m 8s\n",
      "428:\tlearn: 0.0057310\ttotal: 2m 21s\tremaining: 3m 8s\n",
      "429:\tlearn: 0.0057221\ttotal: 2m 21s\tremaining: 3m 7s\n",
      "430:\tlearn: 0.0057088\ttotal: 2m 21s\tremaining: 3m 6s\n",
      "431:\tlearn: 0.0056991\ttotal: 2m 21s\tremaining: 3m 6s\n",
      "432:\tlearn: 0.0056946\ttotal: 2m 21s\tremaining: 3m 5s\n",
      "433:\tlearn: 0.0056813\ttotal: 2m 22s\tremaining: 3m 5s\n",
      "434:\tlearn: 0.0056731\ttotal: 2m 22s\tremaining: 3m 4s\n",
      "435:\tlearn: 0.0056656\ttotal: 2m 22s\tremaining: 3m 4s\n",
      "436:\tlearn: 0.0056608\ttotal: 2m 22s\tremaining: 3m 3s\n",
      "437:\tlearn: 0.0056468\ttotal: 2m 22s\tremaining: 3m 3s\n",
      "438:\tlearn: 0.0056390\ttotal: 2m 23s\tremaining: 3m 2s\n",
      "439:\tlearn: 0.0056308\ttotal: 2m 23s\tremaining: 3m 2s\n",
      "440:\tlearn: 0.0056170\ttotal: 2m 23s\tremaining: 3m 1s\n",
      "441:\tlearn: 0.0056054\ttotal: 2m 23s\tremaining: 3m 1s\n",
      "442:\tlearn: 0.0055999\ttotal: 2m 23s\tremaining: 3m\n",
      "443:\tlearn: 0.0055878\ttotal: 2m 23s\tremaining: 3m\n",
      "444:\tlearn: 0.0055810\ttotal: 2m 24s\tremaining: 2m 59s\n",
      "445:\tlearn: 0.0055736\ttotal: 2m 24s\tremaining: 2m 59s\n",
      "446:\tlearn: 0.0055654\ttotal: 2m 24s\tremaining: 2m 58s\n",
      "447:\tlearn: 0.0055594\ttotal: 2m 24s\tremaining: 2m 58s\n",
      "448:\tlearn: 0.0055462\ttotal: 2m 25s\tremaining: 2m 57s\n",
      "449:\tlearn: 0.0055392\ttotal: 2m 25s\tremaining: 2m 57s\n",
      "450:\tlearn: 0.0055235\ttotal: 2m 25s\tremaining: 2m 57s\n",
      "451:\tlearn: 0.0055203\ttotal: 2m 25s\tremaining: 2m 56s\n",
      "452:\tlearn: 0.0055146\ttotal: 2m 26s\tremaining: 2m 56s\n",
      "453:\tlearn: 0.0054945\ttotal: 2m 26s\tremaining: 2m 55s\n",
      "454:\tlearn: 0.0054931\ttotal: 2m 26s\tremaining: 2m 55s\n",
      "455:\tlearn: 0.0054811\ttotal: 2m 26s\tremaining: 2m 55s\n",
      "456:\tlearn: 0.0054764\ttotal: 2m 26s\tremaining: 2m 54s\n",
      "457:\tlearn: 0.0054730\ttotal: 2m 27s\tremaining: 2m 54s\n",
      "458:\tlearn: 0.0054702\ttotal: 2m 27s\tremaining: 2m 53s\n",
      "459:\tlearn: 0.0054666\ttotal: 2m 27s\tremaining: 2m 53s\n",
      "460:\tlearn: 0.0054593\ttotal: 2m 27s\tremaining: 2m 52s\n",
      "461:\tlearn: 0.0054458\ttotal: 2m 27s\tremaining: 2m 52s\n",
      "462:\tlearn: 0.0054423\ttotal: 2m 28s\tremaining: 2m 51s\n",
      "463:\tlearn: 0.0054338\ttotal: 2m 28s\tremaining: 2m 51s\n",
      "464:\tlearn: 0.0054248\ttotal: 2m 28s\tremaining: 2m 51s\n",
      "465:\tlearn: 0.0054232\ttotal: 2m 28s\tremaining: 2m 50s\n",
      "466:\tlearn: 0.0054163\ttotal: 2m 29s\tremaining: 2m 50s\n",
      "467:\tlearn: 0.0054141\ttotal: 2m 29s\tremaining: 2m 49s\n",
      "468:\tlearn: 0.0054025\ttotal: 2m 29s\tremaining: 2m 49s\n",
      "469:\tlearn: 0.0053957\ttotal: 2m 30s\tremaining: 2m 49s\n",
      "470:\tlearn: 0.0053923\ttotal: 2m 30s\tremaining: 2m 48s\n",
      "471:\tlearn: 0.0053840\ttotal: 2m 30s\tremaining: 2m 48s\n",
      "472:\tlearn: 0.0053810\ttotal: 2m 30s\tremaining: 2m 47s\n",
      "473:\tlearn: 0.0053771\ttotal: 2m 30s\tremaining: 2m 47s\n",
      "474:\tlearn: 0.0053724\ttotal: 2m 31s\tremaining: 2m 47s\n",
      "475:\tlearn: 0.0053607\ttotal: 2m 31s\tremaining: 2m 46s\n",
      "476:\tlearn: 0.0053549\ttotal: 2m 31s\tremaining: 2m 46s\n",
      "477:\tlearn: 0.0053518\ttotal: 2m 32s\tremaining: 2m 46s\n",
      "478:\tlearn: 0.0053488\ttotal: 2m 33s\tremaining: 2m 47s\n",
      "479:\tlearn: 0.0053411\ttotal: 2m 33s\tremaining: 2m 46s\n",
      "480:\tlearn: 0.0053265\ttotal: 2m 33s\tremaining: 2m 46s\n",
      "481:\tlearn: 0.0053209\ttotal: 2m 34s\tremaining: 2m 45s\n",
      "482:\tlearn: 0.0053103\ttotal: 2m 34s\tremaining: 2m 45s\n",
      "483:\tlearn: 0.0053039\ttotal: 2m 34s\tremaining: 2m 44s\n",
      "484:\tlearn: 0.0052966\ttotal: 2m 34s\tremaining: 2m 44s\n",
      "485:\tlearn: 0.0052876\ttotal: 2m 34s\tremaining: 2m 43s\n",
      "486:\tlearn: 0.0052828\ttotal: 2m 35s\tremaining: 2m 43s\n",
      "487:\tlearn: 0.0052788\ttotal: 2m 35s\tremaining: 2m 43s\n",
      "488:\tlearn: 0.0052654\ttotal: 2m 35s\tremaining: 2m 42s\n",
      "489:\tlearn: 0.0052607\ttotal: 2m 35s\tremaining: 2m 42s\n",
      "490:\tlearn: 0.0052570\ttotal: 2m 36s\tremaining: 2m 41s\n",
      "491:\tlearn: 0.0052512\ttotal: 2m 36s\tremaining: 2m 41s\n",
      "492:\tlearn: 0.0052487\ttotal: 2m 36s\tremaining: 2m 41s\n",
      "493:\tlearn: 0.0052419\ttotal: 2m 37s\tremaining: 2m 40s\n",
      "494:\tlearn: 0.0052359\ttotal: 2m 37s\tremaining: 2m 40s\n",
      "495:\tlearn: 0.0052290\ttotal: 2m 37s\tremaining: 2m 40s\n",
      "496:\tlearn: 0.0052212\ttotal: 2m 38s\tremaining: 2m 39s\n",
      "497:\tlearn: 0.0052177\ttotal: 2m 38s\tremaining: 2m 39s\n",
      "498:\tlearn: 0.0052159\ttotal: 2m 38s\tremaining: 2m 39s\n",
      "499:\tlearn: 0.0052111\ttotal: 2m 38s\tremaining: 2m 38s\n",
      "500:\tlearn: 0.0052041\ttotal: 2m 38s\tremaining: 2m 38s\n",
      "501:\tlearn: 0.0051994\ttotal: 2m 39s\tremaining: 2m 37s\n",
      "502:\tlearn: 0.0051943\ttotal: 2m 39s\tremaining: 2m 37s\n",
      "503:\tlearn: 0.0051921\ttotal: 2m 39s\tremaining: 2m 37s\n",
      "504:\tlearn: 0.0051846\ttotal: 2m 39s\tremaining: 2m 36s\n",
      "505:\tlearn: 0.0051631\ttotal: 2m 40s\tremaining: 2m 36s\n",
      "506:\tlearn: 0.0051599\ttotal: 2m 40s\tremaining: 2m 35s\n",
      "507:\tlearn: 0.0051542\ttotal: 2m 40s\tremaining: 2m 35s\n",
      "508:\tlearn: 0.0051512\ttotal: 2m 40s\tremaining: 2m 35s\n",
      "509:\tlearn: 0.0051383\ttotal: 2m 41s\tremaining: 2m 34s\n",
      "510:\tlearn: 0.0051239\ttotal: 2m 41s\tremaining: 2m 34s\n",
      "511:\tlearn: 0.0051148\ttotal: 2m 42s\tremaining: 2m 34s\n",
      "512:\tlearn: 0.0051096\ttotal: 2m 42s\tremaining: 2m 34s\n",
      "513:\tlearn: 0.0051054\ttotal: 2m 42s\tremaining: 2m 33s\n",
      "514:\tlearn: 0.0050946\ttotal: 2m 42s\tremaining: 2m 33s\n",
      "515:\tlearn: 0.0050839\ttotal: 2m 42s\tremaining: 2m 32s\n",
      "516:\tlearn: 0.0050791\ttotal: 2m 43s\tremaining: 2m 32s\n",
      "517:\tlearn: 0.0050733\ttotal: 2m 43s\tremaining: 2m 32s\n",
      "518:\tlearn: 0.0050687\ttotal: 2m 43s\tremaining: 2m 31s\n",
      "519:\tlearn: 0.0050571\ttotal: 2m 44s\tremaining: 2m 31s\n",
      "520:\tlearn: 0.0050523\ttotal: 2m 44s\tremaining: 2m 31s\n",
      "521:\tlearn: 0.0050484\ttotal: 2m 45s\tremaining: 2m 31s\n",
      "522:\tlearn: 0.0050436\ttotal: 2m 46s\tremaining: 2m 32s\n",
      "523:\tlearn: 0.0050411\ttotal: 2m 46s\tremaining: 2m 31s\n",
      "524:\tlearn: 0.0050383\ttotal: 2m 47s\tremaining: 2m 31s\n",
      "525:\tlearn: 0.0050346\ttotal: 2m 47s\tremaining: 2m 30s\n",
      "526:\tlearn: 0.0050300\ttotal: 2m 47s\tremaining: 2m 30s\n",
      "527:\tlearn: 0.0050265\ttotal: 2m 47s\tremaining: 2m 29s\n",
      "528:\tlearn: 0.0050212\ttotal: 2m 47s\tremaining: 2m 29s\n",
      "529:\tlearn: 0.0050188\ttotal: 2m 47s\tremaining: 2m 28s\n",
      "530:\tlearn: 0.0050151\ttotal: 2m 47s\tremaining: 2m 28s\n",
      "531:\tlearn: 0.0050132\ttotal: 2m 48s\tremaining: 2m 27s\n",
      "532:\tlearn: 0.0050110\ttotal: 2m 48s\tremaining: 2m 27s\n",
      "533:\tlearn: 0.0050070\ttotal: 2m 48s\tremaining: 2m 27s\n",
      "534:\tlearn: 0.0049919\ttotal: 2m 49s\tremaining: 2m 26s\n",
      "535:\tlearn: 0.0049885\ttotal: 2m 50s\tremaining: 2m 27s\n",
      "536:\tlearn: 0.0049790\ttotal: 2m 50s\tremaining: 2m 26s\n",
      "537:\tlearn: 0.0049677\ttotal: 2m 50s\tremaining: 2m 26s\n",
      "538:\tlearn: 0.0049630\ttotal: 2m 50s\tremaining: 2m 26s\n",
      "539:\tlearn: 0.0049573\ttotal: 2m 50s\tremaining: 2m 25s\n",
      "540:\tlearn: 0.0049480\ttotal: 2m 51s\tremaining: 2m 25s\n",
      "541:\tlearn: 0.0049464\ttotal: 2m 51s\tremaining: 2m 24s\n",
      "542:\tlearn: 0.0049391\ttotal: 2m 51s\tremaining: 2m 24s\n",
      "543:\tlearn: 0.0049331\ttotal: 2m 51s\tremaining: 2m 23s\n",
      "544:\tlearn: 0.0049280\ttotal: 2m 51s\tremaining: 2m 23s\n",
      "545:\tlearn: 0.0049236\ttotal: 2m 52s\tremaining: 2m 23s\n",
      "546:\tlearn: 0.0049109\ttotal: 2m 52s\tremaining: 2m 22s\n",
      "547:\tlearn: 0.0049061\ttotal: 2m 52s\tremaining: 2m 22s\n",
      "548:\tlearn: 0.0048938\ttotal: 2m 52s\tremaining: 2m 22s\n",
      "549:\tlearn: 0.0048900\ttotal: 2m 53s\tremaining: 2m 21s\n",
      "550:\tlearn: 0.0048879\ttotal: 2m 53s\tremaining: 2m 21s\n",
      "551:\tlearn: 0.0048855\ttotal: 2m 53s\tremaining: 2m 20s\n",
      "552:\tlearn: 0.0048836\ttotal: 2m 53s\tremaining: 2m 20s\n",
      "553:\tlearn: 0.0048818\ttotal: 2m 54s\tremaining: 2m 20s\n",
      "554:\tlearn: 0.0048784\ttotal: 2m 54s\tremaining: 2m 19s\n",
      "555:\tlearn: 0.0048770\ttotal: 2m 54s\tremaining: 2m 19s\n",
      "556:\tlearn: 0.0048756\ttotal: 2m 55s\tremaining: 2m 19s\n",
      "557:\tlearn: 0.0048738\ttotal: 2m 55s\tremaining: 2m 18s\n",
      "558:\tlearn: 0.0048705\ttotal: 2m 55s\tremaining: 2m 18s\n",
      "559:\tlearn: 0.0048691\ttotal: 2m 55s\tremaining: 2m 18s\n",
      "560:\tlearn: 0.0048660\ttotal: 2m 55s\tremaining: 2m 17s\n",
      "561:\tlearn: 0.0048552\ttotal: 2m 56s\tremaining: 2m 17s\n",
      "562:\tlearn: 0.0048538\ttotal: 2m 56s\tremaining: 2m 16s\n",
      "563:\tlearn: 0.0048428\ttotal: 2m 56s\tremaining: 2m 16s\n",
      "564:\tlearn: 0.0048359\ttotal: 2m 56s\tremaining: 2m 16s\n",
      "565:\tlearn: 0.0048287\ttotal: 2m 57s\tremaining: 2m 15s\n",
      "566:\tlearn: 0.0048229\ttotal: 2m 57s\tremaining: 2m 15s\n",
      "567:\tlearn: 0.0048193\ttotal: 2m 57s\tremaining: 2m 15s\n",
      "568:\tlearn: 0.0048166\ttotal: 2m 57s\tremaining: 2m 14s\n",
      "569:\tlearn: 0.0048155\ttotal: 2m 57s\tremaining: 2m 14s\n",
      "570:\tlearn: 0.0048084\ttotal: 2m 58s\tremaining: 2m 13s\n",
      "571:\tlearn: 0.0048057\ttotal: 2m 58s\tremaining: 2m 13s\n",
      "572:\tlearn: 0.0047976\ttotal: 2m 58s\tremaining: 2m 13s\n",
      "573:\tlearn: 0.0047927\ttotal: 2m 58s\tremaining: 2m 12s\n",
      "574:\tlearn: 0.0047885\ttotal: 2m 59s\tremaining: 2m 12s\n",
      "575:\tlearn: 0.0047755\ttotal: 2m 59s\tremaining: 2m 11s\n",
      "576:\tlearn: 0.0047742\ttotal: 2m 59s\tremaining: 2m 11s\n",
      "577:\tlearn: 0.0047617\ttotal: 2m 59s\tremaining: 2m 11s\n",
      "578:\tlearn: 0.0047599\ttotal: 3m\tremaining: 2m 11s\n",
      "579:\tlearn: 0.0047551\ttotal: 3m\tremaining: 2m 10s\n",
      "580:\tlearn: 0.0047514\ttotal: 3m\tremaining: 2m 10s\n",
      "581:\tlearn: 0.0047477\ttotal: 3m\tremaining: 2m 9s\n",
      "582:\tlearn: 0.0047336\ttotal: 3m 1s\tremaining: 2m 9s\n",
      "583:\tlearn: 0.0047235\ttotal: 3m 1s\tremaining: 2m 9s\n",
      "584:\tlearn: 0.0047204\ttotal: 3m 1s\tremaining: 2m 8s\n",
      "585:\tlearn: 0.0047172\ttotal: 3m 2s\tremaining: 2m 8s\n",
      "586:\tlearn: 0.0047137\ttotal: 3m 2s\tremaining: 2m 8s\n",
      "587:\tlearn: 0.0047125\ttotal: 3m 2s\tremaining: 2m 7s\n",
      "588:\tlearn: 0.0047069\ttotal: 3m 2s\tremaining: 2m 7s\n",
      "589:\tlearn: 0.0047043\ttotal: 3m 2s\tremaining: 2m 7s\n",
      "590:\tlearn: 0.0047010\ttotal: 3m 3s\tremaining: 2m 6s\n",
      "591:\tlearn: 0.0046917\ttotal: 3m 3s\tremaining: 2m 6s\n",
      "592:\tlearn: 0.0046860\ttotal: 3m 3s\tremaining: 2m 6s\n",
      "593:\tlearn: 0.0046827\ttotal: 3m 3s\tremaining: 2m 5s\n",
      "594:\tlearn: 0.0046787\ttotal: 3m 4s\tremaining: 2m 5s\n",
      "595:\tlearn: 0.0046755\ttotal: 3m 4s\tremaining: 2m 4s\n",
      "596:\tlearn: 0.0046618\ttotal: 3m 4s\tremaining: 2m 4s\n",
      "597:\tlearn: 0.0046588\ttotal: 3m 4s\tremaining: 2m 4s\n",
      "598:\tlearn: 0.0046550\ttotal: 3m 5s\tremaining: 2m 4s\n",
      "599:\tlearn: 0.0046510\ttotal: 3m 5s\tremaining: 2m 3s\n",
      "600:\tlearn: 0.0046474\ttotal: 3m 5s\tremaining: 2m 3s\n",
      "601:\tlearn: 0.0046374\ttotal: 3m 6s\tremaining: 2m 3s\n",
      "602:\tlearn: 0.0046320\ttotal: 3m 7s\tremaining: 2m 3s\n",
      "603:\tlearn: 0.0046258\ttotal: 3m 7s\tremaining: 2m 3s\n",
      "604:\tlearn: 0.0046239\ttotal: 3m 8s\tremaining: 2m 2s\n",
      "605:\tlearn: 0.0046187\ttotal: 3m 8s\tremaining: 2m 2s\n",
      "606:\tlearn: 0.0046108\ttotal: 3m 8s\tremaining: 2m 2s\n",
      "607:\tlearn: 0.0046080\ttotal: 3m 8s\tremaining: 2m 1s\n",
      "608:\tlearn: 0.0046045\ttotal: 3m 8s\tremaining: 2m 1s\n",
      "609:\tlearn: 0.0045981\ttotal: 3m 9s\tremaining: 2m\n",
      "610:\tlearn: 0.0045951\ttotal: 3m 9s\tremaining: 2m\n",
      "611:\tlearn: 0.0045903\ttotal: 3m 9s\tremaining: 2m\n",
      "612:\tlearn: 0.0045786\ttotal: 3m 10s\tremaining: 1m 59s\n",
      "613:\tlearn: 0.0045766\ttotal: 3m 10s\tremaining: 1m 59s\n",
      "614:\tlearn: 0.0045697\ttotal: 3m 10s\tremaining: 1m 59s\n",
      "615:\tlearn: 0.0045649\ttotal: 3m 10s\tremaining: 1m 58s\n",
      "616:\tlearn: 0.0045620\ttotal: 3m 11s\tremaining: 1m 58s\n",
      "617:\tlearn: 0.0045587\ttotal: 3m 11s\tremaining: 1m 58s\n",
      "618:\tlearn: 0.0045521\ttotal: 3m 12s\tremaining: 1m 58s\n",
      "619:\tlearn: 0.0045488\ttotal: 3m 13s\tremaining: 1m 58s\n",
      "620:\tlearn: 0.0045415\ttotal: 3m 14s\tremaining: 1m 58s\n",
      "621:\tlearn: 0.0045360\ttotal: 3m 14s\tremaining: 1m 58s\n",
      "622:\tlearn: 0.0045315\ttotal: 3m 14s\tremaining: 1m 57s\n",
      "623:\tlearn: 0.0045276\ttotal: 3m 15s\tremaining: 1m 57s\n",
      "624:\tlearn: 0.0045240\ttotal: 3m 15s\tremaining: 1m 57s\n",
      "625:\tlearn: 0.0045211\ttotal: 3m 15s\tremaining: 1m 56s\n",
      "626:\tlearn: 0.0045162\ttotal: 3m 15s\tremaining: 1m 56s\n",
      "627:\tlearn: 0.0045085\ttotal: 3m 16s\tremaining: 1m 56s\n",
      "628:\tlearn: 0.0045024\ttotal: 3m 16s\tremaining: 1m 55s\n",
      "629:\tlearn: 0.0044924\ttotal: 3m 17s\tremaining: 1m 55s\n",
      "630:\tlearn: 0.0044881\ttotal: 3m 18s\tremaining: 1m 55s\n",
      "631:\tlearn: 0.0044714\ttotal: 3m 19s\tremaining: 1m 55s\n",
      "632:\tlearn: 0.0044693\ttotal: 3m 21s\tremaining: 1m 56s\n",
      "633:\tlearn: 0.0044543\ttotal: 3m 21s\tremaining: 1m 56s\n",
      "634:\tlearn: 0.0044488\ttotal: 3m 21s\tremaining: 1m 56s\n",
      "635:\tlearn: 0.0044463\ttotal: 3m 22s\tremaining: 1m 55s\n",
      "636:\tlearn: 0.0044365\ttotal: 3m 22s\tremaining: 1m 55s\n",
      "637:\tlearn: 0.0044332\ttotal: 3m 22s\tremaining: 1m 54s\n",
      "638:\tlearn: 0.0044283\ttotal: 3m 22s\tremaining: 1m 54s\n",
      "639:\tlearn: 0.0044252\ttotal: 3m 23s\tremaining: 1m 54s\n",
      "640:\tlearn: 0.0044223\ttotal: 3m 23s\tremaining: 1m 54s\n",
      "641:\tlearn: 0.0044147\ttotal: 3m 23s\tremaining: 1m 53s\n",
      "642:\tlearn: 0.0044085\ttotal: 3m 24s\tremaining: 1m 53s\n",
      "643:\tlearn: 0.0044009\ttotal: 3m 24s\tremaining: 1m 53s\n",
      "644:\tlearn: 0.0043920\ttotal: 3m 25s\tremaining: 1m 52s\n",
      "645:\tlearn: 0.0043908\ttotal: 3m 25s\tremaining: 1m 52s\n",
      "646:\tlearn: 0.0043881\ttotal: 3m 25s\tremaining: 1m 52s\n",
      "647:\tlearn: 0.0043854\ttotal: 3m 25s\tremaining: 1m 51s\n",
      "648:\tlearn: 0.0043782\ttotal: 3m 25s\tremaining: 1m 51s\n",
      "649:\tlearn: 0.0043769\ttotal: 3m 26s\tremaining: 1m 50s\n",
      "650:\tlearn: 0.0043695\ttotal: 3m 26s\tremaining: 1m 50s\n",
      "651:\tlearn: 0.0043653\ttotal: 3m 26s\tremaining: 1m 50s\n",
      "652:\tlearn: 0.0043630\ttotal: 3m 26s\tremaining: 1m 49s\n",
      "653:\tlearn: 0.0043609\ttotal: 3m 26s\tremaining: 1m 49s\n",
      "654:\tlearn: 0.0043574\ttotal: 3m 27s\tremaining: 1m 49s\n",
      "655:\tlearn: 0.0043524\ttotal: 3m 27s\tremaining: 1m 48s\n",
      "656:\tlearn: 0.0043497\ttotal: 3m 27s\tremaining: 1m 48s\n",
      "657:\tlearn: 0.0043478\ttotal: 3m 27s\tremaining: 1m 48s\n",
      "658:\tlearn: 0.0043448\ttotal: 3m 28s\tremaining: 1m 47s\n",
      "659:\tlearn: 0.0043404\ttotal: 3m 28s\tremaining: 1m 47s\n",
      "660:\tlearn: 0.0043275\ttotal: 3m 28s\tremaining: 1m 46s\n",
      "661:\tlearn: 0.0043220\ttotal: 3m 28s\tremaining: 1m 46s\n",
      "662:\tlearn: 0.0043167\ttotal: 3m 29s\tremaining: 1m 46s\n",
      "663:\tlearn: 0.0043141\ttotal: 3m 29s\tremaining: 1m 45s\n",
      "664:\tlearn: 0.0043101\ttotal: 3m 29s\tremaining: 1m 45s\n",
      "665:\tlearn: 0.0042987\ttotal: 3m 29s\tremaining: 1m 45s\n",
      "666:\tlearn: 0.0042898\ttotal: 3m 29s\tremaining: 1m 44s\n",
      "667:\tlearn: 0.0042874\ttotal: 3m 30s\tremaining: 1m 44s\n",
      "668:\tlearn: 0.0042861\ttotal: 3m 30s\tremaining: 1m 44s\n",
      "669:\tlearn: 0.0042795\ttotal: 3m 30s\tremaining: 1m 43s\n",
      "670:\tlearn: 0.0042788\ttotal: 3m 31s\tremaining: 1m 43s\n",
      "671:\tlearn: 0.0042747\ttotal: 3m 31s\tremaining: 1m 43s\n",
      "672:\tlearn: 0.0042647\ttotal: 3m 31s\tremaining: 1m 42s\n",
      "673:\tlearn: 0.0042602\ttotal: 3m 32s\tremaining: 1m 42s\n",
      "674:\tlearn: 0.0042516\ttotal: 3m 32s\tremaining: 1m 42s\n",
      "675:\tlearn: 0.0042480\ttotal: 3m 32s\tremaining: 1m 41s\n",
      "676:\tlearn: 0.0042454\ttotal: 3m 32s\tremaining: 1m 41s\n",
      "677:\tlearn: 0.0042412\ttotal: 3m 32s\tremaining: 1m 41s\n",
      "678:\tlearn: 0.0042403\ttotal: 3m 32s\tremaining: 1m 40s\n",
      "679:\tlearn: 0.0042366\ttotal: 3m 33s\tremaining: 1m 40s\n",
      "680:\tlearn: 0.0042351\ttotal: 3m 33s\tremaining: 1m 39s\n",
      "681:\tlearn: 0.0042297\ttotal: 3m 33s\tremaining: 1m 39s\n",
      "682:\tlearn: 0.0042264\ttotal: 3m 33s\tremaining: 1m 39s\n",
      "683:\tlearn: 0.0042216\ttotal: 3m 34s\tremaining: 1m 38s\n",
      "684:\tlearn: 0.0042163\ttotal: 3m 34s\tremaining: 1m 38s\n",
      "685:\tlearn: 0.0042141\ttotal: 3m 34s\tremaining: 1m 38s\n",
      "686:\tlearn: 0.0042113\ttotal: 3m 34s\tremaining: 1m 37s\n",
      "687:\tlearn: 0.0042088\ttotal: 3m 34s\tremaining: 1m 37s\n",
      "688:\tlearn: 0.0042045\ttotal: 3m 35s\tremaining: 1m 37s\n",
      "689:\tlearn: 0.0042026\ttotal: 3m 35s\tremaining: 1m 36s\n",
      "690:\tlearn: 0.0042008\ttotal: 3m 35s\tremaining: 1m 36s\n",
      "691:\tlearn: 0.0041928\ttotal: 3m 35s\tremaining: 1m 36s\n",
      "692:\tlearn: 0.0041842\ttotal: 3m 36s\tremaining: 1m 35s\n",
      "693:\tlearn: 0.0041833\ttotal: 3m 36s\tremaining: 1m 35s\n",
      "694:\tlearn: 0.0041808\ttotal: 3m 36s\tremaining: 1m 35s\n",
      "695:\tlearn: 0.0041751\ttotal: 3m 37s\tremaining: 1m 34s\n",
      "696:\tlearn: 0.0041699\ttotal: 3m 37s\tremaining: 1m 34s\n",
      "697:\tlearn: 0.0041649\ttotal: 3m 37s\tremaining: 1m 34s\n",
      "698:\tlearn: 0.0041608\ttotal: 3m 37s\tremaining: 1m 33s\n",
      "699:\tlearn: 0.0041579\ttotal: 3m 38s\tremaining: 1m 33s\n",
      "700:\tlearn: 0.0041553\ttotal: 3m 38s\tremaining: 1m 33s\n",
      "701:\tlearn: 0.0041540\ttotal: 3m 39s\tremaining: 1m 33s\n",
      "702:\tlearn: 0.0041496\ttotal: 3m 39s\tremaining: 1m 32s\n",
      "703:\tlearn: 0.0041473\ttotal: 3m 40s\tremaining: 1m 32s\n",
      "704:\tlearn: 0.0041430\ttotal: 3m 41s\tremaining: 1m 32s\n",
      "705:\tlearn: 0.0041344\ttotal: 3m 41s\tremaining: 1m 32s\n",
      "706:\tlearn: 0.0041227\ttotal: 3m 42s\tremaining: 1m 32s\n",
      "707:\tlearn: 0.0041180\ttotal: 3m 43s\tremaining: 1m 32s\n",
      "708:\tlearn: 0.0041105\ttotal: 3m 43s\tremaining: 1m 31s\n",
      "709:\tlearn: 0.0041046\ttotal: 3m 44s\tremaining: 1m 31s\n",
      "710:\tlearn: 0.0041035\ttotal: 3m 44s\tremaining: 1m 31s\n",
      "711:\tlearn: 0.0040970\ttotal: 3m 44s\tremaining: 1m 30s\n",
      "712:\tlearn: 0.0040929\ttotal: 3m 44s\tremaining: 1m 30s\n",
      "713:\tlearn: 0.0040886\ttotal: 3m 45s\tremaining: 1m 30s\n",
      "714:\tlearn: 0.0040853\ttotal: 3m 45s\tremaining: 1m 29s\n",
      "715:\tlearn: 0.0040820\ttotal: 3m 45s\tremaining: 1m 29s\n",
      "716:\tlearn: 0.0040764\ttotal: 3m 45s\tremaining: 1m 29s\n",
      "717:\tlearn: 0.0040728\ttotal: 3m 45s\tremaining: 1m 28s\n",
      "718:\tlearn: 0.0040639\ttotal: 3m 46s\tremaining: 1m 28s\n",
      "719:\tlearn: 0.0040596\ttotal: 3m 46s\tremaining: 1m 27s\n",
      "720:\tlearn: 0.0040573\ttotal: 3m 46s\tremaining: 1m 27s\n",
      "721:\tlearn: 0.0040472\ttotal: 3m 46s\tremaining: 1m 27s\n",
      "722:\tlearn: 0.0040438\ttotal: 3m 46s\tremaining: 1m 26s\n",
      "723:\tlearn: 0.0040417\ttotal: 3m 47s\tremaining: 1m 26s\n",
      "724:\tlearn: 0.0040350\ttotal: 3m 47s\tremaining: 1m 26s\n",
      "725:\tlearn: 0.0040292\ttotal: 3m 47s\tremaining: 1m 25s\n",
      "726:\tlearn: 0.0040265\ttotal: 3m 47s\tremaining: 1m 25s\n",
      "727:\tlearn: 0.0040221\ttotal: 3m 47s\tremaining: 1m 25s\n",
      "728:\tlearn: 0.0040189\ttotal: 3m 47s\tremaining: 1m 24s\n",
      "729:\tlearn: 0.0040169\ttotal: 3m 48s\tremaining: 1m 24s\n",
      "730:\tlearn: 0.0040155\ttotal: 3m 48s\tremaining: 1m 23s\n",
      "731:\tlearn: 0.0040106\ttotal: 3m 48s\tremaining: 1m 23s\n",
      "732:\tlearn: 0.0040033\ttotal: 3m 48s\tremaining: 1m 23s\n",
      "733:\tlearn: 0.0039966\ttotal: 3m 48s\tremaining: 1m 22s\n",
      "734:\tlearn: 0.0039908\ttotal: 3m 49s\tremaining: 1m 22s\n",
      "735:\tlearn: 0.0039877\ttotal: 3m 49s\tremaining: 1m 22s\n",
      "736:\tlearn: 0.0039781\ttotal: 3m 49s\tremaining: 1m 21s\n",
      "737:\tlearn: 0.0039755\ttotal: 3m 49s\tremaining: 1m 21s\n",
      "738:\tlearn: 0.0039738\ttotal: 3m 49s\tremaining: 1m 21s\n",
      "739:\tlearn: 0.0039706\ttotal: 3m 50s\tremaining: 1m 20s\n",
      "740:\tlearn: 0.0039644\ttotal: 3m 50s\tremaining: 1m 20s\n",
      "741:\tlearn: 0.0039588\ttotal: 3m 50s\tremaining: 1m 20s\n",
      "742:\tlearn: 0.0039572\ttotal: 3m 50s\tremaining: 1m 19s\n",
      "743:\tlearn: 0.0039536\ttotal: 3m 50s\tremaining: 1m 19s\n",
      "744:\tlearn: 0.0039499\ttotal: 3m 51s\tremaining: 1m 19s\n",
      "745:\tlearn: 0.0039493\ttotal: 3m 51s\tremaining: 1m 18s\n",
      "746:\tlearn: 0.0039473\ttotal: 3m 51s\tremaining: 1m 18s\n",
      "747:\tlearn: 0.0039464\ttotal: 3m 51s\tremaining: 1m 18s\n",
      "748:\tlearn: 0.0039411\ttotal: 3m 51s\tremaining: 1m 17s\n",
      "749:\tlearn: 0.0039324\ttotal: 3m 51s\tremaining: 1m 17s\n",
      "750:\tlearn: 0.0039293\ttotal: 3m 52s\tremaining: 1m 16s\n",
      "751:\tlearn: 0.0039253\ttotal: 3m 52s\tremaining: 1m 16s\n",
      "752:\tlearn: 0.0039211\ttotal: 3m 52s\tremaining: 1m 16s\n",
      "753:\tlearn: 0.0039187\ttotal: 3m 52s\tremaining: 1m 15s\n",
      "754:\tlearn: 0.0039137\ttotal: 3m 52s\tremaining: 1m 15s\n",
      "755:\tlearn: 0.0039124\ttotal: 3m 53s\tremaining: 1m 15s\n",
      "756:\tlearn: 0.0039079\ttotal: 3m 53s\tremaining: 1m 14s\n",
      "757:\tlearn: 0.0039043\ttotal: 3m 53s\tremaining: 1m 14s\n",
      "758:\tlearn: 0.0039036\ttotal: 3m 53s\tremaining: 1m 14s\n",
      "759:\tlearn: 0.0039005\ttotal: 3m 53s\tremaining: 1m 13s\n",
      "760:\tlearn: 0.0038995\ttotal: 3m 53s\tremaining: 1m 13s\n",
      "761:\tlearn: 0.0038961\ttotal: 3m 54s\tremaining: 1m 13s\n",
      "762:\tlearn: 0.0038940\ttotal: 3m 54s\tremaining: 1m 12s\n",
      "763:\tlearn: 0.0038825\ttotal: 3m 54s\tremaining: 1m 12s\n",
      "764:\tlearn: 0.0038806\ttotal: 3m 54s\tremaining: 1m 12s\n",
      "765:\tlearn: 0.0038749\ttotal: 3m 54s\tremaining: 1m 11s\n",
      "766:\tlearn: 0.0038693\ttotal: 3m 54s\tremaining: 1m 11s\n",
      "767:\tlearn: 0.0038646\ttotal: 3m 55s\tremaining: 1m 11s\n",
      "768:\tlearn: 0.0038606\ttotal: 3m 55s\tremaining: 1m 10s\n",
      "769:\tlearn: 0.0038525\ttotal: 3m 55s\tremaining: 1m 10s\n",
      "770:\tlearn: 0.0038487\ttotal: 3m 55s\tremaining: 1m 9s\n",
      "771:\tlearn: 0.0038429\ttotal: 3m 55s\tremaining: 1m 9s\n",
      "772:\tlearn: 0.0038400\ttotal: 3m 56s\tremaining: 1m 9s\n",
      "773:\tlearn: 0.0038339\ttotal: 3m 56s\tremaining: 1m 8s\n",
      "774:\tlearn: 0.0038299\ttotal: 3m 56s\tremaining: 1m 8s\n",
      "775:\tlearn: 0.0038233\ttotal: 3m 56s\tremaining: 1m 8s\n",
      "776:\tlearn: 0.0038193\ttotal: 3m 56s\tremaining: 1m 8s\n",
      "777:\tlearn: 0.0038144\ttotal: 3m 57s\tremaining: 1m 7s\n",
      "778:\tlearn: 0.0038127\ttotal: 3m 57s\tremaining: 1m 7s\n",
      "779:\tlearn: 0.0038015\ttotal: 3m 57s\tremaining: 1m 6s\n",
      "780:\tlearn: 0.0037993\ttotal: 3m 57s\tremaining: 1m 6s\n",
      "781:\tlearn: 0.0037927\ttotal: 3m 57s\tremaining: 1m 6s\n",
      "782:\tlearn: 0.0037902\ttotal: 3m 58s\tremaining: 1m 5s\n",
      "783:\tlearn: 0.0037875\ttotal: 3m 58s\tremaining: 1m 5s\n",
      "784:\tlearn: 0.0037832\ttotal: 3m 58s\tremaining: 1m 5s\n",
      "785:\tlearn: 0.0037816\ttotal: 3m 58s\tremaining: 1m 4s\n",
      "786:\tlearn: 0.0037751\ttotal: 3m 58s\tremaining: 1m 4s\n",
      "787:\tlearn: 0.0037732\ttotal: 3m 58s\tremaining: 1m 4s\n",
      "788:\tlearn: 0.0037691\ttotal: 3m 58s\tremaining: 1m 3s\n",
      "789:\tlearn: 0.0037653\ttotal: 3m 59s\tremaining: 1m 3s\n",
      "790:\tlearn: 0.0037640\ttotal: 3m 59s\tremaining: 1m 3s\n",
      "791:\tlearn: 0.0037550\ttotal: 3m 59s\tremaining: 1m 2s\n",
      "792:\tlearn: 0.0037513\ttotal: 3m 59s\tremaining: 1m 2s\n",
      "793:\tlearn: 0.0037453\ttotal: 3m 59s\tremaining: 1m 2s\n",
      "794:\tlearn: 0.0037420\ttotal: 3m 59s\tremaining: 1m 1s\n",
      "795:\tlearn: 0.0037377\ttotal: 3m 59s\tremaining: 1m 1s\n",
      "796:\tlearn: 0.0037361\ttotal: 3m 59s\tremaining: 1m 1s\n",
      "797:\tlearn: 0.0037233\ttotal: 4m\tremaining: 1m\n",
      "798:\tlearn: 0.0037229\ttotal: 4m\tremaining: 1m\n",
      "799:\tlearn: 0.0037173\ttotal: 4m\tremaining: 1m\n",
      "800:\tlearn: 0.0037099\ttotal: 4m\tremaining: 59.8s\n",
      "801:\tlearn: 0.0037079\ttotal: 4m\tremaining: 59.4s\n",
      "802:\tlearn: 0.0037044\ttotal: 4m\tremaining: 59.1s\n",
      "803:\tlearn: 0.0036968\ttotal: 4m\tremaining: 58.7s\n",
      "804:\tlearn: 0.0036934\ttotal: 4m 1s\tremaining: 58.4s\n",
      "805:\tlearn: 0.0036902\ttotal: 4m 1s\tremaining: 58.1s\n",
      "806:\tlearn: 0.0036898\ttotal: 4m 1s\tremaining: 57.7s\n",
      "807:\tlearn: 0.0036846\ttotal: 4m 1s\tremaining: 57.4s\n",
      "808:\tlearn: 0.0036772\ttotal: 4m 1s\tremaining: 57s\n",
      "809:\tlearn: 0.0036738\ttotal: 4m 1s\tremaining: 56.7s\n",
      "810:\tlearn: 0.0036704\ttotal: 4m 1s\tremaining: 56.4s\n",
      "811:\tlearn: 0.0036664\ttotal: 4m 2s\tremaining: 56s\n",
      "812:\tlearn: 0.0036632\ttotal: 4m 2s\tremaining: 55.7s\n",
      "813:\tlearn: 0.0036600\ttotal: 4m 2s\tremaining: 55.4s\n",
      "814:\tlearn: 0.0036586\ttotal: 4m 2s\tremaining: 55s\n",
      "815:\tlearn: 0.0036556\ttotal: 4m 2s\tremaining: 54.7s\n",
      "816:\tlearn: 0.0036524\ttotal: 4m 2s\tremaining: 54.4s\n",
      "817:\tlearn: 0.0036504\ttotal: 4m 2s\tremaining: 54s\n",
      "818:\tlearn: 0.0036478\ttotal: 4m 3s\tremaining: 53.7s\n",
      "819:\tlearn: 0.0036328\ttotal: 4m 3s\tremaining: 53.4s\n",
      "820:\tlearn: 0.0036313\ttotal: 4m 3s\tremaining: 53.1s\n",
      "821:\tlearn: 0.0036297\ttotal: 4m 3s\tremaining: 52.8s\n",
      "822:\tlearn: 0.0036283\ttotal: 4m 3s\tremaining: 52.5s\n",
      "823:\tlearn: 0.0036227\ttotal: 4m 4s\tremaining: 52.1s\n",
      "824:\tlearn: 0.0036209\ttotal: 4m 4s\tremaining: 51.8s\n",
      "825:\tlearn: 0.0036191\ttotal: 4m 4s\tremaining: 51.5s\n",
      "826:\tlearn: 0.0036162\ttotal: 4m 4s\tremaining: 51.1s\n",
      "827:\tlearn: 0.0036117\ttotal: 4m 4s\tremaining: 50.8s\n",
      "828:\tlearn: 0.0036084\ttotal: 4m 4s\tremaining: 50.5s\n",
      "829:\tlearn: 0.0036059\ttotal: 4m 4s\tremaining: 50.1s\n",
      "830:\tlearn: 0.0036039\ttotal: 4m 4s\tremaining: 49.8s\n",
      "831:\tlearn: 0.0036008\ttotal: 4m 5s\tremaining: 49.5s\n",
      "832:\tlearn: 0.0035948\ttotal: 4m 5s\tremaining: 49.2s\n",
      "833:\tlearn: 0.0035884\ttotal: 4m 5s\tremaining: 48.8s\n",
      "834:\tlearn: 0.0035839\ttotal: 4m 5s\tremaining: 48.5s\n",
      "835:\tlearn: 0.0035818\ttotal: 4m 5s\tremaining: 48.2s\n",
      "836:\tlearn: 0.0035809\ttotal: 4m 5s\tremaining: 47.9s\n",
      "837:\tlearn: 0.0035786\ttotal: 4m 5s\tremaining: 47.5s\n",
      "838:\tlearn: 0.0035767\ttotal: 4m 6s\tremaining: 47.2s\n",
      "839:\tlearn: 0.0035665\ttotal: 4m 6s\tremaining: 46.9s\n",
      "840:\tlearn: 0.0035655\ttotal: 4m 6s\tremaining: 46.6s\n",
      "841:\tlearn: 0.0035600\ttotal: 4m 6s\tremaining: 46.3s\n",
      "842:\tlearn: 0.0035518\ttotal: 4m 6s\tremaining: 46s\n",
      "843:\tlearn: 0.0035491\ttotal: 4m 7s\tremaining: 45.7s\n",
      "844:\tlearn: 0.0035463\ttotal: 4m 7s\tremaining: 45.3s\n",
      "845:\tlearn: 0.0035414\ttotal: 4m 7s\tremaining: 45s\n",
      "846:\tlearn: 0.0035309\ttotal: 4m 7s\tremaining: 44.7s\n",
      "847:\tlearn: 0.0035296\ttotal: 4m 7s\tremaining: 44.5s\n",
      "848:\tlearn: 0.0035274\ttotal: 4m 8s\tremaining: 44.1s\n",
      "849:\tlearn: 0.0035234\ttotal: 4m 8s\tremaining: 43.8s\n",
      "850:\tlearn: 0.0035209\ttotal: 4m 8s\tremaining: 43.5s\n",
      "851:\tlearn: 0.0035121\ttotal: 4m 8s\tremaining: 43.2s\n",
      "852:\tlearn: 0.0035105\ttotal: 4m 8s\tremaining: 42.9s\n",
      "853:\tlearn: 0.0035042\ttotal: 4m 8s\tremaining: 42.6s\n",
      "854:\tlearn: 0.0035013\ttotal: 4m 9s\tremaining: 42.3s\n",
      "855:\tlearn: 0.0035005\ttotal: 4m 9s\tremaining: 41.9s\n",
      "856:\tlearn: 0.0034984\ttotal: 4m 9s\tremaining: 41.6s\n",
      "857:\tlearn: 0.0034967\ttotal: 4m 9s\tremaining: 41.3s\n",
      "858:\tlearn: 0.0034962\ttotal: 4m 9s\tremaining: 41s\n",
      "859:\tlearn: 0.0034882\ttotal: 4m 10s\tremaining: 40.7s\n",
      "860:\tlearn: 0.0034835\ttotal: 4m 10s\tremaining: 40.4s\n",
      "861:\tlearn: 0.0034817\ttotal: 4m 10s\tremaining: 40.1s\n",
      "862:\tlearn: 0.0034794\ttotal: 4m 10s\tremaining: 39.8s\n",
      "863:\tlearn: 0.0034757\ttotal: 4m 10s\tremaining: 39.5s\n",
      "864:\tlearn: 0.0034743\ttotal: 4m 10s\tremaining: 39.2s\n",
      "865:\tlearn: 0.0034732\ttotal: 4m 11s\tremaining: 38.9s\n",
      "866:\tlearn: 0.0034708\ttotal: 4m 11s\tremaining: 38.5s\n",
      "867:\tlearn: 0.0034694\ttotal: 4m 11s\tremaining: 38.2s\n",
      "868:\tlearn: 0.0034667\ttotal: 4m 11s\tremaining: 37.9s\n",
      "869:\tlearn: 0.0034655\ttotal: 4m 11s\tremaining: 37.6s\n",
      "870:\tlearn: 0.0034592\ttotal: 4m 11s\tremaining: 37.3s\n",
      "871:\tlearn: 0.0034545\ttotal: 4m 12s\tremaining: 37s\n",
      "872:\tlearn: 0.0034525\ttotal: 4m 12s\tremaining: 36.7s\n",
      "873:\tlearn: 0.0034475\ttotal: 4m 12s\tremaining: 36.4s\n",
      "874:\tlearn: 0.0034440\ttotal: 4m 12s\tremaining: 36.1s\n",
      "875:\tlearn: 0.0034388\ttotal: 4m 12s\tremaining: 35.8s\n",
      "876:\tlearn: 0.0034362\ttotal: 4m 13s\tremaining: 35.5s\n",
      "877:\tlearn: 0.0034347\ttotal: 4m 13s\tremaining: 35.2s\n",
      "878:\tlearn: 0.0034308\ttotal: 4m 13s\tremaining: 34.9s\n",
      "879:\tlearn: 0.0034243\ttotal: 4m 13s\tremaining: 34.6s\n",
      "880:\tlearn: 0.0034228\ttotal: 4m 13s\tremaining: 34.3s\n",
      "881:\tlearn: 0.0034180\ttotal: 4m 13s\tremaining: 34s\n",
      "882:\tlearn: 0.0034142\ttotal: 4m 13s\tremaining: 33.7s\n",
      "883:\tlearn: 0.0034045\ttotal: 4m 14s\tremaining: 33.4s\n",
      "884:\tlearn: 0.0034028\ttotal: 4m 14s\tremaining: 33s\n",
      "885:\tlearn: 0.0034012\ttotal: 4m 14s\tremaining: 32.8s\n",
      "886:\tlearn: 0.0033976\ttotal: 4m 14s\tremaining: 32.5s\n",
      "887:\tlearn: 0.0033937\ttotal: 4m 14s\tremaining: 32.1s\n",
      "888:\tlearn: 0.0033902\ttotal: 4m 15s\tremaining: 31.8s\n",
      "889:\tlearn: 0.0033809\ttotal: 4m 15s\tremaining: 31.5s\n",
      "890:\tlearn: 0.0033779\ttotal: 4m 15s\tremaining: 31.2s\n",
      "891:\tlearn: 0.0033764\ttotal: 4m 15s\tremaining: 30.9s\n",
      "892:\tlearn: 0.0033709\ttotal: 4m 15s\tremaining: 30.6s\n",
      "893:\tlearn: 0.0033669\ttotal: 4m 15s\tremaining: 30.3s\n",
      "894:\tlearn: 0.0033608\ttotal: 4m 16s\tremaining: 30s\n",
      "895:\tlearn: 0.0033568\ttotal: 4m 16s\tremaining: 29.7s\n",
      "896:\tlearn: 0.0033523\ttotal: 4m 16s\tremaining: 29.4s\n",
      "897:\tlearn: 0.0033466\ttotal: 4m 16s\tremaining: 29.2s\n",
      "898:\tlearn: 0.0033428\ttotal: 4m 16s\tremaining: 28.9s\n",
      "899:\tlearn: 0.0033384\ttotal: 4m 16s\tremaining: 28.6s\n",
      "900:\tlearn: 0.0033324\ttotal: 4m 17s\tremaining: 28.3s\n",
      "901:\tlearn: 0.0033303\ttotal: 4m 17s\tremaining: 28s\n",
      "902:\tlearn: 0.0033281\ttotal: 4m 17s\tremaining: 27.7s\n",
      "903:\tlearn: 0.0033257\ttotal: 4m 17s\tremaining: 27.4s\n",
      "904:\tlearn: 0.0033210\ttotal: 4m 17s\tremaining: 27.1s\n",
      "905:\tlearn: 0.0033203\ttotal: 4m 17s\tremaining: 26.8s\n",
      "906:\tlearn: 0.0033183\ttotal: 4m 18s\tremaining: 26.5s\n",
      "907:\tlearn: 0.0033111\ttotal: 4m 18s\tremaining: 26.2s\n",
      "908:\tlearn: 0.0033039\ttotal: 4m 18s\tremaining: 25.9s\n",
      "909:\tlearn: 0.0032999\ttotal: 4m 18s\tremaining: 25.6s\n",
      "910:\tlearn: 0.0032984\ttotal: 4m 18s\tremaining: 25.3s\n",
      "911:\tlearn: 0.0032958\ttotal: 4m 18s\tremaining: 25s\n",
      "912:\tlearn: 0.0032933\ttotal: 4m 19s\tremaining: 24.7s\n",
      "913:\tlearn: 0.0032927\ttotal: 4m 19s\tremaining: 24.4s\n",
      "914:\tlearn: 0.0032905\ttotal: 4m 19s\tremaining: 24.1s\n",
      "915:\tlearn: 0.0032881\ttotal: 4m 19s\tremaining: 23.8s\n",
      "916:\tlearn: 0.0032802\ttotal: 4m 20s\tremaining: 23.5s\n",
      "917:\tlearn: 0.0032776\ttotal: 4m 20s\tremaining: 23.2s\n",
      "918:\tlearn: 0.0032749\ttotal: 4m 20s\tremaining: 22.9s\n",
      "919:\tlearn: 0.0032726\ttotal: 4m 20s\tremaining: 22.7s\n",
      "920:\tlearn: 0.0032666\ttotal: 4m 20s\tremaining: 22.4s\n",
      "921:\tlearn: 0.0032650\ttotal: 4m 20s\tremaining: 22.1s\n",
      "922:\tlearn: 0.0032625\ttotal: 4m 21s\tremaining: 21.8s\n",
      "923:\tlearn: 0.0032607\ttotal: 4m 21s\tremaining: 21.5s\n",
      "924:\tlearn: 0.0032561\ttotal: 4m 21s\tremaining: 21.2s\n",
      "925:\tlearn: 0.0032539\ttotal: 4m 21s\tremaining: 20.9s\n",
      "926:\tlearn: 0.0032503\ttotal: 4m 21s\tremaining: 20.6s\n",
      "927:\tlearn: 0.0032472\ttotal: 4m 22s\tremaining: 20.3s\n",
      "928:\tlearn: 0.0032428\ttotal: 4m 22s\tremaining: 20s\n",
      "929:\tlearn: 0.0032403\ttotal: 4m 22s\tremaining: 19.8s\n",
      "930:\tlearn: 0.0032365\ttotal: 4m 22s\tremaining: 19.5s\n",
      "931:\tlearn: 0.0032346\ttotal: 4m 22s\tremaining: 19.2s\n",
      "932:\tlearn: 0.0032316\ttotal: 4m 23s\tremaining: 18.9s\n",
      "933:\tlearn: 0.0032304\ttotal: 4m 23s\tremaining: 18.6s\n",
      "934:\tlearn: 0.0032289\ttotal: 4m 23s\tremaining: 18.3s\n",
      "935:\tlearn: 0.0032258\ttotal: 4m 23s\tremaining: 18s\n",
      "936:\tlearn: 0.0032216\ttotal: 4m 23s\tremaining: 17.7s\n",
      "937:\tlearn: 0.0032207\ttotal: 4m 23s\tremaining: 17.4s\n",
      "938:\tlearn: 0.0032111\ttotal: 4m 23s\tremaining: 17.1s\n",
      "939:\tlearn: 0.0032095\ttotal: 4m 24s\tremaining: 16.9s\n",
      "940:\tlearn: 0.0032063\ttotal: 4m 24s\tremaining: 16.6s\n",
      "941:\tlearn: 0.0032044\ttotal: 4m 24s\tremaining: 16.3s\n",
      "942:\tlearn: 0.0031981\ttotal: 4m 24s\tremaining: 16s\n",
      "943:\tlearn: 0.0031954\ttotal: 4m 24s\tremaining: 15.7s\n",
      "944:\tlearn: 0.0031904\ttotal: 4m 24s\tremaining: 15.4s\n",
      "945:\tlearn: 0.0031893\ttotal: 4m 25s\tremaining: 15.1s\n",
      "946:\tlearn: 0.0031882\ttotal: 4m 25s\tremaining: 14.8s\n",
      "947:\tlearn: 0.0031875\ttotal: 4m 25s\tremaining: 14.6s\n",
      "948:\tlearn: 0.0031858\ttotal: 4m 25s\tremaining: 14.3s\n",
      "949:\tlearn: 0.0031829\ttotal: 4m 25s\tremaining: 14s\n",
      "950:\tlearn: 0.0031802\ttotal: 4m 26s\tremaining: 13.7s\n",
      "951:\tlearn: 0.0031753\ttotal: 4m 26s\tremaining: 13.4s\n",
      "952:\tlearn: 0.0031715\ttotal: 4m 26s\tremaining: 13.1s\n",
      "953:\tlearn: 0.0031616\ttotal: 4m 26s\tremaining: 12.9s\n",
      "954:\tlearn: 0.0031582\ttotal: 4m 26s\tremaining: 12.6s\n",
      "955:\tlearn: 0.0031567\ttotal: 4m 26s\tremaining: 12.3s\n",
      "956:\tlearn: 0.0031551\ttotal: 4m 26s\tremaining: 12s\n",
      "957:\tlearn: 0.0031500\ttotal: 4m 27s\tremaining: 11.7s\n",
      "958:\tlearn: 0.0031430\ttotal: 4m 27s\tremaining: 11.4s\n",
      "959:\tlearn: 0.0031405\ttotal: 4m 27s\tremaining: 11.1s\n",
      "960:\tlearn: 0.0031388\ttotal: 4m 27s\tremaining: 10.9s\n",
      "961:\tlearn: 0.0031379\ttotal: 4m 27s\tremaining: 10.6s\n",
      "962:\tlearn: 0.0031351\ttotal: 4m 27s\tremaining: 10.3s\n",
      "963:\tlearn: 0.0031293\ttotal: 4m 27s\tremaining: 10s\n",
      "964:\tlearn: 0.0031204\ttotal: 4m 28s\tremaining: 9.72s\n",
      "965:\tlearn: 0.0031172\ttotal: 4m 28s\tremaining: 9.44s\n",
      "966:\tlearn: 0.0031158\ttotal: 4m 28s\tremaining: 9.15s\n",
      "967:\tlearn: 0.0031131\ttotal: 4m 28s\tremaining: 8.87s\n",
      "968:\tlearn: 0.0031111\ttotal: 4m 28s\tremaining: 8.59s\n",
      "969:\tlearn: 0.0031074\ttotal: 4m 28s\tremaining: 8.31s\n",
      "970:\tlearn: 0.0031057\ttotal: 4m 28s\tremaining: 8.03s\n",
      "971:\tlearn: 0.0031025\ttotal: 4m 29s\tremaining: 7.75s\n",
      "972:\tlearn: 0.0030984\ttotal: 4m 29s\tremaining: 7.47s\n",
      "973:\tlearn: 0.0030935\ttotal: 4m 29s\tremaining: 7.19s\n",
      "974:\tlearn: 0.0030910\ttotal: 4m 29s\tremaining: 6.91s\n",
      "975:\tlearn: 0.0030863\ttotal: 4m 29s\tremaining: 6.63s\n",
      "976:\tlearn: 0.0030848\ttotal: 4m 29s\tremaining: 6.35s\n",
      "977:\tlearn: 0.0030764\ttotal: 4m 29s\tremaining: 6.07s\n",
      "978:\tlearn: 0.0030732\ttotal: 4m 29s\tremaining: 5.79s\n",
      "979:\tlearn: 0.0030727\ttotal: 4m 30s\tremaining: 5.51s\n",
      "980:\tlearn: 0.0030699\ttotal: 4m 30s\tremaining: 5.23s\n",
      "981:\tlearn: 0.0030654\ttotal: 4m 30s\tremaining: 4.96s\n",
      "982:\tlearn: 0.0030619\ttotal: 4m 30s\tremaining: 4.68s\n",
      "983:\tlearn: 0.0030459\ttotal: 4m 31s\tremaining: 4.41s\n",
      "984:\tlearn: 0.0030453\ttotal: 4m 31s\tremaining: 4.13s\n",
      "985:\tlearn: 0.0030371\ttotal: 4m 31s\tremaining: 3.85s\n",
      "986:\tlearn: 0.0030341\ttotal: 4m 31s\tremaining: 3.58s\n",
      "987:\tlearn: 0.0030318\ttotal: 4m 31s\tremaining: 3.3s\n",
      "988:\tlearn: 0.0030237\ttotal: 4m 31s\tremaining: 3.02s\n",
      "989:\tlearn: 0.0030225\ttotal: 4m 32s\tremaining: 2.75s\n",
      "990:\tlearn: 0.0030153\ttotal: 4m 32s\tremaining: 2.47s\n",
      "991:\tlearn: 0.0030120\ttotal: 4m 32s\tremaining: 2.2s\n",
      "992:\tlearn: 0.0030086\ttotal: 4m 32s\tremaining: 1.92s\n",
      "993:\tlearn: 0.0030042\ttotal: 4m 32s\tremaining: 1.65s\n",
      "994:\tlearn: 0.0029996\ttotal: 4m 33s\tremaining: 1.37s\n",
      "995:\tlearn: 0.0029962\ttotal: 4m 33s\tremaining: 1.1s\n",
      "996:\tlearn: 0.0029945\ttotal: 4m 33s\tremaining: 823ms\n",
      "997:\tlearn: 0.0029865\ttotal: 4m 33s\tremaining: 548ms\n",
      "998:\tlearn: 0.0029780\ttotal: 4m 33s\tremaining: 274ms\n",
      "999:\tlearn: 0.0029754\ttotal: 4m 33s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x256ea5f8980>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.72418531e-03 1.97577509e-03 4.06482059e-05 ... 2.37687743e-04\n",
      " 1.63888926e-04 2.47633521e-04]\n"
     ]
    }
   ],
   "source": [
    "test_prediction = model.predict_proba(test_data_processed)\n",
    "\n",
    "test_prediction=test_prediction[:, 1]\n",
    "\n",
    "print(test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write into csv\n",
    "now we write the predictions into the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300001</td>\n",
       "      <td>0.002724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300002</td>\n",
       "      <td>0.001976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300003</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300004</td>\n",
       "      <td>0.000904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300005</td>\n",
       "      <td>0.000208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105477</th>\n",
       "      <td>405478</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105478</th>\n",
       "      <td>405479</td>\n",
       "      <td>0.090761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105479</th>\n",
       "      <td>405480</td>\n",
       "      <td>0.000238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105480</th>\n",
       "      <td>405481</td>\n",
       "      <td>0.000164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105481</th>\n",
       "      <td>405482</td>\n",
       "      <td>0.000248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105482 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RecordId         Y\n",
       "0         300001  0.002724\n",
       "1         300002  0.001976\n",
       "2         300003  0.000041\n",
       "3         300004  0.000904\n",
       "4         300005  0.000208\n",
       "...          ...       ...\n",
       "105477    405478  0.000030\n",
       "105478    405479  0.090761\n",
       "105479    405480  0.000238\n",
       "105480    405481  0.000164\n",
       "105481    405482  0.000248\n",
       "\n",
       "[105482 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = pd.read_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger1\\iml-fall-2024-challenge-1\\sample_submission.csv\")\n",
    "\n",
    "sample_data['Y'] = test_prediction\n",
    "sample_data\n",
    "\n",
    "sample_data.to_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger1\\iml-fall-2024-challenge-1\\cat1.csv\", index=False)\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x256ea5f8980>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
