{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries\n",
    "in this part we will install all the necessary libraries on command prompt and then import the necessary functions from those libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import mean\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# step 1: preprocessing\n",
    "from sklearn.impute import SimpleImputer # import some strategic imputer to fill in any missing values using mean\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler, Normalizer # scale all the values to one range to avoid any biasness (this bias is seen in mostly naive bayes and knn etc)\n",
    "\n",
    "from sklearn.impute import KNNImputer # import some strategic imputer to fill missing values using KNN (finds the nearest neighbour and fills it with that value)\n",
    "\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, SelectKBest, f_classif, VarianceThreshold\n",
    "\n",
    "# step 2: data division\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, cross_val_score, GridSearchCV, ParameterGrid # to divide the code into train/test using a specific percentage or with/without replacement\n",
    "\n",
    "# step 3: model\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# step 4: displaying accuracy\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score # to display the accuracy of our tree\n",
    "\n",
    "# step 5: warning filter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this block to install any libraries not on the system\n",
    "# !pip install pandas\n",
    "# !pip install sklearn\n",
    "# python -m pip install scikit-learn lightgbm xgboost catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "data shall be loaded into variables as data sets using pandas and csv readers. they will be checked to see if they are loaded properly and will be loaded as 2 sets: train and test as per given in the kaggle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.118411</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>829</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>82.372284</td>\n",
       "      <td>31.573280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162.983897</td>\n",
       "      <td>1</td>\n",
       "      <td>724</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>27.771653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>895</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>66.236109</td>\n",
       "      <td>26.515922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.009549</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>81.303299</td>\n",
       "      <td>20.843691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158.165419</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  ...  \\\n",
       "0         1  87.000000  34.118411   0   2   0  165.100000   1  829    2  ...   \n",
       "1         2  82.372284  31.573280   0   0   1  162.983897   1  724    0  ...   \n",
       "2         3  50.000000  27.771653   0   0   1  165.100000   1  895    2  ...   \n",
       "3         4  66.236109  26.515922   0   0   1  167.009549   1  637    0  ...   \n",
       "4         5  81.303299  20.843691   0   0   1  158.165419   0  564    0  ...   \n",
       "\n",
       "        X70  X71  X72  X73  X74  X75  X76  X77  X78  Y  \n",
       "0  0.040000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "1  0.033431  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "2  0.010000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "3  0.039363  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "4  0.069242  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets load the training data set\n",
    "train_data = pd.read_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger1\\iml-fall-2024-challenge-1\\train_set.csv\")\n",
    "\n",
    "# lets also check it by getting the first few rows of the data, there should be x1 - x78 and one target variable Y\n",
    "train_data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X69</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300001</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>17.122318</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>170.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300002</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>43.693579</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>814</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300003</td>\n",
       "      <td>36.064225</td>\n",
       "      <td>23.998944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.086735</td>\n",
       "      <td>1</td>\n",
       "      <td>662</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300004</td>\n",
       "      <td>61.846764</td>\n",
       "      <td>31.693449</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>182.355708</td>\n",
       "      <td>2</td>\n",
       "      <td>862</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062613</td>\n",
       "      <td>0.033153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300005</td>\n",
       "      <td>71.591991</td>\n",
       "      <td>20.086147</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>166.704917</td>\n",
       "      <td>2</td>\n",
       "      <td>335</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014854</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  ...  \\\n",
       "0    300001  79.000000  17.122318   0   0   1  170.200000   1  700    0  ...   \n",
       "1    300002  38.000000  43.693579   0   0   1  165.100000   1  814    0  ...   \n",
       "2    300003  36.064225  23.998944   0   0   1  167.086735   1  662    0  ...   \n",
       "3    300004  61.846764  31.693449   0   3   1  182.355708   2  862    0  ...   \n",
       "4    300005  71.591991  20.086147   1   0   1  166.704917   2  335    0  ...   \n",
       "\n",
       "        X69       X70  X71  X72  X73  X74  X75  X76  X77  X78  \n",
       "0  0.070000  0.030000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.050000  0.040000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.006948  0.006948  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.062613  0.033153  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.014854  0.004854  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets load the test data\n",
    "test_data = pd.read_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger1\\iml-fall-2024-challenge-1\\test_set.csv\")\n",
    "\n",
    "# check if the data has been loaded by getting the first 5 rows - there should be x1 - x78 and no target variable Y as this is test data\n",
    "test_data.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "before we start processing this data and using algorithms, we will fix this data first, this is called data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion of Categorical to Numerical\n",
    "First we will convert categorical data to numerical data by doing one hot encoding, which turns it into binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.118411</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>829</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>82.372284</td>\n",
       "      <td>31.573280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162.983897</td>\n",
       "      <td>1</td>\n",
       "      <td>724</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>27.771653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>895</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>66.236109</td>\n",
       "      <td>26.515922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.009549</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>81.303299</td>\n",
       "      <td>20.843691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158.165419</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246117</th>\n",
       "      <td>246118</td>\n",
       "      <td>65.149110</td>\n",
       "      <td>33.357948</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156.317941</td>\n",
       "      <td>1</td>\n",
       "      <td>711</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246118</th>\n",
       "      <td>246119</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>46.736176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246119</th>\n",
       "      <td>246120</td>\n",
       "      <td>57.472080</td>\n",
       "      <td>41.854115</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189.868698</td>\n",
       "      <td>2</td>\n",
       "      <td>455</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246120</th>\n",
       "      <td>246121</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>23.738662</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246121</th>\n",
       "      <td>246122</td>\n",
       "      <td>50.257640</td>\n",
       "      <td>32.753911</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>173.665068</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246122 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  \\\n",
       "0              1  87.000000  34.118411   0   2   0  165.100000   1  829    2   \n",
       "1              2  82.372284  31.573280   0   0   1  162.983897   1  724    0   \n",
       "2              3  50.000000  27.771653   0   0   1  165.100000   1  895    2   \n",
       "3              4  66.236109  26.515922   0   0   1  167.009549   1  637    0   \n",
       "4              5  81.303299  20.843691   0   0   1  158.165419   0  564    0   \n",
       "...          ...        ...        ...  ..  ..  ..         ...  ..  ...  ...   \n",
       "246117    246118  65.149110  33.357948   0   0   1  156.317941   1  711    0   \n",
       "246118    246119  48.000000  46.736176   0   0   1  157.000000   1  594    2   \n",
       "246119    246120  57.472080  41.854115   1   0   0  189.868698   2  455    0   \n",
       "246120    246121  66.000000  23.738662   1   0   1  168.000000   2  609    0   \n",
       "246121    246122  50.257640  32.753911   0   2   0  173.665068   1  637    0   \n",
       "\n",
       "        ...       X70  X71  X72       X73  X74       X75  X76  X77       X78  \\\n",
       "0       ...  0.040000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "1       ...  0.033431  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "2       ...  0.010000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "3       ...  0.039363  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "4       ...  0.069242  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "...     ...       ...  ...  ...       ...  ...       ...  ...  ...       ...   \n",
       "246117  ...  0.027152  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "246118  ...  0.560000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "246119  ...  0.020601  0.0  0.0  0.587987  0.0  0.412013  0.0  0.0  0.412013   \n",
       "246120  ... -1.000000  0.0  0.0  1.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "246121  ...  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "\n",
       "        Y  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "...    ..  \n",
       "246117  0  \n",
       "246118  1  \n",
       "246119  0  \n",
       "246120  0  \n",
       "246121  0  \n",
       "\n",
       "[246122 rows x 79 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding - display it\n",
    "pd.get_dummies(train_data) # this line will convert the train_data to one hot encoding but it will only display the result and not save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that there is no change in the number of columns meaning there is no categorical data. but for the sake of running the program. we must perform the preprocessing therefore we shall re-run the one hot encoding and save it somewhere\n",
    "train_data_processed = pd.get_dummies(train_data)\n",
    "\n",
    "# now we shall do the same on the test data so that we maintain the rules over all data\n",
    "test_data_processed = pd.get_dummies(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting - festures and targets\n",
    "the data in train_data set is of x1 - x78 columns (79 variables) and one target variable (Y). we must split that data so that we can perform data preprocessing on the features variables (will be referred to as X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X69</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.118411</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>829</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>82.372284</td>\n",
       "      <td>31.573280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162.983897</td>\n",
       "      <td>1</td>\n",
       "      <td>724</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100292</td>\n",
       "      <td>0.033431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>27.771653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>895</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>66.236109</td>\n",
       "      <td>26.515922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.009549</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108249</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>81.303299</td>\n",
       "      <td>20.843691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158.165419</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164645</td>\n",
       "      <td>0.069242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246117</th>\n",
       "      <td>246118</td>\n",
       "      <td>65.149110</td>\n",
       "      <td>33.357948</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156.317941</td>\n",
       "      <td>1</td>\n",
       "      <td>711</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088610</td>\n",
       "      <td>0.027152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246118</th>\n",
       "      <td>246119</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>46.736176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246119</th>\n",
       "      <td>246120</td>\n",
       "      <td>57.472080</td>\n",
       "      <td>41.854115</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189.868698</td>\n",
       "      <td>2</td>\n",
       "      <td>455</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032961</td>\n",
       "      <td>0.020601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246120</th>\n",
       "      <td>246121</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>23.738662</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246121</th>\n",
       "      <td>246122</td>\n",
       "      <td>50.257640</td>\n",
       "      <td>32.753911</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>173.665068</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246122 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  \\\n",
       "0              1  87.000000  34.118411   0   2   0  165.100000   1  829    2   \n",
       "1              2  82.372284  31.573280   0   0   1  162.983897   1  724    0   \n",
       "2              3  50.000000  27.771653   0   0   1  165.100000   1  895    2   \n",
       "3              4  66.236109  26.515922   0   0   1  167.009549   1  637    0   \n",
       "4              5  81.303299  20.843691   0   0   1  158.165419   0  564    0   \n",
       "...          ...        ...        ...  ..  ..  ..         ...  ..  ...  ...   \n",
       "246117    246118  65.149110  33.357948   0   0   1  156.317941   1  711    0   \n",
       "246118    246119  48.000000  46.736176   0   0   1  157.000000   1  594    2   \n",
       "246119    246120  57.472080  41.854115   1   0   0  189.868698   2  455    0   \n",
       "246120    246121  66.000000  23.738662   1   0   1  168.000000   2  609    0   \n",
       "246121    246122  50.257640  32.753911   0   2   0  173.665068   1  637    0   \n",
       "\n",
       "        ...       X69       X70  X71  X72       X73  X74       X75  X76  X77  \\\n",
       "0       ...  0.110000  0.040000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "1       ...  0.100292  0.033431  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "2       ...  0.020000  0.010000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "3       ...  0.108249  0.039363  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "4       ...  0.164645  0.069242  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "...     ...       ...       ...  ...  ...       ...  ...       ...  ...  ...   \n",
       "246117  ...  0.088610  0.027152  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "246118  ... -1.000000  0.560000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "246119  ...  0.032961  0.020601  0.0  0.0  0.587987  0.0  0.412013  0.0  0.0   \n",
       "246120  ...  0.020000 -1.000000  0.0  0.0  1.000000  0.0  0.000000  0.0  0.0   \n",
       "246121  ...  0.013712  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "\n",
       "             X78  \n",
       "0       0.000000  \n",
       "1       0.000000  \n",
       "2       0.000000  \n",
       "3       0.000000  \n",
       "4       0.000000  \n",
       "...          ...  \n",
       "246117  0.000000  \n",
       "246118  0.000000  \n",
       "246119  0.412013  \n",
       "246120  0.000000  \n",
       "246121  0.000000  \n",
       "\n",
       "[246122 rows x 78 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so in X, it is ALL the columns EXCEPT the last column known as 'Y' (we can confirm this using the train_data.head() we did earlier) so we must get all columns and DROP only the 'y' column\n",
    "X = train_data_processed.drop(columns=['Y'])\n",
    "X # lets display X and see what it is now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "246117    0\n",
       "246118    1\n",
       "246119    0\n",
       "246120    0\n",
       "246121    0\n",
       "Name: Y, Length: 246122, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so as per our X output, we can see that number of columns in train_data is 79 and number of columns in X is 78 meaning we have successfully performed our removal of target variable\n",
    "# now to get the target variable alone, we can just get it alone,\n",
    "Y = train_data_processed['Y']\n",
    "Y # lets see what it is\n",
    "# as per our Y output, we can see it is of one column and 246k rows which means we have successfully extracted the target variable column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imputation \n",
    "many cells in our data may be empty - we must fill these cells with data. we have multiple options to deal with them:\n",
    "- we remove the entire rows (Case 1)\n",
    "- we fill the cells with the average of the column (Case 2)\n",
    "- we fill the cells based on KNN imputation (nearest neighbour) (Case 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE ROWS \n",
    "# ----------------------------- case  -----------------------------\n",
    "# in this case, lets remove the entire rows that have NaN values. before saving the removed rows data set, lets first run it and display it to see the outcome, then we shall save in X\n",
    "# X.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE ROWS\n",
    "# # so we originally had 246122 rows and now after removing empty cell rows we have 239650 rows which is a 6472 rows difference. as our first try, lets work with it. lets assign this data set in place of X\n",
    "# X = X.dropna(axis=0)\n",
    "# X\n",
    "# these above 2 lines were commented out as there was an error handling, rows were being removed from X and not from Y so we fixed it by removing from train_data and then splitting into X and Y\n",
    "# train_data_processed = train_data_processed.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Mean Imputation\n",
    "# ----------------------------- case  -----------------------------\n",
    "# this will fill all the empty spaces using the average of all the spaces\n",
    "imputer = SimpleImputer(strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Imputation\n",
    "# ----------------------------- case -----------------------------\n",
    "# this fills them in using k-nearest neighbours of all the spaces\n",
    "# imputer = KNNImputer(n_neighbors=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputer.fit_transform(X)                                        # fill them in X\n",
    "test_data_processed = imputer.fit_transform(test_data_processed)    # fill them in test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scaling\n",
    "some columns may be very large then other columns when compared. it would not affect at the moment as we are using decision trees, but to maintain a fair enviroment, we shall perform scaling on every run.\n",
    "there are two types of scaling: \n",
    "- min max scaling (also known as normalization)\n",
    "- standardisation (z-score normalization)\n",
    "- max abs scaler\n",
    "- robust scaler\n",
    "- normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- case  -----------------------------\n",
    "# in this case we shall perform min max scaling. to do that, we must use our MinMaxScaler that we have imported above\n",
    "# scaler = MinMaxScaler()\n",
    "# # now we must use this scaler to scale X\n",
    "# scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.06302565e-06, 9.77528090e-01, 5.03110176e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [8.12605131e-06, 9.25531276e-01, 4.65579663e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.21890770e-05, 5.61797753e-01, 4.09520864e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [9.99991874e-01, 6.45753712e-01, 6.17180876e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.12013395e-01],\n",
       "       [9.99995937e-01, 7.41573034e-01, 3.50050368e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 5.64692584e-01, 4.82989245e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------- case  -----------------------------\n",
    "scaler = MaxAbsScaler()\n",
    "# now we must use this scaler to scale X\n",
    "scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our output shows us that every value in the array is between 0 and 1. thus lets save this value on X\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# now we must do the same on our test_data set\n",
    "test_data_processed = scaler.fit_transform(test_data_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filters\n",
    "there are two types of filters to filter out columns/features:\n",
    "- variance filter (a column which has same values throughout the column like all are sunny)\n",
    "- correlation filter (two columns which are same like weight in kg and weight in pounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :  (246122, 78)\n",
      "test data :  (105482, 78)\n"
     ]
    }
   ],
   "source": [
    "print(\"X : \", X.shape)\n",
    "print(\"test data : \", test_data_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246122, 78)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variance filter\n",
    "# ----------------------------- case  -----------------------------\n",
    "# variance_filter = VarianceThreshold(threshold=0.001)  # Adjust the threshold if needed\n",
    "# X = variance_filter.fit_transform(X)\n",
    "# test_data_processed = variance_filter.fit_transform(test_data_processed)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105482, 78)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246122, 78)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # correlation filter\n",
    "# # ----------------------------- case  -----------------------------\n",
    "# corr_matrix = pd.DataFrame(X).corr().abs()\n",
    "# upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "# to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "# X = pd.DataFrame(X).drop(columns=to_drop)\n",
    "# test_data_processed = pd.DataFrame(test_data_processed).drop(columns=to_drop)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105482, 78)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_processed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting - train and validate\n",
    "now our test_data set is of rows with NO target variable whereas the train_data set is WITH target variable.\n",
    "our rules in machine learning is that we must train half or 70% of the data and then we must check its accuracy using the remaining half or 30% of the data - we can only check accuracy IF we have the answers i.e. the target variable. \n",
    "So, what we need to do is, is split the train_data set into 2, by a 70% and 30% ratio. we train the model using the 70% and then test the model using the 30% and then use that model to predict the test_data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holdout method\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model intialization\n",
    "here model is intialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(loss_function='Logloss', depth=10)\n",
    "# --\n",
    "# model = CatBoostClassifier()                                      # case 107\n",
    "# model = CatBoostClassifier(n_estimators=100)                      # case 109"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "in this we select columns and features we want to keep. there are several algos to do so:\n",
    "- forward selection\n",
    "- backward selection\n",
    "- Kbest (best out of all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward selection\n",
    "# ----------------------------- case -----------------------------\n",
    "# selection = SequentialFeatureSelector(model, direction='forward',n_features_to_select=10, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # backward selection\n",
    "# selection = SequentialFeatureSelector(model, direction='backward',n_features_to_select=5, scoring='roc_auc', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k best\n",
    "# ----------------------------- case -----------------------------\n",
    "# selection = SelectKBest(score_func=f_classif, k=5)             # Use f_classif for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection fitting\n",
    "# trainX = selection.fit_transform(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection applying\n",
    "# testX = selection.transform(testX)                                  # Ensure the test set is transformed similarly\n",
    "# test_data_processed = selection.transform(test_data_processed)      # test data is also transformed\n",
    "# X = selection.transform(X)                                          # full data transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172285, 78)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyper parameters of grid\n",
    "# param_grid = {\n",
    "#     'max_depth': [2, 3, 6, 7, 8, 9, 10],\n",
    "#     'learning_rate': [0.001, 0.005, 0.01, 0.05],\n",
    "#     'n_estimators': [400, 500, 1000, 2000, 3000]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize grid search\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "# grid_search.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the best model grid search found\n",
    "# best_model = grid_search.best_estimator_\n",
    "# best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the best parameters of the best model\n",
    "# best_parameters = grid_search.best_params_\n",
    "# best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the best model our model\n",
    "# model = best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging intialization\n",
    "here we will introduce and intialize bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = BaggingClassifier(estimator=model, n_estimators=50, verbose=2)\n",
    "# -- \n",
    "# model = BaggingClassifier(estimator=model, n_estimators=50)                   # case 109\n",
    "# model = BaggingClassifier(estimator=model, n_estimators=100)                  # case "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model running\n",
    "here we run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.092856\n",
      "0:\tlearn: 0.4486890\ttotal: 529ms\tremaining: 8m 48s\n",
      "1:\tlearn: 0.2805319\ttotal: 912ms\tremaining: 7m 34s\n",
      "2:\tlearn: 0.1841972\ttotal: 1.43s\tremaining: 7m 56s\n",
      "3:\tlearn: 0.1260519\ttotal: 1.89s\tremaining: 7m 49s\n",
      "4:\tlearn: 0.0875370\ttotal: 2.38s\tremaining: 7m 52s\n",
      "5:\tlearn: 0.0645735\ttotal: 2.77s\tremaining: 7m 39s\n",
      "6:\tlearn: 0.0481892\ttotal: 3.16s\tremaining: 7m 28s\n",
      "7:\tlearn: 0.0373947\ttotal: 3.62s\tremaining: 7m 28s\n",
      "8:\tlearn: 0.0301681\ttotal: 3.96s\tremaining: 7m 15s\n",
      "9:\tlearn: 0.0255025\ttotal: 4.29s\tremaining: 7m 4s\n",
      "10:\tlearn: 0.0219437\ttotal: 4.6s\tremaining: 6m 53s\n",
      "11:\tlearn: 0.0195510\ttotal: 4.88s\tremaining: 6m 42s\n",
      "12:\tlearn: 0.0177500\ttotal: 5.22s\tremaining: 6m 36s\n",
      "13:\tlearn: 0.0161585\ttotal: 5.54s\tremaining: 6m 29s\n",
      "14:\tlearn: 0.0150044\ttotal: 5.84s\tremaining: 6m 23s\n",
      "15:\tlearn: 0.0143060\ttotal: 6.14s\tremaining: 6m 17s\n",
      "16:\tlearn: 0.0136635\ttotal: 6.44s\tremaining: 6m 12s\n",
      "17:\tlearn: 0.0131044\ttotal: 6.74s\tremaining: 6m 7s\n",
      "18:\tlearn: 0.0126980\ttotal: 7.03s\tremaining: 6m 3s\n",
      "19:\tlearn: 0.0123016\ttotal: 7.43s\tremaining: 6m 4s\n",
      "20:\tlearn: 0.0119794\ttotal: 7.79s\tremaining: 6m 3s\n",
      "21:\tlearn: 0.0116723\ttotal: 8.12s\tremaining: 6m 1s\n",
      "22:\tlearn: 0.0114166\ttotal: 8.49s\tremaining: 6m\n",
      "23:\tlearn: 0.0111851\ttotal: 9.03s\tremaining: 6m 7s\n",
      "24:\tlearn: 0.0110226\ttotal: 9.38s\tremaining: 6m 5s\n",
      "25:\tlearn: 0.0108986\ttotal: 9.83s\tremaining: 6m 8s\n",
      "26:\tlearn: 0.0107416\ttotal: 10.2s\tremaining: 6m 8s\n",
      "27:\tlearn: 0.0106555\ttotal: 10.6s\tremaining: 6m 7s\n",
      "28:\tlearn: 0.0105422\ttotal: 11s\tremaining: 6m 9s\n",
      "29:\tlearn: 0.0104302\ttotal: 11.5s\tremaining: 6m 11s\n",
      "30:\tlearn: 0.0103172\ttotal: 11.8s\tremaining: 6m 9s\n",
      "31:\tlearn: 0.0102409\ttotal: 12.2s\tremaining: 6m 8s\n",
      "32:\tlearn: 0.0101398\ttotal: 12.6s\tremaining: 6m 9s\n",
      "33:\tlearn: 0.0100376\ttotal: 13.1s\tremaining: 6m 11s\n",
      "34:\tlearn: 0.0099629\ttotal: 13.6s\tremaining: 6m 14s\n",
      "35:\tlearn: 0.0098633\ttotal: 14s\tremaining: 6m 15s\n",
      "36:\tlearn: 0.0098107\ttotal: 14.4s\tremaining: 6m 15s\n",
      "37:\tlearn: 0.0097115\ttotal: 14.8s\tremaining: 6m 15s\n",
      "38:\tlearn: 0.0095939\ttotal: 15.3s\tremaining: 6m 16s\n",
      "39:\tlearn: 0.0095062\ttotal: 15.7s\tremaining: 6m 17s\n",
      "40:\tlearn: 0.0094105\ttotal: 16.1s\tremaining: 6m 15s\n",
      "41:\tlearn: 0.0093559\ttotal: 16.4s\tremaining: 6m 14s\n",
      "42:\tlearn: 0.0092988\ttotal: 16.8s\tremaining: 6m 13s\n",
      "43:\tlearn: 0.0092144\ttotal: 17.1s\tremaining: 6m 11s\n",
      "44:\tlearn: 0.0091547\ttotal: 17.5s\tremaining: 6m 10s\n",
      "45:\tlearn: 0.0091022\ttotal: 17.8s\tremaining: 6m 9s\n",
      "46:\tlearn: 0.0090601\ttotal: 18.2s\tremaining: 6m 9s\n",
      "47:\tlearn: 0.0089785\ttotal: 18.7s\tremaining: 6m 11s\n",
      "48:\tlearn: 0.0089390\ttotal: 19.2s\tremaining: 6m 13s\n",
      "49:\tlearn: 0.0088315\ttotal: 19.7s\tremaining: 6m 14s\n",
      "50:\tlearn: 0.0087900\ttotal: 20.3s\tremaining: 6m 18s\n",
      "51:\tlearn: 0.0087545\ttotal: 20.7s\tremaining: 6m 18s\n",
      "52:\tlearn: 0.0087275\ttotal: 21.1s\tremaining: 6m 17s\n",
      "53:\tlearn: 0.0086844\ttotal: 21.5s\tremaining: 6m 16s\n",
      "54:\tlearn: 0.0086492\ttotal: 21.9s\tremaining: 6m 15s\n",
      "55:\tlearn: 0.0086131\ttotal: 22.2s\tremaining: 6m 14s\n",
      "56:\tlearn: 0.0085734\ttotal: 22.6s\tremaining: 6m 13s\n",
      "57:\tlearn: 0.0085289\ttotal: 23s\tremaining: 6m 13s\n",
      "58:\tlearn: 0.0084733\ttotal: 23.4s\tremaining: 6m 12s\n",
      "59:\tlearn: 0.0084489\ttotal: 23.7s\tremaining: 6m 11s\n",
      "60:\tlearn: 0.0084010\ttotal: 24.1s\tremaining: 6m 11s\n",
      "61:\tlearn: 0.0083704\ttotal: 24.6s\tremaining: 6m 11s\n",
      "62:\tlearn: 0.0083384\ttotal: 25s\tremaining: 6m 11s\n",
      "63:\tlearn: 0.0082921\ttotal: 25.4s\tremaining: 6m 12s\n",
      "64:\tlearn: 0.0082635\ttotal: 25.8s\tremaining: 6m 11s\n",
      "65:\tlearn: 0.0082316\ttotal: 26.2s\tremaining: 6m 10s\n",
      "66:\tlearn: 0.0081815\ttotal: 26.6s\tremaining: 6m 10s\n",
      "67:\tlearn: 0.0081290\ttotal: 27s\tremaining: 6m 9s\n",
      "68:\tlearn: 0.0080468\ttotal: 27.3s\tremaining: 6m 8s\n",
      "69:\tlearn: 0.0079945\ttotal: 27.7s\tremaining: 6m 7s\n",
      "70:\tlearn: 0.0079247\ttotal: 28s\tremaining: 6m 6s\n",
      "71:\tlearn: 0.0078916\ttotal: 28.4s\tremaining: 6m 5s\n",
      "72:\tlearn: 0.0078325\ttotal: 28.7s\tremaining: 6m 4s\n",
      "73:\tlearn: 0.0077960\ttotal: 29.1s\tremaining: 6m 4s\n",
      "74:\tlearn: 0.0077566\ttotal: 29.6s\tremaining: 6m 5s\n",
      "75:\tlearn: 0.0077362\ttotal: 30s\tremaining: 6m 4s\n",
      "76:\tlearn: 0.0077015\ttotal: 30.6s\tremaining: 6m 7s\n",
      "77:\tlearn: 0.0076674\ttotal: 31.2s\tremaining: 6m 9s\n",
      "78:\tlearn: 0.0076295\ttotal: 31.7s\tremaining: 6m 9s\n",
      "79:\tlearn: 0.0076001\ttotal: 32.1s\tremaining: 6m 9s\n",
      "80:\tlearn: 0.0075249\ttotal: 32.6s\tremaining: 6m 9s\n",
      "81:\tlearn: 0.0074493\ttotal: 33s\tremaining: 6m 9s\n",
      "82:\tlearn: 0.0073596\ttotal: 33.4s\tremaining: 6m 9s\n",
      "83:\tlearn: 0.0073293\ttotal: 33.8s\tremaining: 6m 9s\n",
      "84:\tlearn: 0.0073005\ttotal: 34.2s\tremaining: 6m 8s\n",
      "85:\tlearn: 0.0071869\ttotal: 34.8s\tremaining: 6m 9s\n",
      "86:\tlearn: 0.0071715\ttotal: 35.2s\tremaining: 6m 9s\n",
      "87:\tlearn: 0.0071224\ttotal: 35.7s\tremaining: 6m 9s\n",
      "88:\tlearn: 0.0070923\ttotal: 36s\tremaining: 6m 8s\n",
      "89:\tlearn: 0.0070574\ttotal: 36.4s\tremaining: 6m 8s\n",
      "90:\tlearn: 0.0070179\ttotal: 36.9s\tremaining: 6m 8s\n",
      "91:\tlearn: 0.0069748\ttotal: 37.4s\tremaining: 6m 8s\n",
      "92:\tlearn: 0.0069505\ttotal: 37.7s\tremaining: 6m 7s\n",
      "93:\tlearn: 0.0069223\ttotal: 38.1s\tremaining: 6m 7s\n",
      "94:\tlearn: 0.0068811\ttotal: 38.5s\tremaining: 6m 6s\n",
      "95:\tlearn: 0.0068441\ttotal: 38.9s\tremaining: 6m 5s\n",
      "96:\tlearn: 0.0068113\ttotal: 39.3s\tremaining: 6m 5s\n",
      "97:\tlearn: 0.0067643\ttotal: 39.7s\tremaining: 6m 5s\n",
      "98:\tlearn: 0.0067392\ttotal: 40.2s\tremaining: 6m 5s\n",
      "99:\tlearn: 0.0066781\ttotal: 40.6s\tremaining: 6m 5s\n",
      "100:\tlearn: 0.0066447\ttotal: 41s\tremaining: 6m 4s\n",
      "101:\tlearn: 0.0065737\ttotal: 41.3s\tremaining: 6m 3s\n",
      "102:\tlearn: 0.0064757\ttotal: 41.7s\tremaining: 6m 3s\n",
      "103:\tlearn: 0.0064398\ttotal: 42.1s\tremaining: 6m 2s\n",
      "104:\tlearn: 0.0063870\ttotal: 42.7s\tremaining: 6m 3s\n",
      "105:\tlearn: 0.0063638\ttotal: 43.1s\tremaining: 6m 3s\n",
      "106:\tlearn: 0.0063133\ttotal: 43.5s\tremaining: 6m 3s\n",
      "107:\tlearn: 0.0062974\ttotal: 43.8s\tremaining: 6m 2s\n",
      "108:\tlearn: 0.0062832\ttotal: 44.2s\tremaining: 6m 1s\n",
      "109:\tlearn: 0.0062676\ttotal: 44.7s\tremaining: 6m 1s\n",
      "110:\tlearn: 0.0062186\ttotal: 45.1s\tremaining: 6m 1s\n",
      "111:\tlearn: 0.0062085\ttotal: 45.5s\tremaining: 6m\n",
      "112:\tlearn: 0.0061930\ttotal: 45.8s\tremaining: 5m 59s\n",
      "113:\tlearn: 0.0061729\ttotal: 46.2s\tremaining: 5m 59s\n",
      "114:\tlearn: 0.0061558\ttotal: 46.6s\tremaining: 5m 58s\n",
      "115:\tlearn: 0.0061400\ttotal: 46.9s\tremaining: 5m 57s\n",
      "116:\tlearn: 0.0061217\ttotal: 47.2s\tremaining: 5m 56s\n",
      "117:\tlearn: 0.0060776\ttotal: 47.6s\tremaining: 5m 55s\n",
      "118:\tlearn: 0.0060540\ttotal: 48s\tremaining: 5m 55s\n",
      "119:\tlearn: 0.0060122\ttotal: 48.4s\tremaining: 5m 55s\n",
      "120:\tlearn: 0.0059835\ttotal: 48.9s\tremaining: 5m 54s\n",
      "121:\tlearn: 0.0059584\ttotal: 49.4s\tremaining: 5m 55s\n",
      "122:\tlearn: 0.0059416\ttotal: 49.8s\tremaining: 5m 55s\n",
      "123:\tlearn: 0.0058662\ttotal: 50.3s\tremaining: 5m 55s\n",
      "124:\tlearn: 0.0058544\ttotal: 50.7s\tremaining: 5m 54s\n",
      "125:\tlearn: 0.0058424\ttotal: 51.1s\tremaining: 5m 54s\n",
      "126:\tlearn: 0.0058183\ttotal: 51.6s\tremaining: 5m 54s\n",
      "127:\tlearn: 0.0057902\ttotal: 52s\tremaining: 5m 54s\n",
      "128:\tlearn: 0.0057797\ttotal: 52.5s\tremaining: 5m 54s\n",
      "129:\tlearn: 0.0057638\ttotal: 52.8s\tremaining: 5m 53s\n",
      "130:\tlearn: 0.0057146\ttotal: 53.2s\tremaining: 5m 53s\n",
      "131:\tlearn: 0.0057079\ttotal: 53.8s\tremaining: 5m 54s\n",
      "132:\tlearn: 0.0056841\ttotal: 54.3s\tremaining: 5m 53s\n",
      "133:\tlearn: 0.0056607\ttotal: 54.7s\tremaining: 5m 53s\n",
      "134:\tlearn: 0.0056069\ttotal: 55.1s\tremaining: 5m 53s\n",
      "135:\tlearn: 0.0055748\ttotal: 55.5s\tremaining: 5m 52s\n",
      "136:\tlearn: 0.0055282\ttotal: 56s\tremaining: 5m 52s\n",
      "137:\tlearn: 0.0055110\ttotal: 56.3s\tremaining: 5m 51s\n",
      "138:\tlearn: 0.0055025\ttotal: 56.7s\tremaining: 5m 51s\n",
      "139:\tlearn: 0.0054851\ttotal: 57.1s\tremaining: 5m 51s\n",
      "140:\tlearn: 0.0054725\ttotal: 57.7s\tremaining: 5m 51s\n",
      "141:\tlearn: 0.0054534\ttotal: 58.1s\tremaining: 5m 51s\n",
      "142:\tlearn: 0.0054021\ttotal: 58.5s\tremaining: 5m 50s\n",
      "143:\tlearn: 0.0053867\ttotal: 58.9s\tremaining: 5m 50s\n",
      "144:\tlearn: 0.0053686\ttotal: 59.4s\tremaining: 5m 50s\n",
      "145:\tlearn: 0.0053553\ttotal: 59.8s\tremaining: 5m 49s\n",
      "146:\tlearn: 0.0053449\ttotal: 1m\tremaining: 5m 50s\n",
      "147:\tlearn: 0.0053214\ttotal: 1m\tremaining: 5m 50s\n",
      "148:\tlearn: 0.0053083\ttotal: 1m 1s\tremaining: 5m 49s\n",
      "149:\tlearn: 0.0052766\ttotal: 1m 1s\tremaining: 5m 50s\n",
      "150:\tlearn: 0.0052484\ttotal: 1m 2s\tremaining: 5m 50s\n",
      "151:\tlearn: 0.0052329\ttotal: 1m 2s\tremaining: 5m 50s\n",
      "152:\tlearn: 0.0052079\ttotal: 1m 3s\tremaining: 5m 50s\n",
      "153:\tlearn: 0.0051563\ttotal: 1m 3s\tremaining: 5m 49s\n",
      "154:\tlearn: 0.0051345\ttotal: 1m 4s\tremaining: 5m 49s\n",
      "155:\tlearn: 0.0051245\ttotal: 1m 4s\tremaining: 5m 48s\n",
      "156:\tlearn: 0.0051057\ttotal: 1m 4s\tremaining: 5m 48s\n",
      "157:\tlearn: 0.0050651\ttotal: 1m 5s\tremaining: 5m 47s\n",
      "158:\tlearn: 0.0050406\ttotal: 1m 5s\tremaining: 5m 47s\n",
      "159:\tlearn: 0.0050140\ttotal: 1m 6s\tremaining: 5m 46s\n",
      "160:\tlearn: 0.0049761\ttotal: 1m 6s\tremaining: 5m 47s\n",
      "161:\tlearn: 0.0049520\ttotal: 1m 7s\tremaining: 5m 47s\n",
      "162:\tlearn: 0.0049425\ttotal: 1m 7s\tremaining: 5m 46s\n",
      "163:\tlearn: 0.0049221\ttotal: 1m 7s\tremaining: 5m 46s\n",
      "164:\tlearn: 0.0048709\ttotal: 1m 8s\tremaining: 5m 46s\n",
      "165:\tlearn: 0.0048432\ttotal: 1m 8s\tremaining: 5m 45s\n",
      "166:\tlearn: 0.0048377\ttotal: 1m 9s\tremaining: 5m 45s\n",
      "167:\tlearn: 0.0048310\ttotal: 1m 9s\tremaining: 5m 45s\n",
      "168:\tlearn: 0.0048238\ttotal: 1m 10s\tremaining: 5m 45s\n",
      "169:\tlearn: 0.0047988\ttotal: 1m 10s\tremaining: 5m 45s\n",
      "170:\tlearn: 0.0047398\ttotal: 1m 11s\tremaining: 5m 44s\n",
      "171:\tlearn: 0.0046887\ttotal: 1m 11s\tremaining: 5m 44s\n",
      "172:\tlearn: 0.0046128\ttotal: 1m 11s\tremaining: 5m 43s\n",
      "173:\tlearn: 0.0045918\ttotal: 1m 12s\tremaining: 5m 43s\n",
      "174:\tlearn: 0.0045711\ttotal: 1m 12s\tremaining: 5m 42s\n",
      "175:\tlearn: 0.0045624\ttotal: 1m 13s\tremaining: 5m 41s\n",
      "176:\tlearn: 0.0045314\ttotal: 1m 13s\tremaining: 5m 41s\n",
      "177:\tlearn: 0.0045238\ttotal: 1m 13s\tremaining: 5m 40s\n",
      "178:\tlearn: 0.0044811\ttotal: 1m 14s\tremaining: 5m 39s\n",
      "179:\tlearn: 0.0044740\ttotal: 1m 14s\tremaining: 5m 38s\n",
      "180:\tlearn: 0.0044467\ttotal: 1m 14s\tremaining: 5m 38s\n",
      "181:\tlearn: 0.0044093\ttotal: 1m 15s\tremaining: 5m 37s\n",
      "182:\tlearn: 0.0043800\ttotal: 1m 15s\tremaining: 5m 36s\n",
      "183:\tlearn: 0.0043677\ttotal: 1m 15s\tremaining: 5m 35s\n",
      "184:\tlearn: 0.0043565\ttotal: 1m 15s\tremaining: 5m 34s\n",
      "185:\tlearn: 0.0043391\ttotal: 1m 16s\tremaining: 5m 33s\n",
      "186:\tlearn: 0.0043332\ttotal: 1m 16s\tremaining: 5m 33s\n",
      "187:\tlearn: 0.0043197\ttotal: 1m 16s\tremaining: 5m 32s\n",
      "188:\tlearn: 0.0043068\ttotal: 1m 17s\tremaining: 5m 31s\n",
      "189:\tlearn: 0.0042865\ttotal: 1m 17s\tremaining: 5m 30s\n",
      "190:\tlearn: 0.0042517\ttotal: 1m 17s\tremaining: 5m 30s\n",
      "191:\tlearn: 0.0042184\ttotal: 1m 18s\tremaining: 5m 29s\n",
      "192:\tlearn: 0.0042057\ttotal: 1m 18s\tremaining: 5m 29s\n",
      "193:\tlearn: 0.0041997\ttotal: 1m 19s\tremaining: 5m 28s\n",
      "194:\tlearn: 0.0041889\ttotal: 1m 19s\tremaining: 5m 28s\n",
      "195:\tlearn: 0.0041759\ttotal: 1m 19s\tremaining: 5m 28s\n",
      "196:\tlearn: 0.0041412\ttotal: 1m 20s\tremaining: 5m 27s\n",
      "197:\tlearn: 0.0041312\ttotal: 1m 20s\tremaining: 5m 27s\n",
      "198:\tlearn: 0.0041193\ttotal: 1m 21s\tremaining: 5m 27s\n",
      "199:\tlearn: 0.0041016\ttotal: 1m 21s\tremaining: 5m 27s\n",
      "200:\tlearn: 0.0040798\ttotal: 1m 22s\tremaining: 5m 27s\n",
      "201:\tlearn: 0.0040628\ttotal: 1m 22s\tremaining: 5m 26s\n",
      "202:\tlearn: 0.0040041\ttotal: 1m 23s\tremaining: 5m 26s\n",
      "203:\tlearn: 0.0039748\ttotal: 1m 23s\tremaining: 5m 26s\n",
      "204:\tlearn: 0.0039560\ttotal: 1m 24s\tremaining: 5m 26s\n",
      "205:\tlearn: 0.0039465\ttotal: 1m 24s\tremaining: 5m 26s\n",
      "206:\tlearn: 0.0039391\ttotal: 1m 24s\tremaining: 5m 25s\n",
      "207:\tlearn: 0.0039223\ttotal: 1m 25s\tremaining: 5m 25s\n",
      "208:\tlearn: 0.0038997\ttotal: 1m 25s\tremaining: 5m 24s\n",
      "209:\tlearn: 0.0038947\ttotal: 1m 26s\tremaining: 5m 24s\n",
      "210:\tlearn: 0.0038811\ttotal: 1m 26s\tremaining: 5m 24s\n",
      "211:\tlearn: 0.0038537\ttotal: 1m 27s\tremaining: 5m 23s\n",
      "212:\tlearn: 0.0038422\ttotal: 1m 27s\tremaining: 5m 23s\n",
      "213:\tlearn: 0.0038021\ttotal: 1m 27s\tremaining: 5m 23s\n",
      "214:\tlearn: 0.0037825\ttotal: 1m 28s\tremaining: 5m 22s\n",
      "215:\tlearn: 0.0037595\ttotal: 1m 28s\tremaining: 5m 21s\n",
      "216:\tlearn: 0.0037518\ttotal: 1m 29s\tremaining: 5m 21s\n",
      "217:\tlearn: 0.0037224\ttotal: 1m 29s\tremaining: 5m 21s\n",
      "218:\tlearn: 0.0037111\ttotal: 1m 30s\tremaining: 5m 22s\n",
      "219:\tlearn: 0.0036992\ttotal: 1m 30s\tremaining: 5m 21s\n",
      "220:\tlearn: 0.0036945\ttotal: 1m 31s\tremaining: 5m 21s\n",
      "221:\tlearn: 0.0036688\ttotal: 1m 31s\tremaining: 5m 21s\n",
      "222:\tlearn: 0.0036544\ttotal: 1m 32s\tremaining: 5m 20s\n",
      "223:\tlearn: 0.0036391\ttotal: 1m 32s\tremaining: 5m 20s\n",
      "224:\tlearn: 0.0035902\ttotal: 1m 32s\tremaining: 5m 20s\n",
      "225:\tlearn: 0.0035648\ttotal: 1m 33s\tremaining: 5m 19s\n",
      "226:\tlearn: 0.0035607\ttotal: 1m 33s\tremaining: 5m 19s\n",
      "227:\tlearn: 0.0035320\ttotal: 1m 34s\tremaining: 5m 19s\n",
      "228:\tlearn: 0.0035249\ttotal: 1m 34s\tremaining: 5m 18s\n",
      "229:\tlearn: 0.0034945\ttotal: 1m 34s\tremaining: 5m 18s\n",
      "230:\tlearn: 0.0034711\ttotal: 1m 35s\tremaining: 5m 17s\n",
      "231:\tlearn: 0.0034426\ttotal: 1m 35s\tremaining: 5m 17s\n",
      "232:\tlearn: 0.0033831\ttotal: 1m 36s\tremaining: 5m 17s\n",
      "233:\tlearn: 0.0033771\ttotal: 1m 37s\tremaining: 5m 17s\n",
      "234:\tlearn: 0.0033674\ttotal: 1m 37s\tremaining: 5m 17s\n",
      "235:\tlearn: 0.0033584\ttotal: 1m 38s\tremaining: 5m 17s\n",
      "236:\tlearn: 0.0033498\ttotal: 1m 38s\tremaining: 5m 17s\n",
      "237:\tlearn: 0.0033451\ttotal: 1m 39s\tremaining: 5m 17s\n",
      "238:\tlearn: 0.0033204\ttotal: 1m 39s\tremaining: 5m 16s\n",
      "239:\tlearn: 0.0033115\ttotal: 1m 39s\tremaining: 5m 16s\n",
      "240:\tlearn: 0.0033049\ttotal: 1m 40s\tremaining: 5m 15s\n",
      "241:\tlearn: 0.0032869\ttotal: 1m 40s\tremaining: 5m 15s\n",
      "242:\tlearn: 0.0032470\ttotal: 1m 40s\tremaining: 5m 14s\n",
      "243:\tlearn: 0.0032418\ttotal: 1m 41s\tremaining: 5m 13s\n",
      "244:\tlearn: 0.0032157\ttotal: 1m 41s\tremaining: 5m 13s\n",
      "245:\tlearn: 0.0031957\ttotal: 1m 42s\tremaining: 5m 12s\n",
      "246:\tlearn: 0.0031876\ttotal: 1m 42s\tremaining: 5m 12s\n",
      "247:\tlearn: 0.0031781\ttotal: 1m 42s\tremaining: 5m 11s\n",
      "248:\tlearn: 0.0031720\ttotal: 1m 43s\tremaining: 5m 10s\n",
      "249:\tlearn: 0.0031477\ttotal: 1m 43s\tremaining: 5m 10s\n",
      "250:\tlearn: 0.0031446\ttotal: 1m 43s\tremaining: 5m 9s\n",
      "251:\tlearn: 0.0031283\ttotal: 1m 44s\tremaining: 5m 9s\n",
      "252:\tlearn: 0.0031116\ttotal: 1m 44s\tremaining: 5m 9s\n",
      "253:\tlearn: 0.0030973\ttotal: 1m 45s\tremaining: 5m 8s\n",
      "254:\tlearn: 0.0030813\ttotal: 1m 45s\tremaining: 5m 7s\n",
      "255:\tlearn: 0.0030766\ttotal: 1m 45s\tremaining: 5m 7s\n",
      "256:\tlearn: 0.0030637\ttotal: 1m 46s\tremaining: 5m 6s\n",
      "257:\tlearn: 0.0030574\ttotal: 1m 46s\tremaining: 5m 6s\n",
      "258:\tlearn: 0.0030207\ttotal: 1m 47s\tremaining: 5m 6s\n",
      "259:\tlearn: 0.0030139\ttotal: 1m 47s\tremaining: 5m 5s\n",
      "260:\tlearn: 0.0030052\ttotal: 1m 47s\tremaining: 5m 5s\n",
      "261:\tlearn: 0.0029871\ttotal: 1m 48s\tremaining: 5m 5s\n",
      "262:\tlearn: 0.0029704\ttotal: 1m 48s\tremaining: 5m 4s\n",
      "263:\tlearn: 0.0029648\ttotal: 1m 49s\tremaining: 5m 4s\n",
      "264:\tlearn: 0.0029486\ttotal: 1m 49s\tremaining: 5m 4s\n",
      "265:\tlearn: 0.0029451\ttotal: 1m 50s\tremaining: 5m 3s\n",
      "266:\tlearn: 0.0029327\ttotal: 1m 50s\tremaining: 5m 3s\n",
      "267:\tlearn: 0.0029299\ttotal: 1m 51s\tremaining: 5m 4s\n",
      "268:\tlearn: 0.0029264\ttotal: 1m 52s\tremaining: 5m 4s\n",
      "269:\tlearn: 0.0029135\ttotal: 1m 52s\tremaining: 5m 4s\n",
      "270:\tlearn: 0.0028866\ttotal: 1m 52s\tremaining: 5m 3s\n",
      "271:\tlearn: 0.0028423\ttotal: 1m 53s\tremaining: 5m 3s\n",
      "272:\tlearn: 0.0028359\ttotal: 1m 53s\tremaining: 5m 3s\n",
      "273:\tlearn: 0.0028305\ttotal: 1m 54s\tremaining: 5m 2s\n",
      "274:\tlearn: 0.0028205\ttotal: 1m 54s\tremaining: 5m 2s\n",
      "275:\tlearn: 0.0028178\ttotal: 1m 55s\tremaining: 5m 1s\n",
      "276:\tlearn: 0.0028035\ttotal: 1m 55s\tremaining: 5m 1s\n",
      "277:\tlearn: 0.0027970\ttotal: 1m 56s\tremaining: 5m 1s\n",
      "278:\tlearn: 0.0027931\ttotal: 1m 56s\tremaining: 5m 1s\n",
      "279:\tlearn: 0.0027884\ttotal: 1m 56s\tremaining: 5m\n",
      "280:\tlearn: 0.0027638\ttotal: 1m 57s\tremaining: 5m\n",
      "281:\tlearn: 0.0027602\ttotal: 1m 57s\tremaining: 4m 59s\n",
      "282:\tlearn: 0.0027428\ttotal: 1m 57s\tremaining: 4m 58s\n",
      "283:\tlearn: 0.0027358\ttotal: 1m 58s\tremaining: 4m 58s\n",
      "284:\tlearn: 0.0027266\ttotal: 1m 58s\tremaining: 4m 57s\n",
      "285:\tlearn: 0.0027207\ttotal: 1m 59s\tremaining: 4m 57s\n",
      "286:\tlearn: 0.0027178\ttotal: 1m 59s\tremaining: 4m 56s\n",
      "287:\tlearn: 0.0026977\ttotal: 1m 59s\tremaining: 4m 56s\n",
      "288:\tlearn: 0.0026908\ttotal: 2m\tremaining: 4m 56s\n",
      "289:\tlearn: 0.0026803\ttotal: 2m\tremaining: 4m 55s\n",
      "290:\tlearn: 0.0026686\ttotal: 2m 1s\tremaining: 4m 55s\n",
      "291:\tlearn: 0.0026331\ttotal: 2m 1s\tremaining: 4m 55s\n",
      "292:\tlearn: 0.0026284\ttotal: 2m 2s\tremaining: 4m 55s\n",
      "293:\tlearn: 0.0026123\ttotal: 2m 2s\tremaining: 4m 54s\n",
      "294:\tlearn: 0.0025961\ttotal: 2m 3s\tremaining: 4m 54s\n",
      "295:\tlearn: 0.0025876\ttotal: 2m 3s\tremaining: 4m 53s\n",
      "296:\tlearn: 0.0025760\ttotal: 2m 3s\tremaining: 4m 53s\n",
      "297:\tlearn: 0.0025664\ttotal: 2m 4s\tremaining: 4m 52s\n",
      "298:\tlearn: 0.0025568\ttotal: 2m 4s\tremaining: 4m 52s\n",
      "299:\tlearn: 0.0025497\ttotal: 2m 5s\tremaining: 4m 51s\n",
      "300:\tlearn: 0.0025380\ttotal: 2m 5s\tremaining: 4m 51s\n",
      "301:\tlearn: 0.0025331\ttotal: 2m 5s\tremaining: 4m 50s\n",
      "302:\tlearn: 0.0025153\ttotal: 2m 6s\tremaining: 4m 50s\n",
      "303:\tlearn: 0.0025076\ttotal: 2m 6s\tremaining: 4m 49s\n",
      "304:\tlearn: 0.0025026\ttotal: 2m 6s\tremaining: 4m 49s\n",
      "305:\tlearn: 0.0024757\ttotal: 2m 7s\tremaining: 4m 48s\n",
      "306:\tlearn: 0.0024709\ttotal: 2m 7s\tremaining: 4m 48s\n",
      "307:\tlearn: 0.0024419\ttotal: 2m 8s\tremaining: 4m 47s\n",
      "308:\tlearn: 0.0024324\ttotal: 2m 8s\tremaining: 4m 47s\n",
      "309:\tlearn: 0.0024220\ttotal: 2m 8s\tremaining: 4m 46s\n",
      "310:\tlearn: 0.0024158\ttotal: 2m 9s\tremaining: 4m 46s\n",
      "311:\tlearn: 0.0024120\ttotal: 2m 9s\tremaining: 4m 45s\n",
      "312:\tlearn: 0.0024055\ttotal: 2m 9s\tremaining: 4m 44s\n",
      "313:\tlearn: 0.0023946\ttotal: 2m 10s\tremaining: 4m 44s\n",
      "314:\tlearn: 0.0023688\ttotal: 2m 10s\tremaining: 4m 43s\n",
      "315:\tlearn: 0.0023566\ttotal: 2m 10s\tremaining: 4m 43s\n",
      "316:\tlearn: 0.0023544\ttotal: 2m 11s\tremaining: 4m 42s\n",
      "317:\tlearn: 0.0023453\ttotal: 2m 11s\tremaining: 4m 42s\n",
      "318:\tlearn: 0.0023332\ttotal: 2m 12s\tremaining: 4m 42s\n",
      "319:\tlearn: 0.0023309\ttotal: 2m 12s\tremaining: 4m 41s\n",
      "320:\tlearn: 0.0023212\ttotal: 2m 12s\tremaining: 4m 41s\n",
      "321:\tlearn: 0.0023156\ttotal: 2m 13s\tremaining: 4m 40s\n",
      "322:\tlearn: 0.0023034\ttotal: 2m 13s\tremaining: 4m 40s\n",
      "323:\tlearn: 0.0022959\ttotal: 2m 14s\tremaining: 4m 39s\n",
      "324:\tlearn: 0.0022920\ttotal: 2m 14s\tremaining: 4m 39s\n",
      "325:\tlearn: 0.0022765\ttotal: 2m 14s\tremaining: 4m 38s\n",
      "326:\tlearn: 0.0022740\ttotal: 2m 15s\tremaining: 4m 38s\n",
      "327:\tlearn: 0.0022705\ttotal: 2m 15s\tremaining: 4m 37s\n",
      "328:\tlearn: 0.0022603\ttotal: 2m 15s\tremaining: 4m 36s\n",
      "329:\tlearn: 0.0022523\ttotal: 2m 16s\tremaining: 4m 36s\n",
      "330:\tlearn: 0.0022327\ttotal: 2m 16s\tremaining: 4m 36s\n",
      "331:\tlearn: 0.0022221\ttotal: 2m 16s\tremaining: 4m 35s\n",
      "332:\tlearn: 0.0022182\ttotal: 2m 17s\tremaining: 4m 34s\n",
      "333:\tlearn: 0.0022157\ttotal: 2m 17s\tremaining: 4m 34s\n",
      "334:\tlearn: 0.0022024\ttotal: 2m 17s\tremaining: 4m 33s\n",
      "335:\tlearn: 0.0021995\ttotal: 2m 18s\tremaining: 4m 33s\n",
      "336:\tlearn: 0.0021893\ttotal: 2m 18s\tremaining: 4m 32s\n",
      "337:\tlearn: 0.0021845\ttotal: 2m 18s\tremaining: 4m 32s\n",
      "338:\tlearn: 0.0021821\ttotal: 2m 19s\tremaining: 4m 31s\n",
      "339:\tlearn: 0.0021765\ttotal: 2m 19s\tremaining: 4m 30s\n",
      "340:\tlearn: 0.0021720\ttotal: 2m 19s\tremaining: 4m 30s\n",
      "341:\tlearn: 0.0021677\ttotal: 2m 20s\tremaining: 4m 29s\n",
      "342:\tlearn: 0.0021587\ttotal: 2m 20s\tremaining: 4m 29s\n",
      "343:\tlearn: 0.0021546\ttotal: 2m 21s\tremaining: 4m 28s\n",
      "344:\tlearn: 0.0021458\ttotal: 2m 21s\tremaining: 4m 28s\n",
      "345:\tlearn: 0.0021298\ttotal: 2m 21s\tremaining: 4m 28s\n",
      "346:\tlearn: 0.0021283\ttotal: 2m 22s\tremaining: 4m 27s\n",
      "347:\tlearn: 0.0021209\ttotal: 2m 22s\tremaining: 4m 27s\n",
      "348:\tlearn: 0.0021192\ttotal: 2m 23s\tremaining: 4m 26s\n",
      "349:\tlearn: 0.0021163\ttotal: 2m 23s\tremaining: 4m 26s\n",
      "350:\tlearn: 0.0021119\ttotal: 2m 23s\tremaining: 4m 26s\n",
      "351:\tlearn: 0.0021062\ttotal: 2m 24s\tremaining: 4m 25s\n",
      "352:\tlearn: 0.0021044\ttotal: 2m 24s\tremaining: 4m 25s\n",
      "353:\tlearn: 0.0020854\ttotal: 2m 25s\tremaining: 4m 24s\n",
      "354:\tlearn: 0.0020822\ttotal: 2m 25s\tremaining: 4m 24s\n",
      "355:\tlearn: 0.0020795\ttotal: 2m 25s\tremaining: 4m 24s\n",
      "356:\tlearn: 0.0020705\ttotal: 2m 26s\tremaining: 4m 23s\n",
      "357:\tlearn: 0.0020619\ttotal: 2m 26s\tremaining: 4m 23s\n",
      "358:\tlearn: 0.0020445\ttotal: 2m 27s\tremaining: 4m 22s\n",
      "359:\tlearn: 0.0020411\ttotal: 2m 27s\tremaining: 4m 22s\n",
      "360:\tlearn: 0.0020295\ttotal: 2m 28s\tremaining: 4m 21s\n",
      "361:\tlearn: 0.0020263\ttotal: 2m 28s\tremaining: 4m 21s\n",
      "362:\tlearn: 0.0020181\ttotal: 2m 28s\tremaining: 4m 20s\n",
      "363:\tlearn: 0.0020160\ttotal: 2m 29s\tremaining: 4m 20s\n",
      "364:\tlearn: 0.0020111\ttotal: 2m 29s\tremaining: 4m 19s\n",
      "365:\tlearn: 0.0019903\ttotal: 2m 29s\tremaining: 4m 19s\n",
      "366:\tlearn: 0.0019878\ttotal: 2m 30s\tremaining: 4m 18s\n",
      "367:\tlearn: 0.0019785\ttotal: 2m 30s\tremaining: 4m 18s\n",
      "368:\tlearn: 0.0019682\ttotal: 2m 31s\tremaining: 4m 18s\n",
      "369:\tlearn: 0.0019647\ttotal: 2m 31s\tremaining: 4m 18s\n",
      "370:\tlearn: 0.0019597\ttotal: 2m 32s\tremaining: 4m 17s\n",
      "371:\tlearn: 0.0019544\ttotal: 2m 32s\tremaining: 4m 17s\n",
      "372:\tlearn: 0.0019501\ttotal: 2m 32s\tremaining: 4m 17s\n",
      "373:\tlearn: 0.0019461\ttotal: 2m 33s\tremaining: 4m 16s\n",
      "374:\tlearn: 0.0019440\ttotal: 2m 33s\tremaining: 4m 16s\n",
      "375:\tlearn: 0.0019316\ttotal: 2m 34s\tremaining: 4m 15s\n",
      "376:\tlearn: 0.0019286\ttotal: 2m 34s\tremaining: 4m 15s\n",
      "377:\tlearn: 0.0019233\ttotal: 2m 35s\tremaining: 4m 15s\n",
      "378:\tlearn: 0.0019180\ttotal: 2m 35s\tremaining: 4m 14s\n",
      "379:\tlearn: 0.0019120\ttotal: 2m 35s\tremaining: 4m 14s\n",
      "380:\tlearn: 0.0019097\ttotal: 2m 36s\tremaining: 4m 13s\n",
      "381:\tlearn: 0.0019024\ttotal: 2m 36s\tremaining: 4m 13s\n",
      "382:\tlearn: 0.0018916\ttotal: 2m 37s\tremaining: 4m 12s\n",
      "383:\tlearn: 0.0018761\ttotal: 2m 37s\tremaining: 4m 12s\n",
      "384:\tlearn: 0.0018731\ttotal: 2m 37s\tremaining: 4m 11s\n",
      "385:\tlearn: 0.0018702\ttotal: 2m 38s\tremaining: 4m 11s\n",
      "386:\tlearn: 0.0018627\ttotal: 2m 38s\tremaining: 4m 10s\n",
      "387:\tlearn: 0.0018587\ttotal: 2m 38s\tremaining: 4m 10s\n",
      "388:\tlearn: 0.0018510\ttotal: 2m 39s\tremaining: 4m 10s\n",
      "389:\tlearn: 0.0018499\ttotal: 2m 39s\tremaining: 4m 9s\n",
      "390:\tlearn: 0.0018357\ttotal: 2m 40s\tremaining: 4m 9s\n",
      "391:\tlearn: 0.0018319\ttotal: 2m 40s\tremaining: 4m 8s\n",
      "392:\tlearn: 0.0018232\ttotal: 2m 40s\tremaining: 4m 8s\n",
      "393:\tlearn: 0.0018169\ttotal: 2m 41s\tremaining: 4m 8s\n",
      "394:\tlearn: 0.0018095\ttotal: 2m 41s\tremaining: 4m 7s\n",
      "395:\tlearn: 0.0018055\ttotal: 2m 42s\tremaining: 4m 7s\n",
      "396:\tlearn: 0.0017999\ttotal: 2m 42s\tremaining: 4m 6s\n",
      "397:\tlearn: 0.0017907\ttotal: 2m 42s\tremaining: 4m 6s\n",
      "398:\tlearn: 0.0017804\ttotal: 2m 43s\tremaining: 4m 5s\n",
      "399:\tlearn: 0.0017679\ttotal: 2m 43s\tremaining: 4m 5s\n",
      "400:\tlearn: 0.0017663\ttotal: 2m 43s\tremaining: 4m 4s\n",
      "401:\tlearn: 0.0017639\ttotal: 2m 44s\tremaining: 4m 4s\n",
      "402:\tlearn: 0.0017569\ttotal: 2m 44s\tremaining: 4m 3s\n",
      "403:\tlearn: 0.0017524\ttotal: 2m 45s\tremaining: 4m 3s\n",
      "404:\tlearn: 0.0017503\ttotal: 2m 45s\tremaining: 4m 3s\n",
      "405:\tlearn: 0.0017478\ttotal: 2m 45s\tremaining: 4m 2s\n",
      "406:\tlearn: 0.0017458\ttotal: 2m 46s\tremaining: 4m 2s\n",
      "407:\tlearn: 0.0017358\ttotal: 2m 46s\tremaining: 4m 1s\n",
      "408:\tlearn: 0.0017199\ttotal: 2m 47s\tremaining: 4m 1s\n",
      "409:\tlearn: 0.0017160\ttotal: 2m 47s\tremaining: 4m 1s\n",
      "410:\tlearn: 0.0017131\ttotal: 2m 47s\tremaining: 4m\n",
      "411:\tlearn: 0.0017112\ttotal: 2m 48s\tremaining: 4m\n",
      "412:\tlearn: 0.0017086\ttotal: 2m 48s\tremaining: 3m 59s\n",
      "413:\tlearn: 0.0017046\ttotal: 2m 49s\tremaining: 3m 59s\n",
      "414:\tlearn: 0.0016967\ttotal: 2m 49s\tremaining: 3m 59s\n",
      "415:\tlearn: 0.0016945\ttotal: 2m 50s\tremaining: 3m 58s\n",
      "416:\tlearn: 0.0016862\ttotal: 2m 50s\tremaining: 3m 58s\n",
      "417:\tlearn: 0.0016773\ttotal: 2m 50s\tremaining: 3m 57s\n",
      "418:\tlearn: 0.0016690\ttotal: 2m 51s\tremaining: 3m 57s\n",
      "419:\tlearn: 0.0016630\ttotal: 2m 51s\tremaining: 3m 56s\n",
      "420:\tlearn: 0.0016605\ttotal: 2m 51s\tremaining: 3m 56s\n",
      "421:\tlearn: 0.0016544\ttotal: 2m 52s\tremaining: 3m 56s\n",
      "422:\tlearn: 0.0016508\ttotal: 2m 52s\tremaining: 3m 55s\n",
      "423:\tlearn: 0.0016438\ttotal: 2m 53s\tremaining: 3m 55s\n",
      "424:\tlearn: 0.0016425\ttotal: 2m 53s\tremaining: 3m 54s\n",
      "425:\tlearn: 0.0016406\ttotal: 2m 53s\tremaining: 3m 54s\n",
      "426:\tlearn: 0.0016368\ttotal: 2m 54s\tremaining: 3m 53s\n",
      "427:\tlearn: 0.0016323\ttotal: 2m 54s\tremaining: 3m 53s\n",
      "428:\tlearn: 0.0016312\ttotal: 2m 54s\tremaining: 3m 52s\n",
      "429:\tlearn: 0.0016287\ttotal: 2m 55s\tremaining: 3m 52s\n",
      "430:\tlearn: 0.0016258\ttotal: 2m 55s\tremaining: 3m 51s\n",
      "431:\tlearn: 0.0016222\ttotal: 2m 55s\tremaining: 3m 51s\n",
      "432:\tlearn: 0.0016160\ttotal: 2m 56s\tremaining: 3m 50s\n",
      "433:\tlearn: 0.0016108\ttotal: 2m 56s\tremaining: 3m 50s\n",
      "434:\tlearn: 0.0016057\ttotal: 2m 57s\tremaining: 3m 49s\n",
      "435:\tlearn: 0.0015945\ttotal: 2m 57s\tremaining: 3m 49s\n",
      "436:\tlearn: 0.0015917\ttotal: 2m 57s\tremaining: 3m 49s\n",
      "437:\tlearn: 0.0015846\ttotal: 2m 58s\tremaining: 3m 48s\n",
      "438:\tlearn: 0.0015770\ttotal: 2m 58s\tremaining: 3m 48s\n",
      "439:\tlearn: 0.0015750\ttotal: 2m 59s\tremaining: 3m 47s\n",
      "440:\tlearn: 0.0015721\ttotal: 2m 59s\tremaining: 3m 47s\n",
      "441:\tlearn: 0.0015657\ttotal: 2m 59s\tremaining: 3m 47s\n",
      "442:\tlearn: 0.0015527\ttotal: 3m\tremaining: 3m 46s\n",
      "443:\tlearn: 0.0015501\ttotal: 3m\tremaining: 3m 46s\n",
      "444:\tlearn: 0.0015455\ttotal: 3m 1s\tremaining: 3m 46s\n",
      "445:\tlearn: 0.0015441\ttotal: 3m 1s\tremaining: 3m 45s\n",
      "446:\tlearn: 0.0015422\ttotal: 3m 2s\tremaining: 3m 45s\n",
      "447:\tlearn: 0.0015402\ttotal: 3m 2s\tremaining: 3m 45s\n",
      "448:\tlearn: 0.0015365\ttotal: 3m 3s\tremaining: 3m 45s\n",
      "449:\tlearn: 0.0015328\ttotal: 3m 3s\tremaining: 3m 44s\n",
      "450:\tlearn: 0.0015262\ttotal: 3m 4s\tremaining: 3m 44s\n",
      "451:\tlearn: 0.0015218\ttotal: 3m 4s\tremaining: 3m 43s\n",
      "452:\tlearn: 0.0015138\ttotal: 3m 5s\tremaining: 3m 43s\n",
      "453:\tlearn: 0.0015076\ttotal: 3m 5s\tremaining: 3m 43s\n",
      "454:\tlearn: 0.0015030\ttotal: 3m 5s\tremaining: 3m 42s\n",
      "455:\tlearn: 0.0014971\ttotal: 3m 6s\tremaining: 3m 42s\n",
      "456:\tlearn: 0.0014915\ttotal: 3m 6s\tremaining: 3m 41s\n",
      "457:\tlearn: 0.0014878\ttotal: 3m 6s\tremaining: 3m 41s\n",
      "458:\tlearn: 0.0014860\ttotal: 3m 7s\tremaining: 3m 40s\n",
      "459:\tlearn: 0.0014844\ttotal: 3m 7s\tremaining: 3m 40s\n",
      "460:\tlearn: 0.0014817\ttotal: 3m 8s\tremaining: 3m 40s\n",
      "461:\tlearn: 0.0014784\ttotal: 3m 8s\tremaining: 3m 39s\n",
      "462:\tlearn: 0.0014758\ttotal: 3m 9s\tremaining: 3m 39s\n",
      "463:\tlearn: 0.0014718\ttotal: 3m 9s\tremaining: 3m 39s\n",
      "464:\tlearn: 0.0014647\ttotal: 3m 10s\tremaining: 3m 38s\n",
      "465:\tlearn: 0.0014636\ttotal: 3m 10s\tremaining: 3m 38s\n",
      "466:\tlearn: 0.0014608\ttotal: 3m 10s\tremaining: 3m 37s\n",
      "467:\tlearn: 0.0014533\ttotal: 3m 11s\tremaining: 3m 37s\n",
      "468:\tlearn: 0.0014521\ttotal: 3m 11s\tremaining: 3m 37s\n",
      "469:\tlearn: 0.0014506\ttotal: 3m 12s\tremaining: 3m 36s\n",
      "470:\tlearn: 0.0014454\ttotal: 3m 12s\tremaining: 3m 36s\n",
      "471:\tlearn: 0.0014436\ttotal: 3m 13s\tremaining: 3m 35s\n",
      "472:\tlearn: 0.0014354\ttotal: 3m 13s\tremaining: 3m 35s\n",
      "473:\tlearn: 0.0014339\ttotal: 3m 13s\tremaining: 3m 35s\n",
      "474:\tlearn: 0.0014288\ttotal: 3m 14s\tremaining: 3m 34s\n",
      "475:\tlearn: 0.0014278\ttotal: 3m 14s\tremaining: 3m 34s\n",
      "476:\tlearn: 0.0014259\ttotal: 3m 14s\tremaining: 3m 33s\n",
      "477:\tlearn: 0.0014163\ttotal: 3m 15s\tremaining: 3m 33s\n",
      "478:\tlearn: 0.0014124\ttotal: 3m 15s\tremaining: 3m 32s\n",
      "479:\tlearn: 0.0014115\ttotal: 3m 16s\tremaining: 3m 32s\n",
      "480:\tlearn: 0.0014109\ttotal: 3m 16s\tremaining: 3m 31s\n",
      "481:\tlearn: 0.0014078\ttotal: 3m 16s\tremaining: 3m 31s\n",
      "482:\tlearn: 0.0014069\ttotal: 3m 16s\tremaining: 3m 30s\n",
      "483:\tlearn: 0.0014018\ttotal: 3m 17s\tremaining: 3m 30s\n",
      "484:\tlearn: 0.0013999\ttotal: 3m 17s\tremaining: 3m 30s\n",
      "485:\tlearn: 0.0013947\ttotal: 3m 18s\tremaining: 3m 29s\n",
      "486:\tlearn: 0.0013907\ttotal: 3m 19s\tremaining: 3m 29s\n",
      "487:\tlearn: 0.0013863\ttotal: 3m 19s\tremaining: 3m 29s\n",
      "488:\tlearn: 0.0013840\ttotal: 3m 20s\tremaining: 3m 29s\n",
      "489:\tlearn: 0.0013797\ttotal: 3m 20s\tremaining: 3m 28s\n",
      "490:\tlearn: 0.0013777\ttotal: 3m 20s\tremaining: 3m 28s\n",
      "491:\tlearn: 0.0013766\ttotal: 3m 21s\tremaining: 3m 27s\n",
      "492:\tlearn: 0.0013738\ttotal: 3m 21s\tremaining: 3m 27s\n",
      "493:\tlearn: 0.0013691\ttotal: 3m 22s\tremaining: 3m 27s\n",
      "494:\tlearn: 0.0013623\ttotal: 3m 22s\tremaining: 3m 27s\n",
      "495:\tlearn: 0.0013597\ttotal: 3m 23s\tremaining: 3m 26s\n",
      "496:\tlearn: 0.0013529\ttotal: 3m 24s\tremaining: 3m 26s\n",
      "497:\tlearn: 0.0013504\ttotal: 3m 24s\tremaining: 3m 26s\n",
      "498:\tlearn: 0.0013484\ttotal: 3m 25s\tremaining: 3m 26s\n",
      "499:\tlearn: 0.0013449\ttotal: 3m 25s\tremaining: 3m 25s\n",
      "500:\tlearn: 0.0013434\ttotal: 3m 26s\tremaining: 3m 25s\n",
      "501:\tlearn: 0.0013418\ttotal: 3m 26s\tremaining: 3m 25s\n",
      "502:\tlearn: 0.0013379\ttotal: 3m 27s\tremaining: 3m 25s\n",
      "503:\tlearn: 0.0013337\ttotal: 3m 28s\tremaining: 3m 25s\n",
      "504:\tlearn: 0.0013282\ttotal: 3m 28s\tremaining: 3m 24s\n",
      "505:\tlearn: 0.0013221\ttotal: 3m 29s\tremaining: 3m 24s\n",
      "506:\tlearn: 0.0013198\ttotal: 3m 29s\tremaining: 3m 24s\n",
      "507:\tlearn: 0.0013172\ttotal: 3m 30s\tremaining: 3m 23s\n",
      "508:\tlearn: 0.0013154\ttotal: 3m 30s\tremaining: 3m 23s\n",
      "509:\tlearn: 0.0013076\ttotal: 3m 31s\tremaining: 3m 23s\n",
      "510:\tlearn: 0.0013058\ttotal: 3m 32s\tremaining: 3m 23s\n",
      "511:\tlearn: 0.0012926\ttotal: 3m 33s\tremaining: 3m 23s\n",
      "512:\tlearn: 0.0012890\ttotal: 3m 34s\tremaining: 3m 24s\n",
      "513:\tlearn: 0.0012881\ttotal: 3m 36s\tremaining: 3m 24s\n",
      "514:\tlearn: 0.0012855\ttotal: 3m 37s\tremaining: 3m 24s\n",
      "515:\tlearn: 0.0012831\ttotal: 3m 37s\tremaining: 3m 24s\n",
      "516:\tlearn: 0.0012814\ttotal: 3m 38s\tremaining: 3m 23s\n",
      "517:\tlearn: 0.0012756\ttotal: 3m 38s\tremaining: 3m 23s\n",
      "518:\tlearn: 0.0012749\ttotal: 3m 39s\tremaining: 3m 23s\n",
      "519:\tlearn: 0.0012732\ttotal: 3m 39s\tremaining: 3m 22s\n",
      "520:\tlearn: 0.0012662\ttotal: 3m 40s\tremaining: 3m 22s\n",
      "521:\tlearn: 0.0012631\ttotal: 3m 40s\tremaining: 3m 22s\n",
      "522:\tlearn: 0.0012596\ttotal: 3m 41s\tremaining: 3m 21s\n",
      "523:\tlearn: 0.0012587\ttotal: 3m 42s\tremaining: 3m 21s\n",
      "524:\tlearn: 0.0012551\ttotal: 3m 42s\tremaining: 3m 21s\n",
      "525:\tlearn: 0.0012504\ttotal: 3m 43s\tremaining: 3m 21s\n",
      "526:\tlearn: 0.0012473\ttotal: 3m 43s\tremaining: 3m 20s\n",
      "527:\tlearn: 0.0012465\ttotal: 3m 44s\tremaining: 3m 20s\n",
      "528:\tlearn: 0.0012443\ttotal: 3m 44s\tremaining: 3m 20s\n",
      "529:\tlearn: 0.0012392\ttotal: 3m 45s\tremaining: 3m 19s\n",
      "530:\tlearn: 0.0012318\ttotal: 3m 45s\tremaining: 3m 19s\n",
      "531:\tlearn: 0.0012292\ttotal: 3m 46s\tremaining: 3m 19s\n",
      "532:\tlearn: 0.0012227\ttotal: 3m 46s\tremaining: 3m 18s\n",
      "533:\tlearn: 0.0012163\ttotal: 3m 47s\tremaining: 3m 18s\n",
      "534:\tlearn: 0.0012105\ttotal: 3m 47s\tremaining: 3m 17s\n",
      "535:\tlearn: 0.0012012\ttotal: 3m 48s\tremaining: 3m 17s\n",
      "536:\tlearn: 0.0011984\ttotal: 3m 49s\tremaining: 3m 17s\n",
      "537:\tlearn: 0.0011971\ttotal: 3m 49s\tremaining: 3m 17s\n",
      "538:\tlearn: 0.0011942\ttotal: 3m 50s\tremaining: 3m 16s\n",
      "539:\tlearn: 0.0011904\ttotal: 3m 50s\tremaining: 3m 16s\n",
      "540:\tlearn: 0.0011864\ttotal: 3m 51s\tremaining: 3m 16s\n",
      "541:\tlearn: 0.0011843\ttotal: 3m 52s\tremaining: 3m 16s\n",
      "542:\tlearn: 0.0011794\ttotal: 3m 52s\tremaining: 3m 15s\n",
      "543:\tlearn: 0.0011759\ttotal: 3m 53s\tremaining: 3m 15s\n",
      "544:\tlearn: 0.0011727\ttotal: 3m 54s\tremaining: 3m 15s\n",
      "545:\tlearn: 0.0011630\ttotal: 3m 55s\tremaining: 3m 15s\n",
      "546:\tlearn: 0.0011612\ttotal: 3m 57s\tremaining: 3m 16s\n",
      "547:\tlearn: 0.0011575\ttotal: 3m 59s\tremaining: 3m 17s\n",
      "548:\tlearn: 0.0011546\ttotal: 3m 59s\tremaining: 3m 16s\n",
      "549:\tlearn: 0.0011482\ttotal: 3m 59s\tremaining: 3m 16s\n",
      "550:\tlearn: 0.0011458\ttotal: 4m\tremaining: 3m 15s\n",
      "551:\tlearn: 0.0011373\ttotal: 4m\tremaining: 3m 15s\n",
      "552:\tlearn: 0.0011289\ttotal: 4m\tremaining: 3m 14s\n",
      "553:\tlearn: 0.0011275\ttotal: 4m 1s\tremaining: 3m 14s\n",
      "554:\tlearn: 0.0011237\ttotal: 4m 1s\tremaining: 3m 13s\n",
      "555:\tlearn: 0.0011222\ttotal: 4m 2s\tremaining: 3m 13s\n",
      "556:\tlearn: 0.0011206\ttotal: 4m 2s\tremaining: 3m 13s\n",
      "557:\tlearn: 0.0011177\ttotal: 4m 3s\tremaining: 3m 12s\n",
      "558:\tlearn: 0.0011166\ttotal: 4m 3s\tremaining: 3m 12s\n",
      "559:\tlearn: 0.0011137\ttotal: 4m 3s\tremaining: 3m 11s\n",
      "560:\tlearn: 0.0011126\ttotal: 4m 4s\tremaining: 3m 11s\n",
      "561:\tlearn: 0.0011067\ttotal: 4m 4s\tremaining: 3m 10s\n",
      "562:\tlearn: 0.0011049\ttotal: 4m 4s\tremaining: 3m 10s\n",
      "563:\tlearn: 0.0011014\ttotal: 4m 5s\tremaining: 3m 9s\n",
      "564:\tlearn: 0.0010986\ttotal: 4m 5s\tremaining: 3m 9s\n",
      "565:\tlearn: 0.0010834\ttotal: 4m 6s\tremaining: 3m 8s\n",
      "566:\tlearn: 0.0010831\ttotal: 4m 6s\tremaining: 3m 8s\n",
      "567:\tlearn: 0.0010822\ttotal: 4m 6s\tremaining: 3m 7s\n",
      "568:\tlearn: 0.0010805\ttotal: 4m 7s\tremaining: 3m 7s\n",
      "569:\tlearn: 0.0010730\ttotal: 4m 7s\tremaining: 3m 6s\n",
      "570:\tlearn: 0.0010707\ttotal: 4m 8s\tremaining: 3m 6s\n",
      "571:\tlearn: 0.0010691\ttotal: 4m 8s\tremaining: 3m 5s\n",
      "572:\tlearn: 0.0010686\ttotal: 4m 8s\tremaining: 3m 5s\n",
      "573:\tlearn: 0.0010620\ttotal: 4m 9s\tremaining: 3m 4s\n",
      "574:\tlearn: 0.0010595\ttotal: 4m 9s\tremaining: 3m 4s\n",
      "575:\tlearn: 0.0010547\ttotal: 4m 9s\tremaining: 3m 3s\n",
      "576:\tlearn: 0.0010538\ttotal: 4m 9s\tremaining: 3m 3s\n",
      "577:\tlearn: 0.0010520\ttotal: 4m 10s\tremaining: 3m 2s\n",
      "578:\tlearn: 0.0010512\ttotal: 4m 10s\tremaining: 3m 2s\n",
      "579:\tlearn: 0.0010477\ttotal: 4m 11s\tremaining: 3m 2s\n",
      "580:\tlearn: 0.0010381\ttotal: 4m 12s\tremaining: 3m 1s\n",
      "581:\tlearn: 0.0010362\ttotal: 4m 12s\tremaining: 3m 1s\n",
      "582:\tlearn: 0.0010341\ttotal: 4m 13s\tremaining: 3m 1s\n",
      "583:\tlearn: 0.0010318\ttotal: 4m 13s\tremaining: 3m\n",
      "584:\tlearn: 0.0010313\ttotal: 4m 13s\tremaining: 3m\n",
      "585:\tlearn: 0.0010282\ttotal: 4m 14s\tremaining: 2m 59s\n",
      "586:\tlearn: 0.0010234\ttotal: 4m 14s\tremaining: 2m 59s\n",
      "587:\tlearn: 0.0010123\ttotal: 4m 15s\tremaining: 2m 58s\n",
      "588:\tlearn: 0.0010106\ttotal: 4m 15s\tremaining: 2m 58s\n",
      "589:\tlearn: 0.0010088\ttotal: 4m 16s\tremaining: 2m 57s\n",
      "590:\tlearn: 0.0010052\ttotal: 4m 16s\tremaining: 2m 57s\n",
      "591:\tlearn: 0.0010043\ttotal: 4m 16s\tremaining: 2m 57s\n",
      "592:\tlearn: 0.0010035\ttotal: 4m 17s\tremaining: 2m 56s\n",
      "593:\tlearn: 0.0009981\ttotal: 4m 17s\tremaining: 2m 56s\n",
      "594:\tlearn: 0.0009957\ttotal: 4m 18s\tremaining: 2m 55s\n",
      "595:\tlearn: 0.0009920\ttotal: 4m 18s\tremaining: 2m 55s\n",
      "596:\tlearn: 0.0009891\ttotal: 4m 18s\tremaining: 2m 54s\n",
      "597:\tlearn: 0.0009866\ttotal: 4m 19s\tremaining: 2m 54s\n",
      "598:\tlearn: 0.0009843\ttotal: 4m 19s\tremaining: 2m 53s\n",
      "599:\tlearn: 0.0009818\ttotal: 4m 19s\tremaining: 2m 53s\n",
      "600:\tlearn: 0.0009809\ttotal: 4m 20s\tremaining: 2m 52s\n",
      "601:\tlearn: 0.0009782\ttotal: 4m 20s\tremaining: 2m 52s\n",
      "602:\tlearn: 0.0009764\ttotal: 4m 21s\tremaining: 2m 51s\n",
      "603:\tlearn: 0.0009740\ttotal: 4m 21s\tremaining: 2m 51s\n",
      "604:\tlearn: 0.0009678\ttotal: 4m 21s\tremaining: 2m 50s\n",
      "605:\tlearn: 0.0009647\ttotal: 4m 22s\tremaining: 2m 50s\n",
      "606:\tlearn: 0.0009617\ttotal: 4m 22s\tremaining: 2m 49s\n",
      "607:\tlearn: 0.0009610\ttotal: 4m 22s\tremaining: 2m 49s\n",
      "608:\tlearn: 0.0009581\ttotal: 4m 23s\tremaining: 2m 49s\n",
      "609:\tlearn: 0.0009545\ttotal: 4m 23s\tremaining: 2m 48s\n",
      "610:\tlearn: 0.0009536\ttotal: 4m 24s\tremaining: 2m 48s\n",
      "611:\tlearn: 0.0009532\ttotal: 4m 24s\tremaining: 2m 47s\n",
      "612:\tlearn: 0.0009506\ttotal: 4m 25s\tremaining: 2m 47s\n",
      "613:\tlearn: 0.0009496\ttotal: 4m 25s\tremaining: 2m 46s\n",
      "614:\tlearn: 0.0009447\ttotal: 4m 26s\tremaining: 2m 46s\n",
      "615:\tlearn: 0.0009442\ttotal: 4m 26s\tremaining: 2m 46s\n",
      "616:\tlearn: 0.0009425\ttotal: 4m 27s\tremaining: 2m 45s\n",
      "617:\tlearn: 0.0009411\ttotal: 4m 27s\tremaining: 2m 45s\n",
      "618:\tlearn: 0.0009398\ttotal: 4m 28s\tremaining: 2m 45s\n",
      "619:\tlearn: 0.0009388\ttotal: 4m 29s\tremaining: 2m 44s\n",
      "620:\tlearn: 0.0009353\ttotal: 4m 29s\tremaining: 2m 44s\n",
      "621:\tlearn: 0.0009344\ttotal: 4m 30s\tremaining: 2m 44s\n",
      "622:\tlearn: 0.0009323\ttotal: 4m 31s\tremaining: 2m 44s\n",
      "623:\tlearn: 0.0009291\ttotal: 4m 31s\tremaining: 2m 43s\n",
      "624:\tlearn: 0.0009284\ttotal: 4m 32s\tremaining: 2m 43s\n",
      "625:\tlearn: 0.0009277\ttotal: 4m 32s\tremaining: 2m 42s\n",
      "626:\tlearn: 0.0009264\ttotal: 4m 33s\tremaining: 2m 42s\n",
      "627:\tlearn: 0.0009246\ttotal: 4m 33s\tremaining: 2m 42s\n",
      "628:\tlearn: 0.0009215\ttotal: 4m 34s\tremaining: 2m 41s\n",
      "629:\tlearn: 0.0009195\ttotal: 4m 34s\tremaining: 2m 41s\n",
      "630:\tlearn: 0.0009183\ttotal: 4m 34s\tremaining: 2m 40s\n",
      "631:\tlearn: 0.0009175\ttotal: 4m 35s\tremaining: 2m 40s\n",
      "632:\tlearn: 0.0009160\ttotal: 4m 35s\tremaining: 2m 39s\n",
      "633:\tlearn: 0.0009130\ttotal: 4m 35s\tremaining: 2m 39s\n",
      "634:\tlearn: 0.0009107\ttotal: 4m 36s\tremaining: 2m 38s\n",
      "635:\tlearn: 0.0009097\ttotal: 4m 36s\tremaining: 2m 38s\n",
      "636:\tlearn: 0.0009069\ttotal: 4m 37s\tremaining: 2m 38s\n",
      "637:\tlearn: 0.0009032\ttotal: 4m 37s\tremaining: 2m 37s\n",
      "638:\tlearn: 0.0009025\ttotal: 4m 38s\tremaining: 2m 37s\n",
      "639:\tlearn: 0.0009004\ttotal: 4m 38s\tremaining: 2m 36s\n",
      "640:\tlearn: 0.0008990\ttotal: 4m 39s\tremaining: 2m 36s\n",
      "641:\tlearn: 0.0008947\ttotal: 4m 39s\tremaining: 2m 35s\n",
      "642:\tlearn: 0.0008885\ttotal: 4m 39s\tremaining: 2m 35s\n",
      "643:\tlearn: 0.0008861\ttotal: 4m 40s\tremaining: 2m 34s\n",
      "644:\tlearn: 0.0008851\ttotal: 4m 40s\tremaining: 2m 34s\n",
      "645:\tlearn: 0.0008821\ttotal: 4m 41s\tremaining: 2m 34s\n",
      "646:\tlearn: 0.0008742\ttotal: 4m 41s\tremaining: 2m 33s\n",
      "647:\tlearn: 0.0008738\ttotal: 4m 41s\tremaining: 2m 33s\n",
      "648:\tlearn: 0.0008724\ttotal: 4m 42s\tremaining: 2m 32s\n",
      "649:\tlearn: 0.0008700\ttotal: 4m 42s\tremaining: 2m 32s\n",
      "650:\tlearn: 0.0008683\ttotal: 4m 43s\tremaining: 2m 31s\n",
      "651:\tlearn: 0.0008672\ttotal: 4m 43s\tremaining: 2m 31s\n",
      "652:\tlearn: 0.0008657\ttotal: 4m 43s\tremaining: 2m 30s\n",
      "653:\tlearn: 0.0008608\ttotal: 4m 44s\tremaining: 2m 30s\n",
      "654:\tlearn: 0.0008603\ttotal: 4m 44s\tremaining: 2m 29s\n",
      "655:\tlearn: 0.0008596\ttotal: 4m 45s\tremaining: 2m 29s\n",
      "656:\tlearn: 0.0008586\ttotal: 4m 45s\tremaining: 2m 29s\n",
      "657:\tlearn: 0.0008534\ttotal: 4m 46s\tremaining: 2m 28s\n",
      "658:\tlearn: 0.0008501\ttotal: 4m 46s\tremaining: 2m 28s\n",
      "659:\tlearn: 0.0008484\ttotal: 4m 46s\tremaining: 2m 27s\n",
      "660:\tlearn: 0.0008444\ttotal: 4m 47s\tremaining: 2m 27s\n",
      "661:\tlearn: 0.0008424\ttotal: 4m 47s\tremaining: 2m 26s\n",
      "662:\tlearn: 0.0008409\ttotal: 4m 48s\tremaining: 2m 26s\n",
      "663:\tlearn: 0.0008400\ttotal: 4m 48s\tremaining: 2m 26s\n",
      "664:\tlearn: 0.0008384\ttotal: 4m 49s\tremaining: 2m 25s\n",
      "665:\tlearn: 0.0008376\ttotal: 4m 49s\tremaining: 2m 25s\n",
      "666:\tlearn: 0.0008370\ttotal: 4m 49s\tremaining: 2m 24s\n",
      "667:\tlearn: 0.0008362\ttotal: 4m 50s\tremaining: 2m 24s\n",
      "668:\tlearn: 0.0008345\ttotal: 4m 50s\tremaining: 2m 23s\n",
      "669:\tlearn: 0.0008334\ttotal: 4m 51s\tremaining: 2m 23s\n",
      "670:\tlearn: 0.0008331\ttotal: 4m 51s\tremaining: 2m 22s\n",
      "671:\tlearn: 0.0008276\ttotal: 4m 52s\tremaining: 2m 22s\n",
      "672:\tlearn: 0.0008266\ttotal: 4m 52s\tremaining: 2m 22s\n",
      "673:\tlearn: 0.0008257\ttotal: 4m 53s\tremaining: 2m 21s\n",
      "674:\tlearn: 0.0008247\ttotal: 4m 53s\tremaining: 2m 21s\n",
      "675:\tlearn: 0.0008204\ttotal: 4m 54s\tremaining: 2m 21s\n",
      "676:\tlearn: 0.0008200\ttotal: 4m 54s\tremaining: 2m 20s\n",
      "677:\tlearn: 0.0008195\ttotal: 4m 55s\tremaining: 2m 20s\n",
      "678:\tlearn: 0.0008190\ttotal: 4m 55s\tremaining: 2m 19s\n",
      "679:\tlearn: 0.0008173\ttotal: 4m 56s\tremaining: 2m 19s\n",
      "680:\tlearn: 0.0008129\ttotal: 4m 57s\tremaining: 2m 19s\n",
      "681:\tlearn: 0.0008098\ttotal: 4m 57s\tremaining: 2m 18s\n",
      "682:\tlearn: 0.0008077\ttotal: 4m 58s\tremaining: 2m 18s\n",
      "683:\tlearn: 0.0008039\ttotal: 4m 58s\tremaining: 2m 17s\n",
      "684:\tlearn: 0.0008034\ttotal: 4m 58s\tremaining: 2m 17s\n",
      "685:\tlearn: 0.0008014\ttotal: 4m 59s\tremaining: 2m 17s\n",
      "686:\tlearn: 0.0008011\ttotal: 4m 59s\tremaining: 2m 16s\n",
      "687:\tlearn: 0.0007930\ttotal: 5m\tremaining: 2m 16s\n",
      "688:\tlearn: 0.0007917\ttotal: 5m\tremaining: 2m 15s\n",
      "689:\tlearn: 0.0007899\ttotal: 5m\tremaining: 2m 15s\n",
      "690:\tlearn: 0.0007849\ttotal: 5m 1s\tremaining: 2m 14s\n",
      "691:\tlearn: 0.0007831\ttotal: 5m 1s\tremaining: 2m 14s\n",
      "692:\tlearn: 0.0007816\ttotal: 5m 2s\tremaining: 2m 13s\n",
      "693:\tlearn: 0.0007790\ttotal: 5m 2s\tremaining: 2m 13s\n",
      "694:\tlearn: 0.0007750\ttotal: 5m 2s\tremaining: 2m 12s\n",
      "695:\tlearn: 0.0007734\ttotal: 5m 3s\tremaining: 2m 12s\n",
      "696:\tlearn: 0.0007698\ttotal: 5m 3s\tremaining: 2m 12s\n",
      "697:\tlearn: 0.0007682\ttotal: 5m 4s\tremaining: 2m 11s\n",
      "698:\tlearn: 0.0007675\ttotal: 5m 4s\tremaining: 2m 11s\n",
      "699:\tlearn: 0.0007664\ttotal: 5m 4s\tremaining: 2m 10s\n",
      "700:\tlearn: 0.0007651\ttotal: 5m 5s\tremaining: 2m 10s\n",
      "701:\tlearn: 0.0007636\ttotal: 5m 5s\tremaining: 2m 9s\n",
      "702:\tlearn: 0.0007627\ttotal: 5m 5s\tremaining: 2m 9s\n",
      "703:\tlearn: 0.0007600\ttotal: 5m 6s\tremaining: 2m 8s\n",
      "704:\tlearn: 0.0007571\ttotal: 5m 6s\tremaining: 2m 8s\n",
      "705:\tlearn: 0.0007562\ttotal: 5m 6s\tremaining: 2m 7s\n",
      "706:\tlearn: 0.0007549\ttotal: 5m 7s\tremaining: 2m 7s\n",
      "707:\tlearn: 0.0007539\ttotal: 5m 7s\tremaining: 2m 6s\n",
      "708:\tlearn: 0.0007515\ttotal: 5m 8s\tremaining: 2m 6s\n",
      "709:\tlearn: 0.0007509\ttotal: 5m 8s\tremaining: 2m 6s\n",
      "710:\tlearn: 0.0007496\ttotal: 5m 9s\tremaining: 2m 5s\n",
      "711:\tlearn: 0.0007489\ttotal: 5m 9s\tremaining: 2m 5s\n",
      "712:\tlearn: 0.0007461\ttotal: 5m 9s\tremaining: 2m 4s\n",
      "713:\tlearn: 0.0007455\ttotal: 5m 10s\tremaining: 2m 4s\n",
      "714:\tlearn: 0.0007441\ttotal: 5m 10s\tremaining: 2m 3s\n",
      "715:\tlearn: 0.0007428\ttotal: 5m 10s\tremaining: 2m 3s\n",
      "716:\tlearn: 0.0007392\ttotal: 5m 11s\tremaining: 2m 2s\n",
      "717:\tlearn: 0.0007383\ttotal: 5m 11s\tremaining: 2m 2s\n",
      "718:\tlearn: 0.0007367\ttotal: 5m 12s\tremaining: 2m 2s\n",
      "719:\tlearn: 0.0007359\ttotal: 5m 12s\tremaining: 2m 1s\n",
      "720:\tlearn: 0.0007337\ttotal: 5m 12s\tremaining: 2m 1s\n",
      "721:\tlearn: 0.0007327\ttotal: 5m 13s\tremaining: 2m\n",
      "722:\tlearn: 0.0007319\ttotal: 5m 13s\tremaining: 2m\n",
      "723:\tlearn: 0.0007306\ttotal: 5m 14s\tremaining: 1m 59s\n",
      "724:\tlearn: 0.0007289\ttotal: 5m 14s\tremaining: 1m 59s\n",
      "725:\tlearn: 0.0007250\ttotal: 5m 15s\tremaining: 1m 58s\n",
      "726:\tlearn: 0.0007240\ttotal: 5m 15s\tremaining: 1m 58s\n",
      "727:\tlearn: 0.0007230\ttotal: 5m 16s\tremaining: 1m 58s\n",
      "728:\tlearn: 0.0007224\ttotal: 5m 16s\tremaining: 1m 57s\n",
      "729:\tlearn: 0.0007217\ttotal: 5m 17s\tremaining: 1m 57s\n",
      "730:\tlearn: 0.0007204\ttotal: 5m 17s\tremaining: 1m 56s\n",
      "731:\tlearn: 0.0007195\ttotal: 5m 18s\tremaining: 1m 56s\n",
      "732:\tlearn: 0.0007185\ttotal: 5m 18s\tremaining: 1m 56s\n",
      "733:\tlearn: 0.0007169\ttotal: 5m 18s\tremaining: 1m 55s\n",
      "734:\tlearn: 0.0007160\ttotal: 5m 19s\tremaining: 1m 55s\n",
      "735:\tlearn: 0.0007151\ttotal: 5m 19s\tremaining: 1m 54s\n",
      "736:\tlearn: 0.0007135\ttotal: 5m 20s\tremaining: 1m 54s\n",
      "737:\tlearn: 0.0007131\ttotal: 5m 20s\tremaining: 1m 53s\n",
      "738:\tlearn: 0.0007088\ttotal: 5m 21s\tremaining: 1m 53s\n",
      "739:\tlearn: 0.0007077\ttotal: 5m 21s\tremaining: 1m 53s\n",
      "740:\tlearn: 0.0007068\ttotal: 5m 22s\tremaining: 1m 52s\n",
      "741:\tlearn: 0.0007060\ttotal: 5m 22s\tremaining: 1m 52s\n",
      "742:\tlearn: 0.0007023\ttotal: 5m 23s\tremaining: 1m 51s\n",
      "743:\tlearn: 0.0007005\ttotal: 5m 23s\tremaining: 1m 51s\n",
      "744:\tlearn: 0.0006993\ttotal: 5m 24s\tremaining: 1m 50s\n",
      "745:\tlearn: 0.0006957\ttotal: 5m 24s\tremaining: 1m 50s\n",
      "746:\tlearn: 0.0006950\ttotal: 5m 24s\tremaining: 1m 50s\n",
      "747:\tlearn: 0.0006937\ttotal: 5m 25s\tremaining: 1m 49s\n",
      "748:\tlearn: 0.0006910\ttotal: 5m 26s\tremaining: 1m 49s\n",
      "749:\tlearn: 0.0006904\ttotal: 5m 26s\tremaining: 1m 48s\n",
      "750:\tlearn: 0.0006879\ttotal: 5m 27s\tremaining: 1m 48s\n",
      "751:\tlearn: 0.0006874\ttotal: 5m 27s\tremaining: 1m 47s\n",
      "752:\tlearn: 0.0006865\ttotal: 5m 27s\tremaining: 1m 47s\n",
      "753:\tlearn: 0.0006857\ttotal: 5m 28s\tremaining: 1m 47s\n",
      "754:\tlearn: 0.0006847\ttotal: 5m 28s\tremaining: 1m 46s\n",
      "755:\tlearn: 0.0006843\ttotal: 5m 28s\tremaining: 1m 46s\n",
      "756:\tlearn: 0.0006832\ttotal: 5m 29s\tremaining: 1m 45s\n",
      "757:\tlearn: 0.0006824\ttotal: 5m 29s\tremaining: 1m 45s\n",
      "758:\tlearn: 0.0006813\ttotal: 5m 29s\tremaining: 1m 44s\n",
      "759:\tlearn: 0.0006810\ttotal: 5m 30s\tremaining: 1m 44s\n",
      "760:\tlearn: 0.0006789\ttotal: 5m 30s\tremaining: 1m 43s\n",
      "761:\tlearn: 0.0006778\ttotal: 5m 31s\tremaining: 1m 43s\n",
      "762:\tlearn: 0.0006775\ttotal: 5m 31s\tremaining: 1m 42s\n",
      "763:\tlearn: 0.0006757\ttotal: 5m 32s\tremaining: 1m 42s\n",
      "764:\tlearn: 0.0006747\ttotal: 5m 32s\tremaining: 1m 42s\n",
      "765:\tlearn: 0.0006736\ttotal: 5m 32s\tremaining: 1m 41s\n",
      "766:\tlearn: 0.0006727\ttotal: 5m 33s\tremaining: 1m 41s\n",
      "767:\tlearn: 0.0006701\ttotal: 5m 33s\tremaining: 1m 40s\n",
      "768:\tlearn: 0.0006696\ttotal: 5m 34s\tremaining: 1m 40s\n",
      "769:\tlearn: 0.0006686\ttotal: 5m 34s\tremaining: 1m 39s\n",
      "770:\tlearn: 0.0006668\ttotal: 5m 34s\tremaining: 1m 39s\n",
      "771:\tlearn: 0.0006644\ttotal: 5m 35s\tremaining: 1m 38s\n",
      "772:\tlearn: 0.0006634\ttotal: 5m 35s\tremaining: 1m 38s\n",
      "773:\tlearn: 0.0006623\ttotal: 5m 35s\tremaining: 1m 38s\n",
      "774:\tlearn: 0.0006610\ttotal: 5m 36s\tremaining: 1m 37s\n",
      "775:\tlearn: 0.0006606\ttotal: 5m 36s\tremaining: 1m 37s\n",
      "776:\tlearn: 0.0006598\ttotal: 5m 36s\tremaining: 1m 36s\n",
      "777:\tlearn: 0.0006582\ttotal: 5m 37s\tremaining: 1m 36s\n",
      "778:\tlearn: 0.0006570\ttotal: 5m 37s\tremaining: 1m 35s\n",
      "779:\tlearn: 0.0006548\ttotal: 5m 38s\tremaining: 1m 35s\n",
      "780:\tlearn: 0.0006542\ttotal: 5m 38s\tremaining: 1m 34s\n",
      "781:\tlearn: 0.0006528\ttotal: 5m 39s\tremaining: 1m 34s\n",
      "782:\tlearn: 0.0006518\ttotal: 5m 39s\tremaining: 1m 34s\n",
      "783:\tlearn: 0.0006515\ttotal: 5m 39s\tremaining: 1m 33s\n",
      "784:\tlearn: 0.0006490\ttotal: 5m 40s\tremaining: 1m 33s\n",
      "785:\tlearn: 0.0006480\ttotal: 5m 40s\tremaining: 1m 32s\n",
      "786:\tlearn: 0.0006463\ttotal: 5m 41s\tremaining: 1m 32s\n",
      "787:\tlearn: 0.0006457\ttotal: 5m 41s\tremaining: 1m 31s\n",
      "788:\tlearn: 0.0006415\ttotal: 5m 42s\tremaining: 1m 31s\n",
      "789:\tlearn: 0.0006407\ttotal: 5m 42s\tremaining: 1m 31s\n",
      "790:\tlearn: 0.0006398\ttotal: 5m 43s\tremaining: 1m 30s\n",
      "791:\tlearn: 0.0006388\ttotal: 5m 43s\tremaining: 1m 30s\n",
      "792:\tlearn: 0.0006385\ttotal: 5m 43s\tremaining: 1m 29s\n",
      "793:\tlearn: 0.0006340\ttotal: 5m 44s\tremaining: 1m 29s\n",
      "794:\tlearn: 0.0006334\ttotal: 5m 44s\tremaining: 1m 28s\n",
      "795:\tlearn: 0.0006317\ttotal: 5m 44s\tremaining: 1m 28s\n",
      "796:\tlearn: 0.0006293\ttotal: 5m 45s\tremaining: 1m 28s\n",
      "797:\tlearn: 0.0006290\ttotal: 5m 45s\tremaining: 1m 27s\n",
      "798:\tlearn: 0.0006286\ttotal: 5m 46s\tremaining: 1m 27s\n",
      "799:\tlearn: 0.0006279\ttotal: 5m 46s\tremaining: 1m 26s\n",
      "800:\tlearn: 0.0006274\ttotal: 5m 47s\tremaining: 1m 26s\n",
      "801:\tlearn: 0.0006255\ttotal: 5m 47s\tremaining: 1m 25s\n",
      "802:\tlearn: 0.0006246\ttotal: 5m 47s\tremaining: 1m 25s\n",
      "803:\tlearn: 0.0006215\ttotal: 5m 48s\tremaining: 1m 24s\n",
      "804:\tlearn: 0.0006209\ttotal: 5m 48s\tremaining: 1m 24s\n",
      "805:\tlearn: 0.0006203\ttotal: 5m 49s\tremaining: 1m 24s\n",
      "806:\tlearn: 0.0006190\ttotal: 5m 49s\tremaining: 1m 23s\n",
      "807:\tlearn: 0.0006189\ttotal: 5m 49s\tremaining: 1m 23s\n",
      "808:\tlearn: 0.0006184\ttotal: 5m 50s\tremaining: 1m 22s\n",
      "809:\tlearn: 0.0006180\ttotal: 5m 50s\tremaining: 1m 22s\n",
      "810:\tlearn: 0.0006164\ttotal: 5m 51s\tremaining: 1m 21s\n",
      "811:\tlearn: 0.0006148\ttotal: 5m 51s\tremaining: 1m 21s\n",
      "812:\tlearn: 0.0006139\ttotal: 5m 51s\tremaining: 1m 20s\n",
      "813:\tlearn: 0.0006110\ttotal: 5m 52s\tremaining: 1m 20s\n",
      "814:\tlearn: 0.0006100\ttotal: 5m 52s\tremaining: 1m 20s\n",
      "815:\tlearn: 0.0006076\ttotal: 5m 52s\tremaining: 1m 19s\n",
      "816:\tlearn: 0.0006068\ttotal: 5m 53s\tremaining: 1m 19s\n",
      "817:\tlearn: 0.0006060\ttotal: 5m 53s\tremaining: 1m 18s\n",
      "818:\tlearn: 0.0006012\ttotal: 5m 54s\tremaining: 1m 18s\n",
      "819:\tlearn: 0.0006009\ttotal: 5m 54s\tremaining: 1m 17s\n",
      "820:\tlearn: 0.0006006\ttotal: 5m 54s\tremaining: 1m 17s\n",
      "821:\tlearn: 0.0006000\ttotal: 5m 55s\tremaining: 1m 16s\n",
      "822:\tlearn: 0.0005987\ttotal: 5m 55s\tremaining: 1m 16s\n",
      "823:\tlearn: 0.0005981\ttotal: 5m 56s\tremaining: 1m 16s\n",
      "824:\tlearn: 0.0005975\ttotal: 5m 56s\tremaining: 1m 15s\n",
      "825:\tlearn: 0.0005972\ttotal: 5m 56s\tremaining: 1m 15s\n",
      "826:\tlearn: 0.0005960\ttotal: 5m 57s\tremaining: 1m 14s\n",
      "827:\tlearn: 0.0005936\ttotal: 5m 57s\tremaining: 1m 14s\n",
      "828:\tlearn: 0.0005915\ttotal: 5m 57s\tremaining: 1m 13s\n",
      "829:\tlearn: 0.0005908\ttotal: 5m 58s\tremaining: 1m 13s\n",
      "830:\tlearn: 0.0005899\ttotal: 5m 58s\tremaining: 1m 12s\n",
      "831:\tlearn: 0.0005894\ttotal: 5m 58s\tremaining: 1m 12s\n",
      "832:\tlearn: 0.0005892\ttotal: 5m 59s\tremaining: 1m 11s\n",
      "833:\tlearn: 0.0005887\ttotal: 5m 59s\tremaining: 1m 11s\n",
      "834:\tlearn: 0.0005862\ttotal: 5m 59s\tremaining: 1m 11s\n",
      "835:\tlearn: 0.0005856\ttotal: 6m\tremaining: 1m 10s\n",
      "836:\tlearn: 0.0005840\ttotal: 6m\tremaining: 1m 10s\n",
      "837:\tlearn: 0.0005830\ttotal: 6m\tremaining: 1m 9s\n",
      "838:\tlearn: 0.0005829\ttotal: 6m 1s\tremaining: 1m 9s\n",
      "839:\tlearn: 0.0005823\ttotal: 6m 1s\tremaining: 1m 8s\n",
      "840:\tlearn: 0.0005799\ttotal: 6m 1s\tremaining: 1m 8s\n",
      "841:\tlearn: 0.0005787\ttotal: 6m 1s\tremaining: 1m 7s\n",
      "842:\tlearn: 0.0005779\ttotal: 6m 2s\tremaining: 1m 7s\n",
      "843:\tlearn: 0.0005764\ttotal: 6m 2s\tremaining: 1m 7s\n",
      "844:\tlearn: 0.0005755\ttotal: 6m 3s\tremaining: 1m 6s\n",
      "845:\tlearn: 0.0005752\ttotal: 6m 3s\tremaining: 1m 6s\n",
      "846:\tlearn: 0.0005749\ttotal: 6m 4s\tremaining: 1m 5s\n",
      "847:\tlearn: 0.0005746\ttotal: 6m 4s\tremaining: 1m 5s\n",
      "848:\tlearn: 0.0005734\ttotal: 6m 5s\tremaining: 1m 5s\n",
      "849:\tlearn: 0.0005730\ttotal: 6m 7s\tremaining: 1m 4s\n",
      "850:\tlearn: 0.0005725\ttotal: 6m 8s\tremaining: 1m 4s\n",
      "851:\tlearn: 0.0005702\ttotal: 6m 9s\tremaining: 1m 4s\n",
      "852:\tlearn: 0.0005690\ttotal: 6m 10s\tremaining: 1m 3s\n",
      "853:\tlearn: 0.0005664\ttotal: 6m 12s\tremaining: 1m 3s\n",
      "854:\tlearn: 0.0005643\ttotal: 6m 14s\tremaining: 1m 3s\n",
      "855:\tlearn: 0.0005612\ttotal: 6m 15s\tremaining: 1m 3s\n",
      "856:\tlearn: 0.0005608\ttotal: 6m 15s\tremaining: 1m 2s\n",
      "857:\tlearn: 0.0005605\ttotal: 6m 16s\tremaining: 1m 2s\n",
      "858:\tlearn: 0.0005598\ttotal: 6m 17s\tremaining: 1m 1s\n",
      "859:\tlearn: 0.0005591\ttotal: 6m 18s\tremaining: 1m 1s\n",
      "860:\tlearn: 0.0005560\ttotal: 6m 18s\tremaining: 1m 1s\n",
      "861:\tlearn: 0.0005541\ttotal: 6m 19s\tremaining: 1m\n",
      "862:\tlearn: 0.0005539\ttotal: 6m 21s\tremaining: 1m\n",
      "863:\tlearn: 0.0005537\ttotal: 6m 22s\tremaining: 1m\n",
      "864:\tlearn: 0.0005521\ttotal: 6m 22s\tremaining: 59.7s\n",
      "865:\tlearn: 0.0005506\ttotal: 6m 23s\tremaining: 59.3s\n",
      "866:\tlearn: 0.0005480\ttotal: 6m 24s\tremaining: 58.9s\n",
      "867:\tlearn: 0.0005476\ttotal: 6m 24s\tremaining: 58.5s\n",
      "868:\tlearn: 0.0005468\ttotal: 6m 25s\tremaining: 58.1s\n",
      "869:\tlearn: 0.0005457\ttotal: 6m 26s\tremaining: 57.7s\n",
      "870:\tlearn: 0.0005453\ttotal: 6m 27s\tremaining: 57.4s\n",
      "871:\tlearn: 0.0005452\ttotal: 6m 28s\tremaining: 57s\n",
      "872:\tlearn: 0.0005449\ttotal: 6m 29s\tremaining: 56.6s\n",
      "873:\tlearn: 0.0005443\ttotal: 6m 29s\tremaining: 56.2s\n",
      "874:\tlearn: 0.0005438\ttotal: 6m 30s\tremaining: 55.8s\n",
      "875:\tlearn: 0.0005431\ttotal: 6m 31s\tremaining: 55.4s\n",
      "876:\tlearn: 0.0005425\ttotal: 6m 32s\tremaining: 55s\n",
      "877:\tlearn: 0.0005417\ttotal: 6m 32s\tremaining: 54.6s\n",
      "878:\tlearn: 0.0005402\ttotal: 6m 33s\tremaining: 54.2s\n",
      "879:\tlearn: 0.0005392\ttotal: 6m 34s\tremaining: 53.8s\n",
      "880:\tlearn: 0.0005390\ttotal: 6m 35s\tremaining: 53.4s\n",
      "881:\tlearn: 0.0005386\ttotal: 6m 35s\tremaining: 53s\n",
      "882:\tlearn: 0.0005384\ttotal: 6m 36s\tremaining: 52.6s\n",
      "883:\tlearn: 0.0005374\ttotal: 6m 37s\tremaining: 52.1s\n",
      "884:\tlearn: 0.0005372\ttotal: 6m 37s\tremaining: 51.7s\n",
      "885:\tlearn: 0.0005367\ttotal: 6m 38s\tremaining: 51.3s\n",
      "886:\tlearn: 0.0005339\ttotal: 6m 39s\tremaining: 50.8s\n",
      "887:\tlearn: 0.0005331\ttotal: 6m 39s\tremaining: 50.4s\n",
      "888:\tlearn: 0.0005323\ttotal: 6m 40s\tremaining: 50s\n",
      "889:\tlearn: 0.0005288\ttotal: 6m 41s\tremaining: 49.6s\n",
      "890:\tlearn: 0.0005281\ttotal: 6m 42s\tremaining: 49.2s\n",
      "891:\tlearn: 0.0005263\ttotal: 6m 42s\tremaining: 48.8s\n",
      "892:\tlearn: 0.0005254\ttotal: 6m 43s\tremaining: 48.4s\n",
      "893:\tlearn: 0.0005252\ttotal: 6m 44s\tremaining: 47.9s\n",
      "894:\tlearn: 0.0005248\ttotal: 6m 44s\tremaining: 47.5s\n",
      "895:\tlearn: 0.0005243\ttotal: 6m 45s\tremaining: 47.1s\n",
      "896:\tlearn: 0.0005238\ttotal: 6m 46s\tremaining: 46.7s\n",
      "897:\tlearn: 0.0005225\ttotal: 6m 47s\tremaining: 46.3s\n",
      "898:\tlearn: 0.0005193\ttotal: 6m 48s\tremaining: 45.9s\n",
      "899:\tlearn: 0.0005185\ttotal: 6m 49s\tremaining: 45.4s\n",
      "900:\tlearn: 0.0005178\ttotal: 6m 49s\tremaining: 45s\n",
      "901:\tlearn: 0.0005167\ttotal: 6m 50s\tremaining: 44.6s\n",
      "902:\tlearn: 0.0005165\ttotal: 6m 51s\tremaining: 44.2s\n",
      "903:\tlearn: 0.0005156\ttotal: 6m 52s\tremaining: 43.8s\n",
      "904:\tlearn: 0.0005151\ttotal: 6m 53s\tremaining: 43.4s\n",
      "905:\tlearn: 0.0005150\ttotal: 6m 53s\tremaining: 42.9s\n",
      "906:\tlearn: 0.0005146\ttotal: 6m 54s\tremaining: 42.5s\n",
      "907:\tlearn: 0.0005142\ttotal: 6m 54s\tremaining: 42s\n",
      "908:\tlearn: 0.0005123\ttotal: 6m 55s\tremaining: 41.6s\n",
      "909:\tlearn: 0.0005118\ttotal: 6m 56s\tremaining: 41.2s\n",
      "910:\tlearn: 0.0005097\ttotal: 6m 57s\tremaining: 40.7s\n",
      "911:\tlearn: 0.0005070\ttotal: 6m 57s\tremaining: 40.3s\n",
      "912:\tlearn: 0.0005069\ttotal: 6m 58s\tremaining: 39.9s\n",
      "913:\tlearn: 0.0005068\ttotal: 6m 59s\tremaining: 39.5s\n",
      "914:\tlearn: 0.0005065\ttotal: 6m 59s\tremaining: 39s\n",
      "915:\tlearn: 0.0005063\ttotal: 7m\tremaining: 38.6s\n",
      "916:\tlearn: 0.0005043\ttotal: 7m 1s\tremaining: 38.1s\n",
      "917:\tlearn: 0.0005039\ttotal: 7m 1s\tremaining: 37.7s\n",
      "918:\tlearn: 0.0005035\ttotal: 7m 2s\tremaining: 37.2s\n",
      "919:\tlearn: 0.0005034\ttotal: 7m 2s\tremaining: 36.8s\n",
      "920:\tlearn: 0.0005028\ttotal: 7m 3s\tremaining: 36.3s\n",
      "921:\tlearn: 0.0004997\ttotal: 7m 4s\tremaining: 35.9s\n",
      "922:\tlearn: 0.0004985\ttotal: 7m 5s\tremaining: 35.5s\n",
      "923:\tlearn: 0.0004976\ttotal: 7m 6s\tremaining: 35s\n",
      "924:\tlearn: 0.0004971\ttotal: 7m 6s\tremaining: 34.6s\n",
      "925:\tlearn: 0.0004971\ttotal: 7m 7s\tremaining: 34.1s\n",
      "926:\tlearn: 0.0004958\ttotal: 7m 8s\tremaining: 33.7s\n",
      "927:\tlearn: 0.0004953\ttotal: 7m 8s\tremaining: 33.3s\n",
      "928:\tlearn: 0.0004948\ttotal: 7m 9s\tremaining: 32.8s\n",
      "929:\tlearn: 0.0004938\ttotal: 7m 10s\tremaining: 32.4s\n",
      "930:\tlearn: 0.0004933\ttotal: 7m 11s\tremaining: 32s\n",
      "931:\tlearn: 0.0004926\ttotal: 7m 11s\tremaining: 31.5s\n",
      "932:\tlearn: 0.0004925\ttotal: 7m 12s\tremaining: 31.1s\n",
      "933:\tlearn: 0.0004923\ttotal: 7m 13s\tremaining: 30.6s\n",
      "934:\tlearn: 0.0004918\ttotal: 7m 13s\tremaining: 30.2s\n",
      "935:\tlearn: 0.0004915\ttotal: 7m 14s\tremaining: 29.7s\n",
      "936:\tlearn: 0.0004902\ttotal: 7m 15s\tremaining: 29.3s\n",
      "937:\tlearn: 0.0004898\ttotal: 7m 16s\tremaining: 28.8s\n",
      "938:\tlearn: 0.0004894\ttotal: 7m 16s\tremaining: 28.4s\n",
      "939:\tlearn: 0.0004878\ttotal: 7m 17s\tremaining: 27.9s\n",
      "940:\tlearn: 0.0004853\ttotal: 7m 17s\tremaining: 27.5s\n",
      "941:\tlearn: 0.0004850\ttotal: 7m 18s\tremaining: 27s\n",
      "942:\tlearn: 0.0004846\ttotal: 7m 19s\tremaining: 26.6s\n",
      "943:\tlearn: 0.0004838\ttotal: 7m 19s\tremaining: 26.1s\n",
      "944:\tlearn: 0.0004837\ttotal: 7m 20s\tremaining: 25.6s\n",
      "945:\tlearn: 0.0004820\ttotal: 7m 21s\tremaining: 25.2s\n",
      "946:\tlearn: 0.0004814\ttotal: 7m 21s\tremaining: 24.7s\n",
      "947:\tlearn: 0.0004799\ttotal: 7m 22s\tremaining: 24.3s\n",
      "948:\tlearn: 0.0004780\ttotal: 7m 23s\tremaining: 23.8s\n",
      "949:\tlearn: 0.0004772\ttotal: 7m 24s\tremaining: 23.4s\n",
      "950:\tlearn: 0.0004748\ttotal: 7m 25s\tremaining: 22.9s\n",
      "951:\tlearn: 0.0004740\ttotal: 7m 25s\tremaining: 22.5s\n",
      "952:\tlearn: 0.0004735\ttotal: 7m 26s\tremaining: 22s\n",
      "953:\tlearn: 0.0004730\ttotal: 7m 27s\tremaining: 21.6s\n",
      "954:\tlearn: 0.0004718\ttotal: 7m 28s\tremaining: 21.1s\n",
      "955:\tlearn: 0.0004717\ttotal: 7m 29s\tremaining: 20.7s\n",
      "956:\tlearn: 0.0004700\ttotal: 7m 30s\tremaining: 20.2s\n",
      "957:\tlearn: 0.0004698\ttotal: 7m 31s\tremaining: 19.8s\n",
      "958:\tlearn: 0.0004687\ttotal: 7m 31s\tremaining: 19.3s\n",
      "959:\tlearn: 0.0004684\ttotal: 7m 32s\tremaining: 18.8s\n",
      "960:\tlearn: 0.0004682\ttotal: 7m 33s\tremaining: 18.4s\n",
      "961:\tlearn: 0.0004678\ttotal: 7m 33s\tremaining: 17.9s\n",
      "962:\tlearn: 0.0004670\ttotal: 7m 34s\tremaining: 17.5s\n",
      "963:\tlearn: 0.0004661\ttotal: 7m 35s\tremaining: 17s\n",
      "964:\tlearn: 0.0004638\ttotal: 7m 35s\tremaining: 16.5s\n",
      "965:\tlearn: 0.0004636\ttotal: 7m 36s\tremaining: 16.1s\n",
      "966:\tlearn: 0.0004626\ttotal: 7m 37s\tremaining: 15.6s\n",
      "967:\tlearn: 0.0004620\ttotal: 7m 37s\tremaining: 15.1s\n",
      "968:\tlearn: 0.0004616\ttotal: 7m 38s\tremaining: 14.7s\n",
      "969:\tlearn: 0.0004615\ttotal: 7m 39s\tremaining: 14.2s\n",
      "970:\tlearn: 0.0004609\ttotal: 7m 40s\tremaining: 13.7s\n",
      "971:\tlearn: 0.0004606\ttotal: 7m 41s\tremaining: 13.3s\n",
      "972:\tlearn: 0.0004595\ttotal: 7m 41s\tremaining: 12.8s\n",
      "973:\tlearn: 0.0004593\ttotal: 7m 42s\tremaining: 12.4s\n",
      "974:\tlearn: 0.0004591\ttotal: 7m 43s\tremaining: 11.9s\n",
      "975:\tlearn: 0.0004587\ttotal: 7m 43s\tremaining: 11.4s\n",
      "976:\tlearn: 0.0004585\ttotal: 7m 44s\tremaining: 10.9s\n",
      "977:\tlearn: 0.0004583\ttotal: 7m 44s\tremaining: 10.5s\n",
      "978:\tlearn: 0.0004578\ttotal: 7m 45s\tremaining: 9.99s\n",
      "979:\tlearn: 0.0004577\ttotal: 7m 46s\tremaining: 9.52s\n",
      "980:\tlearn: 0.0004571\ttotal: 7m 47s\tremaining: 9.04s\n",
      "981:\tlearn: 0.0004567\ttotal: 7m 47s\tremaining: 8.57s\n",
      "982:\tlearn: 0.0004562\ttotal: 7m 48s\tremaining: 8.1s\n",
      "983:\tlearn: 0.0004539\ttotal: 7m 49s\tremaining: 7.63s\n",
      "984:\tlearn: 0.0004533\ttotal: 7m 50s\tremaining: 7.16s\n",
      "985:\tlearn: 0.0004526\ttotal: 7m 51s\tremaining: 6.69s\n",
      "986:\tlearn: 0.0004519\ttotal: 7m 52s\tremaining: 6.22s\n",
      "987:\tlearn: 0.0004507\ttotal: 7m 52s\tremaining: 5.74s\n",
      "988:\tlearn: 0.0004501\ttotal: 7m 53s\tremaining: 5.26s\n",
      "989:\tlearn: 0.0004500\ttotal: 7m 54s\tremaining: 4.79s\n",
      "990:\tlearn: 0.0004497\ttotal: 7m 55s\tremaining: 4.32s\n",
      "991:\tlearn: 0.0004484\ttotal: 7m 56s\tremaining: 3.84s\n",
      "992:\tlearn: 0.0004480\ttotal: 7m 57s\tremaining: 3.37s\n",
      "993:\tlearn: 0.0004479\ttotal: 7m 58s\tremaining: 2.89s\n",
      "994:\tlearn: 0.0004465\ttotal: 7m 59s\tremaining: 2.41s\n",
      "995:\tlearn: 0.0004456\ttotal: 8m\tremaining: 1.93s\n",
      "996:\tlearn: 0.0004448\ttotal: 8m 1s\tremaining: 1.45s\n",
      "997:\tlearn: 0.0004441\ttotal: 8m 1s\tremaining: 966ms\n",
      "998:\tlearn: 0.0004432\ttotal: 8m 2s\tremaining: 483ms\n",
      "999:\tlearn: 0.0004421\ttotal: 8m 3s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x256fff10a70>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using this model\n",
    "y_pred = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy =  0.99729133090456    \n",
      "roc score =  0.504950495049505    \n"
     ]
    }
   ],
   "source": [
    "# display the accuracy of this prediction\n",
    "accuracy = accuracy_score(testY, y_pred)\n",
    "print(\"model accuracy = \", accuracy, \"   \")\n",
    "\n",
    "# now lets calculate the ROC AUC score according to this prediction\n",
    "roc_score = roc_auc_score(testY, y_pred)\n",
    "print(\"roc score = \", roc_score, \"   \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict for test dataset\n",
    "fit the model and predict for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.108132\n",
      "0:\tlearn: 0.4110137\ttotal: 1.02s\tremaining: 16m 59s\n",
      "1:\tlearn: 0.2460541\ttotal: 2.01s\tremaining: 16m 41s\n",
      "2:\tlearn: 0.1556658\ttotal: 3.6s\tremaining: 19m 56s\n",
      "3:\tlearn: 0.1015658\ttotal: 4.13s\tremaining: 17m 8s\n",
      "4:\tlearn: 0.0679074\ttotal: 4.7s\tremaining: 15m 34s\n",
      "5:\tlearn: 0.0475558\ttotal: 5.57s\tremaining: 15m 23s\n",
      "6:\tlearn: 0.0355893\ttotal: 6.31s\tremaining: 14m 55s\n",
      "7:\tlearn: 0.0281044\ttotal: 6.93s\tremaining: 14m 19s\n",
      "8:\tlearn: 0.0235667\ttotal: 7.67s\tremaining: 14m 4s\n",
      "9:\tlearn: 0.0199017\ttotal: 8.29s\tremaining: 13m 40s\n",
      "10:\tlearn: 0.0176493\ttotal: 9.03s\tremaining: 13m 31s\n",
      "11:\tlearn: 0.0160674\ttotal: 9.97s\tremaining: 13m 41s\n",
      "12:\tlearn: 0.0149005\ttotal: 10.8s\tremaining: 13m 40s\n",
      "13:\tlearn: 0.0140074\ttotal: 11.6s\tremaining: 13m 36s\n",
      "14:\tlearn: 0.0134183\ttotal: 12.4s\tremaining: 13m 35s\n",
      "15:\tlearn: 0.0128569\ttotal: 13.3s\tremaining: 13m 38s\n",
      "16:\tlearn: 0.0125391\ttotal: 14.3s\tremaining: 13m 46s\n",
      "17:\tlearn: 0.0122294\ttotal: 15s\tremaining: 13m 40s\n",
      "18:\tlearn: 0.0119305\ttotal: 15.8s\tremaining: 13m 37s\n",
      "19:\tlearn: 0.0116910\ttotal: 16.7s\tremaining: 13m 38s\n",
      "20:\tlearn: 0.0114904\ttotal: 17.6s\tremaining: 13m 41s\n",
      "21:\tlearn: 0.0113128\ttotal: 18.4s\tremaining: 13m 38s\n",
      "22:\tlearn: 0.0111700\ttotal: 19.3s\tremaining: 13m 37s\n",
      "23:\tlearn: 0.0109693\ttotal: 20.1s\tremaining: 13m 36s\n",
      "24:\tlearn: 0.0108708\ttotal: 21s\tremaining: 13m 39s\n",
      "25:\tlearn: 0.0107726\ttotal: 21.8s\tremaining: 13m 37s\n",
      "26:\tlearn: 0.0106416\ttotal: 22.8s\tremaining: 13m 41s\n",
      "27:\tlearn: 0.0105330\ttotal: 23.6s\tremaining: 13m 37s\n",
      "28:\tlearn: 0.0104045\ttotal: 24.4s\tremaining: 13m 36s\n",
      "29:\tlearn: 0.0102726\ttotal: 25.1s\tremaining: 13m 32s\n",
      "30:\tlearn: 0.0101572\ttotal: 26s\tremaining: 13m 34s\n",
      "31:\tlearn: 0.0100350\ttotal: 26.9s\tremaining: 13m 34s\n",
      "32:\tlearn: 0.0099345\ttotal: 27.8s\tremaining: 13m 35s\n",
      "33:\tlearn: 0.0098262\ttotal: 28.6s\tremaining: 13m 33s\n",
      "34:\tlearn: 0.0097548\ttotal: 29.4s\tremaining: 13m 31s\n",
      "35:\tlearn: 0.0096715\ttotal: 30.3s\tremaining: 13m 30s\n",
      "36:\tlearn: 0.0095505\ttotal: 31.2s\tremaining: 13m 31s\n",
      "37:\tlearn: 0.0094707\ttotal: 31.7s\tremaining: 13m 23s\n",
      "38:\tlearn: 0.0094106\ttotal: 33.1s\tremaining: 13m 35s\n",
      "39:\tlearn: 0.0093561\ttotal: 33.9s\tremaining: 13m 32s\n",
      "40:\tlearn: 0.0092184\ttotal: 35s\tremaining: 13m 39s\n",
      "41:\tlearn: 0.0091832\ttotal: 36.3s\tremaining: 13m 48s\n",
      "42:\tlearn: 0.0090660\ttotal: 37.5s\tremaining: 13m 55s\n",
      "43:\tlearn: 0.0090146\ttotal: 38.5s\tremaining: 13m 55s\n",
      "44:\tlearn: 0.0089811\ttotal: 39.3s\tremaining: 13m 53s\n",
      "45:\tlearn: 0.0089174\ttotal: 40.1s\tremaining: 13m 52s\n",
      "46:\tlearn: 0.0087943\ttotal: 41s\tremaining: 13m 51s\n",
      "47:\tlearn: 0.0087305\ttotal: 41.8s\tremaining: 13m 48s\n",
      "48:\tlearn: 0.0086547\ttotal: 42.9s\tremaining: 13m 52s\n",
      "49:\tlearn: 0.0086264\ttotal: 44s\tremaining: 13m 55s\n",
      "50:\tlearn: 0.0085996\ttotal: 45.4s\tremaining: 14m 4s\n",
      "51:\tlearn: 0.0085691\ttotal: 46.5s\tremaining: 14m 7s\n",
      "52:\tlearn: 0.0085326\ttotal: 47.5s\tremaining: 14m 9s\n",
      "53:\tlearn: 0.0084792\ttotal: 48.3s\tremaining: 14m 6s\n",
      "54:\tlearn: 0.0084495\ttotal: 49.3s\tremaining: 14m 6s\n",
      "55:\tlearn: 0.0084079\ttotal: 50.3s\tremaining: 14m 7s\n",
      "56:\tlearn: 0.0083726\ttotal: 51.3s\tremaining: 14m 8s\n",
      "57:\tlearn: 0.0083478\ttotal: 52.2s\tremaining: 14m 7s\n",
      "58:\tlearn: 0.0082860\ttotal: 53.1s\tremaining: 14m 7s\n",
      "59:\tlearn: 0.0082635\ttotal: 54s\tremaining: 14m 5s\n",
      "60:\tlearn: 0.0082308\ttotal: 55s\tremaining: 14m 7s\n",
      "61:\tlearn: 0.0082001\ttotal: 55.9s\tremaining: 14m 6s\n",
      "62:\tlearn: 0.0081760\ttotal: 56.6s\tremaining: 14m 2s\n",
      "63:\tlearn: 0.0081180\ttotal: 57.5s\tremaining: 14m 1s\n",
      "64:\tlearn: 0.0080648\ttotal: 58.5s\tremaining: 14m\n",
      "65:\tlearn: 0.0080263\ttotal: 59.6s\tremaining: 14m 3s\n",
      "66:\tlearn: 0.0079983\ttotal: 1m\tremaining: 14m\n",
      "67:\tlearn: 0.0079555\ttotal: 1m\tremaining: 13m 55s\n",
      "68:\tlearn: 0.0079227\ttotal: 1m 1s\tremaining: 13m 54s\n",
      "69:\tlearn: 0.0078680\ttotal: 1m 3s\tremaining: 14m\n",
      "70:\tlearn: 0.0078242\ttotal: 1m 4s\tremaining: 14m 1s\n",
      "71:\tlearn: 0.0077914\ttotal: 1m 5s\tremaining: 14m 1s\n",
      "72:\tlearn: 0.0076910\ttotal: 1m 6s\tremaining: 14m 1s\n",
      "73:\tlearn: 0.0076578\ttotal: 1m 7s\tremaining: 14m 9s\n",
      "74:\tlearn: 0.0076201\ttotal: 1m 8s\tremaining: 14m 10s\n",
      "75:\tlearn: 0.0075697\ttotal: 1m 9s\tremaining: 14m 10s\n",
      "76:\tlearn: 0.0075378\ttotal: 1m 10s\tremaining: 14m 8s\n",
      "77:\tlearn: 0.0074782\ttotal: 1m 11s\tremaining: 14m 7s\n",
      "78:\tlearn: 0.0074134\ttotal: 1m 12s\tremaining: 14m 6s\n",
      "79:\tlearn: 0.0073973\ttotal: 1m 13s\tremaining: 14m 6s\n",
      "80:\tlearn: 0.0073645\ttotal: 1m 14s\tremaining: 14m 2s\n",
      "81:\tlearn: 0.0073400\ttotal: 1m 15s\tremaining: 14m 2s\n",
      "82:\tlearn: 0.0073124\ttotal: 1m 15s\tremaining: 13m 59s\n",
      "83:\tlearn: 0.0072773\ttotal: 1m 16s\tremaining: 13m 58s\n",
      "84:\tlearn: 0.0072402\ttotal: 1m 17s\tremaining: 13m 55s\n",
      "85:\tlearn: 0.0072174\ttotal: 1m 18s\tremaining: 13m 55s\n",
      "86:\tlearn: 0.0071937\ttotal: 1m 19s\tremaining: 13m 52s\n",
      "87:\tlearn: 0.0071467\ttotal: 1m 20s\tremaining: 13m 54s\n",
      "88:\tlearn: 0.0071128\ttotal: 1m 21s\tremaining: 13m 55s\n",
      "89:\tlearn: 0.0070956\ttotal: 1m 22s\tremaining: 13m 58s\n",
      "90:\tlearn: 0.0070326\ttotal: 1m 23s\tremaining: 13m 58s\n",
      "91:\tlearn: 0.0070183\ttotal: 1m 24s\tremaining: 13m 54s\n",
      "92:\tlearn: 0.0069717\ttotal: 1m 25s\tremaining: 13m 53s\n",
      "93:\tlearn: 0.0068714\ttotal: 1m 26s\tremaining: 13m 51s\n",
      "94:\tlearn: 0.0068570\ttotal: 1m 27s\tremaining: 13m 51s\n",
      "95:\tlearn: 0.0068152\ttotal: 1m 28s\tremaining: 13m 53s\n",
      "96:\tlearn: 0.0068008\ttotal: 1m 29s\tremaining: 13m 51s\n",
      "97:\tlearn: 0.0067687\ttotal: 1m 30s\tremaining: 13m 53s\n",
      "98:\tlearn: 0.0067459\ttotal: 1m 31s\tremaining: 13m 54s\n",
      "99:\tlearn: 0.0066817\ttotal: 1m 33s\tremaining: 13m 57s\n",
      "100:\tlearn: 0.0066540\ttotal: 1m 34s\tremaining: 13m 56s\n",
      "101:\tlearn: 0.0066271\ttotal: 1m 35s\tremaining: 13m 59s\n",
      "102:\tlearn: 0.0066144\ttotal: 1m 36s\tremaining: 14m\n",
      "103:\tlearn: 0.0065628\ttotal: 1m 37s\tremaining: 14m 1s\n",
      "104:\tlearn: 0.0065343\ttotal: 1m 39s\tremaining: 14m 4s\n",
      "105:\tlearn: 0.0065187\ttotal: 1m 40s\tremaining: 14m 6s\n",
      "106:\tlearn: 0.0065028\ttotal: 1m 42s\tremaining: 14m 12s\n",
      "107:\tlearn: 0.0064877\ttotal: 1m 43s\tremaining: 14m 14s\n",
      "108:\tlearn: 0.0064678\ttotal: 1m 44s\tremaining: 14m 15s\n",
      "109:\tlearn: 0.0064512\ttotal: 1m 45s\tremaining: 14m 12s\n",
      "110:\tlearn: 0.0064394\ttotal: 1m 46s\tremaining: 14m 11s\n",
      "111:\tlearn: 0.0064153\ttotal: 1m 47s\tremaining: 14m 10s\n",
      "112:\tlearn: 0.0063940\ttotal: 1m 48s\tremaining: 14m 10s\n",
      "113:\tlearn: 0.0063509\ttotal: 1m 49s\tremaining: 14m 10s\n",
      "114:\tlearn: 0.0063268\ttotal: 1m 50s\tremaining: 14m 11s\n",
      "115:\tlearn: 0.0062944\ttotal: 1m 51s\tremaining: 14m 8s\n",
      "116:\tlearn: 0.0062722\ttotal: 1m 52s\tremaining: 14m 9s\n",
      "117:\tlearn: 0.0062469\ttotal: 1m 53s\tremaining: 14m 10s\n",
      "118:\tlearn: 0.0062206\ttotal: 1m 55s\tremaining: 14m 12s\n",
      "119:\tlearn: 0.0061554\ttotal: 1m 55s\tremaining: 14m 10s\n",
      "120:\tlearn: 0.0060886\ttotal: 1m 56s\tremaining: 14m 7s\n",
      "121:\tlearn: 0.0060506\ttotal: 1m 57s\tremaining: 14m 4s\n",
      "122:\tlearn: 0.0060263\ttotal: 1m 57s\tremaining: 14m 1s\n",
      "123:\tlearn: 0.0059707\ttotal: 1m 58s\tremaining: 13m 58s\n",
      "124:\tlearn: 0.0059348\ttotal: 1m 59s\tremaining: 13m 56s\n",
      "125:\tlearn: 0.0058933\ttotal: 2m\tremaining: 13m 56s\n",
      "126:\tlearn: 0.0058808\ttotal: 2m 1s\tremaining: 13m 54s\n",
      "127:\tlearn: 0.0058628\ttotal: 2m 2s\tremaining: 13m 52s\n",
      "128:\tlearn: 0.0058513\ttotal: 2m 2s\tremaining: 13m 49s\n",
      "129:\tlearn: 0.0058238\ttotal: 2m 3s\tremaining: 13m 47s\n",
      "130:\tlearn: 0.0058085\ttotal: 2m 4s\tremaining: 13m 46s\n",
      "131:\tlearn: 0.0057642\ttotal: 2m 5s\tremaining: 13m 44s\n",
      "132:\tlearn: 0.0057428\ttotal: 2m 6s\tremaining: 13m 41s\n",
      "133:\tlearn: 0.0057060\ttotal: 2m 6s\tremaining: 13m 38s\n",
      "134:\tlearn: 0.0056901\ttotal: 2m 7s\tremaining: 13m 36s\n",
      "135:\tlearn: 0.0056571\ttotal: 2m 8s\tremaining: 13m 34s\n",
      "136:\tlearn: 0.0056342\ttotal: 2m 8s\tremaining: 13m 32s\n",
      "137:\tlearn: 0.0056175\ttotal: 2m 9s\tremaining: 13m 31s\n",
      "138:\tlearn: 0.0055759\ttotal: 2m 10s\tremaining: 13m 29s\n",
      "139:\tlearn: 0.0055691\ttotal: 2m 11s\tremaining: 13m 27s\n",
      "140:\tlearn: 0.0055625\ttotal: 2m 12s\tremaining: 13m 26s\n",
      "141:\tlearn: 0.0055505\ttotal: 2m 13s\tremaining: 13m 26s\n",
      "142:\tlearn: 0.0055211\ttotal: 2m 14s\tremaining: 13m 26s\n",
      "143:\tlearn: 0.0055042\ttotal: 2m 15s\tremaining: 13m 27s\n",
      "144:\tlearn: 0.0054703\ttotal: 2m 16s\tremaining: 13m 26s\n",
      "145:\tlearn: 0.0054250\ttotal: 2m 17s\tremaining: 13m 26s\n",
      "146:\tlearn: 0.0053971\ttotal: 2m 18s\tremaining: 13m 24s\n",
      "147:\tlearn: 0.0053876\ttotal: 2m 19s\tremaining: 13m 23s\n",
      "148:\tlearn: 0.0053502\ttotal: 2m 20s\tremaining: 13m 21s\n",
      "149:\tlearn: 0.0053171\ttotal: 2m 21s\tremaining: 13m 20s\n",
      "150:\tlearn: 0.0052975\ttotal: 2m 22s\tremaining: 13m 19s\n",
      "151:\tlearn: 0.0052688\ttotal: 2m 22s\tremaining: 13m 17s\n",
      "152:\tlearn: 0.0052606\ttotal: 2m 23s\tremaining: 13m 14s\n",
      "153:\tlearn: 0.0052307\ttotal: 2m 24s\tremaining: 13m 15s\n",
      "154:\tlearn: 0.0052085\ttotal: 2m 26s\tremaining: 13m 16s\n",
      "155:\tlearn: 0.0051793\ttotal: 2m 27s\tremaining: 13m 16s\n",
      "156:\tlearn: 0.0051606\ttotal: 2m 28s\tremaining: 13m 15s\n",
      "157:\tlearn: 0.0051391\ttotal: 2m 29s\tremaining: 13m 15s\n",
      "158:\tlearn: 0.0051010\ttotal: 2m 30s\tremaining: 13m 13s\n",
      "159:\tlearn: 0.0050946\ttotal: 2m 31s\tremaining: 13m 13s\n",
      "160:\tlearn: 0.0050403\ttotal: 2m 32s\tremaining: 13m 12s\n",
      "161:\tlearn: 0.0050203\ttotal: 2m 32s\tremaining: 13m 10s\n",
      "162:\tlearn: 0.0049878\ttotal: 2m 33s\tremaining: 13m 8s\n",
      "163:\tlearn: 0.0049540\ttotal: 2m 34s\tremaining: 13m 7s\n",
      "164:\tlearn: 0.0049499\ttotal: 2m 35s\tremaining: 13m 4s\n",
      "165:\tlearn: 0.0049262\ttotal: 2m 35s\tremaining: 13m 2s\n",
      "166:\tlearn: 0.0049093\ttotal: 2m 36s\tremaining: 13m\n",
      "167:\tlearn: 0.0048916\ttotal: 2m 37s\tremaining: 12m 58s\n",
      "168:\tlearn: 0.0048451\ttotal: 2m 37s\tremaining: 12m 56s\n",
      "169:\tlearn: 0.0048343\ttotal: 2m 38s\tremaining: 12m 54s\n",
      "170:\tlearn: 0.0047721\ttotal: 2m 39s\tremaining: 12m 53s\n",
      "171:\tlearn: 0.0047648\ttotal: 2m 40s\tremaining: 12m 51s\n",
      "172:\tlearn: 0.0047201\ttotal: 2m 41s\tremaining: 12m 50s\n",
      "173:\tlearn: 0.0046799\ttotal: 2m 42s\tremaining: 12m 49s\n",
      "174:\tlearn: 0.0046712\ttotal: 2m 42s\tremaining: 12m 47s\n",
      "175:\tlearn: 0.0046129\ttotal: 2m 43s\tremaining: 12m 45s\n",
      "176:\tlearn: 0.0045896\ttotal: 2m 44s\tremaining: 12m 46s\n",
      "177:\tlearn: 0.0045734\ttotal: 2m 46s\tremaining: 12m 46s\n",
      "178:\tlearn: 0.0045409\ttotal: 2m 47s\tremaining: 12m 49s\n",
      "179:\tlearn: 0.0045154\ttotal: 2m 48s\tremaining: 12m 49s\n",
      "180:\tlearn: 0.0044998\ttotal: 2m 50s\tremaining: 12m 49s\n",
      "181:\tlearn: 0.0044873\ttotal: 2m 51s\tremaining: 12m 49s\n",
      "182:\tlearn: 0.0044734\ttotal: 2m 52s\tremaining: 12m 48s\n",
      "183:\tlearn: 0.0044578\ttotal: 2m 53s\tremaining: 12m 48s\n",
      "184:\tlearn: 0.0044164\ttotal: 2m 54s\tremaining: 12m 48s\n",
      "185:\tlearn: 0.0043380\ttotal: 2m 55s\tremaining: 12m 49s\n",
      "186:\tlearn: 0.0043335\ttotal: 2m 56s\tremaining: 12m 49s\n",
      "187:\tlearn: 0.0043041\ttotal: 2m 58s\tremaining: 12m 50s\n",
      "188:\tlearn: 0.0042763\ttotal: 2m 59s\tremaining: 12m 49s\n",
      "189:\tlearn: 0.0042657\ttotal: 3m\tremaining: 12m 48s\n",
      "190:\tlearn: 0.0042228\ttotal: 3m 1s\tremaining: 12m 48s\n",
      "191:\tlearn: 0.0042082\ttotal: 3m 2s\tremaining: 12m 48s\n",
      "192:\tlearn: 0.0041823\ttotal: 3m 3s\tremaining: 12m 45s\n",
      "193:\tlearn: 0.0041604\ttotal: 3m 4s\tremaining: 12m 48s\n",
      "194:\tlearn: 0.0041484\ttotal: 3m 5s\tremaining: 12m 47s\n",
      "195:\tlearn: 0.0041421\ttotal: 3m 6s\tremaining: 12m 46s\n",
      "196:\tlearn: 0.0041266\ttotal: 3m 7s\tremaining: 12m 45s\n",
      "197:\tlearn: 0.0041016\ttotal: 3m 8s\tremaining: 12m 44s\n",
      "198:\tlearn: 0.0040867\ttotal: 3m 9s\tremaining: 12m 42s\n",
      "199:\tlearn: 0.0040478\ttotal: 3m 10s\tremaining: 12m 42s\n",
      "200:\tlearn: 0.0040431\ttotal: 3m 11s\tremaining: 12m 40s\n",
      "201:\tlearn: 0.0040210\ttotal: 3m 12s\tremaining: 12m 39s\n",
      "202:\tlearn: 0.0040046\ttotal: 3m 13s\tremaining: 12m 38s\n",
      "203:\tlearn: 0.0039718\ttotal: 3m 14s\tremaining: 12m 37s\n",
      "204:\tlearn: 0.0039650\ttotal: 3m 15s\tremaining: 12m 36s\n",
      "205:\tlearn: 0.0039598\ttotal: 3m 15s\tremaining: 12m 34s\n",
      "206:\tlearn: 0.0039447\ttotal: 3m 16s\tremaining: 12m 34s\n",
      "207:\tlearn: 0.0039035\ttotal: 3m 17s\tremaining: 12m 33s\n",
      "208:\tlearn: 0.0038981\ttotal: 3m 18s\tremaining: 12m 32s\n",
      "209:\tlearn: 0.0038708\ttotal: 3m 19s\tremaining: 12m 32s\n",
      "210:\tlearn: 0.0038468\ttotal: 3m 21s\tremaining: 12m 31s\n",
      "211:\tlearn: 0.0038412\ttotal: 3m 22s\tremaining: 12m 31s\n",
      "212:\tlearn: 0.0038209\ttotal: 3m 23s\tremaining: 12m 31s\n",
      "213:\tlearn: 0.0037864\ttotal: 3m 24s\tremaining: 12m 30s\n",
      "214:\tlearn: 0.0037799\ttotal: 3m 25s\tremaining: 12m 30s\n",
      "215:\tlearn: 0.0037654\ttotal: 3m 26s\tremaining: 12m 29s\n",
      "216:\tlearn: 0.0037472\ttotal: 3m 27s\tremaining: 12m 27s\n",
      "217:\tlearn: 0.0037249\ttotal: 3m 28s\tremaining: 12m 27s\n",
      "218:\tlearn: 0.0037180\ttotal: 3m 29s\tremaining: 12m 27s\n",
      "219:\tlearn: 0.0036757\ttotal: 3m 30s\tremaining: 12m 26s\n",
      "220:\tlearn: 0.0036647\ttotal: 3m 31s\tremaining: 12m 25s\n",
      "221:\tlearn: 0.0036446\ttotal: 3m 32s\tremaining: 12m 24s\n",
      "222:\tlearn: 0.0036310\ttotal: 3m 33s\tremaining: 12m 22s\n",
      "223:\tlearn: 0.0036168\ttotal: 3m 33s\tremaining: 12m 21s\n",
      "224:\tlearn: 0.0036029\ttotal: 3m 34s\tremaining: 12m 19s\n",
      "225:\tlearn: 0.0035851\ttotal: 3m 35s\tremaining: 12m 18s\n",
      "226:\tlearn: 0.0035784\ttotal: 3m 36s\tremaining: 12m 18s\n",
      "227:\tlearn: 0.0035667\ttotal: 3m 37s\tremaining: 12m 16s\n",
      "228:\tlearn: 0.0035578\ttotal: 3m 38s\tremaining: 12m 16s\n",
      "229:\tlearn: 0.0035519\ttotal: 3m 39s\tremaining: 12m 15s\n",
      "230:\tlearn: 0.0035395\ttotal: 3m 40s\tremaining: 12m 13s\n",
      "231:\tlearn: 0.0035361\ttotal: 3m 41s\tremaining: 12m 11s\n",
      "232:\tlearn: 0.0035329\ttotal: 3m 41s\tremaining: 12m 10s\n",
      "233:\tlearn: 0.0035180\ttotal: 3m 42s\tremaining: 12m 9s\n",
      "234:\tlearn: 0.0034906\ttotal: 3m 43s\tremaining: 12m 8s\n",
      "235:\tlearn: 0.0034698\ttotal: 3m 44s\tremaining: 12m 7s\n",
      "236:\tlearn: 0.0034606\ttotal: 3m 45s\tremaining: 12m 6s\n",
      "237:\tlearn: 0.0034547\ttotal: 3m 46s\tremaining: 12m 4s\n",
      "238:\tlearn: 0.0034344\ttotal: 3m 47s\tremaining: 12m 3s\n",
      "239:\tlearn: 0.0034183\ttotal: 3m 48s\tremaining: 12m 4s\n",
      "240:\tlearn: 0.0033963\ttotal: 3m 50s\tremaining: 12m 6s\n",
      "241:\tlearn: 0.0033749\ttotal: 3m 52s\tremaining: 12m 7s\n",
      "242:\tlearn: 0.0033701\ttotal: 3m 53s\tremaining: 12m 6s\n",
      "243:\tlearn: 0.0033407\ttotal: 3m 54s\tremaining: 12m 5s\n",
      "244:\tlearn: 0.0033081\ttotal: 3m 54s\tremaining: 12m 4s\n",
      "245:\tlearn: 0.0032864\ttotal: 3m 56s\tremaining: 12m 3s\n",
      "246:\tlearn: 0.0032819\ttotal: 3m 57s\tremaining: 12m 2s\n",
      "247:\tlearn: 0.0032630\ttotal: 3m 58s\tremaining: 12m 2s\n",
      "248:\tlearn: 0.0032580\ttotal: 3m 59s\tremaining: 12m 1s\n",
      "249:\tlearn: 0.0032384\ttotal: 4m\tremaining: 12m 1s\n",
      "250:\tlearn: 0.0032318\ttotal: 4m 1s\tremaining: 11m 59s\n",
      "251:\tlearn: 0.0032273\ttotal: 4m 1s\tremaining: 11m 57s\n",
      "252:\tlearn: 0.0032228\ttotal: 4m 2s\tremaining: 11m 55s\n",
      "253:\tlearn: 0.0032074\ttotal: 4m 3s\tremaining: 11m 54s\n",
      "254:\tlearn: 0.0031983\ttotal: 4m 4s\tremaining: 11m 54s\n",
      "255:\tlearn: 0.0031879\ttotal: 4m 5s\tremaining: 11m 53s\n",
      "256:\tlearn: 0.0031858\ttotal: 4m 6s\tremaining: 11m 52s\n",
      "257:\tlearn: 0.0031807\ttotal: 4m 7s\tremaining: 11m 51s\n",
      "258:\tlearn: 0.0031713\ttotal: 4m 8s\tremaining: 11m 50s\n",
      "259:\tlearn: 0.0031632\ttotal: 4m 9s\tremaining: 11m 49s\n",
      "260:\tlearn: 0.0031524\ttotal: 4m 10s\tremaining: 11m 48s\n",
      "261:\tlearn: 0.0031450\ttotal: 4m 11s\tremaining: 11m 48s\n",
      "262:\tlearn: 0.0031397\ttotal: 4m 13s\tremaining: 11m 48s\n",
      "263:\tlearn: 0.0031251\ttotal: 4m 13s\tremaining: 11m 47s\n",
      "264:\tlearn: 0.0030925\ttotal: 4m 14s\tremaining: 11m 46s\n",
      "265:\tlearn: 0.0030882\ttotal: 4m 15s\tremaining: 11m 45s\n",
      "266:\tlearn: 0.0030578\ttotal: 4m 16s\tremaining: 11m 44s\n",
      "267:\tlearn: 0.0030508\ttotal: 4m 17s\tremaining: 11m 43s\n",
      "268:\tlearn: 0.0030376\ttotal: 4m 18s\tremaining: 11m 42s\n",
      "269:\tlearn: 0.0030232\ttotal: 4m 19s\tremaining: 11m 42s\n",
      "270:\tlearn: 0.0030120\ttotal: 4m 21s\tremaining: 11m 42s\n",
      "271:\tlearn: 0.0030082\ttotal: 4m 22s\tremaining: 11m 43s\n",
      "272:\tlearn: 0.0029825\ttotal: 4m 24s\tremaining: 11m 43s\n",
      "273:\tlearn: 0.0029702\ttotal: 4m 25s\tremaining: 11m 42s\n",
      "274:\tlearn: 0.0029663\ttotal: 4m 26s\tremaining: 11m 43s\n",
      "275:\tlearn: 0.0029582\ttotal: 4m 27s\tremaining: 11m 42s\n",
      "276:\tlearn: 0.0029332\ttotal: 4m 29s\tremaining: 11m 42s\n",
      "277:\tlearn: 0.0029103\ttotal: 4m 29s\tremaining: 11m 40s\n",
      "278:\tlearn: 0.0029059\ttotal: 4m 30s\tremaining: 11m 39s\n",
      "279:\tlearn: 0.0029007\ttotal: 4m 31s\tremaining: 11m 38s\n",
      "280:\tlearn: 0.0028854\ttotal: 4m 32s\tremaining: 11m 37s\n",
      "281:\tlearn: 0.0028680\ttotal: 4m 34s\tremaining: 11m 37s\n",
      "282:\tlearn: 0.0028636\ttotal: 4m 34s\tremaining: 11m 36s\n",
      "283:\tlearn: 0.0028436\ttotal: 4m 35s\tremaining: 11m 35s\n",
      "284:\tlearn: 0.0028375\ttotal: 4m 36s\tremaining: 11m 34s\n",
      "285:\tlearn: 0.0028241\ttotal: 4m 37s\tremaining: 11m 33s\n",
      "286:\tlearn: 0.0028174\ttotal: 4m 38s\tremaining: 11m 32s\n",
      "287:\tlearn: 0.0027990\ttotal: 4m 39s\tremaining: 11m 30s\n",
      "288:\tlearn: 0.0027952\ttotal: 4m 40s\tremaining: 11m 30s\n",
      "289:\tlearn: 0.0027845\ttotal: 4m 41s\tremaining: 11m 28s\n",
      "290:\tlearn: 0.0027724\ttotal: 4m 42s\tremaining: 11m 27s\n",
      "291:\tlearn: 0.0027645\ttotal: 4m 42s\tremaining: 11m 25s\n",
      "292:\tlearn: 0.0027553\ttotal: 4m 44s\tremaining: 11m 25s\n",
      "293:\tlearn: 0.0027256\ttotal: 4m 44s\tremaining: 11m 24s\n",
      "294:\tlearn: 0.0027245\ttotal: 4m 46s\tremaining: 11m 23s\n",
      "295:\tlearn: 0.0027073\ttotal: 4m 47s\tremaining: 11m 22s\n",
      "296:\tlearn: 0.0026890\ttotal: 4m 47s\tremaining: 11m 21s\n",
      "297:\tlearn: 0.0026879\ttotal: 4m 48s\tremaining: 11m 19s\n",
      "298:\tlearn: 0.0026836\ttotal: 4m 49s\tremaining: 11m 18s\n",
      "299:\tlearn: 0.0026741\ttotal: 4m 50s\tremaining: 11m 16s\n",
      "300:\tlearn: 0.0026653\ttotal: 4m 50s\tremaining: 11m 15s\n",
      "301:\tlearn: 0.0026626\ttotal: 4m 51s\tremaining: 11m 13s\n",
      "302:\tlearn: 0.0026495\ttotal: 4m 51s\tremaining: 11m 11s\n",
      "303:\tlearn: 0.0026417\ttotal: 4m 52s\tremaining: 11m 9s\n",
      "304:\tlearn: 0.0026383\ttotal: 4m 53s\tremaining: 11m 8s\n",
      "305:\tlearn: 0.0026231\ttotal: 4m 53s\tremaining: 11m 6s\n",
      "306:\tlearn: 0.0026216\ttotal: 4m 54s\tremaining: 11m 5s\n",
      "307:\tlearn: 0.0026152\ttotal: 4m 55s\tremaining: 11m 4s\n",
      "308:\tlearn: 0.0026126\ttotal: 4m 56s\tremaining: 11m 2s\n",
      "309:\tlearn: 0.0025959\ttotal: 4m 56s\tremaining: 11m 1s\n",
      "310:\tlearn: 0.0025823\ttotal: 4m 58s\tremaining: 11m\n",
      "311:\tlearn: 0.0025700\ttotal: 4m 59s\tremaining: 10m 59s\n",
      "312:\tlearn: 0.0025630\ttotal: 4m 59s\tremaining: 10m 58s\n",
      "313:\tlearn: 0.0025574\ttotal: 5m\tremaining: 10m 56s\n",
      "314:\tlearn: 0.0025539\ttotal: 5m 1s\tremaining: 10m 55s\n",
      "315:\tlearn: 0.0025421\ttotal: 5m 1s\tremaining: 10m 53s\n",
      "316:\tlearn: 0.0025306\ttotal: 5m 2s\tremaining: 10m 52s\n",
      "317:\tlearn: 0.0025277\ttotal: 5m 3s\tremaining: 10m 50s\n",
      "318:\tlearn: 0.0025244\ttotal: 5m 3s\tremaining: 10m 48s\n",
      "319:\tlearn: 0.0025202\ttotal: 5m 4s\tremaining: 10m 46s\n",
      "320:\tlearn: 0.0025173\ttotal: 5m 5s\tremaining: 10m 45s\n",
      "321:\tlearn: 0.0025123\ttotal: 5m 6s\tremaining: 10m 44s\n",
      "322:\tlearn: 0.0024972\ttotal: 5m 6s\tremaining: 10m 43s\n",
      "323:\tlearn: 0.0024920\ttotal: 5m 7s\tremaining: 10m 42s\n",
      "324:\tlearn: 0.0024877\ttotal: 5m 8s\tremaining: 10m 40s\n",
      "325:\tlearn: 0.0024792\ttotal: 5m 9s\tremaining: 10m 39s\n",
      "326:\tlearn: 0.0024762\ttotal: 5m 9s\tremaining: 10m 37s\n",
      "327:\tlearn: 0.0024700\ttotal: 5m 10s\tremaining: 10m 35s\n",
      "328:\tlearn: 0.0024674\ttotal: 5m 10s\tremaining: 10m 33s\n",
      "329:\tlearn: 0.0024462\ttotal: 5m 11s\tremaining: 10m 31s\n",
      "330:\tlearn: 0.0024420\ttotal: 5m 11s\tremaining: 10m 30s\n",
      "331:\tlearn: 0.0024389\ttotal: 5m 12s\tremaining: 10m 28s\n",
      "332:\tlearn: 0.0024322\ttotal: 5m 12s\tremaining: 10m 26s\n",
      "333:\tlearn: 0.0024227\ttotal: 5m 13s\tremaining: 10m 25s\n",
      "334:\tlearn: 0.0024006\ttotal: 5m 14s\tremaining: 10m 23s\n",
      "335:\tlearn: 0.0023983\ttotal: 5m 14s\tremaining: 10m 21s\n",
      "336:\tlearn: 0.0023896\ttotal: 5m 14s\tremaining: 10m 19s\n",
      "337:\tlearn: 0.0023860\ttotal: 5m 15s\tremaining: 10m 18s\n",
      "338:\tlearn: 0.0023828\ttotal: 5m 16s\tremaining: 10m 17s\n",
      "339:\tlearn: 0.0023728\ttotal: 5m 17s\tremaining: 10m 15s\n",
      "340:\tlearn: 0.0023682\ttotal: 5m 17s\tremaining: 10m 14s\n",
      "341:\tlearn: 0.0023654\ttotal: 5m 18s\tremaining: 10m 12s\n",
      "342:\tlearn: 0.0023576\ttotal: 5m 19s\tremaining: 10m 11s\n",
      "343:\tlearn: 0.0023528\ttotal: 5m 20s\tremaining: 10m 10s\n",
      "344:\tlearn: 0.0023489\ttotal: 5m 21s\tremaining: 10m 9s\n",
      "345:\tlearn: 0.0023418\ttotal: 5m 21s\tremaining: 10m 8s\n",
      "346:\tlearn: 0.0023338\ttotal: 5m 22s\tremaining: 10m 6s\n",
      "347:\tlearn: 0.0023258\ttotal: 5m 23s\tremaining: 10m 5s\n",
      "348:\tlearn: 0.0023203\ttotal: 5m 23s\tremaining: 10m 4s\n",
      "349:\tlearn: 0.0023135\ttotal: 5m 24s\tremaining: 10m 3s\n",
      "350:\tlearn: 0.0023089\ttotal: 5m 25s\tremaining: 10m 1s\n",
      "351:\tlearn: 0.0023046\ttotal: 5m 26s\tremaining: 10m\n",
      "352:\tlearn: 0.0023002\ttotal: 5m 26s\tremaining: 9m 58s\n",
      "353:\tlearn: 0.0022906\ttotal: 5m 27s\tremaining: 9m 57s\n",
      "354:\tlearn: 0.0022801\ttotal: 5m 28s\tremaining: 9m 56s\n",
      "355:\tlearn: 0.0022734\ttotal: 5m 28s\tremaining: 9m 54s\n",
      "356:\tlearn: 0.0022706\ttotal: 5m 29s\tremaining: 9m 52s\n",
      "357:\tlearn: 0.0022665\ttotal: 5m 29s\tremaining: 9m 51s\n",
      "358:\tlearn: 0.0022511\ttotal: 5m 31s\tremaining: 9m 51s\n",
      "359:\tlearn: 0.0022405\ttotal: 5m 31s\tremaining: 9m 50s\n",
      "360:\tlearn: 0.0022387\ttotal: 5m 32s\tremaining: 9m 48s\n",
      "361:\tlearn: 0.0022297\ttotal: 5m 33s\tremaining: 9m 47s\n",
      "362:\tlearn: 0.0022274\ttotal: 5m 34s\tremaining: 9m 46s\n",
      "363:\tlearn: 0.0022165\ttotal: 5m 34s\tremaining: 9m 45s\n",
      "364:\tlearn: 0.0022151\ttotal: 5m 35s\tremaining: 9m 43s\n",
      "365:\tlearn: 0.0021892\ttotal: 5m 36s\tremaining: 9m 42s\n",
      "366:\tlearn: 0.0021803\ttotal: 5m 36s\tremaining: 9m 41s\n",
      "367:\tlearn: 0.0021715\ttotal: 5m 37s\tremaining: 9m 39s\n",
      "368:\tlearn: 0.0021656\ttotal: 5m 38s\tremaining: 9m 38s\n",
      "369:\tlearn: 0.0021609\ttotal: 5m 39s\tremaining: 9m 37s\n",
      "370:\tlearn: 0.0021592\ttotal: 5m 39s\tremaining: 9m 36s\n",
      "371:\tlearn: 0.0021572\ttotal: 5m 40s\tremaining: 9m 35s\n",
      "372:\tlearn: 0.0021515\ttotal: 5m 41s\tremaining: 9m 34s\n",
      "373:\tlearn: 0.0021472\ttotal: 5m 42s\tremaining: 9m 33s\n",
      "374:\tlearn: 0.0021379\ttotal: 5m 43s\tremaining: 9m 31s\n",
      "375:\tlearn: 0.0021258\ttotal: 5m 43s\tremaining: 9m 30s\n",
      "376:\tlearn: 0.0021248\ttotal: 5m 43s\tremaining: 9m 28s\n",
      "377:\tlearn: 0.0021212\ttotal: 5m 44s\tremaining: 9m 27s\n",
      "378:\tlearn: 0.0021122\ttotal: 5m 45s\tremaining: 9m 25s\n",
      "379:\tlearn: 0.0021086\ttotal: 5m 45s\tremaining: 9m 24s\n",
      "380:\tlearn: 0.0021019\ttotal: 5m 46s\tremaining: 9m 23s\n",
      "381:\tlearn: 0.0020997\ttotal: 5m 47s\tremaining: 9m 21s\n",
      "382:\tlearn: 0.0020944\ttotal: 5m 47s\tremaining: 9m 20s\n",
      "383:\tlearn: 0.0020891\ttotal: 5m 48s\tremaining: 9m 19s\n",
      "384:\tlearn: 0.0020806\ttotal: 5m 49s\tremaining: 9m 18s\n",
      "385:\tlearn: 0.0020722\ttotal: 5m 50s\tremaining: 9m 17s\n",
      "386:\tlearn: 0.0020586\ttotal: 5m 51s\tremaining: 9m 16s\n",
      "387:\tlearn: 0.0020508\ttotal: 5m 52s\tremaining: 9m 15s\n",
      "388:\tlearn: 0.0020496\ttotal: 5m 53s\tremaining: 9m 14s\n",
      "389:\tlearn: 0.0020459\ttotal: 5m 54s\tremaining: 9m 13s\n",
      "390:\tlearn: 0.0020436\ttotal: 5m 54s\tremaining: 9m 12s\n",
      "391:\tlearn: 0.0020411\ttotal: 5m 55s\tremaining: 9m 11s\n",
      "392:\tlearn: 0.0020387\ttotal: 5m 56s\tremaining: 9m 10s\n",
      "393:\tlearn: 0.0020247\ttotal: 5m 56s\tremaining: 9m 9s\n",
      "394:\tlearn: 0.0020230\ttotal: 5m 57s\tremaining: 9m 7s\n",
      "395:\tlearn: 0.0020191\ttotal: 5m 58s\tremaining: 9m 6s\n",
      "396:\tlearn: 0.0020112\ttotal: 5m 59s\tremaining: 9m 5s\n",
      "397:\tlearn: 0.0020087\ttotal: 5m 59s\tremaining: 9m 4s\n",
      "398:\tlearn: 0.0019995\ttotal: 6m\tremaining: 9m 3s\n",
      "399:\tlearn: 0.0019956\ttotal: 6m 1s\tremaining: 9m 1s\n",
      "400:\tlearn: 0.0019909\ttotal: 6m 2s\tremaining: 9m 1s\n",
      "401:\tlearn: 0.0019879\ttotal: 6m 3s\tremaining: 9m\n",
      "402:\tlearn: 0.0019791\ttotal: 6m 3s\tremaining: 8m 58s\n",
      "403:\tlearn: 0.0019746\ttotal: 6m 5s\tremaining: 8m 58s\n",
      "404:\tlearn: 0.0019633\ttotal: 6m 5s\tremaining: 8m 57s\n",
      "405:\tlearn: 0.0019569\ttotal: 6m 6s\tremaining: 8m 56s\n",
      "406:\tlearn: 0.0019521\ttotal: 6m 7s\tremaining: 8m 55s\n",
      "407:\tlearn: 0.0019412\ttotal: 6m 7s\tremaining: 8m 53s\n",
      "408:\tlearn: 0.0019379\ttotal: 6m 8s\tremaining: 8m 52s\n",
      "409:\tlearn: 0.0019320\ttotal: 6m 9s\tremaining: 8m 51s\n",
      "410:\tlearn: 0.0019290\ttotal: 6m 10s\tremaining: 8m 50s\n",
      "411:\tlearn: 0.0019217\ttotal: 6m 10s\tremaining: 8m 48s\n",
      "412:\tlearn: 0.0019105\ttotal: 6m 11s\tremaining: 8m 47s\n",
      "413:\tlearn: 0.0019082\ttotal: 6m 12s\tremaining: 8m 46s\n",
      "414:\tlearn: 0.0019047\ttotal: 6m 12s\tremaining: 8m 45s\n",
      "415:\tlearn: 0.0019012\ttotal: 6m 13s\tremaining: 8m 44s\n",
      "416:\tlearn: 0.0018959\ttotal: 6m 14s\tremaining: 8m 43s\n",
      "417:\tlearn: 0.0018943\ttotal: 6m 15s\tremaining: 8m 42s\n",
      "418:\tlearn: 0.0018880\ttotal: 6m 16s\tremaining: 8m 41s\n",
      "419:\tlearn: 0.0018830\ttotal: 6m 16s\tremaining: 8m 40s\n",
      "420:\tlearn: 0.0018802\ttotal: 6m 17s\tremaining: 8m 38s\n",
      "421:\tlearn: 0.0018777\ttotal: 6m 17s\tremaining: 8m 37s\n",
      "422:\tlearn: 0.0018733\ttotal: 6m 18s\tremaining: 8m 36s\n",
      "423:\tlearn: 0.0018726\ttotal: 6m 18s\tremaining: 8m 34s\n",
      "424:\tlearn: 0.0018693\ttotal: 6m 19s\tremaining: 8m 33s\n",
      "425:\tlearn: 0.0018667\ttotal: 6m 19s\tremaining: 8m 31s\n",
      "426:\tlearn: 0.0018643\ttotal: 6m 20s\tremaining: 8m 30s\n",
      "427:\tlearn: 0.0018621\ttotal: 6m 20s\tremaining: 8m 28s\n",
      "428:\tlearn: 0.0018595\ttotal: 6m 21s\tremaining: 8m 27s\n",
      "429:\tlearn: 0.0018578\ttotal: 6m 21s\tremaining: 8m 25s\n",
      "430:\tlearn: 0.0018508\ttotal: 6m 22s\tremaining: 8m 24s\n",
      "431:\tlearn: 0.0018483\ttotal: 6m 22s\tremaining: 8m 23s\n",
      "432:\tlearn: 0.0018441\ttotal: 6m 23s\tremaining: 8m 21s\n",
      "433:\tlearn: 0.0018277\ttotal: 6m 24s\tremaining: 8m 20s\n",
      "434:\tlearn: 0.0018260\ttotal: 6m 24s\tremaining: 8m 19s\n",
      "435:\tlearn: 0.0018222\ttotal: 6m 25s\tremaining: 8m 18s\n",
      "436:\tlearn: 0.0018183\ttotal: 6m 25s\tremaining: 8m 17s\n",
      "437:\tlearn: 0.0018147\ttotal: 6m 26s\tremaining: 8m 15s\n",
      "438:\tlearn: 0.0018123\ttotal: 6m 27s\tremaining: 8m 14s\n",
      "439:\tlearn: 0.0018045\ttotal: 6m 27s\tremaining: 8m 13s\n",
      "440:\tlearn: 0.0017981\ttotal: 6m 28s\tremaining: 8m 12s\n",
      "441:\tlearn: 0.0017949\ttotal: 6m 28s\tremaining: 8m 10s\n",
      "442:\tlearn: 0.0017933\ttotal: 6m 29s\tremaining: 8m 9s\n",
      "443:\tlearn: 0.0017885\ttotal: 6m 29s\tremaining: 8m 8s\n",
      "444:\tlearn: 0.0017793\ttotal: 6m 30s\tremaining: 8m 6s\n",
      "445:\tlearn: 0.0017726\ttotal: 6m 30s\tremaining: 8m 5s\n",
      "446:\tlearn: 0.0017674\ttotal: 6m 31s\tremaining: 8m 4s\n",
      "447:\tlearn: 0.0017662\ttotal: 6m 31s\tremaining: 8m 2s\n",
      "448:\tlearn: 0.0017595\ttotal: 6m 32s\tremaining: 8m 1s\n",
      "449:\tlearn: 0.0017555\ttotal: 6m 33s\tremaining: 8m 1s\n",
      "450:\tlearn: 0.0017520\ttotal: 6m 34s\tremaining: 8m\n",
      "451:\tlearn: 0.0017481\ttotal: 6m 35s\tremaining: 7m 58s\n",
      "452:\tlearn: 0.0017374\ttotal: 6m 35s\tremaining: 7m 58s\n",
      "453:\tlearn: 0.0017351\ttotal: 6m 36s\tremaining: 7m 57s\n",
      "454:\tlearn: 0.0017337\ttotal: 6m 37s\tremaining: 7m 56s\n",
      "455:\tlearn: 0.0017259\ttotal: 6m 38s\tremaining: 7m 55s\n",
      "456:\tlearn: 0.0017205\ttotal: 6m 38s\tremaining: 7m 53s\n",
      "457:\tlearn: 0.0017183\ttotal: 6m 39s\tremaining: 7m 52s\n",
      "458:\tlearn: 0.0017099\ttotal: 6m 40s\tremaining: 7m 51s\n",
      "459:\tlearn: 0.0017014\ttotal: 6m 40s\tremaining: 7m 50s\n",
      "460:\tlearn: 0.0016977\ttotal: 6m 41s\tremaining: 7m 49s\n",
      "461:\tlearn: 0.0016933\ttotal: 6m 42s\tremaining: 7m 48s\n",
      "462:\tlearn: 0.0016911\ttotal: 6m 42s\tremaining: 7m 47s\n",
      "463:\tlearn: 0.0016879\ttotal: 6m 43s\tremaining: 7m 45s\n",
      "464:\tlearn: 0.0016727\ttotal: 6m 43s\tremaining: 7m 44s\n",
      "465:\tlearn: 0.0016702\ttotal: 6m 44s\tremaining: 7m 43s\n",
      "466:\tlearn: 0.0016677\ttotal: 6m 44s\tremaining: 7m 41s\n",
      "467:\tlearn: 0.0016664\ttotal: 6m 45s\tremaining: 7m 40s\n",
      "468:\tlearn: 0.0016606\ttotal: 6m 45s\tremaining: 7m 39s\n",
      "469:\tlearn: 0.0016587\ttotal: 6m 46s\tremaining: 7m 38s\n",
      "470:\tlearn: 0.0016410\ttotal: 6m 46s\tremaining: 7m 36s\n",
      "471:\tlearn: 0.0016392\ttotal: 6m 47s\tremaining: 7m 35s\n",
      "472:\tlearn: 0.0016367\ttotal: 6m 47s\tremaining: 7m 34s\n",
      "473:\tlearn: 0.0016315\ttotal: 6m 48s\tremaining: 7m 32s\n",
      "474:\tlearn: 0.0016305\ttotal: 6m 48s\tremaining: 7m 31s\n",
      "475:\tlearn: 0.0016293\ttotal: 6m 49s\tremaining: 7m 30s\n",
      "476:\tlearn: 0.0016231\ttotal: 6m 50s\tremaining: 7m 29s\n",
      "477:\tlearn: 0.0016171\ttotal: 6m 50s\tremaining: 7m 28s\n",
      "478:\tlearn: 0.0016123\ttotal: 6m 51s\tremaining: 7m 27s\n",
      "479:\tlearn: 0.0016054\ttotal: 6m 52s\tremaining: 7m 26s\n",
      "480:\tlearn: 0.0016013\ttotal: 6m 52s\tremaining: 7m 25s\n",
      "481:\tlearn: 0.0016002\ttotal: 6m 53s\tremaining: 7m 24s\n",
      "482:\tlearn: 0.0015991\ttotal: 6m 54s\tremaining: 7m 23s\n",
      "483:\tlearn: 0.0015964\ttotal: 6m 54s\tremaining: 7m 22s\n",
      "484:\tlearn: 0.0015942\ttotal: 6m 55s\tremaining: 7m 20s\n",
      "485:\tlearn: 0.0015905\ttotal: 6m 55s\tremaining: 7m 19s\n",
      "486:\tlearn: 0.0015870\ttotal: 6m 56s\tremaining: 7m 19s\n",
      "487:\tlearn: 0.0015838\ttotal: 6m 58s\tremaining: 7m 18s\n",
      "488:\tlearn: 0.0015811\ttotal: 6m 59s\tremaining: 7m 17s\n",
      "489:\tlearn: 0.0015792\ttotal: 6m 59s\tremaining: 7m 16s\n",
      "490:\tlearn: 0.0015682\ttotal: 7m\tremaining: 7m 15s\n",
      "491:\tlearn: 0.0015596\ttotal: 7m\tremaining: 7m 14s\n",
      "492:\tlearn: 0.0015562\ttotal: 7m 1s\tremaining: 7m 13s\n",
      "493:\tlearn: 0.0015513\ttotal: 7m 2s\tremaining: 7m 12s\n",
      "494:\tlearn: 0.0015503\ttotal: 7m 2s\tremaining: 7m 11s\n",
      "495:\tlearn: 0.0015457\ttotal: 7m 3s\tremaining: 7m 10s\n",
      "496:\tlearn: 0.0015432\ttotal: 7m 3s\tremaining: 7m 8s\n",
      "497:\tlearn: 0.0015379\ttotal: 7m 4s\tremaining: 7m 7s\n",
      "498:\tlearn: 0.0015268\ttotal: 7m 5s\tremaining: 7m 6s\n",
      "499:\tlearn: 0.0015238\ttotal: 7m 5s\tremaining: 7m 5s\n",
      "500:\tlearn: 0.0015205\ttotal: 7m 6s\tremaining: 7m 4s\n",
      "501:\tlearn: 0.0015169\ttotal: 7m 6s\tremaining: 7m 3s\n",
      "502:\tlearn: 0.0015141\ttotal: 7m 7s\tremaining: 7m 2s\n",
      "503:\tlearn: 0.0015119\ttotal: 7m 8s\tremaining: 7m 1s\n",
      "504:\tlearn: 0.0015084\ttotal: 7m 8s\tremaining: 7m\n",
      "505:\tlearn: 0.0014881\ttotal: 7m 9s\tremaining: 6m 59s\n",
      "506:\tlearn: 0.0014843\ttotal: 7m 10s\tremaining: 6m 58s\n",
      "507:\tlearn: 0.0014838\ttotal: 7m 10s\tremaining: 6m 56s\n",
      "508:\tlearn: 0.0014812\ttotal: 7m 10s\tremaining: 6m 55s\n",
      "509:\tlearn: 0.0014749\ttotal: 7m 11s\tremaining: 6m 54s\n",
      "510:\tlearn: 0.0014739\ttotal: 7m 11s\tremaining: 6m 52s\n",
      "511:\tlearn: 0.0014724\ttotal: 7m 11s\tremaining: 6m 51s\n",
      "512:\tlearn: 0.0014708\ttotal: 7m 12s\tremaining: 6m 50s\n",
      "513:\tlearn: 0.0014667\ttotal: 7m 13s\tremaining: 6m 49s\n",
      "514:\tlearn: 0.0014663\ttotal: 7m 13s\tremaining: 6m 48s\n",
      "515:\tlearn: 0.0014638\ttotal: 7m 14s\tremaining: 6m 47s\n",
      "516:\tlearn: 0.0014611\ttotal: 7m 14s\tremaining: 6m 46s\n",
      "517:\tlearn: 0.0014579\ttotal: 7m 15s\tremaining: 6m 45s\n",
      "518:\tlearn: 0.0014478\ttotal: 7m 16s\tremaining: 6m 44s\n",
      "519:\tlearn: 0.0014457\ttotal: 7m 16s\tremaining: 6m 42s\n",
      "520:\tlearn: 0.0014364\ttotal: 7m 16s\tremaining: 6m 41s\n",
      "521:\tlearn: 0.0014342\ttotal: 7m 17s\tremaining: 6m 40s\n",
      "522:\tlearn: 0.0014280\ttotal: 7m 17s\tremaining: 6m 39s\n",
      "523:\tlearn: 0.0014263\ttotal: 7m 18s\tremaining: 6m 38s\n",
      "524:\tlearn: 0.0014227\ttotal: 7m 19s\tremaining: 6m 37s\n",
      "525:\tlearn: 0.0014202\ttotal: 7m 19s\tremaining: 6m 36s\n",
      "526:\tlearn: 0.0014138\ttotal: 7m 20s\tremaining: 6m 35s\n",
      "527:\tlearn: 0.0014116\ttotal: 7m 21s\tremaining: 6m 34s\n",
      "528:\tlearn: 0.0014071\ttotal: 7m 21s\tremaining: 6m 33s\n",
      "529:\tlearn: 0.0014063\ttotal: 7m 22s\tremaining: 6m 32s\n",
      "530:\tlearn: 0.0014055\ttotal: 7m 22s\tremaining: 6m 31s\n",
      "531:\tlearn: 0.0013999\ttotal: 7m 23s\tremaining: 6m 30s\n",
      "532:\tlearn: 0.0013970\ttotal: 7m 24s\tremaining: 6m 29s\n",
      "533:\tlearn: 0.0013932\ttotal: 7m 24s\tremaining: 6m 28s\n",
      "534:\tlearn: 0.0013846\ttotal: 7m 25s\tremaining: 6m 27s\n",
      "535:\tlearn: 0.0013733\ttotal: 7m 25s\tremaining: 6m 26s\n",
      "536:\tlearn: 0.0013699\ttotal: 7m 26s\tremaining: 6m 25s\n",
      "537:\tlearn: 0.0013684\ttotal: 7m 27s\tremaining: 6m 23s\n",
      "538:\tlearn: 0.0013648\ttotal: 7m 27s\tremaining: 6m 22s\n",
      "539:\tlearn: 0.0013609\ttotal: 7m 28s\tremaining: 6m 21s\n",
      "540:\tlearn: 0.0013557\ttotal: 7m 28s\tremaining: 6m 20s\n",
      "541:\tlearn: 0.0013442\ttotal: 7m 29s\tremaining: 6m 19s\n",
      "542:\tlearn: 0.0013417\ttotal: 7m 30s\tremaining: 6m 18s\n",
      "543:\tlearn: 0.0013401\ttotal: 7m 30s\tremaining: 6m 18s\n",
      "544:\tlearn: 0.0013358\ttotal: 7m 31s\tremaining: 6m 17s\n",
      "545:\tlearn: 0.0013303\ttotal: 7m 32s\tremaining: 6m 15s\n",
      "546:\tlearn: 0.0013297\ttotal: 7m 32s\tremaining: 6m 14s\n",
      "547:\tlearn: 0.0013216\ttotal: 7m 33s\tremaining: 6m 14s\n",
      "548:\tlearn: 0.0013201\ttotal: 7m 34s\tremaining: 6m 13s\n",
      "549:\tlearn: 0.0013194\ttotal: 7m 34s\tremaining: 6m 12s\n",
      "550:\tlearn: 0.0013181\ttotal: 7m 35s\tremaining: 6m 11s\n",
      "551:\tlearn: 0.0013158\ttotal: 7m 36s\tremaining: 6m 10s\n",
      "552:\tlearn: 0.0013134\ttotal: 7m 37s\tremaining: 6m 9s\n",
      "553:\tlearn: 0.0013104\ttotal: 7m 37s\tremaining: 6m 8s\n",
      "554:\tlearn: 0.0013092\ttotal: 7m 38s\tremaining: 6m 7s\n",
      "555:\tlearn: 0.0013075\ttotal: 7m 39s\tremaining: 6m 6s\n",
      "556:\tlearn: 0.0012981\ttotal: 7m 40s\tremaining: 6m 5s\n",
      "557:\tlearn: 0.0012954\ttotal: 7m 40s\tremaining: 6m 4s\n",
      "558:\tlearn: 0.0012946\ttotal: 7m 41s\tremaining: 6m 3s\n",
      "559:\tlearn: 0.0012922\ttotal: 7m 41s\tremaining: 6m 2s\n",
      "560:\tlearn: 0.0012861\ttotal: 7m 43s\tremaining: 6m 2s\n",
      "561:\tlearn: 0.0012834\ttotal: 7m 43s\tremaining: 6m 1s\n",
      "562:\tlearn: 0.0012769\ttotal: 7m 44s\tremaining: 6m\n",
      "563:\tlearn: 0.0012731\ttotal: 7m 44s\tremaining: 5m 59s\n",
      "564:\tlearn: 0.0012637\ttotal: 7m 45s\tremaining: 5m 58s\n",
      "565:\tlearn: 0.0012623\ttotal: 7m 46s\tremaining: 5m 57s\n",
      "566:\tlearn: 0.0012609\ttotal: 7m 46s\tremaining: 5m 56s\n",
      "567:\tlearn: 0.0012582\ttotal: 7m 47s\tremaining: 5m 55s\n",
      "568:\tlearn: 0.0012548\ttotal: 7m 48s\tremaining: 5m 55s\n",
      "569:\tlearn: 0.0012530\ttotal: 7m 49s\tremaining: 5m 54s\n",
      "570:\tlearn: 0.0012511\ttotal: 7m 50s\tremaining: 5m 53s\n",
      "571:\tlearn: 0.0012480\ttotal: 7m 50s\tremaining: 5m 52s\n",
      "572:\tlearn: 0.0012468\ttotal: 7m 51s\tremaining: 5m 51s\n",
      "573:\tlearn: 0.0012460\ttotal: 7m 51s\tremaining: 5m 50s\n",
      "574:\tlearn: 0.0012440\ttotal: 7m 52s\tremaining: 5m 49s\n",
      "575:\tlearn: 0.0012417\ttotal: 7m 52s\tremaining: 5m 48s\n",
      "576:\tlearn: 0.0012365\ttotal: 7m 53s\tremaining: 5m 47s\n",
      "577:\tlearn: 0.0012352\ttotal: 7m 54s\tremaining: 5m 46s\n",
      "578:\tlearn: 0.0012336\ttotal: 7m 54s\tremaining: 5m 45s\n",
      "579:\tlearn: 0.0012299\ttotal: 7m 55s\tremaining: 5m 44s\n",
      "580:\tlearn: 0.0012264\ttotal: 7m 55s\tremaining: 5m 43s\n",
      "581:\tlearn: 0.0012227\ttotal: 7m 56s\tremaining: 5m 42s\n",
      "582:\tlearn: 0.0012194\ttotal: 7m 56s\tremaining: 5m 41s\n",
      "583:\tlearn: 0.0012108\ttotal: 7m 57s\tremaining: 5m 40s\n",
      "584:\tlearn: 0.0012077\ttotal: 7m 57s\tremaining: 5m 39s\n",
      "585:\tlearn: 0.0012039\ttotal: 7m 58s\tremaining: 5m 38s\n",
      "586:\tlearn: 0.0011978\ttotal: 7m 59s\tremaining: 5m 37s\n",
      "587:\tlearn: 0.0011933\ttotal: 7m 59s\tremaining: 5m 36s\n",
      "588:\tlearn: 0.0011892\ttotal: 8m\tremaining: 5m 35s\n",
      "589:\tlearn: 0.0011861\ttotal: 8m 1s\tremaining: 5m 34s\n",
      "590:\tlearn: 0.0011812\ttotal: 8m 1s\tremaining: 5m 33s\n",
      "591:\tlearn: 0.0011790\ttotal: 8m 2s\tremaining: 5m 32s\n",
      "592:\tlearn: 0.0011780\ttotal: 8m 3s\tremaining: 5m 31s\n",
      "593:\tlearn: 0.0011771\ttotal: 8m 3s\tremaining: 5m 30s\n",
      "594:\tlearn: 0.0011710\ttotal: 8m 3s\tremaining: 5m 29s\n",
      "595:\tlearn: 0.0011658\ttotal: 8m 4s\tremaining: 5m 28s\n",
      "596:\tlearn: 0.0011653\ttotal: 8m 4s\tremaining: 5m 27s\n",
      "597:\tlearn: 0.0011629\ttotal: 8m 5s\tremaining: 5m 26s\n",
      "598:\tlearn: 0.0011613\ttotal: 8m 5s\tremaining: 5m 25s\n",
      "599:\tlearn: 0.0011593\ttotal: 8m 6s\tremaining: 5m 24s\n",
      "600:\tlearn: 0.0011574\ttotal: 8m 6s\tremaining: 5m 23s\n",
      "601:\tlearn: 0.0011564\ttotal: 8m 7s\tremaining: 5m 22s\n",
      "602:\tlearn: 0.0011544\ttotal: 8m 7s\tremaining: 5m 21s\n",
      "603:\tlearn: 0.0011497\ttotal: 8m 8s\tremaining: 5m 20s\n",
      "604:\tlearn: 0.0011459\ttotal: 8m 8s\tremaining: 5m 18s\n",
      "605:\tlearn: 0.0011420\ttotal: 8m 9s\tremaining: 5m 17s\n",
      "606:\tlearn: 0.0011403\ttotal: 8m 9s\tremaining: 5m 16s\n",
      "607:\tlearn: 0.0011390\ttotal: 8m 9s\tremaining: 5m 15s\n",
      "608:\tlearn: 0.0011363\ttotal: 8m 10s\tremaining: 5m 14s\n",
      "609:\tlearn: 0.0011341\ttotal: 8m 10s\tremaining: 5m 13s\n",
      "610:\tlearn: 0.0011333\ttotal: 8m 11s\tremaining: 5m 12s\n",
      "611:\tlearn: 0.0011305\ttotal: 8m 12s\tremaining: 5m 11s\n",
      "612:\tlearn: 0.0011244\ttotal: 8m 12s\tremaining: 5m 10s\n",
      "613:\tlearn: 0.0011222\ttotal: 8m 13s\tremaining: 5m 10s\n",
      "614:\tlearn: 0.0011213\ttotal: 8m 13s\tremaining: 5m 9s\n",
      "615:\tlearn: 0.0011198\ttotal: 8m 14s\tremaining: 5m 8s\n",
      "616:\tlearn: 0.0011153\ttotal: 8m 15s\tremaining: 5m 7s\n",
      "617:\tlearn: 0.0011114\ttotal: 8m 15s\tremaining: 5m 6s\n",
      "618:\tlearn: 0.0011091\ttotal: 8m 16s\tremaining: 5m 5s\n",
      "619:\tlearn: 0.0011076\ttotal: 8m 17s\tremaining: 5m 4s\n",
      "620:\tlearn: 0.0011063\ttotal: 8m 17s\tremaining: 5m 3s\n",
      "621:\tlearn: 0.0011049\ttotal: 8m 18s\tremaining: 5m 2s\n",
      "622:\tlearn: 0.0011028\ttotal: 8m 18s\tremaining: 5m 1s\n",
      "623:\tlearn: 0.0011021\ttotal: 8m 19s\tremaining: 5m\n",
      "624:\tlearn: 0.0010994\ttotal: 8m 19s\tremaining: 4m 59s\n",
      "625:\tlearn: 0.0010984\ttotal: 8m 20s\tremaining: 4m 59s\n",
      "626:\tlearn: 0.0010952\ttotal: 8m 21s\tremaining: 4m 58s\n",
      "627:\tlearn: 0.0010912\ttotal: 8m 21s\tremaining: 4m 57s\n",
      "628:\tlearn: 0.0010873\ttotal: 8m 22s\tremaining: 4m 56s\n",
      "629:\tlearn: 0.0010855\ttotal: 8m 23s\tremaining: 4m 55s\n",
      "630:\tlearn: 0.0010850\ttotal: 8m 23s\tremaining: 4m 54s\n",
      "631:\tlearn: 0.0010841\ttotal: 8m 24s\tremaining: 4m 53s\n",
      "632:\tlearn: 0.0010823\ttotal: 8m 24s\tremaining: 4m 52s\n",
      "633:\tlearn: 0.0010808\ttotal: 8m 25s\tremaining: 4m 51s\n",
      "634:\tlearn: 0.0010791\ttotal: 8m 26s\tremaining: 4m 50s\n",
      "635:\tlearn: 0.0010771\ttotal: 8m 26s\tremaining: 4m 50s\n",
      "636:\tlearn: 0.0010745\ttotal: 8m 27s\tremaining: 4m 49s\n",
      "637:\tlearn: 0.0010738\ttotal: 8m 29s\tremaining: 4m 48s\n",
      "638:\tlearn: 0.0010699\ttotal: 8m 30s\tremaining: 4m 48s\n",
      "639:\tlearn: 0.0010682\ttotal: 8m 31s\tremaining: 4m 47s\n",
      "640:\tlearn: 0.0010634\ttotal: 8m 32s\tremaining: 4m 47s\n",
      "641:\tlearn: 0.0010608\ttotal: 8m 33s\tremaining: 4m 46s\n",
      "642:\tlearn: 0.0010585\ttotal: 8m 34s\tremaining: 4m 45s\n",
      "643:\tlearn: 0.0010569\ttotal: 8m 36s\tremaining: 4m 45s\n",
      "644:\tlearn: 0.0010561\ttotal: 8m 37s\tremaining: 4m 44s\n",
      "645:\tlearn: 0.0010543\ttotal: 8m 38s\tremaining: 4m 44s\n",
      "646:\tlearn: 0.0010522\ttotal: 8m 39s\tremaining: 4m 43s\n",
      "647:\tlearn: 0.0010499\ttotal: 8m 40s\tremaining: 4m 42s\n",
      "648:\tlearn: 0.0010483\ttotal: 8m 41s\tremaining: 4m 41s\n",
      "649:\tlearn: 0.0010449\ttotal: 8m 42s\tremaining: 4m 41s\n",
      "650:\tlearn: 0.0010405\ttotal: 8m 42s\tremaining: 4m 40s\n",
      "651:\tlearn: 0.0010396\ttotal: 8m 43s\tremaining: 4m 39s\n",
      "652:\tlearn: 0.0010372\ttotal: 8m 44s\tremaining: 4m 38s\n",
      "653:\tlearn: 0.0010327\ttotal: 8m 46s\tremaining: 4m 38s\n",
      "654:\tlearn: 0.0010319\ttotal: 8m 49s\tremaining: 4m 38s\n",
      "655:\tlearn: 0.0010295\ttotal: 8m 52s\tremaining: 4m 39s\n",
      "656:\tlearn: 0.0010282\ttotal: 8m 54s\tremaining: 4m 38s\n",
      "657:\tlearn: 0.0010258\ttotal: 8m 57s\tremaining: 4m 39s\n",
      "658:\tlearn: 0.0010219\ttotal: 9m\tremaining: 4m 39s\n",
      "659:\tlearn: 0.0010214\ttotal: 9m\tremaining: 4m 38s\n",
      "660:\tlearn: 0.0010190\ttotal: 9m 2s\tremaining: 4m 38s\n",
      "661:\tlearn: 0.0010171\ttotal: 9m 4s\tremaining: 4m 37s\n",
      "662:\tlearn: 0.0010163\ttotal: 9m 5s\tremaining: 4m 37s\n",
      "663:\tlearn: 0.0010151\ttotal: 9m 5s\tremaining: 4m 36s\n",
      "664:\tlearn: 0.0010126\ttotal: 9m 6s\tremaining: 4m 35s\n",
      "665:\tlearn: 0.0010118\ttotal: 9m 7s\tremaining: 4m 34s\n",
      "666:\tlearn: 0.0010112\ttotal: 9m 7s\tremaining: 4m 33s\n",
      "667:\tlearn: 0.0010102\ttotal: 9m 8s\tremaining: 4m 32s\n",
      "668:\tlearn: 0.0010082\ttotal: 9m 9s\tremaining: 4m 31s\n",
      "669:\tlearn: 0.0010074\ttotal: 9m 10s\tremaining: 4m 30s\n",
      "670:\tlearn: 0.0010065\ttotal: 9m 10s\tremaining: 4m 30s\n",
      "671:\tlearn: 0.0010039\ttotal: 9m 11s\tremaining: 4m 29s\n",
      "672:\tlearn: 0.0010030\ttotal: 9m 12s\tremaining: 4m 28s\n",
      "673:\tlearn: 0.0010020\ttotal: 9m 12s\tremaining: 4m 27s\n",
      "674:\tlearn: 0.0009983\ttotal: 9m 13s\tremaining: 4m 26s\n",
      "675:\tlearn: 0.0009973\ttotal: 9m 13s\tremaining: 4m 25s\n",
      "676:\tlearn: 0.0009951\ttotal: 9m 14s\tremaining: 4m 24s\n",
      "677:\tlearn: 0.0009926\ttotal: 9m 14s\tremaining: 4m 23s\n",
      "678:\tlearn: 0.0009905\ttotal: 9m 15s\tremaining: 4m 22s\n",
      "679:\tlearn: 0.0009882\ttotal: 9m 15s\tremaining: 4m 21s\n",
      "680:\tlearn: 0.0009804\ttotal: 9m 16s\tremaining: 4m 20s\n",
      "681:\tlearn: 0.0009797\ttotal: 9m 17s\tremaining: 4m 19s\n",
      "682:\tlearn: 0.0009725\ttotal: 9m 17s\tremaining: 4m 18s\n",
      "683:\tlearn: 0.0009691\ttotal: 9m 18s\tremaining: 4m 17s\n",
      "684:\tlearn: 0.0009686\ttotal: 9m 18s\tremaining: 4m 16s\n",
      "685:\tlearn: 0.0009661\ttotal: 9m 19s\tremaining: 4m 15s\n",
      "686:\tlearn: 0.0009655\ttotal: 9m 19s\tremaining: 4m 14s\n",
      "687:\tlearn: 0.0009648\ttotal: 9m 20s\tremaining: 4m 14s\n",
      "688:\tlearn: 0.0009609\ttotal: 9m 20s\tremaining: 4m 13s\n",
      "689:\tlearn: 0.0009581\ttotal: 9m 21s\tremaining: 4m 12s\n",
      "690:\tlearn: 0.0009542\ttotal: 9m 21s\tremaining: 4m 11s\n",
      "691:\tlearn: 0.0009500\ttotal: 9m 22s\tremaining: 4m 10s\n",
      "692:\tlearn: 0.0009483\ttotal: 9m 22s\tremaining: 4m 9s\n",
      "693:\tlearn: 0.0009453\ttotal: 9m 23s\tremaining: 4m 8s\n",
      "694:\tlearn: 0.0009421\ttotal: 9m 23s\tremaining: 4m 7s\n",
      "695:\tlearn: 0.0009408\ttotal: 9m 24s\tremaining: 4m 6s\n",
      "696:\tlearn: 0.0009379\ttotal: 9m 24s\tremaining: 4m 5s\n",
      "697:\tlearn: 0.0009352\ttotal: 9m 25s\tremaining: 4m 4s\n",
      "698:\tlearn: 0.0009342\ttotal: 9m 25s\tremaining: 4m 3s\n",
      "699:\tlearn: 0.0009331\ttotal: 9m 26s\tremaining: 4m 2s\n",
      "700:\tlearn: 0.0009319\ttotal: 9m 26s\tremaining: 4m 1s\n",
      "701:\tlearn: 0.0009293\ttotal: 9m 27s\tremaining: 4m\n",
      "702:\tlearn: 0.0009283\ttotal: 9m 27s\tremaining: 3m 59s\n",
      "703:\tlearn: 0.0009263\ttotal: 9m 28s\tremaining: 3m 58s\n",
      "704:\tlearn: 0.0009255\ttotal: 9m 28s\tremaining: 3m 57s\n",
      "705:\tlearn: 0.0009231\ttotal: 9m 29s\tremaining: 3m 56s\n",
      "706:\tlearn: 0.0009225\ttotal: 9m 29s\tremaining: 3m 56s\n",
      "707:\tlearn: 0.0009153\ttotal: 9m 30s\tremaining: 3m 55s\n",
      "708:\tlearn: 0.0009133\ttotal: 9m 31s\tremaining: 3m 54s\n",
      "709:\tlearn: 0.0009091\ttotal: 9m 31s\tremaining: 3m 53s\n",
      "710:\tlearn: 0.0009080\ttotal: 9m 32s\tremaining: 3m 52s\n",
      "711:\tlearn: 0.0009062\ttotal: 9m 33s\tremaining: 3m 51s\n",
      "712:\tlearn: 0.0009003\ttotal: 9m 34s\tremaining: 3m 51s\n",
      "713:\tlearn: 0.0008994\ttotal: 9m 35s\tremaining: 3m 50s\n",
      "714:\tlearn: 0.0008959\ttotal: 9m 35s\tremaining: 3m 49s\n",
      "715:\tlearn: 0.0008946\ttotal: 9m 36s\tremaining: 3m 48s\n",
      "716:\tlearn: 0.0008939\ttotal: 9m 37s\tremaining: 3m 48s\n",
      "717:\tlearn: 0.0008909\ttotal: 9m 38s\tremaining: 3m 47s\n",
      "718:\tlearn: 0.0008896\ttotal: 9m 38s\tremaining: 3m 46s\n",
      "719:\tlearn: 0.0008892\ttotal: 9m 39s\tremaining: 3m 45s\n",
      "720:\tlearn: 0.0008854\ttotal: 9m 40s\tremaining: 3m 44s\n",
      "721:\tlearn: 0.0008824\ttotal: 9m 41s\tremaining: 3m 43s\n",
      "722:\tlearn: 0.0008809\ttotal: 9m 41s\tremaining: 3m 42s\n",
      "723:\tlearn: 0.0008796\ttotal: 9m 42s\tremaining: 3m 42s\n",
      "724:\tlearn: 0.0008770\ttotal: 9m 43s\tremaining: 3m 41s\n",
      "725:\tlearn: 0.0008748\ttotal: 9m 44s\tremaining: 3m 40s\n",
      "726:\tlearn: 0.0008705\ttotal: 9m 44s\tremaining: 3m 39s\n",
      "727:\tlearn: 0.0008680\ttotal: 9m 45s\tremaining: 3m 38s\n",
      "728:\tlearn: 0.0008667\ttotal: 9m 46s\tremaining: 3m 38s\n",
      "729:\tlearn: 0.0008648\ttotal: 9m 47s\tremaining: 3m 37s\n",
      "730:\tlearn: 0.0008627\ttotal: 9m 47s\tremaining: 3m 36s\n",
      "731:\tlearn: 0.0008598\ttotal: 9m 48s\tremaining: 3m 35s\n",
      "732:\tlearn: 0.0008594\ttotal: 9m 49s\tremaining: 3m 34s\n",
      "733:\tlearn: 0.0008583\ttotal: 9m 49s\tremaining: 3m 33s\n",
      "734:\tlearn: 0.0008579\ttotal: 9m 50s\tremaining: 3m 32s\n",
      "735:\tlearn: 0.0008573\ttotal: 9m 51s\tremaining: 3m 32s\n",
      "736:\tlearn: 0.0008548\ttotal: 9m 51s\tremaining: 3m 31s\n",
      "737:\tlearn: 0.0008536\ttotal: 9m 52s\tremaining: 3m 30s\n",
      "738:\tlearn: 0.0008528\ttotal: 9m 52s\tremaining: 3m 29s\n",
      "739:\tlearn: 0.0008491\ttotal: 9m 53s\tremaining: 3m 28s\n",
      "740:\tlearn: 0.0008483\ttotal: 9m 53s\tremaining: 3m 27s\n",
      "741:\tlearn: 0.0008460\ttotal: 9m 54s\tremaining: 3m 26s\n",
      "742:\tlearn: 0.0008445\ttotal: 9m 55s\tremaining: 3m 25s\n",
      "743:\tlearn: 0.0008430\ttotal: 9m 55s\tremaining: 3m 25s\n",
      "744:\tlearn: 0.0008426\ttotal: 9m 56s\tremaining: 3m 24s\n",
      "745:\tlearn: 0.0008418\ttotal: 9m 57s\tremaining: 3m 23s\n",
      "746:\tlearn: 0.0008415\ttotal: 9m 57s\tremaining: 3m 22s\n",
      "747:\tlearn: 0.0008411\ttotal: 9m 58s\tremaining: 3m 21s\n",
      "748:\tlearn: 0.0008403\ttotal: 9m 58s\tremaining: 3m 20s\n",
      "749:\tlearn: 0.0008393\ttotal: 9m 59s\tremaining: 3m 19s\n",
      "750:\tlearn: 0.0008372\ttotal: 9m 59s\tremaining: 3m 18s\n",
      "751:\tlearn: 0.0008360\ttotal: 10m\tremaining: 3m 17s\n",
      "752:\tlearn: 0.0008353\ttotal: 10m\tremaining: 3m 17s\n",
      "753:\tlearn: 0.0008333\ttotal: 10m 1s\tremaining: 3m 16s\n",
      "754:\tlearn: 0.0008318\ttotal: 10m 2s\tremaining: 3m 15s\n",
      "755:\tlearn: 0.0008300\ttotal: 10m 3s\tremaining: 3m 14s\n",
      "756:\tlearn: 0.0008289\ttotal: 10m 4s\tremaining: 3m 13s\n",
      "757:\tlearn: 0.0008242\ttotal: 10m 5s\tremaining: 3m 13s\n",
      "758:\tlearn: 0.0008230\ttotal: 10m 5s\tremaining: 3m 12s\n",
      "759:\tlearn: 0.0008212\ttotal: 10m 6s\tremaining: 3m 11s\n",
      "760:\tlearn: 0.0008183\ttotal: 10m 7s\tremaining: 3m 10s\n",
      "761:\tlearn: 0.0008134\ttotal: 10m 7s\tremaining: 3m 9s\n",
      "762:\tlearn: 0.0008119\ttotal: 10m 8s\tremaining: 3m 9s\n",
      "763:\tlearn: 0.0008088\ttotal: 10m 9s\tremaining: 3m 8s\n",
      "764:\tlearn: 0.0008069\ttotal: 10m 10s\tremaining: 3m 7s\n",
      "765:\tlearn: 0.0008050\ttotal: 10m 11s\tremaining: 3m 6s\n",
      "766:\tlearn: 0.0008025\ttotal: 10m 12s\tremaining: 3m 5s\n",
      "767:\tlearn: 0.0008016\ttotal: 10m 12s\tremaining: 3m 5s\n",
      "768:\tlearn: 0.0008003\ttotal: 10m 13s\tremaining: 3m 4s\n",
      "769:\tlearn: 0.0008000\ttotal: 10m 14s\tremaining: 3m 3s\n",
      "770:\tlearn: 0.0007983\ttotal: 10m 14s\tremaining: 3m 2s\n",
      "771:\tlearn: 0.0007976\ttotal: 10m 15s\tremaining: 3m 1s\n",
      "772:\tlearn: 0.0007961\ttotal: 10m 16s\tremaining: 3m 1s\n",
      "773:\tlearn: 0.0007943\ttotal: 10m 17s\tremaining: 3m\n",
      "774:\tlearn: 0.0007922\ttotal: 10m 17s\tremaining: 2m 59s\n",
      "775:\tlearn: 0.0007877\ttotal: 10m 18s\tremaining: 2m 58s\n",
      "776:\tlearn: 0.0007873\ttotal: 10m 19s\tremaining: 2m 57s\n",
      "777:\tlearn: 0.0007857\ttotal: 10m 19s\tremaining: 2m 56s\n",
      "778:\tlearn: 0.0007842\ttotal: 10m 20s\tremaining: 2m 56s\n",
      "779:\tlearn: 0.0007838\ttotal: 10m 21s\tremaining: 2m 55s\n",
      "780:\tlearn: 0.0007819\ttotal: 10m 22s\tremaining: 2m 54s\n",
      "781:\tlearn: 0.0007814\ttotal: 10m 23s\tremaining: 2m 53s\n",
      "782:\tlearn: 0.0007807\ttotal: 10m 23s\tremaining: 2m 52s\n",
      "783:\tlearn: 0.0007803\ttotal: 10m 24s\tremaining: 2m 52s\n",
      "784:\tlearn: 0.0007794\ttotal: 10m 25s\tremaining: 2m 51s\n",
      "785:\tlearn: 0.0007779\ttotal: 10m 26s\tremaining: 2m 50s\n",
      "786:\tlearn: 0.0007768\ttotal: 10m 26s\tremaining: 2m 49s\n",
      "787:\tlearn: 0.0007761\ttotal: 10m 27s\tremaining: 2m 48s\n",
      "788:\tlearn: 0.0007760\ttotal: 10m 28s\tremaining: 2m 48s\n",
      "789:\tlearn: 0.0007749\ttotal: 10m 29s\tremaining: 2m 47s\n",
      "790:\tlearn: 0.0007722\ttotal: 10m 29s\tremaining: 2m 46s\n",
      "791:\tlearn: 0.0007712\ttotal: 10m 30s\tremaining: 2m 45s\n",
      "792:\tlearn: 0.0007690\ttotal: 10m 31s\tremaining: 2m 44s\n",
      "793:\tlearn: 0.0007671\ttotal: 10m 32s\tremaining: 2m 44s\n",
      "794:\tlearn: 0.0007659\ttotal: 10m 32s\tremaining: 2m 43s\n",
      "795:\tlearn: 0.0007639\ttotal: 10m 33s\tremaining: 2m 42s\n",
      "796:\tlearn: 0.0007629\ttotal: 10m 34s\tremaining: 2m 41s\n",
      "797:\tlearn: 0.0007610\ttotal: 10m 35s\tremaining: 2m 40s\n",
      "798:\tlearn: 0.0007603\ttotal: 10m 36s\tremaining: 2m 40s\n",
      "799:\tlearn: 0.0007577\ttotal: 10m 37s\tremaining: 2m 39s\n",
      "800:\tlearn: 0.0007564\ttotal: 10m 38s\tremaining: 2m 38s\n",
      "801:\tlearn: 0.0007560\ttotal: 10m 39s\tremaining: 2m 37s\n",
      "802:\tlearn: 0.0007535\ttotal: 10m 40s\tremaining: 2m 37s\n",
      "803:\tlearn: 0.0007528\ttotal: 10m 41s\tremaining: 2m 36s\n",
      "804:\tlearn: 0.0007507\ttotal: 10m 42s\tremaining: 2m 35s\n",
      "805:\tlearn: 0.0007490\ttotal: 10m 43s\tremaining: 2m 34s\n",
      "806:\tlearn: 0.0007452\ttotal: 10m 44s\tremaining: 2m 34s\n",
      "807:\tlearn: 0.0007380\ttotal: 10m 45s\tremaining: 2m 33s\n",
      "808:\tlearn: 0.0007375\ttotal: 10m 46s\tremaining: 2m 32s\n",
      "809:\tlearn: 0.0007329\ttotal: 10m 47s\tremaining: 2m 31s\n",
      "810:\tlearn: 0.0007307\ttotal: 10m 48s\tremaining: 2m 31s\n",
      "811:\tlearn: 0.0007306\ttotal: 10m 48s\tremaining: 2m 30s\n",
      "812:\tlearn: 0.0007299\ttotal: 10m 49s\tremaining: 2m 29s\n",
      "813:\tlearn: 0.0007279\ttotal: 10m 50s\tremaining: 2m 28s\n",
      "814:\tlearn: 0.0007275\ttotal: 10m 51s\tremaining: 2m 27s\n",
      "815:\tlearn: 0.0007266\ttotal: 10m 52s\tremaining: 2m 27s\n",
      "816:\tlearn: 0.0007234\ttotal: 10m 53s\tremaining: 2m 26s\n",
      "817:\tlearn: 0.0007217\ttotal: 10m 54s\tremaining: 2m 25s\n",
      "818:\tlearn: 0.0007195\ttotal: 10m 55s\tremaining: 2m 24s\n",
      "819:\tlearn: 0.0007160\ttotal: 10m 56s\tremaining: 2m 24s\n",
      "820:\tlearn: 0.0007144\ttotal: 10m 57s\tremaining: 2m 23s\n",
      "821:\tlearn: 0.0007132\ttotal: 10m 57s\tremaining: 2m 22s\n",
      "822:\tlearn: 0.0007122\ttotal: 10m 58s\tremaining: 2m 21s\n",
      "823:\tlearn: 0.0007117\ttotal: 10m 59s\tremaining: 2m 20s\n",
      "824:\tlearn: 0.0007115\ttotal: 11m\tremaining: 2m 20s\n",
      "825:\tlearn: 0.0007102\ttotal: 11m 1s\tremaining: 2m 19s\n",
      "826:\tlearn: 0.0007085\ttotal: 11m 1s\tremaining: 2m 18s\n",
      "827:\tlearn: 0.0007077\ttotal: 11m 2s\tremaining: 2m 17s\n",
      "828:\tlearn: 0.0007071\ttotal: 11m 3s\tremaining: 2m 16s\n",
      "829:\tlearn: 0.0007057\ttotal: 11m 4s\tremaining: 2m 16s\n",
      "830:\tlearn: 0.0007039\ttotal: 11m 4s\tremaining: 2m 15s\n",
      "831:\tlearn: 0.0007032\ttotal: 11m 5s\tremaining: 2m 14s\n",
      "832:\tlearn: 0.0007018\ttotal: 11m 6s\tremaining: 2m 13s\n",
      "833:\tlearn: 0.0007002\ttotal: 11m 6s\tremaining: 2m 12s\n",
      "834:\tlearn: 0.0006986\ttotal: 11m 7s\tremaining: 2m 11s\n",
      "835:\tlearn: 0.0006972\ttotal: 11m 8s\tremaining: 2m 11s\n",
      "836:\tlearn: 0.0006952\ttotal: 11m 8s\tremaining: 2m 10s\n",
      "837:\tlearn: 0.0006943\ttotal: 11m 9s\tremaining: 2m 9s\n",
      "838:\tlearn: 0.0006935\ttotal: 11m 10s\tremaining: 2m 8s\n",
      "839:\tlearn: 0.0006919\ttotal: 11m 11s\tremaining: 2m 7s\n",
      "840:\tlearn: 0.0006898\ttotal: 11m 11s\tremaining: 2m 7s\n",
      "841:\tlearn: 0.0006887\ttotal: 11m 12s\tremaining: 2m 6s\n",
      "842:\tlearn: 0.0006878\ttotal: 11m 13s\tremaining: 2m 5s\n",
      "843:\tlearn: 0.0006874\ttotal: 11m 13s\tremaining: 2m 4s\n",
      "844:\tlearn: 0.0006862\ttotal: 11m 14s\tremaining: 2m 3s\n",
      "845:\tlearn: 0.0006860\ttotal: 11m 15s\tremaining: 2m 2s\n",
      "846:\tlearn: 0.0006850\ttotal: 11m 16s\tremaining: 2m 2s\n",
      "847:\tlearn: 0.0006843\ttotal: 11m 16s\tremaining: 2m 1s\n",
      "848:\tlearn: 0.0006835\ttotal: 11m 17s\tremaining: 2m\n",
      "849:\tlearn: 0.0006832\ttotal: 11m 18s\tremaining: 1m 59s\n",
      "850:\tlearn: 0.0006825\ttotal: 11m 18s\tremaining: 1m 58s\n",
      "851:\tlearn: 0.0006815\ttotal: 11m 19s\tremaining: 1m 58s\n",
      "852:\tlearn: 0.0006789\ttotal: 11m 20s\tremaining: 1m 57s\n",
      "853:\tlearn: 0.0006748\ttotal: 11m 21s\tremaining: 1m 56s\n",
      "854:\tlearn: 0.0006720\ttotal: 11m 22s\tremaining: 1m 55s\n",
      "855:\tlearn: 0.0006694\ttotal: 11m 23s\tremaining: 1m 55s\n",
      "856:\tlearn: 0.0006683\ttotal: 11m 24s\tremaining: 1m 54s\n",
      "857:\tlearn: 0.0006678\ttotal: 11m 25s\tremaining: 1m 53s\n",
      "858:\tlearn: 0.0006673\ttotal: 11m 26s\tremaining: 1m 52s\n",
      "859:\tlearn: 0.0006669\ttotal: 11m 27s\tremaining: 1m 51s\n",
      "860:\tlearn: 0.0006667\ttotal: 11m 28s\tremaining: 1m 51s\n",
      "861:\tlearn: 0.0006659\ttotal: 11m 29s\tremaining: 1m 50s\n",
      "862:\tlearn: 0.0006653\ttotal: 11m 29s\tremaining: 1m 49s\n",
      "863:\tlearn: 0.0006640\ttotal: 11m 30s\tremaining: 1m 48s\n",
      "864:\tlearn: 0.0006625\ttotal: 11m 31s\tremaining: 1m 47s\n",
      "865:\tlearn: 0.0006621\ttotal: 11m 32s\tremaining: 1m 47s\n",
      "866:\tlearn: 0.0006619\ttotal: 11m 33s\tremaining: 1m 46s\n",
      "867:\tlearn: 0.0006613\ttotal: 11m 33s\tremaining: 1m 45s\n",
      "868:\tlearn: 0.0006602\ttotal: 11m 34s\tremaining: 1m 44s\n",
      "869:\tlearn: 0.0006594\ttotal: 11m 35s\tremaining: 1m 43s\n",
      "870:\tlearn: 0.0006589\ttotal: 11m 35s\tremaining: 1m 43s\n",
      "871:\tlearn: 0.0006587\ttotal: 11m 36s\tremaining: 1m 42s\n",
      "872:\tlearn: 0.0006585\ttotal: 11m 37s\tremaining: 1m 41s\n",
      "873:\tlearn: 0.0006575\ttotal: 11m 38s\tremaining: 1m 40s\n",
      "874:\tlearn: 0.0006562\ttotal: 11m 38s\tremaining: 1m 39s\n",
      "875:\tlearn: 0.0006547\ttotal: 11m 39s\tremaining: 1m 38s\n",
      "876:\tlearn: 0.0006535\ttotal: 11m 40s\tremaining: 1m 38s\n",
      "877:\tlearn: 0.0006514\ttotal: 11m 40s\tremaining: 1m 37s\n",
      "878:\tlearn: 0.0006498\ttotal: 11m 41s\tremaining: 1m 36s\n",
      "879:\tlearn: 0.0006494\ttotal: 11m 41s\tremaining: 1m 35s\n",
      "880:\tlearn: 0.0006467\ttotal: 11m 42s\tremaining: 1m 34s\n",
      "881:\tlearn: 0.0006445\ttotal: 11m 43s\tremaining: 1m 34s\n",
      "882:\tlearn: 0.0006429\ttotal: 11m 43s\tremaining: 1m 33s\n",
      "883:\tlearn: 0.0006422\ttotal: 11m 44s\tremaining: 1m 32s\n",
      "884:\tlearn: 0.0006420\ttotal: 11m 44s\tremaining: 1m 31s\n",
      "885:\tlearn: 0.0006404\ttotal: 11m 45s\tremaining: 1m 30s\n",
      "886:\tlearn: 0.0006379\ttotal: 11m 45s\tremaining: 1m 29s\n",
      "887:\tlearn: 0.0006363\ttotal: 11m 46s\tremaining: 1m 29s\n",
      "888:\tlearn: 0.0006352\ttotal: 11m 47s\tremaining: 1m 28s\n",
      "889:\tlearn: 0.0006348\ttotal: 11m 47s\tremaining: 1m 27s\n",
      "890:\tlearn: 0.0006346\ttotal: 11m 48s\tremaining: 1m 26s\n",
      "891:\tlearn: 0.0006333\ttotal: 11m 48s\tremaining: 1m 25s\n",
      "892:\tlearn: 0.0006330\ttotal: 11m 49s\tremaining: 1m 25s\n",
      "893:\tlearn: 0.0006300\ttotal: 11m 50s\tremaining: 1m 24s\n",
      "894:\tlearn: 0.0006297\ttotal: 11m 51s\tremaining: 1m 23s\n",
      "895:\tlearn: 0.0006294\ttotal: 11m 52s\tremaining: 1m 22s\n",
      "896:\tlearn: 0.0006281\ttotal: 11m 52s\tremaining: 1m 21s\n",
      "897:\tlearn: 0.0006277\ttotal: 11m 53s\tremaining: 1m 21s\n",
      "898:\tlearn: 0.0006271\ttotal: 11m 54s\tremaining: 1m 20s\n",
      "899:\tlearn: 0.0006267\ttotal: 11m 55s\tremaining: 1m 19s\n",
      "900:\tlearn: 0.0006255\ttotal: 11m 55s\tremaining: 1m 18s\n",
      "901:\tlearn: 0.0006243\ttotal: 11m 56s\tremaining: 1m 17s\n",
      "902:\tlearn: 0.0006240\ttotal: 11m 57s\tremaining: 1m 17s\n",
      "903:\tlearn: 0.0006229\ttotal: 11m 58s\tremaining: 1m 16s\n",
      "904:\tlearn: 0.0006215\ttotal: 11m 59s\tremaining: 1m 15s\n",
      "905:\tlearn: 0.0006212\ttotal: 12m\tremaining: 1m 14s\n",
      "906:\tlearn: 0.0006198\ttotal: 12m\tremaining: 1m 13s\n",
      "907:\tlearn: 0.0006191\ttotal: 12m 1s\tremaining: 1m 13s\n",
      "908:\tlearn: 0.0006163\ttotal: 12m 2s\tremaining: 1m 12s\n",
      "909:\tlearn: 0.0006147\ttotal: 12m 3s\tremaining: 1m 11s\n",
      "910:\tlearn: 0.0006137\ttotal: 12m 3s\tremaining: 1m 10s\n",
      "911:\tlearn: 0.0006122\ttotal: 12m 4s\tremaining: 1m 9s\n",
      "912:\tlearn: 0.0006120\ttotal: 12m 5s\tremaining: 1m 9s\n",
      "913:\tlearn: 0.0006103\ttotal: 12m 5s\tremaining: 1m 8s\n",
      "914:\tlearn: 0.0006097\ttotal: 12m 6s\tremaining: 1m 7s\n",
      "915:\tlearn: 0.0006081\ttotal: 12m 6s\tremaining: 1m 6s\n",
      "916:\tlearn: 0.0006057\ttotal: 12m 7s\tremaining: 1m 5s\n",
      "917:\tlearn: 0.0006041\ttotal: 12m 8s\tremaining: 1m 5s\n",
      "918:\tlearn: 0.0006014\ttotal: 12m 9s\tremaining: 1m 4s\n",
      "919:\tlearn: 0.0006007\ttotal: 12m 10s\tremaining: 1m 3s\n",
      "920:\tlearn: 0.0006001\ttotal: 12m 11s\tremaining: 1m 2s\n",
      "921:\tlearn: 0.0005979\ttotal: 12m 11s\tremaining: 1m 1s\n",
      "922:\tlearn: 0.0005976\ttotal: 12m 12s\tremaining: 1m 1s\n",
      "923:\tlearn: 0.0005970\ttotal: 12m 13s\tremaining: 1m\n",
      "924:\tlearn: 0.0005965\ttotal: 12m 14s\tremaining: 59.5s\n",
      "925:\tlearn: 0.0005941\ttotal: 12m 14s\tremaining: 58.7s\n",
      "926:\tlearn: 0.0005896\ttotal: 12m 15s\tremaining: 57.9s\n",
      "927:\tlearn: 0.0005888\ttotal: 12m 16s\tremaining: 57.1s\n",
      "928:\tlearn: 0.0005877\ttotal: 12m 16s\tremaining: 56.3s\n",
      "929:\tlearn: 0.0005871\ttotal: 12m 17s\tremaining: 55.5s\n",
      "930:\tlearn: 0.0005865\ttotal: 12m 18s\tremaining: 54.7s\n",
      "931:\tlearn: 0.0005851\ttotal: 12m 18s\tremaining: 53.9s\n",
      "932:\tlearn: 0.0005844\ttotal: 12m 19s\tremaining: 53.1s\n",
      "933:\tlearn: 0.0005841\ttotal: 12m 20s\tremaining: 52.3s\n",
      "934:\tlearn: 0.0005824\ttotal: 12m 20s\tremaining: 51.5s\n",
      "935:\tlearn: 0.0005818\ttotal: 12m 21s\tremaining: 50.7s\n",
      "936:\tlearn: 0.0005801\ttotal: 12m 22s\tremaining: 49.9s\n",
      "937:\tlearn: 0.0005793\ttotal: 12m 23s\tremaining: 49.1s\n",
      "938:\tlearn: 0.0005770\ttotal: 12m 23s\tremaining: 48.3s\n",
      "939:\tlearn: 0.0005746\ttotal: 12m 24s\tremaining: 47.5s\n",
      "940:\tlearn: 0.0005738\ttotal: 12m 25s\tremaining: 46.7s\n",
      "941:\tlearn: 0.0005729\ttotal: 12m 26s\tremaining: 45.9s\n",
      "942:\tlearn: 0.0005726\ttotal: 12m 27s\tremaining: 45.2s\n",
      "943:\tlearn: 0.0005720\ttotal: 12m 27s\tremaining: 44.4s\n",
      "944:\tlearn: 0.0005706\ttotal: 12m 28s\tremaining: 43.6s\n",
      "945:\tlearn: 0.0005667\ttotal: 12m 29s\tremaining: 42.8s\n",
      "946:\tlearn: 0.0005654\ttotal: 12m 30s\tremaining: 42s\n",
      "947:\tlearn: 0.0005643\ttotal: 12m 31s\tremaining: 41.2s\n",
      "948:\tlearn: 0.0005639\ttotal: 12m 32s\tremaining: 40.4s\n",
      "949:\tlearn: 0.0005634\ttotal: 12m 33s\tremaining: 39.6s\n",
      "950:\tlearn: 0.0005618\ttotal: 12m 34s\tremaining: 38.9s\n",
      "951:\tlearn: 0.0005607\ttotal: 12m 35s\tremaining: 38.1s\n",
      "952:\tlearn: 0.0005602\ttotal: 12m 35s\tremaining: 37.3s\n",
      "953:\tlearn: 0.0005592\ttotal: 12m 36s\tremaining: 36.5s\n",
      "954:\tlearn: 0.0005583\ttotal: 12m 37s\tremaining: 35.7s\n",
      "955:\tlearn: 0.0005581\ttotal: 12m 38s\tremaining: 34.9s\n",
      "956:\tlearn: 0.0005565\ttotal: 12m 39s\tremaining: 34.1s\n",
      "957:\tlearn: 0.0005545\ttotal: 12m 41s\tremaining: 33.4s\n",
      "958:\tlearn: 0.0005531\ttotal: 12m 42s\tremaining: 32.6s\n",
      "959:\tlearn: 0.0005528\ttotal: 12m 43s\tremaining: 31.8s\n",
      "960:\tlearn: 0.0005518\ttotal: 12m 44s\tremaining: 31s\n",
      "961:\tlearn: 0.0005507\ttotal: 12m 45s\tremaining: 30.2s\n",
      "962:\tlearn: 0.0005495\ttotal: 12m 46s\tremaining: 29.4s\n",
      "963:\tlearn: 0.0005462\ttotal: 12m 47s\tremaining: 28.7s\n",
      "964:\tlearn: 0.0005455\ttotal: 12m 48s\tremaining: 27.9s\n",
      "965:\tlearn: 0.0005447\ttotal: 12m 49s\tremaining: 27.1s\n",
      "966:\tlearn: 0.0005437\ttotal: 12m 50s\tremaining: 26.3s\n",
      "967:\tlearn: 0.0005435\ttotal: 12m 51s\tremaining: 25.5s\n",
      "968:\tlearn: 0.0005418\ttotal: 12m 52s\tremaining: 24.7s\n",
      "969:\tlearn: 0.0005397\ttotal: 12m 54s\tremaining: 23.9s\n",
      "970:\tlearn: 0.0005392\ttotal: 12m 55s\tremaining: 23.1s\n",
      "971:\tlearn: 0.0005386\ttotal: 12m 56s\tremaining: 22.4s\n",
      "972:\tlearn: 0.0005383\ttotal: 12m 57s\tremaining: 21.6s\n",
      "973:\tlearn: 0.0005378\ttotal: 12m 58s\tremaining: 20.8s\n",
      "974:\tlearn: 0.0005374\ttotal: 12m 59s\tremaining: 20s\n",
      "975:\tlearn: 0.0005363\ttotal: 13m\tremaining: 19.2s\n",
      "976:\tlearn: 0.0005355\ttotal: 13m 1s\tremaining: 18.4s\n",
      "977:\tlearn: 0.0005346\ttotal: 13m 2s\tremaining: 17.6s\n",
      "978:\tlearn: 0.0005330\ttotal: 13m 3s\tremaining: 16.8s\n",
      "979:\tlearn: 0.0005326\ttotal: 13m 3s\tremaining: 16s\n",
      "980:\tlearn: 0.0005321\ttotal: 13m 4s\tremaining: 15.2s\n",
      "981:\tlearn: 0.0005319\ttotal: 13m 5s\tremaining: 14.4s\n",
      "982:\tlearn: 0.0005318\ttotal: 13m 6s\tremaining: 13.6s\n",
      "983:\tlearn: 0.0005309\ttotal: 13m 7s\tremaining: 12.8s\n",
      "984:\tlearn: 0.0005301\ttotal: 13m 8s\tremaining: 12s\n",
      "985:\tlearn: 0.0005276\ttotal: 13m 9s\tremaining: 11.2s\n",
      "986:\tlearn: 0.0005268\ttotal: 13m 10s\tremaining: 10.4s\n",
      "987:\tlearn: 0.0005262\ttotal: 13m 10s\tremaining: 9.6s\n",
      "988:\tlearn: 0.0005257\ttotal: 13m 11s\tremaining: 8.8s\n",
      "989:\tlearn: 0.0005254\ttotal: 13m 11s\tremaining: 8s\n",
      "990:\tlearn: 0.0005244\ttotal: 13m 12s\tremaining: 7.2s\n",
      "991:\tlearn: 0.0005235\ttotal: 13m 13s\tremaining: 6.39s\n",
      "992:\tlearn: 0.0005224\ttotal: 13m 13s\tremaining: 5.59s\n",
      "993:\tlearn: 0.0005205\ttotal: 13m 14s\tremaining: 4.8s\n",
      "994:\tlearn: 0.0005191\ttotal: 13m 15s\tremaining: 4s\n",
      "995:\tlearn: 0.0005187\ttotal: 13m 16s\tremaining: 3.2s\n",
      "996:\tlearn: 0.0005185\ttotal: 13m 16s\tremaining: 2.4s\n",
      "997:\tlearn: 0.0005175\ttotal: 13m 17s\tremaining: 1.6s\n",
      "998:\tlearn: 0.0005168\ttotal: 13m 18s\tremaining: 799ms\n",
      "999:\tlearn: 0.0005162\ttotal: 13m 19s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x256fff10a70>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.08726533e-04 2.07526342e-04 3.41480216e-06 ... 6.75200169e-05\n",
      " 2.64211326e-05 9.25492301e-05]\n"
     ]
    }
   ],
   "source": [
    "test_prediction = model.predict_proba(test_data_processed)\n",
    "\n",
    "test_prediction=test_prediction[:, 1]\n",
    "\n",
    "print(test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write into csv\n",
    "now we write the predictions into the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300001</td>\n",
       "      <td>0.000309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300002</td>\n",
       "      <td>0.000208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300003</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300004</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300005</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105477</th>\n",
       "      <td>405478</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105478</th>\n",
       "      <td>405479</td>\n",
       "      <td>0.020696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105479</th>\n",
       "      <td>405480</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105480</th>\n",
       "      <td>405481</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105481</th>\n",
       "      <td>405482</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105482 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RecordId         Y\n",
       "0         300001  0.000309\n",
       "1         300002  0.000208\n",
       "2         300003  0.000003\n",
       "3         300004  0.000153\n",
       "4         300005  0.000014\n",
       "...          ...       ...\n",
       "105477    405478  0.000007\n",
       "105478    405479  0.020696\n",
       "105479    405480  0.000068\n",
       "105480    405481  0.000026\n",
       "105481    405482  0.000093\n",
       "\n",
       "[105482 rows x 2 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = pd.read_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger1\\iml-fall-2024-challenge-1\\sample_submission.csv\")\n",
    "\n",
    "sample_data['Y'] = test_prediction\n",
    "sample_data\n",
    "\n",
    "sample_data.to_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger1\\iml-fall-2024-challenge-1\\cat1.csv\", index=False)\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x256fff10a70>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
