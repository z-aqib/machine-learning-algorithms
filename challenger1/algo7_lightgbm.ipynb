{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries\n",
    "in this part we will install all the necessary libraries on command prompt and then import the necessary functions from those libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import mean\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# step 1: preprocessing\n",
    "from sklearn.impute import SimpleImputer # import some strategic imputer to fill in any missing values using mean\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler, Normalizer # scale all the values to one range to avoid any biasness (this bias is seen in mostly naive bayes and knn etc)\n",
    "\n",
    "from sklearn.impute import KNNImputer # import some strategic imputer to fill missing values using KNN (finds the nearest neighbour and fills it with that value)\n",
    "\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, SelectKBest, f_classif, VarianceThreshold\n",
    "\n",
    "# step 2: data division\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, cross_val_score # to divide the code into train/test using a specific percentage or with/without replacement\n",
    "\n",
    "# step 3: model\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# step 4: displaying accuracy\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score # to display the accuracy of our tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this block to install any libraries not on the system\n",
    "# !pip install pandas\n",
    "# !pip install sklearn\n",
    "# python -m pip install scikit-learn lightgbm xgboost catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "data shall be loaded into variables as data sets using pandas and csv readers. they will be checked to see if they are loaded properly and will be loaded as 2 sets: train and test as per given in the kaggle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.118411</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>829</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>82.372284</td>\n",
       "      <td>31.573280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162.983897</td>\n",
       "      <td>1</td>\n",
       "      <td>724</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>27.771653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>895</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>66.236109</td>\n",
       "      <td>26.515922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.009549</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>81.303299</td>\n",
       "      <td>20.843691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158.165419</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  ...  \\\n",
       "0         1  87.000000  34.118411   0   2   0  165.100000   1  829    2  ...   \n",
       "1         2  82.372284  31.573280   0   0   1  162.983897   1  724    0  ...   \n",
       "2         3  50.000000  27.771653   0   0   1  165.100000   1  895    2  ...   \n",
       "3         4  66.236109  26.515922   0   0   1  167.009549   1  637    0  ...   \n",
       "4         5  81.303299  20.843691   0   0   1  158.165419   0  564    0  ...   \n",
       "\n",
       "        X70  X71  X72  X73  X74  X75  X76  X77  X78  Y  \n",
       "0  0.040000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "1  0.033431  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "2  0.010000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "3  0.039363  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "4  0.069242  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets load the training data set\n",
    "train_data = pd.read_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger1\\iml-fall-2024-challenge-1\\train_set.csv\")\n",
    "\n",
    "# lets also check it by getting the first few rows of the data, there should be x1 - x78 and one target variable Y\n",
    "train_data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X69</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300001</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>17.122318</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>170.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300002</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>43.693579</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>814</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300003</td>\n",
       "      <td>36.064225</td>\n",
       "      <td>23.998944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.086735</td>\n",
       "      <td>1</td>\n",
       "      <td>662</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300004</td>\n",
       "      <td>61.846764</td>\n",
       "      <td>31.693449</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>182.355708</td>\n",
       "      <td>2</td>\n",
       "      <td>862</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062613</td>\n",
       "      <td>0.033153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300005</td>\n",
       "      <td>71.591991</td>\n",
       "      <td>20.086147</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>166.704917</td>\n",
       "      <td>2</td>\n",
       "      <td>335</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014854</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  ...  \\\n",
       "0    300001  79.000000  17.122318   0   0   1  170.200000   1  700    0  ...   \n",
       "1    300002  38.000000  43.693579   0   0   1  165.100000   1  814    0  ...   \n",
       "2    300003  36.064225  23.998944   0   0   1  167.086735   1  662    0  ...   \n",
       "3    300004  61.846764  31.693449   0   3   1  182.355708   2  862    0  ...   \n",
       "4    300005  71.591991  20.086147   1   0   1  166.704917   2  335    0  ...   \n",
       "\n",
       "        X69       X70  X71  X72  X73  X74  X75  X76  X77  X78  \n",
       "0  0.070000  0.030000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.050000  0.040000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.006948  0.006948  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.062613  0.033153  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.014854  0.004854  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets load the test data\n",
    "test_data = pd.read_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger1\\iml-fall-2024-challenge-1\\test_set.csv\")\n",
    "\n",
    "# check if the data has been loaded by getting the first 5 rows - there should be x1 - x78 and no target variable Y as this is test data\n",
    "test_data.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "before we start processing this data and using algorithms, we will fix this data first, this is called data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion of Categorical to Numerical\n",
    "First we will convert categorical data to numerical data by doing one hot encoding, which turns it into binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.118411</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>829</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>82.372284</td>\n",
       "      <td>31.573280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162.983897</td>\n",
       "      <td>1</td>\n",
       "      <td>724</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>27.771653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>895</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>66.236109</td>\n",
       "      <td>26.515922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.009549</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>81.303299</td>\n",
       "      <td>20.843691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158.165419</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246117</th>\n",
       "      <td>246118</td>\n",
       "      <td>65.149110</td>\n",
       "      <td>33.357948</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156.317941</td>\n",
       "      <td>1</td>\n",
       "      <td>711</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246118</th>\n",
       "      <td>246119</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>46.736176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246119</th>\n",
       "      <td>246120</td>\n",
       "      <td>57.472080</td>\n",
       "      <td>41.854115</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189.868698</td>\n",
       "      <td>2</td>\n",
       "      <td>455</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246120</th>\n",
       "      <td>246121</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>23.738662</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246121</th>\n",
       "      <td>246122</td>\n",
       "      <td>50.257640</td>\n",
       "      <td>32.753911</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>173.665068</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246122 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  \\\n",
       "0              1  87.000000  34.118411   0   2   0  165.100000   1  829    2   \n",
       "1              2  82.372284  31.573280   0   0   1  162.983897   1  724    0   \n",
       "2              3  50.000000  27.771653   0   0   1  165.100000   1  895    2   \n",
       "3              4  66.236109  26.515922   0   0   1  167.009549   1  637    0   \n",
       "4              5  81.303299  20.843691   0   0   1  158.165419   0  564    0   \n",
       "...          ...        ...        ...  ..  ..  ..         ...  ..  ...  ...   \n",
       "246117    246118  65.149110  33.357948   0   0   1  156.317941   1  711    0   \n",
       "246118    246119  48.000000  46.736176   0   0   1  157.000000   1  594    2   \n",
       "246119    246120  57.472080  41.854115   1   0   0  189.868698   2  455    0   \n",
       "246120    246121  66.000000  23.738662   1   0   1  168.000000   2  609    0   \n",
       "246121    246122  50.257640  32.753911   0   2   0  173.665068   1  637    0   \n",
       "\n",
       "        ...       X70  X71  X72       X73  X74       X75  X76  X77       X78  \\\n",
       "0       ...  0.040000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "1       ...  0.033431  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "2       ...  0.010000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "3       ...  0.039363  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "4       ...  0.069242  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "...     ...       ...  ...  ...       ...  ...       ...  ...  ...       ...   \n",
       "246117  ...  0.027152  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "246118  ...  0.560000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "246119  ...  0.020601  0.0  0.0  0.587987  0.0  0.412013  0.0  0.0  0.412013   \n",
       "246120  ... -1.000000  0.0  0.0  1.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "246121  ...  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "\n",
       "        Y  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "...    ..  \n",
       "246117  0  \n",
       "246118  1  \n",
       "246119  0  \n",
       "246120  0  \n",
       "246121  0  \n",
       "\n",
       "[246122 rows x 79 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding - display it\n",
    "pd.get_dummies(train_data) # this line will convert the train_data to one hot encoding but it will only display the result and not save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that there is no change in the number of columns meaning there is no categorical data. but for the sake of running the program. we must perform the preprocessing therefore we shall re-run the one hot encoding and save it somewhere\n",
    "train_data_processed = pd.get_dummies(train_data)\n",
    "\n",
    "# now we shall do the same on the test data so that we maintain the rules over all data\n",
    "test_data_processed = pd.get_dummies(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting - festures and targets\n",
    "the data in train_data set is of x1 - x78 columns (79 variables) and one target variable (Y). we must split that data so that we can perform data preprocessing on the features variables (will be referred to as X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X69</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.118411</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>829</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>82.372284</td>\n",
       "      <td>31.573280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162.983897</td>\n",
       "      <td>1</td>\n",
       "      <td>724</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100292</td>\n",
       "      <td>0.033431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>27.771653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>895</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>66.236109</td>\n",
       "      <td>26.515922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.009549</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108249</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>81.303299</td>\n",
       "      <td>20.843691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158.165419</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164645</td>\n",
       "      <td>0.069242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246117</th>\n",
       "      <td>246118</td>\n",
       "      <td>65.149110</td>\n",
       "      <td>33.357948</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156.317941</td>\n",
       "      <td>1</td>\n",
       "      <td>711</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088610</td>\n",
       "      <td>0.027152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246118</th>\n",
       "      <td>246119</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>46.736176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246119</th>\n",
       "      <td>246120</td>\n",
       "      <td>57.472080</td>\n",
       "      <td>41.854115</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189.868698</td>\n",
       "      <td>2</td>\n",
       "      <td>455</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032961</td>\n",
       "      <td>0.020601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246120</th>\n",
       "      <td>246121</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>23.738662</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246121</th>\n",
       "      <td>246122</td>\n",
       "      <td>50.257640</td>\n",
       "      <td>32.753911</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>173.665068</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246122 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  \\\n",
       "0              1  87.000000  34.118411   0   2   0  165.100000   1  829    2   \n",
       "1              2  82.372284  31.573280   0   0   1  162.983897   1  724    0   \n",
       "2              3  50.000000  27.771653   0   0   1  165.100000   1  895    2   \n",
       "3              4  66.236109  26.515922   0   0   1  167.009549   1  637    0   \n",
       "4              5  81.303299  20.843691   0   0   1  158.165419   0  564    0   \n",
       "...          ...        ...        ...  ..  ..  ..         ...  ..  ...  ...   \n",
       "246117    246118  65.149110  33.357948   0   0   1  156.317941   1  711    0   \n",
       "246118    246119  48.000000  46.736176   0   0   1  157.000000   1  594    2   \n",
       "246119    246120  57.472080  41.854115   1   0   0  189.868698   2  455    0   \n",
       "246120    246121  66.000000  23.738662   1   0   1  168.000000   2  609    0   \n",
       "246121    246122  50.257640  32.753911   0   2   0  173.665068   1  637    0   \n",
       "\n",
       "        ...       X69       X70  X71  X72       X73  X74       X75  X76  X77  \\\n",
       "0       ...  0.110000  0.040000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "1       ...  0.100292  0.033431  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "2       ...  0.020000  0.010000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "3       ...  0.108249  0.039363  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "4       ...  0.164645  0.069242  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "...     ...       ...       ...  ...  ...       ...  ...       ...  ...  ...   \n",
       "246117  ...  0.088610  0.027152  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "246118  ... -1.000000  0.560000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "246119  ...  0.032961  0.020601  0.0  0.0  0.587987  0.0  0.412013  0.0  0.0   \n",
       "246120  ...  0.020000 -1.000000  0.0  0.0  1.000000  0.0  0.000000  0.0  0.0   \n",
       "246121  ...  0.013712  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "\n",
       "             X78  \n",
       "0       0.000000  \n",
       "1       0.000000  \n",
       "2       0.000000  \n",
       "3       0.000000  \n",
       "4       0.000000  \n",
       "...          ...  \n",
       "246117  0.000000  \n",
       "246118  0.000000  \n",
       "246119  0.412013  \n",
       "246120  0.000000  \n",
       "246121  0.000000  \n",
       "\n",
       "[246122 rows x 78 columns]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so in X, it is ALL the columns EXCEPT the last column known as 'Y' (we can confirm this using the train_data.head() we did earlier) so we must get all columns and DROP only the 'y' column\n",
    "X = train_data_processed.drop(columns=['Y'])\n",
    "X # lets display X and see what it is now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "246117    0\n",
       "246118    1\n",
       "246119    0\n",
       "246120    0\n",
       "246121    0\n",
       "Name: Y, Length: 246122, dtype: int64"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so as per our X output, we can see that number of columns in train_data is 79 and number of columns in X is 78 meaning we have successfully performed our removal of target variable\n",
    "# now to get the target variable alone, we can just get it alone,\n",
    "Y = train_data_processed['Y']\n",
    "Y # lets see what it is\n",
    "# as per our Y output, we can see it is of one column and 246k rows which means we have successfully extracted the target variable column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imputation \n",
    "many cells in our data may be empty - we must fill these cells with data. we have multiple options to deal with them:\n",
    "- we remove the entire rows (Case 1)\n",
    "- we fill the cells with the average of the column (Case 2)\n",
    "- we fill the cells based on KNN imputation (nearest neighbour) (Case 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE ROWS \n",
    "# ----------------------------- case  -----------------------------\n",
    "# in this case, lets remove the entire rows that have NaN values. before saving the removed rows data set, lets first run it and display it to see the outcome, then we shall save in X\n",
    "# X.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE ROWS\n",
    "# # so we originally had 246122 rows and now after removing empty cell rows we have 239650 rows which is a 6472 rows difference. as our first try, lets work with it. lets assign this data set in place of X\n",
    "# X = X.dropna(axis=0)\n",
    "# X\n",
    "# these above 2 lines were commented out as there was an error handling, rows were being removed from X and not from Y so we fixed it by removing from train_data and then splitting into X and Y\n",
    "# train_data_processed = train_data_processed.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Mean Imputation\n",
    "# ----------------------------- case 91 to 96, 98 to 99 -----------------------------\n",
    "# this will fill all the empty spaces using the average of all the spaces\n",
    "imputer = SimpleImputer(strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Imputation\n",
    "# ----------------------------- case 97 -----------------------------\n",
    "# this fills them in using k-nearest neighbours of all the spaces\n",
    "# imputer = KNNImputer(n_neighbors=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputer.fit_transform(X)                                        # fill them in X\n",
    "test_data_processed = imputer.fit_transform(test_data_processed)    # fill them in test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scaling\n",
    "some columns may be very large then other columns when compared. it would not affect at the moment as we are using decision trees, but to maintain a fair enviroment, we shall perform scaling on every run.\n",
    "there are two types of scaling: \n",
    "- min max scaling (also known as normalization)\n",
    "- standardisation (z-score normalization)\n",
    "- max abs scaler\n",
    "- robust scaler\n",
    "- normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- case 91, 92, 93, 94 -----------------------------\n",
    "# in this case we shall perform min max scaling. to do that, we must use our MinMaxScaler that we have imported above\n",
    "# scaler = MinMaxScaler()\n",
    "# # now we must use this scaler to scale X\n",
    "# scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.06302565e-06, 9.77528090e-01, 5.03110176e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [8.12605131e-06, 9.25531276e-01, 4.65579663e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.21890770e-05, 5.61797753e-01, 4.09520864e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [9.99991874e-01, 6.45753712e-01, 6.17180876e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.12013395e-01],\n",
       "       [9.99995937e-01, 7.41573034e-01, 3.50050368e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 5.64692584e-01, 4.82989245e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------- case 95 to 99 -----------------------------\n",
    "scaler = MaxAbsScaler()\n",
    "# now we must use this scaler to scale X\n",
    "scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our output shows us that every value in the array is between 0 and 1. thus lets save this value on X\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# now we must do the same on our test_data set\n",
    "test_data_processed = scaler.fit_transform(test_data_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filters\n",
    "there are two types of filters to filter out columns/features:\n",
    "- variance filter (a column which has same values throughout the column like all are sunny)\n",
    "- correlation filter (two columns which are same like weight in kg and weight in pounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :  (246122, 78)\n",
      "test data :  (105482, 78)\n"
     ]
    }
   ],
   "source": [
    "print(\"X : \", X.shape)\n",
    "print(\"test data : \", test_data_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246122, 78)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variance filter\n",
    "# ----------------------------- case  -----------------------------\n",
    "# variance_filter = VarianceThreshold(threshold=0.001)  # Adjust the threshold if needed\n",
    "# X = variance_filter.fit_transform(X)\n",
    "# test_data_processed = variance_filter.fit_transform(test_data_processed)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105482, 78)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246122, 78)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # correlation filter\n",
    "# # ----------------------------- case  -----------------------------\n",
    "# corr_matrix = pd.DataFrame(X).corr().abs()\n",
    "# upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "# to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "# X = pd.DataFrame(X).drop(columns=to_drop)\n",
    "# test_data_processed = pd.DataFrame(test_data_processed).drop(columns=to_drop)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105482, 78)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_processed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting - train and validate\n",
    "now our test_data set is of rows with NO target variable whereas the train_data set is WITH target variable.\n",
    "our rules in machine learning is that we must train half or 70% of the data and then we must check its accuracy using the remaining half or 30% of the data - we can only check accuracy IF we have the answers i.e. the target variable. \n",
    "So, what we need to do is, is split the train_data set into 2, by a 70% and 30% ratio. we train the model using the 70% and then test the model using the 30% and then use that model to predict the test_data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holdout method\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model intialization\n",
    "here model is intialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(max_depth=8, n_estimators=300, learning_rate=0.01)  # You can adjust parameters as needed\n",
    "# --\n",
    "# model = lgb.LGBMClassifier(max_depth=10, n_estimators=100, learning_rate=0.9)                 # case 91, 95, 96, 97\n",
    "# model = lgb.LGBMClassifier(max_depth=10, n_estimators=400, learning_rate=0.9)                 # Case 92\n",
    "# model = lgb.LGBMClassifier(max_depth=10, n_estimators=400, learning_rate=0.5)                 # Case 93\n",
    "# model = lgb.LGBMClassifier(max_depth=9, n_estimators=100, learning_rate=0.5)                  # case 94\n",
    "# model = lgb.LGBMClassifier(max_depth=10, n_estimators=200, learning_rate=0.1)                 # case 98\n",
    "# model = lgb.LGBMClassifier(max_depth=10, n_estimators=300, learning_rate=0.01)                # case 99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "in this we select columns and features we want to keep. there are several algos to do so:\n",
    "- forward selection\n",
    "- backward selection\n",
    "- Kbest (best out of all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward selection\n",
    "# ----------------------------- case -----------------------------\n",
    "# selection = SequentialFeatureSelector(model, direction='forward',n_features_to_select=10, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # backward selection\n",
    "# selection = SequentialFeatureSelector(model, direction='backward',n_features_to_select=5, scoring='roc_auc', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k best\n",
    "# ----------------------------- case 97 -----------------------------\n",
    "# selection = SelectKBest(score_func=f_classif, k=5)             # Use f_classif for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection fitting\n",
    "# trainX = selection.fit_transform(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection applying\n",
    "# testX = selection.transform(testX)                                  # Ensure the test set is transformed similarly\n",
    "# test_data_processed = selection.transform(test_data_processed)      # test data is also transformed\n",
    "# X = selection.transform(X)                                          # full data transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172285, 78)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging intialization\n",
    "here we will introduce and intialize bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaggingClassifier(estimator=model, n_estimators=50)\n",
    "# -- \n",
    "# model = BaggingClassifier(estimator=model, n_estimators=50)                   # case 95, 97, 98, 99\n",
    "# model = BaggingClassifier(estimator=model, n_estimators=100)                  # case 96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model running\n",
    "here we run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.221620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002566 -> initscore=-5.963027\n",
      "[LightGBM] [Info] Start training from score -5.963027\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.191988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002728 -> initscore=-5.901441\n",
      "[LightGBM] [Info] Start training from score -5.901441\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.179204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002745 -> initscore=-5.895061\n",
      "[LightGBM] [Info] Start training from score -5.895061\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.153436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002647 -> initscore=-5.931762\n",
      "[LightGBM] [Info] Start training from score -5.931762\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.267563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002525 -> initscore=-5.979031\n",
      "[LightGBM] [Info] Start training from score -5.979031\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.120066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002629 -> initscore=-5.938380\n",
      "[LightGBM] [Info] Start training from score -5.938380\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.132925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002484 -> initscore=-5.995295\n",
      "[LightGBM] [Info] Start training from score -5.995295\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.115242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002728 -> initscore=-5.901441\n",
      "[LightGBM] [Info] Start training from score -5.901441\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.179685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002478 -> initscore=-5.997640\n",
      "[LightGBM] [Info] Start training from score -5.997640\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.123841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002531 -> initscore=-5.976729\n",
      "[LightGBM] [Info] Start training from score -5.976729\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.092106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002409 -> initscore=-6.026215\n",
      "[LightGBM] [Info] Start training from score -6.026215\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.125385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002653 -> initscore=-5.929566\n",
      "[LightGBM] [Info] Start training from score -5.929566\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.220527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002577 -> initscore=-5.958500\n",
      "[LightGBM] [Info] Start training from score -5.958500\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.196071 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002595 -> initscore=-5.951749\n",
      "[LightGBM] [Info] Start training from score -5.951749\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.139664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002496 -> initscore=-5.990621\n",
      "[LightGBM] [Info] Start training from score -5.990621\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.122366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002507 -> initscore=-5.985969\n",
      "[LightGBM] [Info] Start training from score -5.985969\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.137863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002571 -> initscore=-5.960761\n",
      "[LightGBM] [Info] Start training from score -5.960761\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.139614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002566 -> initscore=-5.963027\n",
      "[LightGBM] [Info] Start training from score -5.963027\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002589 -> initscore=-5.953994\n",
      "[LightGBM] [Info] Start training from score -5.953994\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.142959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002560 -> initscore=-5.965297\n",
      "[LightGBM] [Info] Start training from score -5.965297\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002519 -> initscore=-5.981339\n",
      "[LightGBM] [Info] Start training from score -5.981339\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.126330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002542 -> initscore=-5.972141\n",
      "[LightGBM] [Info] Start training from score -5.972141\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.180636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002693 -> initscore=-5.914324\n",
      "[LightGBM] [Info] Start training from score -5.914324\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.119879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002502 -> initscore=-5.988292\n",
      "[LightGBM] [Info] Start training from score -5.988292\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002444 -> initscore=-6.011826\n",
      "[LightGBM] [Info] Start training from score -6.011826\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.658467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002687 -> initscore=-5.916487\n",
      "[LightGBM] [Info] Start training from score -5.916487\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.152681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002658 -> initscore=-5.927374\n",
      "[LightGBM] [Info] Start training from score -5.927374\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002525 -> initscore=-5.979031\n",
      "[LightGBM] [Info] Start training from score -5.979031\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002455 -> initscore=-6.007075\n",
      "[LightGBM] [Info] Start training from score -6.007075\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002716 -> initscore=-5.905717\n",
      "[LightGBM] [Info] Start training from score -5.905717\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.090705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002728 -> initscore=-5.901441\n",
      "[LightGBM] [Info] Start training from score -5.901441\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084016 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002647 -> initscore=-5.931762\n",
      "[LightGBM] [Info] Start training from score -5.931762\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082893 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002461 -> initscore=-6.004708\n",
      "[LightGBM] [Info] Start training from score -6.004708\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002478 -> initscore=-5.997640\n",
      "[LightGBM] [Info] Start training from score -5.997640\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078755 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002827 -> initscore=-5.865811\n",
      "[LightGBM] [Info] Start training from score -5.865811\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002653 -> initscore=-5.929566\n",
      "[LightGBM] [Info] Start training from score -5.929566\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002734 -> initscore=-5.899310\n",
      "[LightGBM] [Info] Start training from score -5.899310\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065851 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002600 -> initscore=-5.949508\n",
      "[LightGBM] [Info] Start training from score -5.949508\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.088716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002525 -> initscore=-5.979031\n",
      "[LightGBM] [Info] Start training from score -5.979031\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002455 -> initscore=-6.007075\n",
      "[LightGBM] [Info] Start training from score -6.007075\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.092513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002571 -> initscore=-5.960761\n",
      "[LightGBM] [Info] Start training from score -5.960761\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002676 -> initscore=-5.920828\n",
      "[LightGBM] [Info] Start training from score -5.920828\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002699 -> initscore=-5.912165\n",
      "[LightGBM] [Info] Start training from score -5.912165\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.090767 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002513 -> initscore=-5.983651\n",
      "[LightGBM] [Info] Start training from score -5.983651\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002531 -> initscore=-5.976729\n",
      "[LightGBM] [Info] Start training from score -5.976729\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079042 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002618 -> initscore=-5.942817\n",
      "[LightGBM] [Info] Start training from score -5.942817\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002595 -> initscore=-5.951749\n",
      "[LightGBM] [Info] Start training from score -5.951749\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002554 -> initscore=-5.967573\n",
      "[LightGBM] [Info] Start training from score -5.967573\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.135826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002653 -> initscore=-5.929566\n",
      "[LightGBM] [Info] Start training from score -5.929566\n",
      "[LightGBM] [Info] Number of positive: 449, number of negative: 171836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17951\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002513 -> initscore=-5.983651\n",
      "[LightGBM] [Info] Start training from score -5.983651\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-17 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-17 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-17 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-17 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-17 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-17 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-17 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-17 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-17 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-17 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingClassifier(estimator=LGBMClassifier(learning_rate=0.01, max_depth=8,\n",
       "                                           n_estimators=300),\n",
       "                  n_estimators=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;BaggingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.BaggingClassifier.html\">?<span>Documentation for BaggingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>BaggingClassifier(estimator=LGBMClassifier(learning_rate=0.01, max_depth=8,\n",
       "                                           n_estimators=300),\n",
       "                  n_estimators=50)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(learning_rate=0.01, max_depth=8, n_estimators=300)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(learning_rate=0.01, max_depth=8, n_estimators=300)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BaggingClassifier(estimator=LGBMClassifier(learning_rate=0.01, max_depth=8,\n",
       "                                           n_estimators=300),\n",
       "                  n_estimators=50)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using this model\n",
    "y_pred = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy =  0.9973455042864688    \n",
      "roc score =  0.5174796298056683    \n"
     ]
    }
   ],
   "source": [
    "# display the accuracy of this prediction\n",
    "accuracy = accuracy_score(testY, y_pred)\n",
    "print(\"model accuracy = \", accuracy, \"   \")\n",
    "\n",
    "# now lets calculate the ROC AUC score according to this prediction\n",
    "roc_score = roc_auc_score(testY, y_pred)\n",
    "print(\"roc score = \", roc_score, \"   \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict for test dataset\n",
    "fit the model and predict for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.212250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17979\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002868 -> initscore=-5.851095\n",
      "[LightGBM] [Info] Start training from score -5.851095\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.211902 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17975\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002710 -> initscore=-5.908079\n",
      "[LightGBM] [Info] Start training from score -5.908079\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.270181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17976\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002653 -> initscore=-5.929349\n",
      "[LightGBM] [Info] Start training from score -5.929349\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.156049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17979\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002641 -> initscore=-5.933966\n",
      "[LightGBM] [Info] Start training from score -5.933966\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.234794 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17981\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002515 -> initscore=-5.982959\n",
      "[LightGBM] [Info] Start training from score -5.982959\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.152741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17975\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002678 -> initscore=-5.920178\n",
      "[LightGBM] [Info] Start training from score -5.920178\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.249719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17980\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002661 -> initscore=-5.926283\n",
      "[LightGBM] [Info] Start training from score -5.926283\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17975\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002649 -> initscore=-5.930885\n",
      "[LightGBM] [Info] Start training from score -5.930885\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.204776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 17960\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002836 -> initscore=-5.862524\n",
      "[LightGBM] [Info] Start training from score -5.862524\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.131466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17978\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002726 -> initscore=-5.902083\n",
      "[LightGBM] [Info] Start training from score -5.902083\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.140090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17983\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002714 -> initscore=-5.906577\n",
      "[LightGBM] [Info] Start training from score -5.906577\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.125529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17960\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002795 -> initscore=-5.876995\n",
      "[LightGBM] [Info] Start training from score -5.876995\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.128553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17980\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002592 -> initscore=-5.952649\n",
      "[LightGBM] [Info] Start training from score -5.952649\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.119829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17976\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002808 -> initscore=-5.872631\n",
      "[LightGBM] [Info] Start training from score -5.872631\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.157317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17982\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002653 -> initscore=-5.929349\n",
      "[LightGBM] [Info] Start training from score -5.929349\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.157399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17978\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002730 -> initscore=-5.900590\n",
      "[LightGBM] [Info] Start training from score -5.900590\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.111696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17981\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002588 -> initscore=-5.954221\n",
      "[LightGBM] [Info] Start training from score -5.954221\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.273284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17975\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002633 -> initscore=-5.937056\n",
      "[LightGBM] [Info] Start training from score -5.937056\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.132718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17979\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002747 -> initscore=-5.894639\n",
      "[LightGBM] [Info] Start training from score -5.894639\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17977\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002556 -> initscore=-5.966892\n",
      "[LightGBM] [Info] Start training from score -5.966892\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17975\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002743 -> initscore=-5.896124\n",
      "[LightGBM] [Info] Start training from score -5.896124\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.117764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17979\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002560 -> initscore=-5.965300\n",
      "[LightGBM] [Info] Start training from score -5.965300\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.129464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17978\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002629 -> initscore=-5.938604\n",
      "[LightGBM] [Info] Start training from score -5.938604\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.126232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17975\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002596 -> initscore=-5.951079\n",
      "[LightGBM] [Info] Start training from score -5.951079\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.128293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17976\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002690 -> initscore=-5.915624\n",
      "[LightGBM] [Info] Start training from score -5.915624\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.121702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17978\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002913 -> initscore=-5.835589\n",
      "[LightGBM] [Info] Start training from score -5.835589\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.133893 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17975\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002710 -> initscore=-5.908079\n",
      "[LightGBM] [Info] Start training from score -5.908079\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.108836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17977\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002726 -> initscore=-5.902083\n",
      "[LightGBM] [Info] Start training from score -5.902083\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.098554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17980\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002377 -> initscore=-6.039591\n",
      "[LightGBM] [Info] Start training from score -6.039591\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17979\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002608 -> initscore=-5.946382\n",
      "[LightGBM] [Info] Start training from score -5.946382\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.140705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17976\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002641 -> initscore=-5.933966\n",
      "[LightGBM] [Info] Start training from score -5.933966\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.163179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17978\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002543 -> initscore=-5.971686\n",
      "[LightGBM] [Info] Start training from score -5.971686\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.126232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17976\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002625 -> initscore=-5.940155\n",
      "[LightGBM] [Info] Start training from score -5.940155\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.166842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17978\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002556 -> initscore=-5.966892\n",
      "[LightGBM] [Info] Start training from score -5.966892\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.161962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17976\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002523 -> initscore=-5.979725\n",
      "[LightGBM] [Info] Start training from score -5.979725\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.138407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17984\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002625 -> initscore=-5.940155\n",
      "[LightGBM] [Info] Start training from score -5.940155\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.112567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17977\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002604 -> initscore=-5.947945\n",
      "[LightGBM] [Info] Start training from score -5.947945\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.130209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17976\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002539 -> initscore=-5.973288\n",
      "[LightGBM] [Info] Start training from score -5.973288\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.144963 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17978\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002775 -> initscore=-5.884309\n",
      "[LightGBM] [Info] Start training from score -5.884309\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.135513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17972\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002678 -> initscore=-5.920178\n",
      "[LightGBM] [Info] Start training from score -5.920178\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.097505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17977\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002442 -> initscore=-6.012543\n",
      "[LightGBM] [Info] Start training from score -6.012543\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.123594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17981\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002673 -> initscore=-5.921701\n",
      "[LightGBM] [Info] Start training from score -5.921701\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17973\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002629 -> initscore=-5.938604\n",
      "[LightGBM] [Info] Start training from score -5.938604\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.124348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17973\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002641 -> initscore=-5.933966\n",
      "[LightGBM] [Info] Start training from score -5.933966\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.133985 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17980\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002694 -> initscore=-5.914110\n",
      "[LightGBM] [Info] Start training from score -5.914110\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.090456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17977\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002653 -> initscore=-5.929349\n",
      "[LightGBM] [Info] Start training from score -5.929349\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17980\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002812 -> initscore=-5.871181\n",
      "[LightGBM] [Info] Start training from score -5.871181\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.108207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17975\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002580 -> initscore=-5.957374\n",
      "[LightGBM] [Info] Start training from score -5.957374\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.108187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17982\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002787 -> initscore=-5.879914\n",
      "[LightGBM] [Info] Start training from score -5.879914\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.095113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17979\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002816 -> initscore=-5.869733\n",
      "[LightGBM] [Info] Start training from score -5.869733\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-18 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-18 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-18 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-18 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-18 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-18 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-18 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-18 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-18 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-18 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingClassifier(estimator=LGBMClassifier(learning_rate=0.01, max_depth=8,\n",
       "                                           n_estimators=300),\n",
       "                  n_estimators=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;BaggingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.BaggingClassifier.html\">?<span>Documentation for BaggingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>BaggingClassifier(estimator=LGBMClassifier(learning_rate=0.01, max_depth=8,\n",
       "                                           n_estimators=300),\n",
       "                  n_estimators=50)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(learning_rate=0.01, max_depth=8, n_estimators=300)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(learning_rate=0.01, max_depth=8, n_estimators=300)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BaggingClassifier(estimator=LGBMClassifier(learning_rate=0.01, max_depth=8,\n",
       "                                           n_estimators=300),\n",
       "                  n_estimators=50)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00074148 0.00146305 0.00023174 ... 0.00074617 0.00057226 0.00037726]\n"
     ]
    }
   ],
   "source": [
    "test_prediction = model.predict_proba(test_data_processed)\n",
    "\n",
    "test_prediction=test_prediction[:, 1]\n",
    "\n",
    "print(test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write into csv\n",
    "now we write the predictions into the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300001</td>\n",
       "      <td>0.000741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300002</td>\n",
       "      <td>0.001463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300003</td>\n",
       "      <td>0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300004</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300005</td>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105477</th>\n",
       "      <td>405478</td>\n",
       "      <td>0.000243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105478</th>\n",
       "      <td>405479</td>\n",
       "      <td>0.120949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105479</th>\n",
       "      <td>405480</td>\n",
       "      <td>0.000746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105480</th>\n",
       "      <td>405481</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105481</th>\n",
       "      <td>405482</td>\n",
       "      <td>0.000377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105482 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RecordId         Y\n",
       "0         300001  0.000741\n",
       "1         300002  0.001463\n",
       "2         300003  0.000232\n",
       "3         300004  0.000522\n",
       "4         300005  0.000369\n",
       "...          ...       ...\n",
       "105477    405478  0.000243\n",
       "105478    405479  0.120949\n",
       "105479    405480  0.000746\n",
       "105480    405481  0.000572\n",
       "105481    405482  0.000377\n",
       "\n",
       "[105482 rows x 2 columns]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = pd.read_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger1\\iml-fall-2024-challenge-1\\sample_submission.csv\")\n",
    "\n",
    "sample_data['Y'] = test_prediction\n",
    "sample_data\n",
    "\n",
    "sample_data.to_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger1\\iml-fall-2024-challenge-1\\lgbm1.csv\", index=False)\n",
    "sample_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
