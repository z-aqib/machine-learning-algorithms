{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries\n",
    "in this part we will install all the necessary libraries on command prompt and then import the necessary functions from those libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import mean\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# step 1: preprocessing\n",
    "from sklearn.impute import SimpleImputer # import some strategic imputer to fill in any missing values using mean\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler, Normalizer # scale all the values to one range to avoid any biasness (this bias is seen in mostly naive bayes and knn etc)\n",
    "\n",
    "from sklearn.impute import KNNImputer # import some strategic imputer to fill missing values using KNN (finds the nearest neighbour and fills it with that value)\n",
    "\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, SelectKBest, f_classif, VarianceThreshold\n",
    "\n",
    "# step 2: data division\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, cross_val_score # to divide the code into train/test using a specific percentage or with/without replacement\n",
    "\n",
    "# step 3: model\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# step 4: displaying accuracy\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score # to display the accuracy of our tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this block to install any libraries not on the system\n",
    "# !pip install pandas\n",
    "# !pip install sklearn\n",
    "# python -m pip install scikit-learn lightgbm xgboost catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "data shall be loaded into variables as data sets using pandas and csv readers. they will be checked to see if they are loaded properly and will be loaded as 2 sets: train and test as per given in the kaggle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.118411</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>829</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>82.372284</td>\n",
       "      <td>31.573280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162.983897</td>\n",
       "      <td>1</td>\n",
       "      <td>724</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>27.771653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>895</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>66.236109</td>\n",
       "      <td>26.515922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.009549</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>81.303299</td>\n",
       "      <td>20.843691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158.165419</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  ...  \\\n",
       "0         1  87.000000  34.118411   0   2   0  165.100000   1  829    2  ...   \n",
       "1         2  82.372284  31.573280   0   0   1  162.983897   1  724    0  ...   \n",
       "2         3  50.000000  27.771653   0   0   1  165.100000   1  895    2  ...   \n",
       "3         4  66.236109  26.515922   0   0   1  167.009549   1  637    0  ...   \n",
       "4         5  81.303299  20.843691   0   0   1  158.165419   0  564    0  ...   \n",
       "\n",
       "        X70  X71  X72  X73  X74  X75  X76  X77  X78  Y  \n",
       "0  0.040000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "1  0.033431  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "2  0.010000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "3  0.039363  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "4  0.069242  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets load the training data set\n",
    "train_data = pd.read_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger1\\iml-fall-2024-challenge-1\\train_set.csv\")\n",
    "\n",
    "# lets also check it by getting the first few rows of the data, there should be x1 - x78 and one target variable Y\n",
    "train_data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X69</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300001</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>17.122318</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>170.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300002</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>43.693579</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>814</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300003</td>\n",
       "      <td>36.064225</td>\n",
       "      <td>23.998944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.086735</td>\n",
       "      <td>1</td>\n",
       "      <td>662</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300004</td>\n",
       "      <td>61.846764</td>\n",
       "      <td>31.693449</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>182.355708</td>\n",
       "      <td>2</td>\n",
       "      <td>862</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062613</td>\n",
       "      <td>0.033153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300005</td>\n",
       "      <td>71.591991</td>\n",
       "      <td>20.086147</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>166.704917</td>\n",
       "      <td>2</td>\n",
       "      <td>335</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014854</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  ...  \\\n",
       "0    300001  79.000000  17.122318   0   0   1  170.200000   1  700    0  ...   \n",
       "1    300002  38.000000  43.693579   0   0   1  165.100000   1  814    0  ...   \n",
       "2    300003  36.064225  23.998944   0   0   1  167.086735   1  662    0  ...   \n",
       "3    300004  61.846764  31.693449   0   3   1  182.355708   2  862    0  ...   \n",
       "4    300005  71.591991  20.086147   1   0   1  166.704917   2  335    0  ...   \n",
       "\n",
       "        X69       X70  X71  X72  X73  X74  X75  X76  X77  X78  \n",
       "0  0.070000  0.030000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.050000  0.040000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.006948  0.006948  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.062613  0.033153  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.014854  0.004854  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets load the test data\n",
    "test_data = pd.read_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger1\\iml-fall-2024-challenge-1\\test_set.csv\")\n",
    "\n",
    "# check if the data has been loaded by getting the first 5 rows - there should be x1 - x78 and no target variable Y as this is test data\n",
    "test_data.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "before we start processing this data and using algorithms, we will fix this data first, this is called data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion of Categorical to Numerical\n",
    "First we will convert categorical data to numerical data by doing one hot encoding, which turns it into binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.118411</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>829</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>82.372284</td>\n",
       "      <td>31.573280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162.983897</td>\n",
       "      <td>1</td>\n",
       "      <td>724</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>27.771653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>895</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>66.236109</td>\n",
       "      <td>26.515922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.009549</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>81.303299</td>\n",
       "      <td>20.843691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158.165419</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246117</th>\n",
       "      <td>246118</td>\n",
       "      <td>65.149110</td>\n",
       "      <td>33.357948</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156.317941</td>\n",
       "      <td>1</td>\n",
       "      <td>711</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246118</th>\n",
       "      <td>246119</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>46.736176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246119</th>\n",
       "      <td>246120</td>\n",
       "      <td>57.472080</td>\n",
       "      <td>41.854115</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189.868698</td>\n",
       "      <td>2</td>\n",
       "      <td>455</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246120</th>\n",
       "      <td>246121</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>23.738662</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246121</th>\n",
       "      <td>246122</td>\n",
       "      <td>50.257640</td>\n",
       "      <td>32.753911</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>173.665068</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246122 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  \\\n",
       "0              1  87.000000  34.118411   0   2   0  165.100000   1  829    2   \n",
       "1              2  82.372284  31.573280   0   0   1  162.983897   1  724    0   \n",
       "2              3  50.000000  27.771653   0   0   1  165.100000   1  895    2   \n",
       "3              4  66.236109  26.515922   0   0   1  167.009549   1  637    0   \n",
       "4              5  81.303299  20.843691   0   0   1  158.165419   0  564    0   \n",
       "...          ...        ...        ...  ..  ..  ..         ...  ..  ...  ...   \n",
       "246117    246118  65.149110  33.357948   0   0   1  156.317941   1  711    0   \n",
       "246118    246119  48.000000  46.736176   0   0   1  157.000000   1  594    2   \n",
       "246119    246120  57.472080  41.854115   1   0   0  189.868698   2  455    0   \n",
       "246120    246121  66.000000  23.738662   1   0   1  168.000000   2  609    0   \n",
       "246121    246122  50.257640  32.753911   0   2   0  173.665068   1  637    0   \n",
       "\n",
       "        ...       X70  X71  X72       X73  X74       X75  X76  X77       X78  \\\n",
       "0       ...  0.040000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "1       ...  0.033431  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "2       ...  0.010000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "3       ...  0.039363  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "4       ...  0.069242  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "...     ...       ...  ...  ...       ...  ...       ...  ...  ...       ...   \n",
       "246117  ...  0.027152  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "246118  ...  0.560000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "246119  ...  0.020601  0.0  0.0  0.587987  0.0  0.412013  0.0  0.0  0.412013   \n",
       "246120  ... -1.000000  0.0  0.0  1.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "246121  ...  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "\n",
       "        Y  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "...    ..  \n",
       "246117  0  \n",
       "246118  1  \n",
       "246119  0  \n",
       "246120  0  \n",
       "246121  0  \n",
       "\n",
       "[246122 rows x 79 columns]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding - display it\n",
    "pd.get_dummies(train_data) # this line will convert the train_data to one hot encoding but it will only display the result and not save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that there is no change in the number of columns meaning there is no categorical data. but for the sake of running the program. we must perform the preprocessing therefore we shall re-run the one hot encoding and save it somewhere\n",
    "train_data_processed = pd.get_dummies(train_data)\n",
    "\n",
    "# now we shall do the same on the test data so that we maintain the rules over all data\n",
    "test_data_processed = pd.get_dummies(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting - festures and targets\n",
    "the data in train_data set is of x1 - x78 columns (79 variables) and one target variable (Y). we must split that data so that we can perform data preprocessing on the features variables (will be referred to as X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X69</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.118411</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>829</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>82.372284</td>\n",
       "      <td>31.573280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162.983897</td>\n",
       "      <td>1</td>\n",
       "      <td>724</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100292</td>\n",
       "      <td>0.033431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>27.771653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>895</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>66.236109</td>\n",
       "      <td>26.515922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.009549</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108249</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>81.303299</td>\n",
       "      <td>20.843691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158.165419</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164645</td>\n",
       "      <td>0.069242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246117</th>\n",
       "      <td>246118</td>\n",
       "      <td>65.149110</td>\n",
       "      <td>33.357948</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156.317941</td>\n",
       "      <td>1</td>\n",
       "      <td>711</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088610</td>\n",
       "      <td>0.027152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246118</th>\n",
       "      <td>246119</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>46.736176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246119</th>\n",
       "      <td>246120</td>\n",
       "      <td>57.472080</td>\n",
       "      <td>41.854115</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189.868698</td>\n",
       "      <td>2</td>\n",
       "      <td>455</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032961</td>\n",
       "      <td>0.020601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246120</th>\n",
       "      <td>246121</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>23.738662</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246121</th>\n",
       "      <td>246122</td>\n",
       "      <td>50.257640</td>\n",
       "      <td>32.753911</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>173.665068</td>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246122 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RecordId         X2         X3  X4  X5  X6          X7  X8   X9  X10  \\\n",
       "0              1  87.000000  34.118411   0   2   0  165.100000   1  829    2   \n",
       "1              2  82.372284  31.573280   0   0   1  162.983897   1  724    0   \n",
       "2              3  50.000000  27.771653   0   0   1  165.100000   1  895    2   \n",
       "3              4  66.236109  26.515922   0   0   1  167.009549   1  637    0   \n",
       "4              5  81.303299  20.843691   0   0   1  158.165419   0  564    0   \n",
       "...          ...        ...        ...  ..  ..  ..         ...  ..  ...  ...   \n",
       "246117    246118  65.149110  33.357948   0   0   1  156.317941   1  711    0   \n",
       "246118    246119  48.000000  46.736176   0   0   1  157.000000   1  594    2   \n",
       "246119    246120  57.472080  41.854115   1   0   0  189.868698   2  455    0   \n",
       "246120    246121  66.000000  23.738662   1   0   1  168.000000   2  609    0   \n",
       "246121    246122  50.257640  32.753911   0   2   0  173.665068   1  637    0   \n",
       "\n",
       "        ...       X69       X70  X71  X72       X73  X74       X75  X76  X77  \\\n",
       "0       ...  0.110000  0.040000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "1       ...  0.100292  0.033431  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "2       ...  0.020000  0.010000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "3       ...  0.108249  0.039363  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "4       ...  0.164645  0.069242  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "...     ...       ...       ...  ...  ...       ...  ...       ...  ...  ...   \n",
       "246117  ...  0.088610  0.027152  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "246118  ... -1.000000  0.560000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "246119  ...  0.032961  0.020601  0.0  0.0  0.587987  0.0  0.412013  0.0  0.0   \n",
       "246120  ...  0.020000 -1.000000  0.0  0.0  1.000000  0.0  0.000000  0.0  0.0   \n",
       "246121  ...  0.013712  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0   \n",
       "\n",
       "             X78  \n",
       "0       0.000000  \n",
       "1       0.000000  \n",
       "2       0.000000  \n",
       "3       0.000000  \n",
       "4       0.000000  \n",
       "...          ...  \n",
       "246117  0.000000  \n",
       "246118  0.000000  \n",
       "246119  0.412013  \n",
       "246120  0.000000  \n",
       "246121  0.000000  \n",
       "\n",
       "[246122 rows x 78 columns]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so in X, it is ALL the columns EXCEPT the last column known as 'Y' (we can confirm this using the train_data.head() we did earlier) so we must get all columns and DROP only the 'y' column\n",
    "X = train_data_processed.drop(columns=['Y'])\n",
    "X # lets display X and see what it is now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "246117    0\n",
       "246118    1\n",
       "246119    0\n",
       "246120    0\n",
       "246121    0\n",
       "Name: Y, Length: 246122, dtype: int64"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so as per our X output, we can see that number of columns in train_data is 79 and number of columns in X is 78 meaning we have successfully performed our removal of target variable\n",
    "# now to get the target variable alone, we can just get it alone,\n",
    "Y = train_data_processed['Y']\n",
    "Y # lets see what it is\n",
    "# as per our Y output, we can see it is of one column and 246k rows which means we have successfully extracted the target variable column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imputation \n",
    "many cells in our data may be empty - we must fill these cells with data. we have multiple options to deal with them:\n",
    "- we remove the entire rows (Case 1)\n",
    "- we fill the cells with the average of the column (Case 2)\n",
    "- we fill the cells based on KNN imputation (nearest neighbour) (Case 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE ROWS \n",
    "# ----------------------------- case  -----------------------------\n",
    "# in this case, lets remove the entire rows that have NaN values. before saving the removed rows data set, lets first run it and display it to see the outcome, then we shall save in X\n",
    "# X.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE ROWS\n",
    "# # so we originally had 246122 rows and now after removing empty cell rows we have 239650 rows which is a 6472 rows difference. as our first try, lets work with it. lets assign this data set in place of X\n",
    "# X = X.dropna(axis=0)\n",
    "# X\n",
    "# these above 2 lines were commented out as there was an error handling, rows were being removed from X and not from Y so we fixed it by removing from train_data and then splitting into X and Y\n",
    "# train_data_processed = train_data_processed.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Mean Imputation\n",
    "# ----------------------------- case 91 to 96, 98 to 100 -----------------------------\n",
    "# this will fill all the empty spaces using the average of all the spaces\n",
    "imputer = SimpleImputer(strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Imputation\n",
    "# ----------------------------- case 97 -----------------------------\n",
    "# this fills them in using k-nearest neighbours of all the spaces\n",
    "# imputer = KNNImputer(n_neighbors=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputer.fit_transform(X)                                        # fill them in X\n",
    "test_data_processed = imputer.fit_transform(test_data_processed)    # fill them in test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scaling\n",
    "some columns may be very large then other columns when compared. it would not affect at the moment as we are using decision trees, but to maintain a fair enviroment, we shall perform scaling on every run.\n",
    "there are two types of scaling: \n",
    "- min max scaling (also known as normalization)\n",
    "- standardisation (z-score normalization)\n",
    "- max abs scaler\n",
    "- robust scaler\n",
    "- normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- case 91, 92, 93, 94 -----------------------------\n",
    "# in this case we shall perform min max scaling. to do that, we must use our MinMaxScaler that we have imported above\n",
    "# scaler = MinMaxScaler()\n",
    "# # now we must use this scaler to scale X\n",
    "# scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.06302565e-06, 9.77528090e-01, 5.03110176e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [8.12605131e-06, 9.25531276e-01, 4.65579663e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.21890770e-05, 5.61797753e-01, 4.09520864e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [9.99991874e-01, 6.45753712e-01, 6.17180876e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.12013395e-01],\n",
       "       [9.99995937e-01, 7.41573034e-01, 3.50050368e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 5.64692584e-01, 4.82989245e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------- case 95 to 100 -----------------------------\n",
    "scaler = MaxAbsScaler()\n",
    "# now we must use this scaler to scale X\n",
    "scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our output shows us that every value in the array is between 0 and 1. thus lets save this value on X\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# now we must do the same on our test_data set\n",
    "test_data_processed = scaler.fit_transform(test_data_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filters\n",
    "there are two types of filters to filter out columns/features:\n",
    "- variance filter (a column which has same values throughout the column like all are sunny)\n",
    "- correlation filter (two columns which are same like weight in kg and weight in pounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :  (246122, 78)\n",
      "test data :  (105482, 78)\n"
     ]
    }
   ],
   "source": [
    "print(\"X : \", X.shape)\n",
    "print(\"test data : \", test_data_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246122, 78)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variance filter\n",
    "# ----------------------------- case  -----------------------------\n",
    "# variance_filter = VarianceThreshold(threshold=0.001)  # Adjust the threshold if needed\n",
    "# X = variance_filter.fit_transform(X)\n",
    "# test_data_processed = variance_filter.fit_transform(test_data_processed)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105482, 78)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246122, 78)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # correlation filter\n",
    "# # ----------------------------- case  -----------------------------\n",
    "# corr_matrix = pd.DataFrame(X).corr().abs()\n",
    "# upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "# to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "# X = pd.DataFrame(X).drop(columns=to_drop)\n",
    "# test_data_processed = pd.DataFrame(test_data_processed).drop(columns=to_drop)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105482, 78)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_processed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting - train and validate\n",
    "now our test_data set is of rows with NO target variable whereas the train_data set is WITH target variable.\n",
    "our rules in machine learning is that we must train half or 70% of the data and then we must check its accuracy using the remaining half or 30% of the data - we can only check accuracy IF we have the answers i.e. the target variable. \n",
    "So, what we need to do is, is split the train_data set into 2, by a 70% and 30% ratio. we train the model using the 70% and then test the model using the 30% and then use that model to predict the test_data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holdout method\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model intialization\n",
    "here model is intialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(max_depth=7, n_estimators=300, learning_rate=0.01)  # You can adjust parameters as needed\n",
    "# --\n",
    "# model = lgb.LGBMClassifier(max_depth=10, n_estimators=100, learning_rate=0.9)                 # case 91, 95, 96, 97\n",
    "# model = lgb.LGBMClassifier(max_depth=10, n_estimators=400, learning_rate=0.9)                 # Case 92\n",
    "# model = lgb.LGBMClassifier(max_depth=10, n_estimators=400, learning_rate=0.5)                 # Case 93\n",
    "# model = lgb.LGBMClassifier(max_depth=9, n_estimators=100, learning_rate=0.5)                  # case 94\n",
    "# model = lgb.LGBMClassifier(max_depth=10, n_estimators=200, learning_rate=0.1)                 # case 98\n",
    "# model = lgb.LGBMClassifier(max_depth=10, n_estimators=300, learning_rate=0.01)                # case 99\n",
    "# model = lgb.LGBMClassifier(max_depth=8, n_estimators=300, learning_rate=0.01)                 # case 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "in this we select columns and features we want to keep. there are several algos to do so:\n",
    "- forward selection\n",
    "- backward selection\n",
    "- Kbest (best out of all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward selection\n",
    "# ----------------------------- case -----------------------------\n",
    "# selection = SequentialFeatureSelector(model, direction='forward',n_features_to_select=10, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # backward selection\n",
    "# selection = SequentialFeatureSelector(model, direction='backward',n_features_to_select=5, scoring='roc_auc', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k best\n",
    "# ----------------------------- case 97 -----------------------------\n",
    "# selection = SelectKBest(score_func=f_classif, k=5)             # Use f_classif for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection fitting\n",
    "# trainX = selection.fit_transform(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection applying\n",
    "# testX = selection.transform(testX)                                  # Ensure the test set is transformed similarly\n",
    "# test_data_processed = selection.transform(test_data_processed)      # test data is also transformed\n",
    "# X = selection.transform(X)                                          # full data transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172285, 78)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging intialization\n",
    "here we will introduce and intialize bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaggingClassifier(estimator=model, n_estimators=100)\n",
    "# -- \n",
    "# model = BaggingClassifier(estimator=model, n_estimators=50)                   # case 95, 97, 98, 99, 100\n",
    "# model = BaggingClassifier(estimator=model, n_estimators=100)                  # case 96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model running\n",
    "here we run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.132770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002670 -> initscore=-5.923005\n",
      "[LightGBM] [Info] Start training from score -5.923005\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.192309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002711 -> initscore=-5.907862\n",
      "[LightGBM] [Info] Start training from score -5.907862\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.193176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002560 -> initscore=-5.965297\n",
      "[LightGBM] [Info] Start training from score -5.965297\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.182748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002536 -> initscore=-5.974432\n",
      "[LightGBM] [Info] Start training from score -5.974432\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.113390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002595 -> initscore=-5.951749\n",
      "[LightGBM] [Info] Start training from score -5.951749\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.160211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002687 -> initscore=-5.916487\n",
      "[LightGBM] [Info] Start training from score -5.916487\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.155036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002531 -> initscore=-5.976729\n",
      "[LightGBM] [Info] Start training from score -5.976729\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.142173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002693 -> initscore=-5.914324\n",
      "[LightGBM] [Info] Start training from score -5.914324\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002380 -> initscore=-6.038366\n",
      "[LightGBM] [Info] Start training from score -6.038366\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002815 -> initscore=-5.869937\n",
      "[LightGBM] [Info] Start training from score -5.869937\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.265267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002774 -> initscore=-5.884516\n",
      "[LightGBM] [Info] Start training from score -5.884516\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002716 -> initscore=-5.905717\n",
      "[LightGBM] [Info] Start training from score -5.905717\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002635 -> initscore=-5.936170\n",
      "[LightGBM] [Info] Start training from score -5.936170\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002513 -> initscore=-5.983651\n",
      "[LightGBM] [Info] Start training from score -5.983651\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.101327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002415 -> initscore=-6.023803\n",
      "[LightGBM] [Info] Start training from score -6.023803\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.094133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002769 -> initscore=-5.886616\n",
      "[LightGBM] [Info] Start training from score -5.886616\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002728 -> initscore=-5.901441\n",
      "[LightGBM] [Info] Start training from score -5.901441\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002606 -> initscore=-5.947273\n",
      "[LightGBM] [Info] Start training from score -5.947273\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.075345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002507 -> initscore=-5.985969\n",
      "[LightGBM] [Info] Start training from score -5.985969\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.409388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002711 -> initscore=-5.907862\n",
      "[LightGBM] [Info] Start training from score -5.907862\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.155532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002624 -> initscore=-5.940596\n",
      "[LightGBM] [Info] Start training from score -5.940596\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.140988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002711 -> initscore=-5.907862\n",
      "[LightGBM] [Info] Start training from score -5.907862\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002716 -> initscore=-5.905717\n",
      "[LightGBM] [Info] Start training from score -5.905717\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002536 -> initscore=-5.974432\n",
      "[LightGBM] [Info] Start training from score -5.974432\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.165624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002595 -> initscore=-5.951749\n",
      "[LightGBM] [Info] Start training from score -5.951749\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002420 -> initscore=-6.021396\n",
      "[LightGBM] [Info] Start training from score -6.021396\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.139716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002670 -> initscore=-5.923005\n",
      "[LightGBM] [Info] Start training from score -5.923005\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.145222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002641 -> initscore=-5.933963\n",
      "[LightGBM] [Info] Start training from score -5.933963\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.109754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002635 -> initscore=-5.936170\n",
      "[LightGBM] [Info] Start training from score -5.936170\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.198205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002624 -> initscore=-5.940596\n",
      "[LightGBM] [Info] Start training from score -5.940596\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002566 -> initscore=-5.963027\n",
      "[LightGBM] [Info] Start training from score -5.963027\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002774 -> initscore=-5.884516\n",
      "[LightGBM] [Info] Start training from score -5.884516\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.194451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002647 -> initscore=-5.931762\n",
      "[LightGBM] [Info] Start training from score -5.931762\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002478 -> initscore=-5.997640\n",
      "[LightGBM] [Info] Start training from score -5.997640\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002606 -> initscore=-5.947273\n",
      "[LightGBM] [Info] Start training from score -5.947273\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.154003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002571 -> initscore=-5.960761\n",
      "[LightGBM] [Info] Start training from score -5.960761\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.142230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002589 -> initscore=-5.953994\n",
      "[LightGBM] [Info] Start training from score -5.953994\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.109942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002896 -> initscore=-5.841399\n",
      "[LightGBM] [Info] Start training from score -5.841399\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.174155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002658 -> initscore=-5.927374\n",
      "[LightGBM] [Info] Start training from score -5.927374\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.172363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002757 -> initscore=-5.890830\n",
      "[LightGBM] [Info] Start training from score -5.890830\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.119312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002624 -> initscore=-5.940596\n",
      "[LightGBM] [Info] Start training from score -5.940596\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.189530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002780 -> initscore=-5.882421\n",
      "[LightGBM] [Info] Start training from score -5.882421\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.185690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002583 -> initscore=-5.956245\n",
      "[LightGBM] [Info] Start training from score -5.956245\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.128305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002676 -> initscore=-5.920828\n",
      "[LightGBM] [Info] Start training from score -5.920828\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002536 -> initscore=-5.974432\n",
      "[LightGBM] [Info] Start training from score -5.974432\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.107857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002583 -> initscore=-5.956245\n",
      "[LightGBM] [Info] Start training from score -5.956245\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.091163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002513 -> initscore=-5.983651\n",
      "[LightGBM] [Info] Start training from score -5.983651\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002531 -> initscore=-5.976729\n",
      "[LightGBM] [Info] Start training from score -5.976729\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.088939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002519 -> initscore=-5.981339\n",
      "[LightGBM] [Info] Start training from score -5.981339\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002891 -> initscore=-5.843411\n",
      "[LightGBM] [Info] Start training from score -5.843411\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.080684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002496 -> initscore=-5.990621\n",
      "[LightGBM] [Info] Start training from score -5.990621\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002745 -> initscore=-5.895061\n",
      "[LightGBM] [Info] Start training from score -5.895061\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002664 -> initscore=-5.925187\n",
      "[LightGBM] [Info] Start training from score -5.925187\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.090528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002716 -> initscore=-5.905717\n",
      "[LightGBM] [Info] Start training from score -5.905717\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002478 -> initscore=-5.997640\n",
      "[LightGBM] [Info] Start training from score -5.997640\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002798 -> initscore=-5.876160\n",
      "[LightGBM] [Info] Start training from score -5.876160\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002519 -> initscore=-5.981339\n",
      "[LightGBM] [Info] Start training from score -5.981339\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002502 -> initscore=-5.988292\n",
      "[LightGBM] [Info] Start training from score -5.988292\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002461 -> initscore=-6.004708\n",
      "[LightGBM] [Info] Start training from score -6.004708\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002577 -> initscore=-5.958500\n",
      "[LightGBM] [Info] Start training from score -5.958500\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002432 -> initscore=-6.016599\n",
      "[LightGBM] [Info] Start training from score -6.016599\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002444 -> initscore=-6.011826\n",
      "[LightGBM] [Info] Start training from score -6.011826\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002653 -> initscore=-5.929566\n",
      "[LightGBM] [Info] Start training from score -5.929566\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002566 -> initscore=-5.963027\n",
      "[LightGBM] [Info] Start training from score -5.963027\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002403 -> initscore=-6.028634\n",
      "[LightGBM] [Info] Start training from score -6.028634\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002624 -> initscore=-5.940596\n",
      "[LightGBM] [Info] Start training from score -5.940596\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.100828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002699 -> initscore=-5.912165\n",
      "[LightGBM] [Info] Start training from score -5.912165\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002670 -> initscore=-5.923005\n",
      "[LightGBM] [Info] Start training from score -5.923005\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002507 -> initscore=-5.985969\n",
      "[LightGBM] [Info] Start training from score -5.985969\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002664 -> initscore=-5.925187\n",
      "[LightGBM] [Info] Start training from score -5.925187\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079088 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002490 -> initscore=-5.992955\n",
      "[LightGBM] [Info] Start training from score -5.992955\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002513 -> initscore=-5.983651\n",
      "[LightGBM] [Info] Start training from score -5.983651\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002792 -> initscore=-5.878242\n",
      "[LightGBM] [Info] Start training from score -5.878242\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002629 -> initscore=-5.938380\n",
      "[LightGBM] [Info] Start training from score -5.938380\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002548 -> initscore=-5.969855\n",
      "[LightGBM] [Info] Start training from score -5.969855\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002798 -> initscore=-5.876160\n",
      "[LightGBM] [Info] Start training from score -5.876160\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.075172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002687 -> initscore=-5.916487\n",
      "[LightGBM] [Info] Start training from score -5.916487\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002589 -> initscore=-5.953994\n",
      "[LightGBM] [Info] Start training from score -5.953994\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002455 -> initscore=-6.007075\n",
      "[LightGBM] [Info] Start training from score -6.007075\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.080012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002600 -> initscore=-5.949508\n",
      "[LightGBM] [Info] Start training from score -5.949508\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002490 -> initscore=-5.992955\n",
      "[LightGBM] [Info] Start training from score -5.992955\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002403 -> initscore=-6.028634\n",
      "[LightGBM] [Info] Start training from score -6.028634\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002600 -> initscore=-5.949508\n",
      "[LightGBM] [Info] Start training from score -5.949508\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002687 -> initscore=-5.916487\n",
      "[LightGBM] [Info] Start training from score -5.916487\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002478 -> initscore=-5.997640\n",
      "[LightGBM] [Info] Start training from score -5.997640\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078108 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002653 -> initscore=-5.929566\n",
      "[LightGBM] [Info] Start training from score -5.929566\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002873 -> initscore=-5.849470\n",
      "[LightGBM] [Info] Start training from score -5.849470\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002682 -> initscore=-5.918655\n",
      "[LightGBM] [Info] Start training from score -5.918655\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002484 -> initscore=-5.995295\n",
      "[LightGBM] [Info] Start training from score -5.995295\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002664 -> initscore=-5.925187\n",
      "[LightGBM] [Info] Start training from score -5.925187\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066884 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002635 -> initscore=-5.936170\n",
      "[LightGBM] [Info] Start training from score -5.936170\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002577 -> initscore=-5.958500\n",
      "[LightGBM] [Info] Start training from score -5.958500\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002751 -> initscore=-5.892943\n",
      "[LightGBM] [Info] Start training from score -5.892943\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002566 -> initscore=-5.963027\n",
      "[LightGBM] [Info] Start training from score -5.963027\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.075681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002560 -> initscore=-5.965297\n",
      "[LightGBM] [Info] Start training from score -5.965297\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.075076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002531 -> initscore=-5.976729\n",
      "[LightGBM] [Info] Start training from score -5.976729\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002618 -> initscore=-5.942817\n",
      "[LightGBM] [Info] Start training from score -5.942817\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002745 -> initscore=-5.895061\n",
      "[LightGBM] [Info] Start training from score -5.895061\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002687 -> initscore=-5.916487\n",
      "[LightGBM] [Info] Start training from score -5.916487\n",
      "[LightGBM] [Info] Number of positive: 451, number of negative: 171834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.075102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17953\n",
      "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002484 -> initscore=-5.995295\n",
      "[LightGBM] [Info] Start training from score -5.995295\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-19 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-19 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-19 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-19 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-19 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-19 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-19 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-19 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-19 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-19 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingClassifier(estimator=LGBMClassifier(learning_rate=0.01, max_depth=7,\n",
       "                                           n_estimators=300),\n",
       "                  n_estimators=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;BaggingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.BaggingClassifier.html\">?<span>Documentation for BaggingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>BaggingClassifier(estimator=LGBMClassifier(learning_rate=0.01, max_depth=7,\n",
       "                                           n_estimators=300),\n",
       "                  n_estimators=100)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(learning_rate=0.01, max_depth=7, n_estimators=300)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(learning_rate=0.01, max_depth=7, n_estimators=300)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BaggingClassifier(estimator=LGBMClassifier(learning_rate=0.01, max_depth=7,\n",
       "                                           n_estimators=300),\n",
       "                  n_estimators=100)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using this model\n",
    "y_pred = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy =  0.997359047631946    \n",
      "roc score =  0.512612682865538    \n"
     ]
    }
   ],
   "source": [
    "# display the accuracy of this prediction\n",
    "accuracy = accuracy_score(testY, y_pred)\n",
    "print(\"model accuracy = \", accuracy, \"   \")\n",
    "\n",
    "# now lets calculate the ROC AUC score according to this prediction\n",
    "roc_score = roc_auc_score(testY, y_pred)\n",
    "print(\"roc score = \", roc_score, \"   \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict for test dataset\n",
    "fit the model and predict for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.101959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17978\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002678 -> initscore=-5.920178\n",
      "[LightGBM] [Info] Start training from score -5.920178\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17977\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002511 -> initscore=-5.984580\n",
      "[LightGBM] [Info] Start training from score -5.984580\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.098443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17983\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002657 -> initscore=-5.927815\n",
      "[LightGBM] [Info] Start training from score -5.927815\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.092298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17975\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002629 -> initscore=-5.938604\n",
      "[LightGBM] [Info] Start training from score -5.938604\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17978\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002661 -> initscore=-5.926283\n",
      "[LightGBM] [Info] Start training from score -5.926283\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17980\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002824 -> initscore=-5.866843\n",
      "[LightGBM] [Info] Start training from score -5.866843\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.098329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17981\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002678 -> initscore=-5.920178\n",
      "[LightGBM] [Info] Start training from score -5.920178\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17976\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002491 -> initscore=-5.992724\n",
      "[LightGBM] [Info] Start training from score -5.992724\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17979\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002734 -> initscore=-5.899099\n",
      "[LightGBM] [Info] Start training from score -5.899099\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17975\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002812 -> initscore=-5.871181\n",
      "[LightGBM] [Info] Start training from score -5.871181\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17972\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002446 -> initscore=-6.010876\n",
      "[LightGBM] [Info] Start training from score -6.010876\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17980\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002580 -> initscore=-5.957374\n",
      "[LightGBM] [Info] Start training from score -5.957374\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.137899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17979\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002714 -> initscore=-5.906577\n",
      "[LightGBM] [Info] Start training from score -5.906577\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17961\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002483 -> initscore=-5.996000\n",
      "[LightGBM] [Info] Start training from score -5.996000\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.104196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17975\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002576 -> initscore=-5.958954\n",
      "[LightGBM] [Info] Start training from score -5.958954\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.113327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17977\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002747 -> initscore=-5.894639\n",
      "[LightGBM] [Info] Start training from score -5.894639\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.133628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17975\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002657 -> initscore=-5.927815\n",
      "[LightGBM] [Info] Start training from score -5.927815\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17973\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002543 -> initscore=-5.971686\n",
      "[LightGBM] [Info] Start training from score -5.971686\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17978\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002657 -> initscore=-5.927815\n",
      "[LightGBM] [Info] Start training from score -5.927815\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.104143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17961\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002556 -> initscore=-5.966892\n",
      "[LightGBM] [Info] Start training from score -5.966892\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.119610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17977\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002543 -> initscore=-5.971686\n",
      "[LightGBM] [Info] Start training from score -5.971686\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.098347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17981\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002548 -> initscore=-5.970085\n",
      "[LightGBM] [Info] Start training from score -5.970085\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.121778 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17973\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002604 -> initscore=-5.947945\n",
      "[LightGBM] [Info] Start training from score -5.947945\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.108950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17975\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002669 -> initscore=-5.923226\n",
      "[LightGBM] [Info] Start training from score -5.923226\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17976\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002665 -> initscore=-5.924753\n",
      "[LightGBM] [Info] Start training from score -5.924753\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.091952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17978\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002507 -> initscore=-5.986204\n",
      "[LightGBM] [Info] Start training from score -5.986204\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.092333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17961\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002511 -> initscore=-5.984580\n",
      "[LightGBM] [Info] Start training from score -5.984580\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.092273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17974\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002625 -> initscore=-5.940155\n",
      "[LightGBM] [Info] Start training from score -5.940155\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17976\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002556 -> initscore=-5.966892\n",
      "[LightGBM] [Info] Start training from score -5.966892\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.110412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17975\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002682 -> initscore=-5.918658\n",
      "[LightGBM] [Info] Start training from score -5.918658\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17982\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002690 -> initscore=-5.915624\n",
      "[LightGBM] [Info] Start training from score -5.915624\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.097243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17977\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002491 -> initscore=-5.992724\n",
      "[LightGBM] [Info] Start training from score -5.992724\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.094286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17977\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002572 -> initscore=-5.960537\n",
      "[LightGBM] [Info] Start training from score -5.960537\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106077 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17981\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002495 -> initscore=-5.991090\n",
      "[LightGBM] [Info] Start training from score -5.991090\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.100292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17976\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002763 -> initscore=-5.888723\n",
      "[LightGBM] [Info] Start training from score -5.888723\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093963 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17972\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002450 -> initscore=-6.009212\n",
      "[LightGBM] [Info] Start training from score -6.009212\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17976\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002738 -> initscore=-5.897610\n",
      "[LightGBM] [Info] Start training from score -5.897610\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17975\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002763 -> initscore=-5.888723\n",
      "[LightGBM] [Info] Start training from score -5.888723\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17977\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002645 -> initscore=-5.932424\n",
      "[LightGBM] [Info] Start training from score -5.932424\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.095518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17978\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002649 -> initscore=-5.930885\n",
      "[LightGBM] [Info] Start training from score -5.930885\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17978\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002389 -> initscore=-6.034464\n",
      "[LightGBM] [Info] Start training from score -6.034464\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.097488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17961\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002653 -> initscore=-5.929349\n",
      "[LightGBM] [Info] Start training from score -5.929349\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17976\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002543 -> initscore=-5.971686\n",
      "[LightGBM] [Info] Start training from score -5.971686\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.098879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17976\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002633 -> initscore=-5.937056\n",
      "[LightGBM] [Info] Start training from score -5.937056\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17974\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002682 -> initscore=-5.918658\n",
      "[LightGBM] [Info] Start training from score -5.918658\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.095877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17976\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002718 -> initscore=-5.905077\n",
      "[LightGBM] [Info] Start training from score -5.905077\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.097549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17974\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002539 -> initscore=-5.973288\n",
      "[LightGBM] [Info] Start training from score -5.973288\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17961\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002840 -> initscore=-5.861088\n",
      "[LightGBM] [Info] Start training from score -5.861088\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.098706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17975\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002576 -> initscore=-5.958954\n",
      "[LightGBM] [Info] Start training from score -5.958954\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.108803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17978\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002653 -> initscore=-5.929349\n",
      "[LightGBM] [Info] Start training from score -5.929349\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17981\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002673 -> initscore=-5.921701\n",
      "[LightGBM] [Info] Start training from score -5.921701\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.098464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17973\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002564 -> initscore=-5.963710\n",
      "[LightGBM] [Info] Start training from score -5.963710\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17977\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002568 -> initscore=-5.962122\n",
      "[LightGBM] [Info] Start training from score -5.962122\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17974\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002580 -> initscore=-5.957374\n",
      "[LightGBM] [Info] Start training from score -5.957374\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.100452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17978\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002511 -> initscore=-5.984580\n",
      "[LightGBM] [Info] Start training from score -5.984580\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.095455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17977\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002787 -> initscore=-5.879914\n",
      "[LightGBM] [Info] Start training from score -5.879914\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.092407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17975\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002698 -> initscore=-5.912599\n",
      "[LightGBM] [Info] Start training from score -5.912599\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17961\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002523 -> initscore=-5.979725\n",
      "[LightGBM] [Info] Start training from score -5.979725\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17979\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002673 -> initscore=-5.921701\n",
      "[LightGBM] [Info] Start training from score -5.921701\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.100553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17980\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002649 -> initscore=-5.930885\n",
      "[LightGBM] [Info] Start training from score -5.930885\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.101616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17959\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002621 -> initscore=-5.941708\n",
      "[LightGBM] [Info] Start training from score -5.941708\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.104410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17976\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002645 -> initscore=-5.932424\n",
      "[LightGBM] [Info] Start training from score -5.932424\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.098312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17977\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002657 -> initscore=-5.927815\n",
      "[LightGBM] [Info] Start training from score -5.927815\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.088095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17975\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002641 -> initscore=-5.933966\n",
      "[LightGBM] [Info] Start training from score -5.933966\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17980\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002669 -> initscore=-5.923226\n",
      "[LightGBM] [Info] Start training from score -5.923226\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17976\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002755 -> initscore=-5.891677\n",
      "[LightGBM] [Info] Start training from score -5.891677\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.100149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17976\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002608 -> initscore=-5.946382\n",
      "[LightGBM] [Info] Start training from score -5.946382\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17975\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002515 -> initscore=-5.982959\n",
      "[LightGBM] [Info] Start training from score -5.982959\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.126188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17977\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002625 -> initscore=-5.940155\n",
      "[LightGBM] [Info] Start training from score -5.940155\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.098422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17973\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002694 -> initscore=-5.914110\n",
      "[LightGBM] [Info] Start training from score -5.914110\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.090932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17975\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002621 -> initscore=-5.941708\n",
      "[LightGBM] [Info] Start training from score -5.941708\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17977\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002649 -> initscore=-5.930885\n",
      "[LightGBM] [Info] Start training from score -5.930885\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.100528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17974\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002572 -> initscore=-5.960537\n",
      "[LightGBM] [Info] Start training from score -5.960537\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17974\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002466 -> initscore=-6.002585\n",
      "[LightGBM] [Info] Start training from score -6.002585\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.098085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17974\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002580 -> initscore=-5.957374\n",
      "[LightGBM] [Info] Start training from score -5.957374\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17979\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002499 -> initscore=-5.989458\n",
      "[LightGBM] [Info] Start training from score -5.989458\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.094053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17977\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002633 -> initscore=-5.937056\n",
      "[LightGBM] [Info] Start training from score -5.937056\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085916 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17974\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002706 -> initscore=-5.909583\n",
      "[LightGBM] [Info] Start training from score -5.909583\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.107143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17976\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002787 -> initscore=-5.879914\n",
      "[LightGBM] [Info] Start training from score -5.879914\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.100821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17973\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002653 -> initscore=-5.929349\n",
      "[LightGBM] [Info] Start training from score -5.929349\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17974\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002629 -> initscore=-5.938604\n",
      "[LightGBM] [Info] Start training from score -5.938604\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.110371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17976\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002653 -> initscore=-5.929349\n",
      "[LightGBM] [Info] Start training from score -5.929349\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.112627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17977\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002564 -> initscore=-5.963710\n",
      "[LightGBM] [Info] Start training from score -5.963710\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.109352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17981\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002596 -> initscore=-5.951079\n",
      "[LightGBM] [Info] Start training from score -5.951079\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.107547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17979\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002625 -> initscore=-5.940155\n",
      "[LightGBM] [Info] Start training from score -5.940155\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17975\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002600 -> initscore=-5.949511\n",
      "[LightGBM] [Info] Start training from score -5.949511\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.095570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17981\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002734 -> initscore=-5.899099\n",
      "[LightGBM] [Info] Start training from score -5.899099\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17978\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002633 -> initscore=-5.937056\n",
      "[LightGBM] [Info] Start training from score -5.937056\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17980\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002657 -> initscore=-5.927815\n",
      "[LightGBM] [Info] Start training from score -5.927815\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17981\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002592 -> initscore=-5.952649\n",
      "[LightGBM] [Info] Start training from score -5.952649\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.092033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17974\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002649 -> initscore=-5.930885\n",
      "[LightGBM] [Info] Start training from score -5.930885\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.097187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17975\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002669 -> initscore=-5.923226\n",
      "[LightGBM] [Info] Start training from score -5.923226\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17975\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002629 -> initscore=-5.938604\n",
      "[LightGBM] [Info] Start training from score -5.938604\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.101820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17977\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002665 -> initscore=-5.924753\n",
      "[LightGBM] [Info] Start training from score -5.924753\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17979\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002787 -> initscore=-5.879914\n",
      "[LightGBM] [Info] Start training from score -5.879914\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17972\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002722 -> initscore=-5.903579\n",
      "[LightGBM] [Info] Start training from score -5.903579\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17979\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002706 -> initscore=-5.909583\n",
      "[LightGBM] [Info] Start training from score -5.909583\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.092181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17974\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002690 -> initscore=-5.915624\n",
      "[LightGBM] [Info] Start training from score -5.915624\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.108082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17972\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002499 -> initscore=-5.989458\n",
      "[LightGBM] [Info] Start training from score -5.989458\n",
      "[LightGBM] [Info] Number of positive: 649, number of negative: 245473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.154704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17981\n",
      "[LightGBM] [Info] Number of data points in the train set: 246122, number of used features: 78\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002669 -> initscore=-5.923226\n",
      "[LightGBM] [Info] Start training from score -5.923226\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-20 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-20 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-20 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-20 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-20 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-20 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-20 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-20 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-20 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-20 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-20 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-20 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-20 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-20 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-20 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-20 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-20 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-20 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-20 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-20 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-20 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-20 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-20 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-20 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-20 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-20 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-20 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-20 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-20 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-20 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-20 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-20 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-20 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-20 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-20 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-20 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingClassifier(estimator=LGBMClassifier(learning_rate=0.01, max_depth=7,\n",
       "                                           n_estimators=300),\n",
       "                  n_estimators=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;BaggingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.BaggingClassifier.html\">?<span>Documentation for BaggingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>BaggingClassifier(estimator=LGBMClassifier(learning_rate=0.01, max_depth=7,\n",
       "                                           n_estimators=300),\n",
       "                  n_estimators=100)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(learning_rate=0.01, max_depth=7, n_estimators=300)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(learning_rate=0.01, max_depth=7, n_estimators=300)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BaggingClassifier(estimator=LGBMClassifier(learning_rate=0.01, max_depth=7,\n",
       "                                           n_estimators=300),\n",
       "                  n_estimators=100)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00072783 0.00142945 0.00022763 ... 0.00085201 0.00056178 0.00037204]\n"
     ]
    }
   ],
   "source": [
    "test_prediction = model.predict_proba(test_data_processed)\n",
    "\n",
    "test_prediction=test_prediction[:, 1]\n",
    "\n",
    "print(test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write into csv\n",
    "now we write the predictions into the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordId</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300001</td>\n",
       "      <td>0.000728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300002</td>\n",
       "      <td>0.001429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300003</td>\n",
       "      <td>0.000228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300004</td>\n",
       "      <td>0.000492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300005</td>\n",
       "      <td>0.000419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105477</th>\n",
       "      <td>405478</td>\n",
       "      <td>0.000248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105478</th>\n",
       "      <td>405479</td>\n",
       "      <td>0.124913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105479</th>\n",
       "      <td>405480</td>\n",
       "      <td>0.000852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105480</th>\n",
       "      <td>405481</td>\n",
       "      <td>0.000562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105481</th>\n",
       "      <td>405482</td>\n",
       "      <td>0.000372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105482 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RecordId         Y\n",
       "0         300001  0.000728\n",
       "1         300002  0.001429\n",
       "2         300003  0.000228\n",
       "3         300004  0.000492\n",
       "4         300005  0.000419\n",
       "...          ...       ...\n",
       "105477    405478  0.000248\n",
       "105478    405479  0.124913\n",
       "105479    405480  0.000852\n",
       "105480    405481  0.000562\n",
       "105481    405482  0.000372\n",
       "\n",
       "[105482 rows x 2 columns]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = pd.read_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger1\\iml-fall-2024-challenge-1\\sample_submission.csv\")\n",
    "\n",
    "sample_data['Y'] = test_prediction\n",
    "sample_data\n",
    "\n",
    "sample_data.to_csv(r\"D:\\Users\\DELL\\OneDrive - Institute of Business Administration\\IBA\\sem5\\machine learning\\ipynb notebooks\\challenger1\\iml-fall-2024-challenge-1\\lgbm1.csv\", index=False)\n",
    "sample_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
